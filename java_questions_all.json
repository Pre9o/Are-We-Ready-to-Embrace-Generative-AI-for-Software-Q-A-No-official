{
    "Id": 70552008,
    "PostTypeId": 1,
    "Title": "Java hidden properties without Spring",
    "Body": "I am currently creating a Java program that uses a MongoDB database and I am storing the connection information in a properties file.\nBut my project is opensource on GitHub and I cannot store the connection information in the properties file.\nAnd so I wanted to ask you if it is possible to give the login information from docker run.\nexample : docker run registry/image -args db.password=psw db.username=user\nI have seen solutions in stackoverflow but all solutions use Spring features, but my project does not use Spring framework.\n",
    "AcceptedAnswerId": 70556743,
    "AcceptedAnswer": "We have multiple solutions for this:\nSecret Docker\nCreate a file with the properties syntax:\n//secret-file.txt\ndb.password=psw\ndb.username=user\n\nWith this file create a docker secret in your docker :\n$ docker secret create test-secret secret-file.txt\n\nAnd use this with the java library docker-secrets in your java program :\nMap secrets = DockerSecrets.loadFromFile(\"test-secret\");\nSystem.out.println(secrets.get(\"db.password\")) // readonly\n\nFor more example, look here.\n\nEnvironment variables\nSet the environment variables in the docker with -e argument :\n$ docker run -e DB_PASSWORD=pwd -e DB_USERNAME=user registry/image:tag\n\nAnd use these variables with System::getenv in your java program :\nSystem.out.println(System.getenv(\"DB_PASSWORD\"))\n\n\nVM Arguments\nThis solution depends on your base image that was used to create your Docker container.\nGive VM Arguments to the docker run command :\n$ docker run -e JAVA_OPTS=\"-Ddb.password=pwd -Ddb.username=user\" registry/image:tag\n\nAnd use these variables with System::getProperty in your java program :\nSystem.out.println(System.getProperty(\"db.password\"))\n\n\nProgram arguments\nGive arguments to docker run command :\nIt is important to give the arguments after declaring the image.\n$ docker run registry/image:tag pwd user\n\nAnd use these arguments with main method in your java program :\npublic static void main(String[] args) {\n    System.out.println(\"The password: \" + args[0]);\n    System.out.println(\"The username: \" + args[1]);\n}\n\nFor better handling of arguments, you can use the Apache's commons-cli java library or use a another library.\n"
}
{
    "Id": 70601508,
    "PostTypeId": 1,
    "Title": "Can I use Java 16 record with JPA entity?",
    "Body": "I am trying to do something similar like below.\n@Entity\n@Table(name=\"Sample\")\npublic record Sample(Integer id, String name) {\n\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    @Column(name=\"user_id\")\n    private Integer id;\n\n    @Column(name=\"username\")\n    private String name;\n\n}\n\nHowever, it gives me error \"User declared non-static fields id are not permitted in a record\"\nand same for name field as well.\nIs there a way to use new java feature \"record\" with JPA annotation?\n",
    "AcceptedAnswerId": 70601646,
    "AcceptedAnswer": "See the article, Using Records as Projections in JPA by Billy Korando. The following is a brief summary.\nRecords cannot be Entities\nJakarta Persistence  (JPA; formerly Java Persistence API) implementations such as Hibernate depend on features either forbidden or not recommended by the JEP 395: Records spec: no-arg constructors, non-final fields, setters, etc.\n\u27a5 So, no, records cannot be used as JPA Entity.\nOther uses of records\nYou can use records with:\n\nCriteriaBuilder\nTypedQuery\nNativeQuery\nMapping definition\n\nSpring data has some support as well.\nSee that article linked above for details, and for links to two other articles.\n"
}
{
    "Id": 70575180,
    "PostTypeId": 1,
    "Title": "Log4j2 vulnerability and Lombok annotation @log4j2",
    "Body": "We are using spring boot 2.1.5 and starter parent as pom dependency.\nSpring boot is using default logback for logging and we haven't explicitly switched to Log4j2 or changes any configurations. Below is our project dependency tree.\n\nWe have lot of lombok @log4j2 annotations in our project. But, we find in dependency tree we do not have any log4j2-core jar dependency (that has been found vulnerable to recent issues with log4j).\n@Log4j2\n@Service\n@DependsOn(\"applicationDependencyCheck\")\n\nIs lombok @log4j2 not dependent on log4j2-core.jar. Is it correct to assume this would show up in maven dependency tree or are we missing something.\nThis is our lombok entry -\n\n    org.projectlombok\n    lombok\n    true\n\n\nPlease share some insights.\nthanks\n",
    "AcceptedAnswerId": 70576095,
    "AcceptedAnswer": "In lombok documentation you can find it here https://projectlombok.org/api/lombok/extern/log4j/Log4j2.html\n\n@Log4j2  public class LogExample {  }\nwill generate:\npublic class LogExample {\nprivate static final org.apache.logging.log4j.Logger log = org.apache.logging.log4j.LogManager.getLogger(LogExample.class);  }\n\nBoth classes are present in log4j API jar\n\nhttps://logging.apache.org/log4j/2.x/log4j-api/apidocs/org/apache/logging/log4j/LogManager.html\nhttps://logging.apache.org/log4j/2.x/log4j-api/apidocs/org/apache/logging/log4j/Logger.html\n\nThere are no known vulnerabilities listed here https://mvnrepository.com/artifact/org.apache.logging.log4j/log4j-api\nAs described here https://logging.apache.org/log4j/2.x/log4j-api/index.html log4j api is just an interface.\nI think in such case your code does not depend on log4j core. You can double check the output of build (e.g. maven /target folder, war file etc)\n"
}
{
    "Id": 70593561,
    "PostTypeId": 1,
    "Title": "Cannot be resolved to absolute file path because it does not reside in the file system",
    "Body": "My Code:\nXWPFDocument doc = new XWPFDocument(OPCPackage.open(ResourceUtils.getFile(\"classpath:assets/OPTIONS_\" + jubilar1.getJubiLanguage().toUpperCase() + \".docx\")));\n\nI have already tried instead of .getFile(), extractJarFileFromURL or resource.getInputStream() but all this does not work. When I package my project and run it as a jar file and it tries to open the following file it always returns the following message.\nError:\n\njava.io.FileNotFoundException: class path resource [assets/OPTIONS_DE.\ndocx] cannot be resolved to absolute file path because it does not\nreside in the file system:\njar:file:/home/tkf6y/IdeaProjects/hrapps/backend/target/backend-3.0.0.jar!/BOOT-INF/classes!/assets/OPTIONS_EN.docx\n\n",
    "AcceptedAnswerId": 70604475,
    "AcceptedAnswer": "So yes it was the problem, as you are now using an InputStream as I suggested. The problem was (and always has been) the getFile stuff. What I suggest to do is don't use what you have now but rather do a new ClassPathResource(your location).getInputStream()) instead, it is easier, or even use a ResourceLoader (a Spring interface you can inject) and then use the path you had an again use getInputStream(). \u2013\n"
}
{
    "Id": 70576798,
    "PostTypeId": 1,
    "Title": "Boolean recursive static method that gets an array of integers",
    "Body": "I'm trying to write a method that would Return true if it is possible to divide all the members of an array into two different groups of equal size so that the sum of the members of the two groups is equal. If this is not possible, the method Return false.\nThe conditions are:\n\nThe method should be recursive with no use of loops at all, So are all the auxiliary methods\nCan not contain loops.\nThe array is neither null nor empty.\nDo not modify the contents of the array (not even temporarily), and do not use an auxiliary array.\n\npublic static boolean equalSplit (int[] arr){\n    if(arr.length % 2 != 0) // if array length is not equal both sides\n        return false;\n    return equalSplit (arr, arr[0],(0 + arr.length-1) / 2 , arr.length-1);\n} \n\npublic static boolean equalSplit (int[] arr, int start, int mid, int end){\n       \n}\n\nI got stuck here and i have no clue what to do next.\n",
    "AcceptedAnswerId": 70583488,
    "AcceptedAnswer": "something like this should solve your problem and handle all cases.\n    public static boolean canBeDividedEqually(int[] arr) {\n        if (arr.length % 2 != 0) {\n            return false;\n        }\n        int sum = getSum(arr);\n        if (sum % 2 != 0) {\n            return false;\n        }\n        return canBeDividedEqually(arr, sum);\n\n    }\n\n    public static int getSum(int[] arr) {\n        return getSum(arr, 0, 0);\n    }\n\n    private static int getSum(int[] arr, int sum, int index) {\n        if (index >= arr.length) {\n            return sum;\n        }\n        return getSum(arr, sum + arr[index], index + 1);\n    }\n\n    private static boolean canBeDividedEqually(int[] arr, int sum) {\n        // this can be optimized by canBeDividedEqually(arr, sum/2, arr[0], arr.length/2, 1, 1) because first element should always belong to first group, so we can start search from second element\n        return canBeDividedEqually(arr, sum/2, 0, arr.length/2, 0, 0);\n//        return canBeDividedEqually(arr, sum/2, arr[0], arr.length/2, 1, 1);\n    }\n\n    private static boolean canBeDividedEqually (int[] arr, int searchSum, int currentSum, int searchQuantity, int currentQuantity, int nextIndex) {\n        if(searchSum == currentSum && searchQuantity == currentQuantity) {\n            return true;\n        }\n        if(searchSum <= currentSum || searchQuantity <= currentQuantity) {\n            // we have too big sum or we take to much elements\n            return false;\n        }\n        if(nextIndex + (searchQuantity - currentQuantity) > arr.length) {\n            // we need to take more elements than we have still available\n            return false;\n        }\n        // add current element into account and search further\n        if(canBeDividedEqually(arr, searchSum, currentSum + arr[nextIndex], searchQuantity, currentQuantity + 1, nextIndex + 1)) {\n            System.out.println(\"true\");\n            return true;\n        }\n        // if above \"if\" statement is not true, then skip current element and try to search further\n        return canBeDividedEqually(arr, searchSum, currentSum, searchQuantity, currentQuantity, nextIndex + 1);\n    }\n\n"
}
{
    "Id": 70595267,
    "PostTypeId": 1,
    "Title": "Why does this code use an oversized array instead of a Map?",
    "Body": "Here's JBoss JSTL implementation for the EscapeXML tag\npublic class EscapeXML {\n\n    private static final String[] ESCAPES;\n\n    static {\n        int size = '>' + 1; // '>' is the largest escaped value\n        ESCAPES = new String[size];\n        ESCAPES['<'] = \"&lt;\";\n        ESCAPES['>'] = \"&gt;\";\n        ESCAPES['&'] = \"&amp;\";\n        ESCAPES['\\''] = \"&#039;\";\n        ESCAPES['\"'] = \"&#034;\";\n    }\n  //omitted\n}\n\nWhy is ESCAPES a 61 elements array? What are the implication of using a Map instead?\n",
    "AcceptedAnswerId": 70638166,
    "AcceptedAnswer": "I think the main reason is performance. Each map query needs to get the hashcode, and then calculate the position of the array in the map, and the array can be obtained directly. The following is a simple test, querying 10,000 times separately, the array is about 10 times faster than the map.\narray query result: cost time= 184041\nmap query result: cost time= 1677042\n\nimport org.junit.Before;\nimport org.junit.Test;\n\nimport java.util.Arrays;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.Random;\n\n/**\n * @author jahe\n * @date 2022/1/9\n * @note\n */\npublic class ArrayMapTest {\n    private char[] chars = {'', '&', '\\'', '\"'};\n    private char[] charsForQuery = new char[10000];\n    @Before\n    public void init(){\n        Random random = new Random(5);\n        random.nextInt(5);\n        for (int i = 0; i < charsForQuery.length; i++) {\n            charsForQuery[i] = chars[random.nextInt(5)];\n        }\n        System.out.println(Arrays.toString(charsForQuery));\n    }\n    @Test\n    public void test() {\n        int size = '>' + 1;\n        String[] ESCAPES = new String[size];\n        ESCAPES['<'] = \"&lt;\";\n        ESCAPES['>'] = \"&gt;\";\n        ESCAPES['&'] = \"&amp;\";\n        ESCAPES['\\''] = \"&#039;\";\n        ESCAPES['\"'] = \"&#034;\";\n        long start = System.nanoTime();\n        doTestForArray(ESCAPES);\n        long end = System.nanoTime();\n        System.out.println(\"array query result: cost time= \" + (end - start));\n\n        Map map = new HashMap();\n        map.put('<', \"&lt;\");\n        map.put('>', \"&gt;\");\n        map.put('&', \"&amp;\");\n        map.put('\\'', \"&#039;\");\n        map.put('\"', \"&#034;\");\n        start = System.nanoTime();\n        doTestForMap(map);\n        end = System.nanoTime();\n        System.out.println(\"map query result: cost time= \" + (end - start));\n\n    }\n    private void doTestForArray(String[] ESCAPES){\n        for (char c : charsForQuery) {\n            String str = ESCAPES[c];\n        }\n    }\n    private void doTestForMap(Map map){\n        for (char c : charsForQuery) {\n            String s = map.get(c);\n        }\n    }\n}\n\n"
}
{
    "Id": 70601178,
    "PostTypeId": 1,
    "Title": "Java Generics: What is the benefit of using wildcards here?",
    "Body": "The Collections.fill method has the following header:\npublic static  void fill(List list, T obj)\n\nWhy is the wildcard necessary? The following header seems to work just as well:\npublic static  void fill(List list, T obj)\n\nI cannot see a reason why the wildcard is needed; code such as the following works with the second header as well as the first:\nList nums = new ArrayList();\nInteger i = 43;\nfill(nums, i); //fill method written using second header\n\nMy question is: For what specific call of fill would the first header work but not the second? And if there is no such call, why include the wildcard? In this case, the wildcard does not make the method more concise nor add to readability (in my opinion).\n",
    "AcceptedAnswerId": 70627059,
    "AcceptedAnswer": "This is a really good question and the simple answer was guessed already:\n\nFor the current version of the fill(List list, T obj) there is no\nsuch input that would be rejected given the signature is changed to fill(List list, T obj), so there is no benefit and the devs are likely followed the PECS principle\n\nThe above statement derives from the principle that: if there is a such type X so that\nX is a supertype of T then List is a supertype of List because of type contravariance.\nSince we can always find such X (at the worst case it's the Object class) - the compiler can infer a suitable List argument type given either form of fill.\nSo, knowing that fact we can interfere with the compiler and infer the type ourselves using \"type witness\" so the code breaks:\nList target = new ArrayList();\n//Compiles OK as we can represent List as List and it fits\nCollections.fill(target, 1);\n\n//Compilation error as List is invariant to List and not a valid substitute\nCollections.fillNew(target, 1);\n\nThis is all of course purely theoretical and nobody in their right mind would use the type argument there.\nHOWEVER\nWhile answering the question \"What is the benefit of using wildcards here?\" we yet considered only one side of the equation - us, consumers of the method and our experience but not library developers.\nHence this question is somewhat similar to why Collections.enumeration(final Collection c) is declared the way it is and not enumeration(Collection c) as final seems superfluous for the end-user.\nWe can speculate here about the real intention, but I can give a few subjective reasons:\n\nFirst: using List (as well as final for enumeration) immediately disambiguates the code that tiny bit more and for the  specifically - it useful to show that only partial knowledge about the\ntype parameter is required and the list cannot be used to produce values of T, but only to consume them.\nQuote:\n\n\nWildcards are useful in situations where only partial knowledge about the type parameter is required.\nJLS 4.5.1. Type Arguments of Parameterized Types\n\n\nSecond: it gives some freedom to the library owners to improve/update the method without breaking backward compatibility while conforming to the existing constraints.\n\n\nNow let's try make up some hypothetical \"improvements\" to see what I mean (I'll call the form of fill that uses List as fillNew):\n#1 The decision is to make method to return the obj value (used to fill up the list) back:\npublic static  void fill(List list, T obj)\n//becomes \u2193\u2193\u2193\npublic static  T fill(List list, T obj)\n\nThe updated method would work just fine for fill signature, but for fillNew - the inferred return type now isn't that obvious:\nList target = new ArrayList();\nLong val = fill(target, 1L); //<<Here Long is the most specific type that fits both arguments\n//Compilation error\nLong val = fillNew(target, 1L); //<<Here Number is, so it cannot be assigned back\n\n//More exotic case:\nInteger val = fill(asList(true), 0); //val is Integer as expected\nComparable val = fillNew(asList(true), 0); //val is now Comparable as the most specific type \n\n#2 The decision to add an overloaded version of fill that is 10x more performant in cases when T is Comparable:\n/* Extremely performant 10x version */\npublic static > void fill(List list, T value)\n/* Normal version */\npublic static void fill(List list, T value)\n\nList target = new ArrayList();\nfill(target, 1);  //\nfillNew(target, 1); //<< Still uses the slow version just because T is inferred to Number which is not Comparable\n    \n\nTo sum up - the current signature of fill is more flexible/descriptive in my opinion for all parties (developers and library designers)\n"
}
{
    "Id": 70581530,
    "PostTypeId": 1,
    "Title": "Error creating bean with name 'securityConfig': Requested bean is currently in creation:",
    "Body": "package ro.contabilitateexpert.AccountExpert.config;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.security.authentication.AuthenticationManager;\nimport org.springframework.security.config.BeanIds;\nimport org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;\nimport org.springframework.security.config.annotation.web.builders.HttpSecurity;\nimport org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;\nimport org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;\nimport org.springframework.security.core.userdetails.UserDetailsService;\nimport org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;\nimport org.springframework.security.crypto.password.PasswordEncoder;\n\n@EnableWebSecurity\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Autowired\n    private UserDetailsService userDetailsService;\n\n    @Bean(BeanIds.AUTHENTICATION_MANAGER)\n    @Override\n    public AuthenticationManager authenticationManagerBean() throws Exception {\n        return super.authenticationManagerBean();\n    }\n\n    @Override\n    public void configure(HttpSecurity httpSecurity) throws Exception {\n        httpSecurity.csrf().disable().authorizeRequests()\n                .antMatchers(\"/api/auth/**\")\n                .permitAll()\n                .anyRequest()\n                .authenticated();\n    }\n\n    @Autowired\n    public void configureGlobal(AuthenticationManagerBuilder authenticationManagerBuilder) throws Exception {\n        authenticationManagerBuilder.userDetailsService(userDetailsService).passwordEncoder(passwordEncoder());\n    }\n\n    @Bean\n    PasswordEncoder passwordEncoder() {\n        return new BCryptPasswordEncoder();\n    }\n}\n\nI have the following error :\nError creating bean with name 'securityConfig': Requested bean is currently in creation: Is there an unresolvable circular reference?\nHow can i solve it?\n",
    "AcceptedAnswerId": 70595758,
    "AcceptedAnswer": "After i changed to configure instead of configureGlobal with @Overrides and deleted @Autowired\nAdded @Configuration\nNow the code is working,\nThanks to  Alexey Veleshko\n"
}
{
    "Id": 70681453,
    "PostTypeId": 1,
    "Title": "How to implement fixed points of functors in Java",
    "Body": "I recently discovered how to simulate higher order types in Java  in a somewhat roundabout way like so\ninterface H { }\n\nHere H encodes a higher order type that takes a type parameter F which itself takes parameter T.\nNow this leaves me to wonder, can we use this to implement some more advanced constructs? E.g. fixed point of functors\nlike Fix in Haskell and its corresponding catamorphisms?\n",
    "AcceptedAnswerId": 70681454,
    "AcceptedAnswer": "Indeed this can be done by carefully translating the corresponding Haskell counterparts. Although this introduces a lot of line noise,\nthe implementation is quite close to the original:\n\n// Encoding of higher kinded type F of T\npublic interface H { }\n\npublic interface Functor {\n     H map(Function f);\n}\n\n// newtype Fix f = Fix {unfix::f (Fix f)}\npublic static record Fix & Functor, T>(F f) {\n    public Functor> unfix() {\n        return (Functor>) f;\n    }\n}\n\n// type Algebra f a = f a -> a\npublic interface Algebra extends Function, T> {}\n\n // cata :: Functor f => Algebra f a -> Fix f -> a\n // cata alg = alg . fmap (cata alg) . unfix\npublic static  & Functor, T> Function, T> cata(Algebra alg) {\n    return fix -> alg.apply(fix.unfix().map(cata(alg)));\n}\n\nAmazingly this works and can be used to implement e.g. interpreters for expression algebras\n// evalExprF :: Algebra ExprF Int\n// evalExprF (Const n) = n\n// evalExprF (Add m n) = m + n\n// evalExprF (Mul m n) = m * n\npublic static class ExprAlg implements Algebra {\n    @Override\n    public Integer apply(H hExpr) {\n        return Expr.expr(hExpr).match(\n            conzt -> conzt.n,\n            add   -> add.t1 + add.t2,\n            mul   -> mul.t1 * mul.t2);\n    }\n}\n\nFull working example in my GitHub repository.\n"
}
{
    "Id": 70604058,
    "PostTypeId": 1,
    "Title": "ObjectMapper enable method is deprecated",
    "Body": "I'm upgrading the version of my project and I am currently using jackson-databind-2.13.0\n.But I noticed that ObjectMapper's enable method is deprecated.\nThey said to use it like this instead.\n@deprecated Since 2.13 use {@code JsonMapper.builder().enable(...)}\n\nBut I couldn't use it.\nBelow is my ObjectMapper instance creation code. how can I change?\n      @Bean(name = {\"objectMapper\"})\n      @Primary\n      ObjectMapper objectMapper() {\n        return newObjectMapper();\n      }\n\n  public static ObjectMapper newObjectMapper() {\n    ObjectMapper objectMapper =\n        new ObjectMapper()\n            .disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS)\n            .configure(SerializationFeature.FAIL_ON_EMPTY_BEANS, false)\n            .configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false)\n            .configure(DeserializationFeature.ACCEPT_SINGLE_VALUE_AS_ARRAY, true)\n            .setSerializationInclusion(JsonInclude.Include.NON_NULL)\n            .enable(MapperFeature.ACCEPT_CASE_INSENSITIVE_PROPERTIES);\nJavaTimeModule javaTimeModule = new JavaTimeModule();\njavaTimeModule.addSerializer(OffsetDateTime.class, new OffsetDateTimeSerializer());\njavaTimeModule.addDeserializer(OffsetDateTime.class, new OffsetDateTimeDeserializer());\njavaTimeModule.addSerializer(LocalDate.class, new LocalDateSerializer());\njavaTimeModule.addDeserializer(LocalDate.class, new LocalDateDeserializer());\nobjectMapper\n    .registerModule(javaTimeModule)\n    .configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false);\n\nreturn objectMapper;\n\n}\nSolution:\n    ObjectMapper objectMapper = JsonMapper\n    .builder()\n    .enable(MapperFeature.ACCEPT_CASE_INSENSITIVE_PROPERTIES)\n    .disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS)\n    .configure(SerializationFeature.FAIL_ON_EMPTY_BEANS, false)\n    .configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false)\n    .configure(DeserializationFeature.ACCEPT_SINGLE_VALUE_AS_ARRAY, true)\n    .serializationInclusion(Include.NON_NULL).build();\n\n",
    "AcceptedAnswerId": 70605226,
    "AcceptedAnswer": "I would suggest to rewrite your code to either\n\nRemove this bean and use a fully Spring Boot configured ObjectMapper (which has the name jacksonObjectMapper)\nUse the Jackson2ObjectMapperBuilder to create an instance of the ObjectMapper.\n\nAll of these solutions hide the intricate parts of constructing the ObjectMapper and will also put the burden of constructing it (properly) on the Spring Boot team, instead of you.\nNow for option 1 you would need to remove your @Bean and place the following in your application.properties.\nspring.jackson.serialization.FAIL_ON_EMPTY_BEANS=false\nspring.jackson.serialization.WRITE_DATES_AS_TIMESTAMPS=false\n\nspring.jackson.deserialization.FAIL_ON_UNKNOWN_PROPERTIES=false\nspring.jackson.deserialization.ACCEPT_SINGLE_VALUE_AS_ARRAY=true\n\nspring.jackson.mapper.ACCEPT_CASE_INSENSITIVE_PROPERTIES=true\n\nspring.jackson.defaultPropertyInclusion=NON_NULL\n\nWhen Spring (Boot) detects the JavaTime module on the classpath it will automatically be registered with the ObjectMapper, so no need to additionally add that (or the serializers for that matter).\nThese lines of configuration should you give the same configured ObjectMapper as your explicitly configured one. H\nFor the second option you can inject the Jackson2ObjectMapperBuilder into the method by using an argument, configure the things you want on there and call the build method in the end.\n@Bean(name = {\"objectMapper\"})\n@Primary\nObjectMapper objectMapper(Jackson2ObjectMapperBuilder builder) {\n    return newObjectMapper(builder);\n}\n\npublic static ObjectMapper newObjectMapper(Jackson2ObjectMapperBuilder builder) {\n   return builder\n            .serializationInclusion(NON_NULL)\n            .failOnEmptyBeans(false)\n            .failOnUnknownProperties(false)\n           .featuresToEnable(MapperFeature.ACCEPT_CASE_INSENSITIVE_PROPERTIES, DeserializationFeature.ACCEPT_SINGLE_VALUE_AS_ARRAY)\n           .featuresToDisable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS)\n.build();\n\nYou still don't need to register the JavaTime module as that is still being auto-detected for you.\nIn theory you could combine 1 and 2 but in your case that wouldn't add much, only some code to construct the ObjectMapper.\n@Bean(name = {\"objectMapper\"})\n@Primary\nObjectMapper objectMapper(Jackson2ObjectMapperBuilder builder) {\n    return newObjectMapper(builder);\n}\n\npublic static ObjectMapper newObjectMapper(Jackson2ObjectMapperBuilder builder) {\n   return builder.build();\n}\n\n"
}
{
    "Id": 70692260,
    "PostTypeId": 1,
    "Title": "cvc-elt.1.a: Cannot find the declaration of element 'project'",
    "Body": "error: cvc-elt.1.a: Cannot find the declaration of element 'project'\nI am getting this error constantly. Whenever I create a project using maven it starts displaying this error. I have even mentioned the 'maven-war-plugin' under plugin tag and then updated and refreshed the project as well.\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n  4.0.0\n  com.myfirstmvcapp\n  helloworldabc\n  war\n  0.0.1-SNAPSHOT\n  helloworldabc Maven Webapp\n  http://maven.apache.org\n  \n    \n      junit\n      junit\n      3.8.1\n      test\n    \n  \n  \n  \n  \n  org.apache.maven.plugins\n  maven-war-plugin\n  3.3.1\n  \n  \n    helloworldabc\n  \n\n\n",
    "AcceptedAnswerId": 70693979,
    "AcceptedAnswer": "I have Found the Solution to this problem, Thanks to @M.Deinum who commented the solution below the question.\nAll I did was add https to the link in the tag, instead of http.\nhere is the previous code:\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n  4.0.0\n  com.myfirstmvcapp\n  helloworldabc\n  war\n  0.0.1-SNAPSHOT\n  helloworldabc Maven Webapp\n  http://maven.apache.org\n  \n    \n      junit\n      junit\n      3.8.1\n      test\n    \n  \n  \n  \n  \n  org.apache.maven.plugins\n  maven-war-plugin\n  3.3.1\n  \n  \n    helloworldabc\n  \n\n\nHere is the lastest code, all that is needed is to add https instead of http to the xsd link in the last link of project tag.\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/maven-v4_0_0.xsd\">\n  4.0.0\n  com.myfirstmvcapp\n  helloworldabc\n  war\n  0.0.1-SNAPSHOT\n  helloworldabc Maven Webapp\n  http://maven.apache.org\n  \n    \n      junit\n      junit\n      3.8.1\n      test\n    \n  \n  \n  \n  \n  org.apache.maven.plugins\n  maven-war-plugin\n  3.3.1\n  \n  \n    helloworldabc\n  \n\n\n"
}
{
    "Id": 70568676,
    "PostTypeId": 1,
    "Title": "Arrange array so adjacent has less space that gives minimum sum",
    "Body": "I have an array of numbers with even size, here is my task:\na) Discard any 2 elements from the array.\nb) Then pair the elements and calculate the sum of differences between the elements in the pair such that the sum is minimum.\nExample:\narray size even say 8.\narray elements : 1,3,4,6,3,4,100,200\n\nAns:\n5\n\nExplanation:\n\nHere I will remove 100 and 200, as pairing them gives me a difference of (200 - 100) = 100.\nSo remaining elements are [1,3,4,6,3,4]\nPairs with minimum sum are : (1 3) , (4 3), (6 4).\n= |3-1| = 2, |4-3|=1,|6-4| = 2. So Sum = 2 + 1 + 2 = 5\n\nExample:\narray size even say 4.\narray elements : 1,50,51,60\n\nAns:\n1\n\nExplanation: Here I will remove 1 and 60 so I will get the minimum sum.\nSo the remaining elements are [50, 51], same as the adjacent   [50 51] = 1. My code will fail for this case and returns 49.\nHow to achieve this in java?\nI tried sorting the elements like this but this is not the correct approach for all kinds of inputs.\npublic static int process(int[] a) {\n   int n = a.length;\n   int n1 = n/2-1;\n   Arrays.sort(arr);\n   int sum = 0;\n   for(int i=0; i<n1*2; i+=2) {\n     sum += a[i+1] - a[i];\n   }\n   return sum;\n}\n\n",
    "AcceptedAnswerId": 70622902,
    "AcceptedAnswer": "In this kind of problem, the real issue is to find a good algorithm.\nthis post will insists on this aspect. A C++ code is provided at the end just to illustrate it.\nIt is clear we must begin by sorting the array.\nA solution consists in iteratively calculate three sums, where\nsum0 is the minimum sum assuming no element has been removed\nsum1 is the minimum sum assuming one element has been removed\nsum2 is the minimum sum assuming two elements has been removed\n\nDuring this process, the code must keep trace of the last element available to calculate a difference,\none for each sum (i_dispo0, i_dispo1, i_dispo2).\nPrinciples:\n- if sum1 > sum0: sum1 is replaced by sum0\n- if sum2 > sum1: sum2 is replaced by sum1\n\nComplexity: O(n logn)for sorting, O(n) for the optimization phase.\nCode:\nThe algorithm is illustrated by the following simple code in C++.\nIt should be easy to understand.\nOutput:\n5\n1\n2\n0\n2\n#include \n#include \n#include \n\nint min_sum_diff (std::vector& arr) {\n    int n = arr.size();\n    if (n%2) exit (1);\n    std::sort (arr.begin(), arr.end());\n    int sum0 = 0, sum1 = arr[n-1] - arr[0] + 1, sum2 = arr[n-1] - arr[0] + 1;\n    int i_dispo0 = -1, i_dispo1 = -1, i_dispo2 = -1;\n    for (int i = 0; i < n; ++i) {\n        int sum0_old = sum0;\n        int sum1_old = sum1;\n        if (i_dispo0 == -1) {\n            i_dispo0 = i;\n        } else {\n            sum0 += arr[i] - arr[i_dispo0];\n            i_dispo0 = -1;\n        }\n        if (i_dispo1 == -1) {\n            i_dispo1 = i;\n        } else {\n            int add = arr[i] - arr[i_dispo1];\n            if (sum0_old < sum1 + add) {\n                sum1 = sum0_old;\n                i_dispo1 = i;\n            } else {\n                sum1 += add;\n                i_dispo1 = -1;\n            }\n        }\n        if (i_dispo2 == -1) {\n            i_dispo2 = i;\n        } else {\n            sum2 += arr[i] - arr[i_dispo2];\n            i_dispo2 = -1;\n        }\n        \n        if (sum2 > sum1_old) {\n            sum2 = sum1_old;\n            i_dispo2 = i;\n        }\n        //std::cout << i << \" : \" << sum0 << \"  \" << sum1 << \"  \" << sum2 << '\\n';\n    }\n    return sum2;\n}\n\nint main() {\n    std::vector> examples = {\n        {1, 3, 4, 6, 3, 4, 100, 200},   // -> 5\n        {1, 50, 51, 60},                // -> 1\n        {1,2,100,200,400,401},          // -> 2\n        {1, 10, 10, 20, 30, 30},        // -> 0\n        {1, 10, 11, 20, 30, 31}         // -> 2\n    };\n    for (std::vector& arr: examples) {\n        int sum = min_sum_diff (arr);\n        std::cout << sum << '\\n';\n    }\n    return 0;\n}\n\n"
}
{
    "Id": 70654559,
    "PostTypeId": 1,
    "Title": "How to give certificate to Java Websocket?",
    "Body": "Forgive me for the newb question, but I am confused and obviously not understanding the fundamentals or explanations of how to use a Websocket server hosted over HTTPS. Everything I find online leads me to have more questions than answers.\nI have a Websocket server hosted on my HTTPS website using Java code.\nThis is my WebsocketServer.java file:\nimport org.java_websocket.WebSocket;\nimport org.java_websocket.handshake.ClientHandshake;\nimport org.java_websocket.server.WebSocketServer;\n\nimport java.net.InetSocketAddress;\nimport java.util.HashSet;\nimport java.util.Set;\n\nimport org.apache.logging.log4j.LogManager;\nimport org.apache.logging.log4j.Logger;\n\npublic class WebsocketServer extends WebSocketServer {\n\n    private static final Logger logger = LogManager.getLogger(WebsocketServer.class);\n\n    private static int TCP_PORT = 6868;\n\n    private static Set conns;\n\n    public WebsocketServer() {\n        super(new InetSocketAddress(TCP_PORT));\n        conns = new HashSet();\n    }\n\n    @Override\n    public void onOpen(WebSocket conn, ClientHandshake handshake) {\n        conns.add(conn);\n        logger.info(\"New connection from \" + conn.getRemoteSocketAddress().getAddress().getHostAddress());\n        logger.info(\"Size of connection list: \" + conns.size());\n    }\n\n    @Override\n    public void onClose(WebSocket conn, int code, String reason, boolean remote) {\n        conns.remove(conn);\n        logger.info(\"Closed connection to \" + conn.getRemoteSocketAddress().getAddress().getHostAddress());\n    }\n\n    @Override\n    public void onMessage(WebSocket conn, String message) {\n        logger.info(\"Message from client: {}\", message);\n        // for (WebSocket sock : conns) {\n        // sock.send(\"SENDING BACK\" + message);\n        // }\n    }\n\n    @Override\n    public void onError(WebSocket conn, Exception ex) {\n\n        // ex.printStackTrace();\n        try {\n            if (conn != null) {\n                conns.remove(conn);\n                // do some thing if required\n            }\n            logger.info(\"ERROR from {}\", conn.getRemoteSocketAddress().getAddress().getHostAddress());\n        } catch (Exception e) {\n            logger.info(\"onError: WebSocketServer may already be running\");\n\n        }\n\n    }\n\n    public Set getConns() {\n        return conns;\n    }\n\n}\n\n\nThen I started the WebsocketServer like this:\nWebsocketServer websocketServer;\n// Start socket server\nwebsocketServer = new WebsocketServer();\nwebsocketServer.start();\n\nAnd on the client side, I connect to it like this:\n    // APP_WEB_SOCKET is the url to my site: api.my_custom_domain.com\n    var connection = new WebSocket(\"wss://\" + APP_WEB_SOCKET + \":6868\");\n\nQUESTIONS:\nI keep reading that I need a certificate if I want to use wss over HTTPS, but cannot find any documents that explain what this means in a way that I can understand.\nMy app is hosted in AWS Elastic Beanstalk environment. Do I need to somehow add a certificate to the setup of the WebsocketServer in my Java code?\nExample:\nWebsocketServer websocketServer;\n// Start socket server\nwebsocketServer = new WebsocketServer();\n\n// example guessing\nwebsocketServer.cert = \"SOMETHING\";??\nwebsocketServer.start();\n\nDoes the client code need to be changed at all?\nWho needs the certificate?\nIf someone could please explain what I am missing or point me in the correct direction, I would really appreciate it.\n",
    "AcceptedAnswerId": 70698577,
    "AcceptedAnswer": "Keep it easy.\nCerts inside your application are complex - they are hard to manage and you will get problems to run your application in a modern cloud environment (start new environments, renew certs, scale your application, ...).\nSimple conclusion: Dont implement any certs.\nHow-to get encrypted connections?\nAs Mike already pointed out in the comments: WebSockets are just upgraded HTTP(S) connections. A normal webserver (nginx, apache) takes care about the certs. It can be done in kubernetes (as ingress-controller) or with a \"bare-metal\" webserver.\nBoth of them should act as a reverse-proxy. This means: Your java-application doesn't know anything about certs. It has just unencrypted connections - like in your code on port 6868.\nBut the client will not use this port. 6868 is only internally reachable.\nThe client will call your reverse-proxy at the normal HTTPS port (=443). The reverse-proxy will forward the connection to your java-application.\nHere some links for further information:\n\nnginx reverse-proxy\nnginx reverse-proxy for websocket\ntutorial for java behind reverse-proxy\nLetsEncrypt for automatic and free certs\n\n"
}
{
    "Id": 70695039,
    "PostTypeId": 1,
    "Title": "org.h2.jdbc.JdbcSQLSyntaxErrorException after H2 version upgrade",
    "Body": "I recently upgraded h2 version from 1.4.200 to 2.0.206. Some of the queries that used to work in the older version are not working properly after the upgrade.\nCREATE TABLE SOMETABLE (\n  ID INT(11) NOT NULL AUTO_INCREMENT,\n  SOURCE_ID VARCHAR(255) NOT NULL,\n  MESSAGE VARCHAR(255) NOT NULL,\n  PRIMARY KEY (`ID`)\n);\n\nCREATE TABLE IF NOT EXISTS SOMEOTHERTABLE (\n    ID VARCHAR(255) NOT NULL,\n    NAME VARCHAR(255) NOT NULL,\n    CREATED_TIME TIMESTAMP NOT NULL,\n    LAST_MODIFIED TIMESTAMP NOT NULL,\n    HAS_FILE BOOLEAN(1) NOT NULL,\n    PRIMARY KEY (ID)\n);\n\nFor both these, I get similar errors\norg.h2.jdbc.JdbcSQLSyntaxErrorException: Syntax error in SQL statement \"  CREATE TABLE SOMETABLE ( ID INT([*]11) NOT NULL AUTO_INCREMENT, SOURCE_ID VARCHAR(255) NOT NULL, MESSAGE VARCHAR(255) NOT NULL, PRIMARY KEY (`ID`) )\"; expected \"ARRAY, INVISIBLE, VISIBLE, NOT, NULL, AS, DEFAULT, GENERATED, ON, NOT, NULL, AUTO_INCREMENT, DEFAULT, NULL_TO_DEFAULT, SEQUENCE, SELECTIVITY, COMMENT, CONSTRAINT, COMMENT, PRIMARY, UNIQUE, NOT, NULL, CHECK, REFERENCES, AUTO_INCREMENT, ., )\";\n\norg.h2.jdbc.JdbcSQLSyntaxErrorException: Syntax error in SQL statement \"  CREATE TABLE IF NOT EXISTS SOMEOTHERTABLE ( ID VARCHAR(255) NOT NULL, NAME VARCHAR(255) NOT NULL, CREATED_TIME TIMESTAMP NOT NULL, LAST_MODIFIED TIMESTAMP NOT NULL, HAS_FILE BOOLEAN([*]1) NOT NULL, PRIMARY KEY (ID) )\"; expected \"ARRAY, INVISIBLE, VISIBLE, NOT, NULL, AS, DEFAULT, GENERATED, ON, NOT, NULL, AUTO_INCREMENT, DEFAULT, NULL_TO_DEFAULT, SEQUENCE, SELECTIVITY, COMMENT, CONSTRAINT, COMMENT, PRIMARY, UNIQUE, NOT, NULL, CHECK, REFERENCES, AUTO_INCREMENT, ., )\";\n\nIt seems that in both these cases, having INT(11) and BOOLEAN(1) is the issue. Are those not allowed anymore in the new version? If so, how should I change those? Any help regarding this is appreciated.\n",
    "AcceptedAnswerId": 70696184,
    "AcceptedAnswer": "Why do you have such definitions? Documentation of H2 1.4.200 doesn't allow any parameters for these data types.\nINT(11) is allowed only in MySQL and MariaDB compatibility modes, but the specified precision is ignored by H2. This definition is rejected in all other compatibility modes in H2 2.0, you need to use INT or INTEGER.\nBOOLEAN(1) is not allowed at all, if it worked in 1.4.200, it was a bug in the parser. You need to use BOOLEAN.\nAUTO_INCREMENT clause also should normally be used only in MySQL and MariaDB compatibility modes, but it works in Regular mode too. The proper clause is GENERATED BY DEFAULT AS IDENTITY and explicit NOT NULL constraint isn't required for primary key and identity columns, you can remove it. Constraints also should normally be specified after all other clauses, NOT NULL before identity options is actually accepted by H2, but this wrong order of clauses isn't documented and isn't supported.\n"
}
{
    "Id": 70570084,
    "PostTypeId": 1,
    "Title": "Code reuse: returning lists of enum fields with common getter methods",
    "Body": "I have two enums:\nMain Menu Options\npublic enum MainMenuOptions {\n    \n    EXIT(\"Exit\"),\n    VIEW_RESERVATIONS(\"View Reservations By Host\"),\n    CREATE_RESERVATION(\"Create A Reservation\"),\n    EDIT_RESERVATION(\"Edit A Reservation\"),\n    CANCEL_RESERVATION(\"Cancel A Reservation\");\n    \n    private final String message;\n    \n    MainMenuOptions(String message) {\n        this.message = message;\n    }\n    \n    public String getMessage() {\n        return message;\n    }\n    \n    public static List asListString() {\n        return Arrays.stream(MainMenuOptions.values())\n                .map(MainMenuOptions::getMessage)\n                .collect(Collectors.toList());\n    }\n}\n\nHost Selection Method Options\npublic enum HostSelectionMethodOptions {\n    \n    FIND_ALL(\"Find all\"),\n    FIND_BY_LASTNAME_PREFIX(\"Find by last name prefix\"),\n    FIND_BY_CITY_STATE(\"Find by city & state\");\n    \n    String message;\n    \n    HostSelectionMethod(String message) {\n        this.message = message;\n    }\n    \n    public String getMessage() {\n        return message;\n    }\n    \n    public static List asListString() {\n        return Arrays.stream(HostSelectionMethod.values())\n                .map(HostSelectionMethod::getMessage)\n                .collect(Collectors.toList());\n    }\n}\n\nBoth enums share the same field\nprivate final String message;\n\nThe same getter\npublic String getMessage() {\n    return message;\n}\n\nAnd the same asListString() method\npublic static List asListString() {\n    return Arrays.stream(MainMenuOptions.values())\n            .map(MainMenuOptions::getMessage)\n            .collect(Collectors.toList());\n}\n\nHow can I DRY out these enums?\nI expect to have more enums with the same fields and methods, and it seems silly to write out the same thing over and over again for each one.\n\nI tried making both of the enums extend a superclass, but enums cannot have extends clauses\nI can create an interface that specifies the contract for the asListString() method, but that doesn't allow me to actually reuse any code.\n\nThe flavor I was hoping the code could have is something like this:\npublic class Utils {\n    \n    public static List enumAsListString(Enum e) {\n        return e.values().stream.map(e::getMessage).collect(Collectors.toList());\n    }\n}\n\n",
    "AcceptedAnswerId": 70570794,
    "AcceptedAnswer": "This is probably one of the cases where you need to pick one between being DRY and using enums.\nEnums don't go very far as far as code reuse is concerned, in Java at least; and the main reason for this is that primary benefits of using enums are reaped in static code - I mean static as in \"not dynamic\"/\"runtime\", rather than static :). Although you can \"reduce\" code duplication, you can hardly do much of that without introducing dependency (yes, that applies to adding a common API/interface, extracting the implementation of asListString to a utility class). And that's still an undesirable trade-off.\nFurthermore, if you must use an enum (for such reasons as built-in support for serialization, database mapping, JSON binding, or, well, because it's data enumeration, etc.), you have no choice but to duplicate method declarations to an extent, even if you can share the implementation: static methods just can't be inherited, and interface methods (of which getMessage would be one) shall need an implementation everywhere. I mean this way of being \"DRY\" will have many ways of being inelegant.\nIf I were you, I would simply make this data completely dynamic\nfinal class MenuOption {\n    private final String category; //MAIN_MENU, HOT_SELECTION\n    private final String message; //Exit, View Reservation By Host, etc.\n    public static MenuOption of(String key, String message) {\n        return new MenuOption(key, message);\n    }\n}\n\nThis is very scalable, although it introduces the need to validate data where enums would statically prevent bad options, and possibly custom code where an enum would offer built-in support.\nIt can be improved with a \"category\" enum, which gives static access to menu lists, and a single place for asListString():\nenum MenuCategory {\n    MAIN_MENU(\n        MenuOption.of(\"Exit\"), \n        MenuOption.of(\"View Reservations By Host\")\n    ),\n    HOT_SELECTION(\n        MenuOption.of(\"Find All\")\n    );\n    \n    private final List menuOptions;\n    \n    MenuCategory(MenuOption... options) {\n        this.menuOptions = List.of(options); //unmodifiable\n    }\n    \n    public ListasListString() {\n        return this.menuOptions.stream()\n                   .map(MenuOption::getMessage)\n                   .collect(Collectors.toList());\n    }\n}\n\nIt should be clear that you can replace class MenuOption with a bunch of enums implementing a common interface, which should change little to nothing in MenuCategory. I wouldn't do that, but it's an option.\n"
}
{
    "Id": 70686277,
    "PostTypeId": 1,
    "Title": "ERROR No qualifying bean of type 'org.springframework.security.oauth2.jwt.JwtDecoder' available",
    "Body": "I am trying to write a test for my controller but the test environment fails to load with the given stackTrace.\n    @PreAuthorize(\"hasAuthority('my.scope')\")\n    @GetMapping(value = \"/path\", produces = APPLICATION_JSON_VALUE)\n    public ResponseEntity>> getPath() {\n        return myService.pathFunction()\n            .map(ResponseEntity::ok);\n    }\n\nand following is how I've configured my security config\n@Configuration\n@EnableWebSecurity\n@EnableGlobalMethodSecurity(securedEnabled = true, prePostEnabled = true)\npublic class WebConfig extends WebSecurityConfigurerAdapter {\n\n    private static final String PRINCIPAL = \"sub\";\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n\n        JwtAuthenticationConverter authenticationConverter =\n            new JwtAuthenticationConverter();\n        authenticationConverter.setJwtGrantedAuthoritiesConverter(...);\n        authenticationConverter.setPrincipalClaimName(PRINCIPAL);\n\n        http.csrf().disable()\n            .cors()\n            .and()\n            .authorizeRequests().antMatchers(\"/actuator/**\").permitAll()\n            .anyRequest().authenticated()\n            .and()\n            .oauth2ResourceServer()\n            .jwt()\n            .jwtAuthenticationConverter(authenticationConverter);\n    }\n}\n\nThe controller is working as needed but my test fails with this error. I am not using any customer JwtDecoder\n@WebMvcTest(controllers = Controller.class)\nclass ControllerTest {\n\n    @MockBean\n    private MyService myService;\n\n    @Autowired\n    private MockMvc mockMvc;\n\n    @Test\n    @WithMockUser(authorities = {\"my.scope\"})\n    void controllerTest() throws Exception{\n        Map> mapResponse = Map.of(\"key\", Set.of(\"foo1\", \"foo2\"));\n        Mockito.when(myService.pathFunction()).thenReturn(Optional.of(mapResponse));\n\n        MockHttpServletResponse result = mockMvc.perform(get(\"/configuration/api-registry\")\n                .contentType(MediaType.APPLICATION_JSON))\n            .andExpect(status().isOk())\n            .andReturn()\n            .getResponse();\n\n        String response = result.getContentAsString();\n        assertTrue(response.contains(\"foo1\"));\n    }\n\n}\n\nHow do I run this test ?\njava.lang.IllegalStateException: Failed to load ApplicationContext\n\nCaused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'springSecurityFilterChain' defined in class path resource [org/springframework/security/config/annotation/web/configuration/WebSecurityConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [javax.servlet.Filter]: Factory method 'springSecurityFilterChain' threw exception; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'org.springframework.security.oauth2.jwt.JwtDecoder' available\n    ...\nCaused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [javax.servlet.Filter]: Factory method 'springSecurityFilterChain' threw exception; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'org.springframework.security.oauth2.jwt.JwtDecoder' available\n    at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185)\n    at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:653)\n    ... 90 more\nCaused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'org.springframework.security.oauth2.jwt.JwtDecoder' available\n    at ...\n\n",
    "AcceptedAnswerId": 70694659,
    "AcceptedAnswer": "I added mocking the decoder in the test as\n@MockBean\nprivate JwtDecoder jwtDecoder;\n\nand the test ran !\n"
}
{
    "Id": 70702544,
    "PostTypeId": 1,
    "Title": "Why do I get an ambiguity error in this code?",
    "Body": "Let's say we have these 3 classes:\nclass A { }\nclass B extends A { }\n\npublic class App {\n    static void f(int i, A a) { }\n    static void f(float j, B b) { }\n   \n    static public void main() {\n        int i = 0;\n        B b = new B();\n        App.f(i, b);\n    }\n}\n\nThis produces the error:\nApp.java:11: error: reference to f is ambiguous\n        App.f(i, b);\n           ^\n  both method f(int,A) in App and method f(float,B) in App match\n1 error\n\nWhy does it not choose the type f(int, A) since i is an integer?\n",
    "AcceptedAnswerId": 70702914,
    "AcceptedAnswer": "It is ambiguous because of two reasons:\n\nboth overloads are applicable, and;\nneither overload is more specific than the other\n\nNotice that both the f(int, A) overload and the f(float, B) overload can be called with the parameters (i, b), since there is an implicit conversion from int to float, and an implicit conversion from B to A.\nWhat happens when there are more than one applicable method? Java is supposed to choose the most specific method. This is described in \u00a715.12.2.5 of the language spec. It turns out that it is not the case that one of these overloads are more specific than the other.\n\nOne applicable method m1 is more specific than another applicable\nmethod m2, for an invocation with argument expressions e1, ..., ek, if\nany of the following are true:\n\nm2 is generic [...]\n\nm2 is not generic, and m1 and m2 are applicable by strict or loose invocation, and where m1 has formal parameter types S1, ..., Sn and m2\nhas formal parameter types T1, ..., Tn, the type Si is more specific\nthan Ti for argument ei for all i (1 \u2264 i \u2264 n, n = k).\n\nm2 is not generic, and m1 and m2 are applicable by variable arity invocation [...]\n\n\n\nOnly the second point applies to the two overloads of f. For one of the overloads to be more specific than the other, every parameter type of one overload has to be more specific than the corresponding parameter type in the other overload.\n\nA type S is more specific than a type T for any expression if S \u00a74.10).\n\nNote that\"B is clearly a subtype of A. float is actually a supertype (not subtype!) of int. This can be derived from the direct subtyping relations listed in \u00a74.10.1. Therefore, neither of the overloads is more specific than the other.\nThe language spec goes on to talk about maximally specific methods, which doesn't really apply to f here. Finally, it says:\n\nOtherwise, the method invocation is ambiguous, and a compile-time error occurs.\n\nMore Examples\nstatic void f(int x) {}\nstatic void f(float x) {}\n\nwhen called with an int are not ambiguous because the int overload is more specific.\nstatic void f(int x, B a) {}\nstatic void f(float x, A a) {}\n\nwhen called with argument types (int, A) are not ambiguous because the (int, B) overload is more specific.\nstatic void f(int x, A a) {}\nstatic void f(float x, A a) {}\n\nwhen called with argument types(int, A) are not ambiguous because the (int, A) overload is more specific. Note that the subtyping relationship is reflexive (i.e. A is a subtype of A).\n"
}
{
    "Id": 70860253,
    "PostTypeId": 1,
    "Title": "Java map function throws non-static method compiler error",
    "Body": "I have an odd problem, where I am struggling to understand the nature of \"static context\" in Java, despite the numerous SO questions regarding the topic.\nTL;DR:\nI have a design flaw, where ...\nThis works:\nList list = orderType.getOrderExtnTransList();\nthis.dtoOrderExtnTransList = list.stream().map(OrderExtnTrans::toDto).collect(Collectors.toList());\n\nBut this does not:\nthis.dtoOrderExtnTransList = orderType.getOrderExtnTransList().stream().map(OrderExtnTrans::toDto).collect(Collectors.toList());\n\n\nThe error shown in the second version is \"Non-static method cannot be referenced from a static context\".\nThe long version:\nObject Model:\nThe model consists of Business Type specific orders (eg. Stock exchange, payments), which inherit from a an order entity via an \"InheritanceType.JOINED\" inheritance strategy.\nThe parent order can be parameterized with the business type specific DTO object of that order, so for example DtoStockExchangeOrder. This is to enable, that JPA objects can be mapped to their DTO equivalent within the Entity, rather than in a service (which I did previously. It worked, but its \"less clean\").\nJPA Order:\n@Entity\n@Table(name = \"ORDER_BASE\")\n@Inheritance(strategy = InheritanceType.JOINED)\npublic class Order implements Serializable {\n\n    @OneToMany(fetch = FetchType.LAZY, mappedBy = \"order\", orphanRemoval = true)\n    private List orderExtnTransList = new ArrayList();\n\n}\n\nJPA Order - Business Type specific example:\n@Entity\n@Table(name = \"ORDER_STEX\")\n@Inheritance(strategy = InheritanceType.JOINED)\npublic class OrderStex extends Order implements Serializable {\n\nLikewise, DTO orders follow the same pattern, where they can be parameterized with the business type specific JPA entity, to enable the relevant mapping:\nDTO Order:\npublic class DtoOrder extends DtoEntity {\n\nDTO Order - Business Type Specific Example\npublic class DtoOrderStex extends DtoOrder {\n\nThe DTOEntity class it inherits from is just a \"wrapper\" class, consisting of an ID and a name.\nNow the tricky part:\nThe DTOOrder class has a constructor which populates the fields that are common to all business types, like the list of process status transitions, an order goes through in its life cycle (placed, cancelled, executed, etc..). Staying with the example of the process status transitions, these are also modelled as JPA entities in the database, with their corresponding DTO counterparts (likewise parameterized, that part works fine).\nHere the constructor:\npublic DtoOrder(OrderType orderType) {\n    super(orderType);\n    // this is the part from above, which works (but it shows a warning: Unchecked assignment: 'java.util.List' to 'java.util.List' )\n    List list = orderType.getOrderExtnTransList();\n    this.dtoOrderExtnTransList = list.stream().map(OrderExtnTrans::toDto).collect(Collectors.toList());\n    // this is how I would have expected it to work, but it does not, with the error shown above: \"Non-static method cannot be referenced from a static context\"\n    this.dtoOrderExtnTransList = orderType.getOrderExtnTransList().stream().map(OrderExtnTrans::toDto).collect(Collectors.toList());\n}\n\nIf I comment out the non-working version, the application behaves as expected and throws no error, so \"logically\", this works. But JAVA does not allow it as developed in the second version.\nIf instead of OrderType I use \"Order\", it works as well, but obviously throws errors elsewhere, because the signature of the constructor changed. I assume another approach would be to parameterise the method based on the the caller of the constructor or to parameterise the parent class DtoOrder to know the type of the child class, but there should be a better way?\nWhat am I doing wrong, and why does the upper version work as expected?\n",
    "AcceptedAnswerId": 70873247,
    "AcceptedAnswer": "Thanks for an interesting question, that shows some unexpected behaviour, that is behaving according to spec.\nTL;DR (ie, the correct way of quickly and easily fixing this) is to add the  generic wildcard to Order in the DtoOrder class declaration, so :\npublic class DtoOrder> extends DtoEntity {\n\nThis will make the all-in-one-line way in the constructor work \u200b:\n\u200bthis.dtoOrderExtnTransList = orderType.getOrderExtnTransList().stream().map(OrderExtnTrans::toDto).collect(Collectors.toList());\n\nAs for why this is the fix, this is because you have defined Order as a Generic type :\npublic class Order \n\nBy NOT specifying the generic type, you are declaring it (and therefore making OrderType as well) as a raw-type.\nGenerally we are used to List being generic, that at run-time undergoes type-erasure.  Further, that if we have old code like :\nList myRawTypeVariable = new ArrayList();\n\nthat myRawType is a raw type, in that we can add any Object and only get Objects out.\nHowever, it turns out that (as you have discovered) raw types go further than that, and type-erasure has compile-time implications as well.\nThe Java Language Specification (JLS) says this (source : https://docs.oracle.com/javase/specs/jls/se8/html/jls-4.html#jls-4.8 )\n\nThe type of a constructor (\u00a78.8), instance method (\u00a78.4, \u00a79.4), or\nnon-static field (\u00a78.3) of a raw type C that is not inherited from its\nsuperclasses or superinterfaces is the raw type that corresponds to\nthe erasure of its type in the generic declaration corresponding to C.\n\nNote that this is NOT limiting type erasure to ONLY those of the generic type;  The types of ALL instance methods get taken to their raw types !\nIn other words, by not specifying the generic type of Order, you are making Order a raw type - and therefore turning off all Generic type-checking for that class (except for methods, etc otherwise specified, from inheritance or interfaces).\nSo even though getOrderExtnTransList() is declared as returning a List, because you are using Order as a raw-type, it's dropping the  generic and treating that method as simply returning a List (effectively a List ).\nYou can confirm this by trying to insert a peek, so :\n   \u200bthis.dtoOrderExtnTransList = orderType.getOrderExtnTransList().stream().peek(s -> s.\n\nthen try to do an auto-complete.   You'll find that the options are only the members for Object, not the endsWith, etc members for String.\nThis, in turn, means that when it hits .map(OrderExtnTrans::toDto), instead of interpreting this for a OrderExtnTrans coming down the stream :\n `.map(o -> o.toDto())`, \n\nit thinks you mean\n  `.map(o -> OrderExtnTrans.toDto(o))` \n\nwhich is what is appropriate for an Object coming down the stream - and that is why it complains about toDto being a non-static method.\nAs stated, the solution is to simply not treat Order as a raw-type, instead to make it generic by adding the  as above.\n"
}
{
    "Id": 70667172,
    "PostTypeId": 1,
    "Title": "PortUnreachableExceptions spamming log after updating Spring Boot Parent",
    "Body": "After upgrading from spring-boot-parent version 2.5.5 to 2.6.0, I started seeing these error messages spamming the logs:\n[INFO] [stdout] 2022-01-11 13:40:01.157  WARN 76859 --- [    udp-epoll-2] i.m.s.reactor.netty.channel.FluxReceive  : [6d1243de, L:/127.0.0.1:58160 - R:localhost/127.0.0.1:8125] An exception has been observed post termination, use DEBUG level to see the full stack: java.net.PortUnreachableException: readAddress(..) failed: Connection refused\nUsing DEBUG level:\n[INFO] [stdout] 2022-01-11 13:38:29.733  WARN 76479 --- [    udp-epoll-2] i.m.s.reactor.netty.channel.FluxReceive  : [43aad7ce, L:/127.0.0.1:38108 - R:localhost/127.0.0.1:8125] An exception has been observed post termination\n[INFO] [stdout] \n[INFO] [stdout] java.net.PortUnreachableException: readAddress(..) failed: Connection refused\n[INFO] [stdout]     at io.micrometer.shaded.io.netty.channel.epoll.EpollDatagramChannel.translateForConnected(EpollDatagramChannel.java:575)\n[INFO] [stdout]     at io.micrometer.shaded.io.netty.channel.epoll.EpollDatagramChannel.access$400(EpollDatagramChannel.java:56)\n[INFO] [stdout]     at io.micrometer.shaded.io.netty.channel.epoll.EpollDatagramChannel$EpollDatagramChannelUnsafe.epollInReady(EpollDatagramChannel.java:503)\n[INFO] [stdout]     at io.micrometer.shaded.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:480)\n[INFO] [stdout]     at io.micrometer.shaded.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:378)\n[INFO] [stdout]     at io.micrometer.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n[INFO] [stdout]     at io.micrometer.shaded.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n[INFO] [stdout]     at io.micrometer.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n[INFO] [stdout]     at java.base/java.lang.Thread.run(Thread.java:833)\n[INFO] [stdout] Caused by: io.micrometer.shaded.io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection refused\n\nI can't find much about it in the release notes, except for a dependency upgrade that seems relevant:\n\nUpgrade to Micrometer 1.8.0 #28516\n\nBut the linked issue is not informative. Neither were Micronaut's own release notes for version 1.8.0 (except for the JVM crash notice, which we did run into - a surprising and rather unfortunate side-effect of upgrading Spring Boot, but I digress)\nWe don't (consciously) use Micrometer, so I tried disabling it in the application.yml file (micrometer.enabled: false and instrumentation.micrometer.enabled: false), but to no avail.\nDespite lots of googling (for various permutations of elements of the error message and digging through code on GitHub), I haven't been able to find how to fix this message, let alone figure out what causes it.\nNow I could of course suppress this message in the logging configuration, but I'd like to know what it's actually trying to achieve here, and whether it is useful for our application. And if not, disable it completely.\n",
    "AcceptedAnswerId": 70700918,
    "AcceptedAnswer": "assuming statsd is not used and configured on your side, since it's pointed to localhost, you may disable it by setting\nmanagement.metrics.export.statsd.enabled\n\nto false\n"
}
{
    "Id": 70709971,
    "PostTypeId": 1,
    "Title": "What is 'serviceability memory category' of Native Memory Tracking?",
    "Body": "I have an java app (JDK13) running in a docker container. Recently I moved the app to JDK17 (OpenJDK17) and found a gradual increase of memory usage by docker container.\nDuring investigation I found that the 'serviceability memory category' NMT grows constantly (15mb per an hour). I checked the page https://docs.oracle.com/en/java/javase/17/troubleshoot/diagnostic-tools.html#GUID-5EF7BB07-C903-4EBD-A9C2-EC0E44048D37 but this category is not mentioned there.\nCould anyone explain what this serviceability category means and what can cause such gradual increase?\nAlso there are some additional new memory categories comparing to JDK13. Maybe someone knows where I can read details about them.\nHere is the result of command jcmd 1 VM.native_memory summary\nNative Memory Tracking:\n\n(Omitting categories weighting less than 1KB)\n\nTotal: reserved=4431401KB, committed=1191617KB\n-                 Java Heap (reserved=2097152KB, committed=479232KB)\n                            (mmap: reserved=2097152KB, committed=479232KB) \n \n-                     Class (reserved=1052227KB, committed=22403KB)\n                            (classes #29547)\n                            (  instance classes #27790, array classes #1757)\n                            (malloc=3651KB #79345) \n                            (mmap: reserved=1048576KB, committed=18752KB) \n                            (  Metadata:   )\n                            (    reserved=139264KB, committed=130816KB)\n                            (    used=130309KB)\n                            (    waste=507KB =0.39%)\n                            (  Class space:)\n                            (    reserved=1048576KB, committed=18752KB)\n                            (    used=18149KB)\n                            (    waste=603KB =3.21%)\n \n-                    Thread (reserved=387638KB, committed=40694KB)\n                            (thread #378)\n                            (stack: reserved=386548KB, committed=39604KB)\n                            (malloc=650KB #2271) \n                            (arena=440KB #752)\n \n-                      Code (reserved=253202KB, committed=76734KB)\n                            (malloc=5518KB #23715) \n                            (mmap: reserved=247684KB, committed=71216KB) \n \n-                        GC (reserved=152419KB, committed=92391KB)\n                            (malloc=40783KB #34817) \n                            (mmap: reserved=111636KB, committed=51608KB) \n \n-                  Compiler (reserved=1506KB, committed=1506KB)\n                            (malloc=1342KB #2557) \n                            (arena=165KB #5)\n \n-                  Internal (reserved=5579KB, committed=5579KB)\n                            (malloc=5543KB #33822) \n                            (mmap: reserved=36KB, committed=36KB) \n \n-                     Other (reserved=231161KB, committed=231161KB)\n                            (malloc=231161KB #347) \n \n-                    Symbol (reserved=30558KB, committed=30558KB)\n                            (malloc=28887KB #769230) \n                            (arena=1670KB #1)\n \n-    Native Memory Tracking (reserved=16412KB, committed=16412KB)\n                            (malloc=575KB #8281) \n                            (tracking overhead=15837KB)\n \n-        Shared class space (reserved=12288KB, committed=12136KB)\n                            (mmap: reserved=12288KB, committed=12136KB) \n \n-               Arena Chunk (reserved=18743KB, committed=18743KB)\n                            (malloc=18743KB) \n \n-                   Tracing (reserved=32KB, committed=32KB)\n                            (arena=32KB #1)\n \n-                   Logging (reserved=7KB, committed=7KB)\n                            (malloc=7KB #289) \n \n-                 Arguments (reserved=1KB, committed=1KB)\n                            (malloc=1KB #53) \n \n-                    Module (reserved=1045KB, committed=1045KB)\n                            (malloc=1045KB #5026) \n \n-                 Safepoint (reserved=8KB, committed=8KB)\n                            (mmap: reserved=8KB, committed=8KB) \n \n-           Synchronization (reserved=204KB, committed=204KB)\n                            (malloc=204KB #2026) \n \n-            Serviceability (reserved=31187KB, committed=31187KB)\n                            (malloc=31187KB #49714) \n \n-                 Metaspace (reserved=140032KB, committed=131584KB)\n                            (malloc=768KB #622) \n                            (mmap: reserved=139264KB, committed=130816KB) \n \n-      String Deduplication (reserved=1KB, committed=1KB)\n                            (malloc=1KB #8) \n\nThe detailed information about increasing part of memory is:\n[0x00007f6ccb970cbe] OopStorage::try_add_block()+0x2e\n[0x00007f6ccb97132d] OopStorage::allocate()+0x3d\n[0x00007f6ccbb34ee8] StackFrameInfo::StackFrameInfo(javaVFrame*, bool)+0x68\n[0x00007f6ccbb35a64] ThreadStackTrace::dump_stack_at_safepoint(int)+0xe4\n                             (malloc=6755KB type=Serviceability #10944)\n\nUpdate#1 from 2022-01-17:\nThanks to @Aleksey Shipilev for help! We were able to find a place which causes the issue, is related to many ThreadMXBean#.dumpAllThreads calls. Here is MCVE, Test.java:\nRun with:\njava -Xmx512M -XX:NativeMemoryTracking=detail Test.java \n\nand check periodically serviceability category in result of\njcmd YOUR_PID VM.native_memory summary \n\nTest java:\nimport java.lang.management.ManagementFactory;\nimport java.lang.management.ThreadInfo;\nimport java.lang.management.ThreadMXBean;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.TimeUnit;\n\npublic class Test {\n\n    private static final int RUNNING = 40;\n    private static final int WAITING = 460;\n\n    private final Object monitor = new Object();\n    private final ThreadMXBean threadMxBean = ManagementFactory.getThreadMXBean();\n    private final ExecutorService executorService = Executors.newFixedThreadPool(RUNNING + WAITING);\n\n    void startRunningThread() {\n        executorService.submit(() -> {\n            while (true) {\n            }\n        });\n    }\n\n    void startWaitingThread() {\n        executorService.submit(() -> {\n            try {\n                monitor.wait();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n    }\n\n    void startThreads() {\n        for (int i = 0; i < RUNNING; i++) {\n            startRunningThread();\n        }\n\n        for (int i = 0; i < WAITING; i++) {\n            startWaitingThread();\n        }\n    }\n\n    void shutdown() {\n        executorService.shutdown();\n        try {\n            executorService.awaitTermination(5, TimeUnit.SECONDS);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n\n    \n    public static void main(String[] args) throws InterruptedException {\n        Test test = new Test();\n\n        Runtime.getRuntime().addShutdownHook(new Thread(test::shutdown));\n\n        test.startThreads();\n\n        for (int i = 0; i < 12000; i++) {\n            ThreadInfo[] threadInfos = test.threadMxBean.dumpAllThreads(false, false);\n            System.out.println(\"ThreadInfos: \" + threadInfos.length);\n\n            Thread.sleep(100);\n        }\n\n        test.shutdown();\n    }\n}\n\n",
    "AcceptedAnswerId": 70713288,
    "AcceptedAnswer": "Unfortunately (?), the easiest way to know for sure what those categories map to is to look at OpenJDK source code. The NMT tag you are looking for is mtServiceability. This would show that \"serviceability\" are basically diagnostic interfaces in JDK/JVM: JVMTI, heap dumps, etc.\nBut the same kind of thing is clear from observing that stack trace sample you are showing mentions ThreadStackTrace::dump_stack_at_safepoint -- that is something that dumps the thread information, for example for jstack, heap dump, etc. If you have a suspicion for the memory leak in that code, you might try to build a MCVE demonstrating it, and submitting the bug against OpenJDK, or showing it to a fellow OpenJDK developer. You probably know better what your application is doing to cause thread dumps, focus there.\nThat being said, I don't see any obvious memory leaks in StackFrameInfo, neither can I reproduce any leak with stress tests, so maybe what you are seeing is \"just\" thread dumping over the larger and larger thread stacks. Or you capture it when thread dump is happening. Or... It is hard to say without the MCVE.\nUpdate: After playing with MCVE, I realized that it reproduces with 17.0.1, but not with either mainline development JDK, or JDK 18 EA, or JDK 17.0.2 EA. I tested with 17.0.2 EA before, so was not seeing it, dang. Bisection between 17.0.1 and 17.0.2 EA shows it was fixed with JDK-8273902 backport. 17.0.2 releases this week, so the bug should disappear after you upgrade.\n"
}
{
    "Id": 70555241,
    "PostTypeId": 1,
    "Title": "Spring Boot, OAuth2 authentication is lost between requests",
    "Body": "EDIT:\nlog from org.springframework.security:\n2022-01-17 12:31:03.495 IST\n2022-01-17 10:31:03.495 DEBUG [080-exec-5] o.s.s.w.s.SessionManagementFilter - Request requested invalid session id D5F8BA31A3D7466AK3K3C8EA26A4F037\nDefault\n\n2022-01-17 12:31:03.495 IST\n2022-01-17 10:31:03.495 DEBUG [080-exec-5] o.s.s.w.a.AnonymousAuthenticationFilter - Set SecurityContextHolder to anonymous SecurityContext\nDebug\n\n2022-01-17 12:31:03.495 IST\n\"Request requested invalid session id D5F8BA31A3D7466AK3K3C8EA26A4F037\"\nDebug\n\n2022-01-17 12:31:03.495 IST\n\"Set SecurityContextHolder to anonymous SecurityContext\"\nDefault\n\n2022-01-17 12:31:03.494 IST\n2022-01-17 10:31:03.494 DEBUG [080-exec-5] o.s.s.w.c.SecurityContextPersistenceFilter - Set SecurityContextHolder to empty SecurityContext\nDebug\n\n2022-01-17 12:31:03.494 IST\n\"Set SecurityContextHolder to empty SecurityContext\"\nDefault\n\n2022-01-17 12:31:03.493 IST\n2022-01-17 10:31:03.493 DEBUG [080-exec-5] o.s.security.web.FilterChainProxy - Securing GET /logo192.png\nDebug\n\n2022-01-17 12:31:03.493 IST\n\"Securing GET /logo192.png\"\n\n***But if I look in the logs some requests after I can get the valid auth:\nDebug\n2022-01-17 12:31:03.945 IST\n\"Set SecurityContextHolder to SecurityContextImpl [Authentication=OAuth2AuthenticationToken [Principal=com..security.oauth.CustomOAuth2User@, Credentials=[PROTECTED], Authenticated=true, Details=WebAuthenticationDetails [RemoteIpAddress=***, SessionId=9438C880A19C93AADJI206B9B8B3386], Granted Authorities=[ROLE_USER, SCOPE_https://www.googleapis.com/auth/userinfo.email, SCOPE_https://www.googleapis.com/auth/userinfo.profile, SCOPE_openid]]]\"\nDebug\n2022-01-17 12:31:03.945 IST\n\"Retrieved SecurityContextImpl [Authentication=OAuth2AuthenticationToken [Principal=com..security.oauth.CustomOAuth2User@, Credentials=[PROTECTED], Authenticated=true, Details=WebAuthenticationDetails [RemoteIpAddress=***, SessionId=9438C880A19C93AADJI206B9B8B3386], Granted Authorities=[ROLE_USER, SCOPE_https://www.googleapis.com/auth/userinfo.email, SCOPE_https://www.googleapis.com/auth/userinfo.profile, SCOPE_openid]]]\"\nDebug\n2022-01-17 12:31:03.945 IST\n\"Retrieved SecurityContextImpl [Authentication=OAuth2AuthenticationToken [Principal=com..security.oauth.CustomOAuth2User@, Credentials=[PROTECTED], Authenticated=true, Details=WebAuthenticationDetails [RemoteIpAddress=***, SessionId=9438C880A19C93AADJI206B9B8B3386], Granted Authorities=[ROLE_USER, SCOPE_https://www.googleapis.com/auth/userinfo.email, SCOPE_https://www.googleapis.com/auth/userinfo.profile, SCOPE_openid]]]\"\nDefault\n2022-01-17 12:31:03.944 IST\n2022-01-17 10:31:03.944 DEBUG [080-exec-8] o.s.security.web.FilterChainProxy - Securing GET /auth/api/getBasicInfo\nit looks like the session id is inconsistent\n\nI use spring security builtin oauth2 social login option,\nI implemented an OAuth2LoginSuccess class with the onAuthenticationSuccess method and inside of it I fetch the user the corresponds to the social id I got from the oauth:\nCustomOAuth2User oAuth2User = (CustomOAuth2User) authentication.getPrincipal();\nint sociald = oAuth2User.getAttribute(\"id\");\nUser user = usersUtils.getUserBySocailId(socialId);\nenter code here\n// add the user details to the Auth\nSecurityContextHolder.clearContext();\n((OAuth2AuthenticationToken) authentication).setDetails(user);\nSecurityContextHolder.getContext().setAuthentication(authentication);\n\nIf I debug inside the onAuthenticationSuccess I can see a valid auth with all the user details.\nafter the login I redirect to the home page and i send a auth get request to the server to check if there is a user logged in.\nthe problem is that 50% of the times the request is completed successfuly and the user can make authenticated requets.\nbut the other 50% i get redirected automaticly to Login page and when i check the log is see that Spring boot says that the user is unauthenticated and the auth is lost.\nBut in the onAuthenticationSuccess i can always see the correct auth.\nMy ApplicationSecurityConfig looks like this:\n    http.csrf().disable().authorizeRequests()\n            .antMatchers(\"/login*\", \"/signin/**\", \"/signup/**\", \"/oauth2/**\").permitAll()\n            .antMatchers(Constants.ADMIN_PREFIX + \"/**\").hasRole(\"ADMIN\")\n            .antMatchers(Constants.AUTH_PREFIX + \"/**\").hasAnyRole(\"ADMIN\", \"USER\")\n            .antMatchers(Constants.PUBLIC_PREFIX + \"/**\").permitAll()\n            .anyRequest().permitAll()\n            .and()\n            .exceptionHandling().authenticationEntryPoint(new UnauthenticatedRequestHandler())\n            .and()\n            .formLogin()\n            .passwordParameter(\"password\")\n            .usernameParameter(\"email\")\n            .loginPage(\"/Login\")\n            .loginProcessingUrl(\"/loginSecure\").permitAll().successHandler(new LoginSuccess()).failureHandler(new FailureSuccess())\n            .and()\n            .oauth2Login()\n            .loginPage(\"/Login\")\n            .userInfoEndpoint()\n            .userService(oAuth2UserService)\n            .and()\n            .successHandler(new OAuth2LoginSuccess())\n            .and()\n            .rememberMe()\n            .rememberMeParameter(\"remember-me\")\n            .tokenValiditySeconds((int) TimeUnit.DAYS.toSeconds(21))\n.userDetailsService(this.applicationUserService)\n            .and()\n            .logout()\n         .clearAuthentication(true).invalidateHttpSession(true).logoutSuccessUrl(\"/login\")\n            .addLogoutHandler(new CustomLogOutHandler());\n\nAnd this is the function i check if the user is logged in:\n   @GetMapping(Constants.AUTH_PREFIX + \"/checkUserLogged\")\npublic Integer checkUserLogged(Authentication authentication,HttpServletRequest request) {\n    try{\n        if (authentication != null) {\n            User (User) authentication.getDetails();\n            if (user == null) {\n                return -1;\n            }\n            return user.getId();\n        }\n    }\n    catch (Exception e){\n        logger.warning(e.getLocalizedMessage());\n    }\n    return -1;\n}\n\nbut when the problem occur it dosen't get to run the controller because spring security return unauthrozed error before.\nThank you in advance for your help\n",
    "AcceptedAnswerId": 70755813,
    "AcceptedAnswer": "I found the solution, I hope this could help.\nThe thing that caused the problem for me was that GCP and GAE use multiple instances of the server, and if the user is logged in a certain instance\ndoes not mean the other instances are familiar with it too because the Spring HTTPSession is in-memory.\nI Switched the Session platform to use the spring-session jdbc using the following configuration in the application.properties :\nspring.session.store-type=jdbc\n\n-- you can use redis instead of jdbc, as long as the session is stored in a shared place among all instances.\nalso added the transaction manager to the SecurtityConfig:\n@Bean\npublic PlatformTransactionManager transactionManager(DataSource dataSource) {\n    return new DataSourceTransactionManager(dataSource);\n}\n\nand added the following configurations :\n    http.csrf().disable()\n            .sessionManagement()\n            .maximumSessions(1)\n            .and()\n            .sessionCreationPolicy(SessionCreationPolicy.ALWAYS)\n\nIn addition like @stringy05 mentioned the authrizenClient Repository needs ti be updated too:\n    /**\n * Use the servlet container session store for authorized OAuth2 Clients\n */\n@Bean\npublic OAuth2AuthorizedClientRepository authorizedClientRepository() {\n    return new HttpSessionOAuth2AuthorizedClientRepository();\n}\n\nand add the .authorizedClientRepository line to the httpconfig:\n....\n                .oauth2Login()\n            .loginPage(\"/Login\")\n            .authorizedClientRepository(authorizedClientRepository)\n            .authorizationEndpoint().and()\n            .userInfoEndpoint()\n            .userService(oAuth2UserService)\n            .and()\n            .successHandler(new OAuth2LoginSuccess())\n\n....\nRegarding the GAE, I added the following line to the app.yaml file:\n  network:\n    session_affinity: true\n\n"
}
{
    "Id": 70664036,
    "PostTypeId": 1,
    "Title": "Find the missing module",
    "Body": "My question: when building a minimal JRE, how can one make sure that no required module is missing?\n\nTo illustrate the question, here is an example where I want to build a minimal JRE for my project. Let's assume for this example that logback is my only dependency.\nI run the following command to see what modules are required:\n$ jar --file=logback-core-1.2.3.jar --describe-module\nNo module descriptor found. Derived automatic module.\n\nlogback.core@1.2.3 automatic\nrequires java.base mandated\ncontains ch.qos.logback.core\ncontains ch.qos.logback.core.boolex\netc. (there are more \"contains ch.qos.logback.XXX\" lines)\n\nIt looks like I only need the java.base module and I build my minimal JRE accordingly:\njlink --output jre-min --add-modules java.base\n\nHowever when running the project with the minimal JRE, I encounter issues using logback's email logger (malformed emails over TLS). Through trial and error, I find that jdk.crypto.cryptoki module is also required:\njlink --output jre-min --add-modules java.base,jdk.crypto.cryptoki\n\nNow my project works fine. How could I have avoided the trial & error step?\n",
    "AcceptedAnswerId": 70733470,
    "AcceptedAnswer": "The JAR you're using there has \"no module descriptor\" (see first line of output) and thus can't tell you what modules it depends on, so you have to find out yourself. The canonical tool for that is jdeps but it may not be enough.\nStatic Dependencies\nI wrote a jdeps tutorial that gets you started, but the interesting bit is this section. The gist is this command:\njdeps --class-path 'jars/*' -summary -recursive logback-core-1.2.3.jar\n\nWhere jars contains all Logback dependencies. (If you don't have those at hand, you can leave --class-path and -recursive out, but then you don't know which modules the dependencies.) Besides a few other things, the output will list the dependencies on JDK modules.\nDynamic Dependencies\njdeps works by analyzing the byte code, which means it will only find dependencies that are statically linked. Consequently, if a JAR uses reflection, the service loader, or other mechanisms to avoid explicitly mentioning the classes it wants to use, jdeps will not notice them.\nTo find those cases, you can run an app with the java command-line option -XX:DumpLoadedClassList=classes.lst - it will generate a file classes.lst that lists all loaded classes.\nMinimal Runtime\nNote that the base module java.base uses a lot of services that are provided by other modules, for example locale data by jdk.localedata. That means a minimal runtime (i.e. one where service provider modules are not included) may miss things that an app needs (in the example, maybe locales).\nYou can list services with java --describe-module java.base (see list of uses ... in output) and then find potentiual providers for each with jlink's --suggest-providers option.\nYou can include all of possible providers with jlink's --bind-services option, but that immediately abandons the idea of a \"minimal\" runtime as it will include a lot of modules. If you're going for \"minimal\", probably better to include them one by one as needed.\nWhatever you do, make sure to thoroughly test your app on the custom-made runtime.\n"
}
{
    "Id": 70890854,
    "PostTypeId": 1,
    "Title": "2 files found with path 'lib/arm64-v8a/libc++_shared.so' from inputs...-react native",
    "Body": "I am trying to enable package of ffmpeg-kit-react-native in react-native.\nThe sample commands given in the example executes successfully. But I want to use libwebp for converting gif files to webp which is under package named video. As instrcuted . I have to enable the package to use some libraries.\n\n2.2.1 Enabling a Package on Android\nEdit android/build.gradle file and add the package name in ext.ffmpegKitPackage variable.\next {\n   ffmpegKitPackage = \"\"\n}\n\n\nSo I added a line in the node_module/ffmpeg-kit-react-native/android/build.gradle\nandroid {\n  compileSdkVersion 30\n\n  defaultConfig {\n    minSdkVersion safeExtGet('ffmpegKitPackage', 'https').contains(\"-lts\") ? 16 : 24\n    targetSdkVersion 30\n    versionCode 451\n    versionName \"4.5.1\"\n  }\n\n  buildTypes {\n    release {\n      minifyEnabled false\n    }\n  }\n  lintOptions {\n    disable 'GradleCompatible'\n  }\n  compileOptions {\n    sourceCompatibility JavaVersion.VERSION_1_8\n    targetCompatibility JavaVersion.VERSION_1_8\n  }\n\n  rootProject.ext.ffmpegKitPackage = \"video\" // Added this line here \n\n}\n\nError:\n* What went wrong:\nExecution failed for task ':app:mergeDebugNativeLibs'.\n> A failure occurred while executing com.android.build.gradle.internal.tasks.MergeJavaResWorkAction\n   > 2 files found with path 'lib/arm64-v8a/libc++_shared.so' from inputs:\n      - C:\\Users\\ADMIN\\.gradle\\caches\\transforms-3\\7403ebe5571a2ce5a6a5fc9876af4814\\transformed\\jetified-react-native-0.66.4\\jni\n      - C:\\Users\\ADMIN\\.gradle\\caches\\transforms-3\\4be54e44fe38656741a8345504588323\\transformed\\jetified-ffmpeg-kit-video-4.5.1-1\\jni\n     If you are using jniLibs and CMake IMPORTED targets, see\n     https://developer.android.com/r/tools/jniLibs-vs-imported-targets\n\nI have tried ./gradlew clean but problem is still there.\nHow to fix this error? Thanks\n",
    "AcceptedAnswerId": 70893407,
    "AcceptedAnswer": "add this in your node_module/ffmpeg-kit-react-native/android/build.gradle\nandroid{\n  packagingOptions {\n      pickFirst 'lib/x86/libc++_shared.so'\n      pickFirst 'lib/x86_64/libc++_shared.so'\n      pickFirst 'lib/armeabi-v7a/libc++_shared.so'\n      pickFirst 'lib/arm64-v8a/libc++_shared.so'\n  }\n  rootProject.ext.ffmpegKitPackage = \"video\"\n}\n\nffmpeg-kit-react-native has already talked about this error here. https://github.com/tanersener/ffmpeg-kit/wiki/Tips#2-depending-another-android-library-containing-libc_sharedso\n"
}
{
    "Id": 71006506,
    "PostTypeId": 1,
    "Title": "Java collector teeing a list of inputs",
    "Body": "I am trying to implement a simple collector, which takes a list of collectors and simultaneously collects values in slightly different ways from a stream.\nIt is quite similar to Collectors.teeing, but differs in that it\n\nReceives a list of collectors instead of just two\nRequires all collectors to produce a value of the same type\n\nThe type signature I want to have is\npublic static  Collector> list(\n      final List> downstreamCollectors);\n\nOne way to create such a collector would be to recursively pair up teeing collectors, like so:\npublic static  Collector> list(\n    final List> downstreamCollectors) {\n  return listrec(\n      Collectors.collectingAndThen(downstreamCollectors.get(0), List::of),\n      downstreamCollectors.stream().skip(1).toList());\n}\n\nprivate static  Collector> listrec(\n    final Collector> teedCollectors,\n    final List> downstreamCollectors) {\n  if (downstreamCollectors.size() == 0) {\n    return teedCollectors;\n  } else {\n    return listrec(\n        teeing(\n            teedCollectors,\n            downstreamCollectors.get(0),\n            (l, s) -> Stream.concat(l.stream(), Stream.of(s)).toList()),\n        downstreamCollectors.stream().skip(1).toList());\n  }\n}\n\nSomething feels a little \"off\" with this solution, so I am trying to create the collector myself, something like:\npublic static  Collector> list2(\n    final List> downstreamCollectors) {\n  return Collector.of(\n      () -> downstreamCollectors.stream().map(c -> c.supplier().get()).toList(),\n      (accumulators, t) ->\n          IntStream.range(0, downstreamCollectors.size())\n              .forEach(\n                  i -> downstreamCollectors.get(i).accumulator().accept(accumulators.get(i), t)),\n      (accumulator1, accumulator2) ->\n          IntStream.range(0, downstreamCollectors.size())\n              .mapToObj(\n                  i ->\n                      downstreamCollectors\n                          .get(i)\n                          .combiner()\n                          .apply(accumulator1.get(i), accumulator2.get(i)))\n              .toList(),\n      accumulators ->\n          IntStream.range(0, downstreamCollectors.size())\n              .mapToObj(i -> downstreamCollectors.get(i).finisher().apply(accumulators.get(i)))\n              .toList());\n}\n\nBecause of the unbounded wildcard in the downstream collectors' accumulator type, this doesn't compile. Changing the type signature to\npublic static  Collector> list2(\n    final List> downstreamCollectors);\n\nsolves the problem, but unfortunately renders the method much less usable as the downstream collectors (like the built in collectors from java.util.stream.Collectors) typically would have a unbounded wildcard in the accumulator type.\nIs there another way to implement this, keeping the wildcard in the method signature?\nI am using OpenJDK 17.0.2.\n",
    "AcceptedAnswerId": 71019502,
    "AcceptedAnswer": "Handling a list of collectors with arbitrary accumulator types as a flat list can\u2019t be done in a type safe way, as it would require declaring n type variables to capture these types, where n is the actual list size.\nTherefore, you can only implement the processing as a composition of operations, each with a finite number of components know at compile time, like your recursive approach.\nThis still has potential for simplifications, like replacing downstreamCollectors.size() == 0 with downstreamCollectors.isEmpty() or downstreamCollectors.stream().skip(1).toList() with a copying free downstreamCollectors.subList(1, downstreamCollectors.size()).\nBut the biggest impact has replacing the recursive code with a Stream Reduction operation:\npublic static  Collector> list(List> collectors) {\n    return collectors.stream()\n            .>>map(c-> Collectors.collectingAndThen(c, List::of))\n            .reduce((c1, c2) -> teeing(c1, c2,\n                        (l1, l2) -> Stream.concat(l1.stream(), l2.stream()).toList()))\n            .orElseThrow(() -> new IllegalArgumentException(\"no collector specified\"));\n}\n\nThis may work fairly well if you don\u2019t have a really large number of collectors to compose. A disadvantage of this concise solution is that every result will be wrapped into a single element list before the actual merging of results and even the result merging may bear multiple list copying operations.\nThis result processing can be optimized using\npublic static  Collector> list(List> collectors) {\n    int num = collectors.size();\n    switch(num) {\n        case 0: throw new IllegalArgumentException(\"no collector specified\");\n        case 1: return collectingAndThen(collectors.get(0), List::of);\n        case 2: return teeing(collectors.get(0), collectors.get(1), List::of);\n        case 3: return teeing(teeing(collectors.get(0), collectors.get(1), List::of),\n                           collectors.get(2), (l,r) -> List.of(l.get(0), l.get(1), r));\n        default:\n    }\n    Collector> c = teeing(collectors.get(0), collectors.get(1), (r1, r2) -> {\n        var list = new ArrayList(num);\n        list.add(r1);\n        list.add(r2);\n        return list;\n    });\n    for(int ix = 2; ix < num; ix ++) {\n        c = teeing(c, collectors.get(ix), (list, r) -> { list.add(r); return list; });\n    }\n    return collectingAndThen(c, List::copyOf);\n}\n\nThis provides special cases for small numbers of collectors whose results can be used to construct an immutable result list directly. For the other cases, all results are added to an ArrayList first, preventing excessive list copying, before converting the list to the final immutable list. This last step could be omitted, if getting an immutable result list is not important, I just tried to be as close to the Stream.toList() behavior of the original approach as possible.\nThere\u2019s still an unbalanced recursive structure behind the scenes during the Stream processing which prohibits really large numbers of collectors. There are two approaches to solve this.\n\nImplement your own type safe variant of teeing which exposes the intermediate container type, to allow to build a balanced tree and collecting all results into a list by traversing this tree without additional intermediate storage.\n\nAbandon the type safety and implement the collector with a flat list and raw types. Try to limit the unsafe code as much as possible.\n\n\nBut this might not be needed when you have an estimate of the expected number of collectors to \u201ctee\u201d and find the first solution working good enough.\n"
}
{
    "Id": 70756414,
    "PostTypeId": 1,
    "Title": "java.lang.reflect.InaccessibleObjectException: Unable to make field private final java.util.Comparator java.util.TreeMap.comparator accessible:module",
    "Body": "This is my first cucumber project and i followed a tutorial when setting everything up. It all seems to be the same but for some reason i get this:\njava.lang.ExceptionInInitializerError.\nCaused by: java.lang.reflect.InaccessibleObjectException: Unable to make field private final java.util.Comparator java.util.TreeMap.comparator accessible: module java.base does not \"opens java.util\" to unnamed module @74ad1f1f\nAny idea how to solve this error ?\nBelow i have posted everything that comes out in my console as well as my pom file in case there is an issue with my dependencies eventhough the guy from the tutorial's pom file is identical.\nThis is everything that comes out in my Console.\n[31mFailed scenarios:[0m\n[31muni/login/Login.feature:3 [0m# Scenario: Enter the system.\n1 Scenarios ([31m1 failed[0m)\n5 Steps ([31m1 failed[0m, [36m4 skipped[0m)\n0m0.185s\n\njava.lang.ExceptionInInitializerError\n    at cucumber.deps.com.thoughtworks.xstream.XStream.setupConverters(XStream.java:820)\n    at cucumber.deps.com.thoughtworks.xstream.XStream.(XStream.java:574)\n    at cucumber.deps.com.thoughtworks.xstream.XStream.(XStream.java:530)\n    at cucumber.runtime.xstream.LocalizedXStreams$LocalizedXStream.(LocalizedXStreams.java:50)\n    at cucumber.runtime.xstream.LocalizedXStreams.newXStream(LocalizedXStreams.java:37)\n    at cucumber.runtime.xstream.LocalizedXStreams.get(LocalizedXStreams.java:29)\n    at cucumber.runtime.StepDefinitionMatch.runStep(StepDefinitionMatch.java:37)\n    at cucumber.runtime.Runtime.runStep(Runtime.java:300)\n    at cucumber.runtime.model.StepContainer.runStep(StepContainer.java:44)\n    at cucumber.runtime.model.StepContainer.runSteps(StepContainer.java:39)\n    at cucumber.runtime.model.CucumberScenario.run(CucumberScenario.java:44)\n    at cucumber.runtime.junit.ExecutionUnitRunner.run(ExecutionUnitRunner.java:102)\n    at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:63)\n    at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:18)\n    at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)\n    at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)\n    at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:413)\n    at cucumber.runtime.junit.FeatureRunner.run(FeatureRunner.java:70)\n    at cucumber.api.junit.Cucumber.runChild(Cucumber.java:95)\n    at cucumber.api.junit.Cucumber.runChild(Cucumber.java:38)\n    at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)\n    at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)\n    at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:413)\n    at cucumber.api.junit.Cucumber.run(Cucumber.java:100)\n    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:93)\n    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:40)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:529)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:756)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:452)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:210)\n    at \u273d.Given \u041f\u043e\u0442\u0440\u0435\u0431\u0438\u0442\u0435\u043b\u044f\u0442 \u043e\u0442\u0432\u0430\u0440\u044f \u0435\u043a\u0440\u0430\u043d\u0430 \u0437\u0430 \u0432\u0445\u043e\u0434 \u0432 \u0441\u0438\u0441\u0442\u0435\u043c\u0430\u0442\u0430(uni/login/Login.feature:4)\nCaused by: java.lang.reflect.InaccessibleObjectException: Unable to make field private final java.util.Comparator java.util.TreeMap.comparator accessible: module java.base does not \"opens java.util\" to unnamed module @74ad1f1f\n    at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:357)\n    at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:297)\n    at java.base/java.lang.reflect.Field.checkCanSetAccessible(Field.java:177)\n    at java.base/java.lang.reflect.Field.setAccessible(Field.java:171)\n    at cucumber.deps.com.thoughtworks.xstream.core.util.Fields.locate(Fields.java:39)\n    at cucumber.deps.com.thoughtworks.xstream.converters.collections.TreeMapConverter.(TreeMapConverter.java:50)\n    at cucumber.deps.com.thoughtworks.xstream.XStream.setupConverters(XStream.java:820)\n    at cucumber.deps.com.thoughtworks.xstream.XStream.(XStream.java:574)\n    at cucumber.deps.com.thoughtworks.xstream.XStream.(XStream.java:530)\n    at cucumber.runtime.xstream.LocalizedXStreams$LocalizedXStream.(LocalizedXStreams.java:50)\n    at cucumber.runtime.xstream.LocalizedXStreams.newXStream(LocalizedXStreams.java:37)\n    at cucumber.runtime.xstream.LocalizedXStreams.get(LocalizedXStreams.java:29)\n    at cucumber.runtime.StepDefinitionMatch.runStep(StepDefinitionMatch.java:37)\n    at cucumber.runtime.Runtime.runStep(Runtime.java:300)\n    at cucumber.runtime.model.StepContainer.runStep(StepContainer.java:44)\n    at cucumber.runtime.model.StepContainer.runSteps(StepContainer.java:39)\n    at cucumber.runtime.model.CucumberScenario.run(CucumberScenario.java:44)\n    at cucumber.runtime.junit.ExecutionUnitRunner.run(ExecutionUnitRunner.java:102)\n    at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:63)\n    at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:18)\n    at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)\n    at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)\n    at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:413)\n    at cucumber.runtime.junit.FeatureRunner.run(FeatureRunner.java:70)\n    at cucumber.api.junit.Cucumber.runChild(Cucumber.java:95)\n    at cucumber.api.junit.Cucumber.runChild(Cucumber.java:38)\n    at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)\n    at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)\n    at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:413)\n    at cucumber.api.junit.Cucumber.run(Cucumber.java:100)\n    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:93)\n    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:40)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:529)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:756)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:452)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:210)\n\nAnd this is my pom.xml\n\n  4.0.0\n  uni.ais\n  first-cucumber-project\n  1.1.0-SNAPSHOT\n  first-cucumber-project-gr\n  \n    1.8\n    1.8\n    UTF-8\n  \n  \n    \n        info.cukes\n        cucumber-java\n        1.2.5\n    \n    \n        info.cukes\n        cucumber-junit\n        1.2.5\n    \n  \n\n\n",
    "AcceptedAnswerId": 70776589,
    "AcceptedAnswer": "I solved my problem. Turns out the JRE that eclipse had automatically downloaded and was using wasn't compatible with this version of cucumber. I manually changed the path to a jre 1.8 that i had in my ProgramFilex(x86)/Java folder and now everything works fine.\n"
}
{
    "Id": 70786275,
    "PostTypeId": 1,
    "Title": "Reading encrypted private key in PKCS#8 format through bouncycastle, Java failing in docker container",
    "Body": "I am trying to read a PKCS#8 private key which looks like following:\nkey.k8 --> (Sample key. Passphrase - 123456):\n-----BEGIN ENCRYPTED PRIVATE KEY-----\nMIIFLTBXBgkqhkiG9w0BBQ0wSjApBgkqhkiG9w0BBQwwHAQILbKY9hPxYSoCAggA\nMAwGCCqGSIb3DQIJBQAwHQYJYIZIAWUDBAEqBBCvaGt2Hmm2NpHpxbLvHKyOBIIE\n0IQ7dVrAGXLZl0exYIvyxLAu6zO00jL6b3sb/agTcCFOz8JU6fBanxY0d5aYO4Dn\nmynQG7BoljU470s0zIwW/wk0MmdUFl4nXWBX/4qnG0sZqZ9KZ7I8R/WrBkmpX8C/\n4pjdVhu8Ht8dfOYbkbjMBTohDJz8vJ0QwDIXi9yFjjef+QjwrFOl6kAeDJFVMGqc\ns7K/wOnhsL1XxfW9uTulPiZh5YTZKcatMkeGDR7c+cg5I+Mutim92diWuCekhNoa\nuvhUy1M3cbs7Azp1Mhz+V0CDKklI95EvN4u23WhiJPCjAofC/e45/heOP3Dwm7WZ\nzHEY1C/X8PsTl6MEEIF3ZJP+4Vr0corAs1L2FqE6oOng8dFFYmF5eRyBx6bxFd05\niYbfOH24/b3qtFKPC689kGEd0gWp1dwES35SNNK+cJqVRTjgI0oKhOai3rhbGnmp\ntx4+JqploQgTorj4w9asbtZ/qZA2mYSSR/Q64SHv7LfoUCI9bgx73MqRQBgvI5yS\nb4BoFBnuEgOduZLaGKGjKVW3m5/q8oiDAaspcSLCJMIrdOTYWJB+7mfxX4Xy0vEe\n5m2jXpSLQmrfjgpSTpHDKi/3b6OzKOcHjSFBf8IoiHuLc5DVvLECzDUxxaMrTZ71\n0YXvEPwl2R9BzEANwwR9ghJvFg1Be/d5W/WA1Efe6cNQNBlmErxD6l+4KDUgGjTr\nAaksp9SZAv8uQAsg7C57NFHpTA5Hznr5JctL+WlO+Gk0cAV6i4Py3kA6EcfatsnS\nPqP2KbxT+rb2ATMUZqgWc20QvDt6j0CTA1BuVD1PNhnAUFvb2ocyEEXOra22DPPS\nUPu6jirSIyFcjqFjJ9A1FD9L4/UuX2UkDSLqblFlYB1+G55KZp+EKz8SZoN5qXy1\nLyMtnacEP5OtRDrOjopzVNiuV1Uv63M9QVi1hZlVLJEomgjWuvuyEuIwDaY2uryW\nvx+jJEZyySFkb1JwAbrm+p6sCTFnbQ/URKC2cit/FJyKqNim6VQvGL8Sez34qV3z\nD13QJgTZfsy+BaZoaQ6cJTXtJ8cN0IcQciOiDNBKMW66zO6ujS8G+KNviNQypDm6\nh4sOgjMqLaZ4ezPEdNj/gaxV7Y15nVRu0re8dVkaa5t9ft/sh6A+yeTD5tS5hHkf\nNI7uJPTaTXVoz7xq2PAJUTWujMLMZKtmNOzNqYvxWRy3tCOFobBQkMxqEBEwHd+x\nSA+gFcJKJ+aNfCGZJ5fFr8rNlhtOF6uMwOAlfiUlP/pCUDUCKPjZVj4K95yNc8Io\njSZSPb5tGPe0HqXgc6IAfQarlUZt90oVtzL0OfOfTxe1bEzS2ccNadbx/6vjLBc4\nq5UuUBppl3rXpbuZ7J1Rp3n2byF4APxFdT2LHKq+MYMfWUToau/TCMT4lFIM9tM8\n7TuuyUT2PKzf/xlsl4iScw96z9xxGPQrXn7IA2W5iL+0eCLztJdjNRX1FisdfIBL\nPraOVlmF8jHKbFdRZ8Yi8pApbQjvHi24g7dX7u/cq1FH/VE+nJ0O8YVCYVDw13CW\nh0p7yD7BuB0R+0WnR0yvkp30vK4/rtCB+Ob8bH/+HvAZrAU5X8jq/wsQbLkrLHZV\n6A6GGfX8+hy5AoaXsH1BHnMyXkaF6Mv29z8JcslDJxX/\n-----END ENCRYPTED PRIVATE KEY-----\n\nFollowing code is being used to parse the private key:\n InputStream privateKeyInputStream = getPrivateKeyInputStream(); // reads the key file from classpath and share as DataStream\n logger.info(\"InputStreamExists --> {} \", privateKeyInputStream.available());\n PEMParser pemParser = new PEMParser(new InputStreamReader(privateKeyInputStream));\n Object pemObject = pemParser.readObject();\n if (pemObject instanceof PKCS8EncryptedPrivateKeyInfo) {\n     // Handle the case where the private key is encrypted.\n     PKCS8EncryptedPrivateKeyInfo encryptedPrivateKeyInfo = (PKCS8EncryptedPrivateKeyInfo) pemObject;\n     InputDecryptorProvider pkcs8Prov =\n            new JceOpenSSLPKCS8DecryptorProviderBuilder().build(passphrase.toCharArray());\n     privateKeyInfo = encryptedPrivateKeyInfo.decryptPrivateKeyInfo(pkcs8Prov); // fails here\n}\n\n\nInputStream resourceAsStream = null;\n    if (\"local\".equals(privateKeyMode)) {\n      resourceAsStream = this.getClass().getResourceAsStream(privateKeyPath);\n    } else {\n      File keyFile = new File(privateKeyPath);\n      logger.info(\n          \"Key file found in {} mode. FileName : {}, Exists : {}\",\n          privateKeyMode,\n          keyFile.getName(),\n          keyFile.exists());\n      try {\n        resourceAsStream = new DataInputStream(new FileInputStream(keyFile));\n      } catch (FileNotFoundException e) {\n        e.printStackTrace();\n      }\n\nWhen I am running this code through intelliJ on windows, the code works fine but when I run it through docker container I am getting following exception:\norg.bouncycastle.pkcs.PKCSException: unable to read encrypted data: failed to construct sequence from byte[]: Extra data detected in stream\nsnowflake-report-sync    |      at org.bouncycastle.pkcs.PKCS8EncryptedPrivateKeyInfo.decryptPrivateKeyInfo(Unknown Source) ~[bcpkix-jdk15on-1.64.jar!/:1.64.00.0]\nsnowflake-report-sync    |      at com.optum.snowflakereportsync.configuration.SnowFlakeConfig.getPrivateKey(SnowFlakeConfig.java:103) ~[classes!/:na]\nsnowflake-report-sync    |      at com.optum.snowflakereportsync.configuration.SnowFlakeConfig.getConnectionProperties(SnowFlakeConfig.java:67) ~[classes!/:na]\n\nFollowing is Dockerfile used:\nFROM adoptopenjdk/openjdk11-openj9:latest\nCOPY build/libs/snowflake-report-sync-*.jar snowflake-report-sync.jar\nRUN mkdir /encryption-keys\nCOPY encryption-keys/ /encryption-keys/ #keys are picked from docker filesystem when running in container\nEXPOSE 8080\nCMD java -Dcom.sun.management.jmxremote -noverify ${JAVA_OPTS} -jar snowflake-report-sync.jar\n\nOptions tried:\n\nEnsured that key file is being read while running in container. Logger \"InputStreamExists --> {}\" gives number of bytes\nRan dos2unix on key.k8 just to make sure there are no Window's \"^M\" characters which be could be causing issue as container is linux one : FROM adoptopenjdk/openjdk11-openj9:latest\n\nNot sure what I am doing wrong but any help or pointers would be appreciated.\n",
    "AcceptedAnswerId": 70905140,
    "AcceptedAnswer": "Like @Bragolgirith suspected, BouncyCastle seems to have problems with OpenJ9. I guess it is not a Docker issue, because I can reproduce it on GitHub Actions, too. It is also not limited to BouncyCastle 1.64 or 1.70, it happens in both versions. It also happens on OpenJ9 JDK 11, 14, 17 on Windows, MacOS and Linux, but for the same matrix of Java and OS versions it works on Adopt-Hotspot and Zulu.\nHere is an example Maven project and a failed matrix build. So if you select another JVM type, you should be fine. I know that @Bragolgirith already suggested that, but I wanted to make the problem reproducible for everyone and also provide an MCVE, in case someone wants to open a BC or OpenJ9 issue.\nP.S.: It is also not a character set issue with the InputStreamReader. This build fails exactly the same as before after I changed the constructor call.\n\nUpdate: I have created BC-Java issue #1099. Let's see what the maintainers can say about this.\n\nUpdate 2: The solution to your problem is to explicitly set the security provider to BC for your input decryptor provider. Thanks to David Hook for his helpful comment in #1099.\nBouncyCastleProvider securityProvider = new BouncyCastleProvider();\nSecurity.addProvider(securityProvider);\n\n// (...)\n\nInputDecryptorProvider pkcs8Prov = new JceOpenSSLPKCS8DecryptorProviderBuilder()\n  // Explicitly setting security provider helps to avoid ambiguities\n  // which otherwise can cause problems, e.g. on OpenJ9 JVMs\n  .setProvider(securityProvider)\n  .build(passphrase.toCharArray());\n\nSee this commit and the corresponding build, now passing on all platforms, Java versions and JVM types (including OpenJ9).\nBecause @Bragolgirith mentioned it in his answer: If you want to avoid the explicit new JceOpenSSLPKCS8DecryptorProviderBuilder().setProvider(securityProvider), the call Security.insertProviderAt(securityProvider, 1) instead of simply Security.addProvider(securityProvider) would in this case also solve the problem. But this holds true only as long as no other part of your code or any third-party library sets another provider to position 1 afterwards, as explained in the Javadoc. So maybe it is not a good idea to rely on that.\n"
}
{
    "Id": 70995023,
    "PostTypeId": 1,
    "Title": "What's the difference between String.format() and str.formatted() in Java?",
    "Body": "I know that method String.format() is nearly the same as method System.out.printf() except it returns a String. But I could hardly find the introduction about method \"formatted\" which is defined as follows:\npublic String formatted(Object... args) {\n        return new Formatter().format(this, args).toString();\n}\n\nAnd I know the functions of two codes below are the same.\nString str1 = String.format(\"%s\", \"abab\");\nSystem.out.println(str1);\n\nString str2;\nstr2 = \"%s\".formatted(\"abab\");\nSystem.out.println(str2);\n\nTherefore I'm wandering what's the difference between them. Thank you!\n",
    "AcceptedAnswerId": 70997302,
    "AcceptedAnswer": "Make sure you use a good IDE so that you have easy access to browse into JDK source code. In Eclipse say, use F3 to open to any declaration. IntelliJ IDEA has similar feature.\nIf you view the source code for both methods, you can see these calls are identical except that variables this is interchanged with format when comparing the instance vs static method:\npublic String formatted(Object... args) {\n    return new Formatter().format(this, args).toString();\n}\npublic static String format(String format, Object... args) {\n    return new Formatter().format(format, args).toString();\n}\n\nSo as you've observed: String.format(str, args) is same as str.formatted(args)\n"
}
{
    "Id": 71041836,
    "PostTypeId": 1,
    "Title": "GitHub Actions: Required property is missing: shell",
    "Body": "Introduction\nI am currently to crate a composite GitHub Actions that build a JavaDoc from Java project and publish it automatically to a static page with GitHub Page.\nProblematic\nBut I got this error when I try to run it:\nCurrent runner version: '2.287.1'\nOperating System\nVirtual Environment\nVirtual Environment Provisioner\nGITHUB_TOKEN Permissions\nSecret source: Actions\nPrepare workflow directory\nPrepare all required actions\nGetting action download info\nDownload action repository 'MathieuSoysal/Javadoc-publisher.yml@v2.0.2' (SHA:878c07f835dd9bcbb8800090d109c91b0f0d4581)\nError: MathieuSoysal/Javadoc-publisher.yml/v2.0.2/action.yml (Line: 29, Col: 5): Required property is missing: shell\nError: MathieuSoysal/Javadoc-publisher.yml/v2.0.2/action.yml (Line: 29, Col: 5): Required property is missing: shell\nError: GitHub.DistributedTask.ObjectTemplating.TemplateValidationException: The template is not valid. MathieuSoysal/Javadoc-publisher.yml/v2.0.2/action.yml (Line: 29, Col: 5): Required property is missing: shell\n   at GitHub.DistributedTask.ObjectTemplating.TemplateValidationErrors.Check()\n   at GitHub.Runner.Worker.ActionManifestManager.ConvertRuns(IExecutionContext executionContext, TemplateContext templateContext, TemplateToken inputsToken, String fileRelativePath, MappingToken outputs)\n   at GitHub.Runner.Worker.ActionManifestManager.Load(IExecutionContext executionContext, String manifestFile)\nError: Fail to load MathieuSoysal/Javadoc-publisher.yml/v2.0.2/action.yml\n\nAffected code:\nname: Deploy Javadoc\ndescription: 'Automatically  generate your Javadoc from your maven project and deploy it with GitHub Page on javadoc branch.'\nbranding:\n  icon: 'book-open'\n  color: 'white'\ninputs:\n  java-version:  # version of java\n    description: 'Java version inside your project'\n    required: true\n    default: '17'\n  GITHUB_TOKEN: # GitHub Token\n    description: 'The GitHub token the GitHub repository'\n    required: true\n  javadoc-branch: # branch where the javadoc is hosted\n    description: 'Branch where the javadoc is hosted'\n    required: true\n    default: javadoc\n \nruns:\n  using: \"composite\"\n  steps:\n  - uses: actions/checkout@v2\n    with:\n      fetch-depth: 0\n  - uses: actions/setup-java@v2\n    with:\n      java-version: ${{ inputs.java-version }}\n      distribution: 'adopt'\n  - name: Generate Javadoc\n    run: mvn org.apache.maven.plugins:maven-javadoc-plugin:3.3.1:aggregate\n  - name: Deploy \ud83d\ude80\n    uses: JamesIves/github-pages-deploy-action@4.1.8\n    with:\n      GITHUB_TOKEN: ${{ inputs.GITHUB_TOKEN }}\n      BRANCH: ${{ inputs.javadoc-branch }}\n      CLEAN: true\n      FOLDER: target/site/apidocs\n      TARGET_FOLDER: javadoc\n\nCode that execute the GitHub Actions in question:\nname: Deploy Javadoc\n\non:\n  push:\n    branches:\n      - master\n\njobs:\n  publish:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Deploy JavaDoc \ud83d\ude80\n        uses: MathieuSoysal/Javadoc-publisher.yml@v2.0.3\n        with:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          javadoc-branch: javadoc\n          java-version: 17\n\nQuestion\nAnyone have an idea to solve this problem?\n",
    "AcceptedAnswerId": 71042698,
    "AcceptedAnswer": "When using composite actions, you have to specify the shell.\nAs you don\u2019t specify a runner type in composite actions, you need to specify the shell instead for each action.\nIn your case, the problem is in this step, you need to add shell: bash here:\n- name: Generate Javadoc\n  shell: bash\n  run: mvn org.apache.maven.plugins:maven-javadoc-plugin:3.3.1:aggregate\n\nDocs: https://docs.github.com/en/actions/creating-actions/creating-a-composite-action#creating-an-action-metadata-file\n"
}
{
    "Id": 70791142,
    "PostTypeId": 1,
    "Title": "Could not set unknown property 'mainClassName' for extension 'springBoot' of type org.springframework.boot.gradle.dsl.SpringBootExtension",
    "Body": "I have build.gradle like this and it works :\nplugins {\n    id 'org.springframework.boot' version '2.5.8' apply false\n    ...\n}\n...\n    springBoot {\n        mainClassName = 'com.mir3.service.contactfileparser.Main'\n    }\n\nbut if I upgrade spring boot version to 2.6.2 it fails with error:\nplugins {\n    id 'org.springframework.boot' version '2.6.2' apply false\n    ...\n}\n...\n    springBoot {\n        mainClassName = 'com.mir3.service.contactfileparser.Main'\n    }\n\nError text is:\nA problem occurred evaluating root project 'myProject'.\n> Could not set unknown property 'mainClassName' for extension 'springBoot' of type org.springframework.boot.gradle.dsl.SpringBootExtension.\n\nHow can I fix it ? What is the proper way to migrate from 2.5.8 to 2.6.2 ?\n",
    "AcceptedAnswerId": 70792363,
    "AcceptedAnswer": "Use:\nspringBoot {\n    mainClass = 'com.mir3.service.contactfileparser.Main'\n}\n\nSpringBootExtension has:\n/**\n * Returns the fully-qualified name of the application's main class.\n * @return the fully-qualified name of the application's main class\n * @since 2.4.0\n */\npublic Property getMainClass() {\n    return this.mainClass;\n}\n\nmainClassName was deprecated in favour of mainClass in 2.4.0 and was scheduled for removal in 2.6.0. It was removed with this commit: Remove deprecated code flagged for removal\n"
}
{
    "Id": 70793779,
    "PostTypeId": 1,
    "Title": "Idiomatic way to remove country code from currency format?",
    "Body": "Somewhere between Java 11 and 17 currency formatting changed to where this:\nNumberFormat.getCurrencyInstance(Locale.CANADA_FRENCH).format(100.00)\n\nwould print 100,00\u00a0$\u00a0CA instead of 100,00\u00a0$.\nIs there a better way than this to remove the country code CA?\nvar currencyFormat = NumberFormat.getCurrencyInstance(Locale.CANADA_FRENCH);\nif (currencyFormat instanceof DecimalFormat decimalFormat) {\n    var symbols = DecimalFormatSymbols.getInstance(Locale.CANADA_FRENCH);\n    symbols.setCurrencySymbol(\"$\");\n    decimalFormat.setDecimalFormatSymbols(symbols);\n}\n\nSeems a bit much just to get back something that was the default behavior up until recently.\n",
    "AcceptedAnswerId": 70911567,
    "AcceptedAnswer": "I dug a bit into this, the JDK locale data comes from Unicode CLDR by default, and it seems they reverted from $ CA to $ back in August, see CLDR-14862 and this commit (expand common/main/fr_CA.xml and then go to lines 5914/5923).\nThis was part of v40, released in October, so too late for JDK 17 whose doc says it uses CLDR v35.1\n(which was introduced in Java 13)\nbut it seems it was updated to v39 in April 2021 and\nthey forgot the release note\n(JDK 16 appears to have been upgraded to v38 already).\nCLDR v40 is planned for JDK 19.\nYou may want to run your application using the COMPAT locales first, with\n-Djava.locale.providers=COMPAT,CLDR,SPI\n\n(found here but see also LocaleServiceProvider)\nThis will use the locales compatible with Java 8, where this issue is not present.\n"
}
{
    "Id": 71051529,
    "PostTypeId": 1,
    "Title": "How to replace deprecated SeekToCurrentErrorHandler with DefaultErrorHandler (spring-kafka)?",
    "Body": "I am trying to find a way to use the new DefaultErrorHandler instead of deprecated SeekToCurrentErrorHandler in spring-kafka 2.8.1, in order to override the retry default behavior in case of errors. I want to \"stop\" the retry process, so if an error occurs, no retry should be done.\nNow I have, in a config class, the following bean that works as expected:\n@Bean\npublic KafkaListenerContainerFactory> kafkaListenerContainerFactory() {\n    ConcurrentKafkaListenerContainerFactory factory = new ConcurrentKafkaListenerContainerFactory();\n    factory.setErrorHandler(new **SeekToCurrentErrorHandler(new FixedBackOff(0L, 1L)**));\n    factory.setConsumerFactory(requestConsumerFactory());\n    factory.setReplyTemplate(kafkaTemplate());\n    return factory;\n}\n\nSince in this spring kafka version, the STCEH is deprecated, I tried to do the following, in the same config class:\n@Bean\npublic DefaultErrorHandler eh() {\n    return new DefaultErrorHandler(new FixedBackOff(0, 1));\n}\n\nBut it seems that it is not working. In case of error, the retry number is the default one, as I can see in logs:\n[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] ERROR DefaultErrorHandler              - Backoff FixedBackOff{interval=0, currentAttempts=10, maxAttempts=9} exhausted for topicX\nHow should this DefaultErrorHandler be used in order to achieve the desired behavior? Or should I use something else?\nThx in advance!\n",
    "AcceptedAnswerId": 71052157,
    "AcceptedAnswer": "factory.setCommonErrorHandler(new Default....)\nBoot auto configuration of a CommonErrorHandler bean requires Boot 2.6.\nhttps://github.com/spring-projects/spring-boot/commit/c3583a4b06cff3f53b3322cd79f2b64d17211d0e\n"
}
{
    "Id": 71059252,
    "PostTypeId": 1,
    "Title": "Mac The operation couldn\u2019t be completed. Unable to locate a Java Runtime that supports jarsigner",
    "Body": "My purpose is to use jarsigner to sign apk.\nI get the following prompt\uff1a\n% jarsigner     \nThe operation couldn\u2019t be completed. Unable to locate a Java Runtime that supports jarsigner.\nPlease visit http://www.java.com for information on installing Java.\n\nmy java version hint\uff1a\n% java -version\njava version \"1.8.0_321\"\nJava(TM) SE Runtime Environment (build 1.8.0_321-b07)\nJava HotSpot(TM) 64-Bit Server VM (build 25.321-b07, mixed mode)\n\nMac version is 11.6.3\nHow can I solve this problem please?\n",
    "AcceptedAnswerId": 71059860,
    "AcceptedAnswer": "I finally solved it by downloading the JDK\n"
}
{
    "Id": 70997077,
    "PostTypeId": 1,
    "Title": "Spring Web MVC vs Spring WebFlux. Blocking and Non-blocking",
    "Body": "I'm new at Spring and I'm reading one book \"Pro Spring boot 2\". It says here that Spring Web MVC has some blocking on each request, and Spring Webflux is a completely non-blocking stack.\n\nTell me, please, what is meant?\nThe request that came to Spring MVC activates one thread to execute this request. When and why is it blocked?\nAnd why doesn't Spring WebFlux block thread?\n\n",
    "AcceptedAnswerId": 71000069,
    "AcceptedAnswer": "\nSpring Web MVC takes a single thread to handle each request to your API. Spring Webflux does not block a thread to handle each request, because no thread is kept waiting for something to be done (e.g. waiting for an answer from a database).\nAs written in 1., it can be blocked while waiting for an answer from a database or from another service that is called via HTTP.\nSpring Webflux takes advantage of the reactive stack (take a look at https://projectreactor.io/) which is fully non-blocking. This means that no thread is blocked waiting for something to happen. Everything is based on reactive streams publishers (Mono and Flux) making your code reactive to data being available (from a database or from another service called via HTTP as examples).\n\n"
}
{
    "Id": 70857274,
    "PostTypeId": 1,
    "Title": "Android 12 Splash Screen API - Increasing SplashScreen Duration",
    "Body": "I am learning Android's new SplashScreen API introduced with Android 12. I have so far gotten it to work on my Emulator and Google Pixel 4A, but I want to increase its duration. In my Splash Screen I do not want a fancy animation, I just want a static drawable.\nI know, I know (sigh) some of you might be thinking, that I should not increase the duration and I know there are several good arguments in favor of not doing so. However, for me the duration of a splash screen with a non animated drawable is so brief (less than a second), I think it raises an accessibility concern, especially so since it cannot be disabled (ironically). Simply, the organization behind the product or its brand/product identity cannot be properly absorbed or recognized by a new user at that size and in that time, rendering  the new splash screen redundant.\nI see the property windowSplashScreenAnimationDuration in the theme for the splash screen (shown below), but this has no effect on the duration presumably because I am not animating.\n \n        \n        @color/gold\n    \n        <!-- Use windowSplashScreenAnimatedIcon to add either a drawable or an\n             animated drawable. One of these is required-->\n        @drawable/accessibility_today\n        300 \n                                                                    \n        \n        @style/Theme.MyActivity\n    \n        @drawable/wculogo\n    \n    \n\nIs there a straightforward way to extend the duration of a non animated splash screen?\n",
    "AcceptedAnswerId": 70857275,
    "AcceptedAnswer": "As I was writing this question and almost ready to post it, I stumbled on the method setKeepOnScreenCondition (below) that belongs to the splashScreen that we must install on the onCreate of our main activity. I thought it seemed wasteful not to post this, given there are no other posts on this topic and no such similar answers to other related questions (as of Jan 2022).\nSplashScreen splashScreen = SplashScreen.installSplashScreen(this);\nplashScreen.setKeepOnScreenCondition(....);\n\nUpon inspecting it I found this method receives an instance of the splashScreen.KeepOnScreenCondition() interface for which the implementation must supply the following method signature implementation:\n public boolean shouldKeepOnScreen() \n\nIt seems this method will be called by the splash screen and retain the splash screen visibly until it returns false.  This is where the light bulb moment I so love about programming occurred.\nWhat if I use a boolean initialized as true, and set it to false after a delay? That hunch turned out to work. Here is my solution. It seems to work and I thought it would be useful to others. Presumably instead of using a Handler for a delay, one could  also use this to set the boolean after some process had completed.\npackage com.example.mystuff.myactivity;\n\nimport androidx.appcompat.app.AppCompatActivity;\nimport androidx.core.splashscreen.SplashScreen;\nimport android.os.Bundle;\nimport android.os.Handler;\n\npublic class MainActivity extends AppCompatActivity {\n    \n    private boolean keep = true;\n    private final int DELAY = 1250;\n\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n        // Handle the splash screen transition.\n        SplashScreen splashScreen = SplashScreen.installSplashScreen(this);\n        super.onCreate(savedInstanceState);\n\n        //Keep returning false to Should Keep On Screen until ready to begin.\n        splashScreen.setKeepOnScreenCondition(new SplashScreen.KeepOnScreenCondition() {\n            @Override\n            public boolean shouldKeepOnScreen() {\n                return keep;\n            }\n        });\n        Handler handler = new Handler();\n        handler.postDelayed(runner, DELAY);\n    }\n\n    /**Will cause a second process to run on the main thread**/\n    private final Runnable runner = new Runnable() {\n        @Override\n        public void run() {\n            keep = false;\n        }\n    };\n    \n}\n\nIf you are into Java Lambdas an even nicer and more compact solution is as follows:\npackage com.example.mystuff.myactivity;\n\nimport androidx.appcompat.app.AppCompatActivity;\nimport androidx.core.splashscreen.SplashScreen;\nimport android.os.Bundle;\nimport android.os.Handler;\n\npublic class MainActivity extends AppCompatActivity {\n    \n    private boolean keep = true;\n    private final int DELAY = 1250;\n\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n        // Handle the splash screen transition.\n        SplashScreen splashScreen = SplashScreen.installSplashScreen(this);\n        super.onCreate(savedInstanceState);\n        setContentView(R.layout.activity_main);\n\n        //Keep returning false to Should Keep On Screen until ready to begin.\n    splashScreen.setKeepOnScreenCondition(() -> keep);\n    Handler handler = new Handler();\n    handler.postDelayed(() -> keep = false, DELAY);;\n    }\n\n\n    \n}\n\nIf you have comments or feedback (besides telling me I should not increase the duration of the splash screen), or a better way please do comment or respond with additional answers.\n"
}
{
    "Id": 70925555,
    "PostTypeId": 1,
    "Title": "How can we provide Jackson annotations for java 17 record class",
    "Body": "How can we create add field level annotations for java 17 record class?\nrecord Rectangle(double length, double width) { }\n\n",
    "AcceptedAnswerId": 70925601,
    "AcceptedAnswer": "yes we can use field level annotations (annotation with @Target(ElementType.FIELD) in the defination.\n@JsonInclude(Include.NON_NULL)\nrecord Rectangle(\n    @JsonProperty(\"lengthAlias\") double length,\n    double width) { }\n\n"
}
{
    "Id": 70819069,
    "PostTypeId": 1,
    "Title": "Springboot: Better handling of error messages",
    "Body": "I'm developing an API with Spring Boot and currently, I'm thinking about how to handle error messages in an easily internationalizable way. My goals are as follows:\n\nDefine error messages in resource files/bundles\nConnect constraint annotation with error messages (e.g., @Length) in a declarative fashion\nError messages contain placeholders, such as {min}, that are replaced by the corresponding value from the annotation, if available, e.g., @Length(min = 5, message = msg) would result in something like msg.replace(\"{min}\", annotation.min()).replace(\"{max}\", annotation.max()).\nThe JSON property path is also available as a placeholder and automatically inserted into the error message when a validation error occurs.\nA solution outside of an error handler is preferred, i.e., when the exceptions arrive in the error handler, they already contain the desired error messages.\nError messages from a resource bundle are automatically registered as constants in Java.\n\nCurrently, I customized the methodArgumentNotValidHandler of my error handler class to read ObjectErrors from e.getBindingResult().getAllErrors() and then try to extract their arguments and error codes to decide which error message to choose from my resource bundle and format it accordingly. A rough sketch of my code looks as follows:\nInput:\n@Data\n@RequiredArgsConstructor\npublic class RequestBody {\n  @NotNull\n  @NotBlank(message = ErrorConstants.NOT_BLANK)\n  @Length(min = 5, max = 255, message = ErrorConstants.LENGTH_MIN_MAX) // LENGTH_MIN_MAX = validation.length.min-max\n  private String greeting;\n}\n\nError handler:\n@ResponseBody\n@ExceptionHandler(MethodArgumentNotValidException.class)\n@ResponseStatus(HttpStatus.BAD_REQUEST)\nErrorMessage methodArgumentNotValidHandler(MethodArgumentNotValidException e) {\n  ObjectError objectError = e.getBindingResult().getAllErrors().get(0);\n  Object[] arguments = objectError.getArguments();\n  String messageCode = objectError.getDefaultMessage(); // e.g., \"validation.length.min-max\" (key in resource bundle)\n  ResourceBundle errMsgBundle = ResourceBundle.getBundle(\"errorMsg\");\n  String message;\n  if (objectError.getCode().equals(\"Length\")) {\n    String messageTemplate = errMsgBundle.getString(messageCode);\n    message = String.format(messageTemplate, arguments[2], arguments[1]);\n  } else {\n    message = \"Bad input, but I cannot tell you the problem because the programmer hasn't handled this yet. Sorry :'(\";\n  }\n  return new ErrorMessage(message);\n}\n\nUnfortunately, I suppose this approach is not maintainable. In the error handler, I will end up with a huge if-else block that has to probe several different situations (error codes, number of arguments, ...) and format error messages accordingly. Changing error messages will possibly result in having to change the code (e.g., the order of arguments). Each property key must be present as a constant in ErrorConstants, which I find undesirable. This code also doesn't query the name or path of the faulty property, e.g., \"name\".\nHence,\n\nis there a solution that can satisfy some or all of the above-mentioned requirements?\nAt which place would I implement this?\nIs there at least a better solution to the above one?\nAre there recipes or patterns in SpringBoot to handle validation errors (I'm definitely not the first one thinking about this)?\n\n",
    "AcceptedAnswerId": 70936114,
    "AcceptedAnswer": "After some digging around, I found the confirmation that what I was looking for was indeed built-in already as this is a question I expect every developer who want to acquit oneself well would ask. And indeed, this question has been asked already (I could have found it earlier if I would have verbalized my requirements correctly). I was just asking to customize my localized error messages via resource bundles.\nWhen I create the resource bundle in the resources folder containing my custom error messages and name it \"validation_errors.properties\", then I can make the validator using these messages by creating a corresponding bean:\n@Bean\npublic Validator validatorFactory (MessageSource messageSource) {\n    LocalValidatorFactoryBean validator =  new LocalValidatorFactoryBean();\n    validator.setValidationMessageSource(messageSource);\n    return validator;\n}\n\n@Bean\npublic MessageSource messageSource() {\n    ReloadableResourceBundleMessageSource bean = new ReloadableResourceBundleMessageSource();\n    bean.addBasenames(\"classpath:org.hibernate.validator.ValidationMessages\", \"classpath:validation_errors\"); // validation_errors.properties is my resource bundle\n    bean.setDefaultEncoding(\"UTF-8\");\n    return bean;\n}\n\nMy custom validator retrieves the validation messages from an instance of ReloadableResourceBundleMessageSource, which in turn retrieves them from a properties file.\nThe properties file contains the qualified path of the \"message\" parameter of a validation annotation as keys and values arbitrary strings, where strings in curly brackets are replaced by arguments from the validation annotation and SpEL expressions are evaluated.\njavax.validation.constraints.NotNull.message = Not null please!\njavax.validation.constraints.NotBlank.message = Not empty please!\norg.hibernate.validator.constraints.Length.message = String length between {min} and {max} please!\n\nNext, in my error handler, I need to detect and unpack if the ObjectError instance in MethodArgumentNotValidException contains a ConstraintViolation (to simplify this example, I ignore other error sources):\n@ResponseBody\n@ExceptionHandler(MethodArgumentNotValidException.class)\n@ResponseStatus(HttpStatus.BAD_REQUEST)\nList methodArgumentNotValidHandler(MethodArgumentNotValidException e) {\n    return e.getBindingResult().getAllErrors().stream()\n            .filter(objectError -> objectError.contains(ConstraintViolation.class))\n            .map(objectError -> objectError.unwrap(ConstraintViolation.class))\n            .map(ConstraintViolation::getMessage)\n            .map(message -> new ErrorMessage(\"VE-400\", message))\n            .collect(Collectors.toList());\n}\n\nThis solution meets requirements 1, 3, 5 and 6. Requirement 2 is considered invalid as it's tied to a specific solution that I had in mind when I asked this question. Requirement 4 remains open, SpEL might be a possibility to look further, otherwise I would continue exploring Tris answer.\n"
}
{
    "Id": 70957923,
    "PostTypeId": 1,
    "Title": "Save authenticated users to database coming from Azure AD",
    "Body": "I am working on a simple web app for learning purposes using Angular for the frontend and Java Spring for the backend. I don't have a particular problem that I want you guys to help me out with, instead I have a question about OAuth2 authentication.\nI have registered my Angular SPA in Azure AD (Authorization Code Flow + PKCE), I set up roles and everything is working okay. My question is what do I do when authenticated users ping my backend? My backend has no information about the users.\nI thought of a solution to make a web filter, and every time an authenticated user pings any endpoint requiring the user to be authenticated, to check the database if the user exists (through the username), and save him if he does not exist. I'm pretty sure this will work, but I don't think this is the best solution, considering my web filter will have to read from the databases for every single HTTP request that comes in, and write to the database occasionally (if the user logs in for the first time).\nI shouldn't be worried about performance issues because I'm building this strictly for learning purposes, but nevertheless I want to do this the right way. I tried googling this in multiple ways, but I guess I'm not using the right keywords to find what I'm looking for. Any opinion or advice would be much appreciated! Thanks!\nEDIT: I followed this article to achieve the OAuth2 + OIDC authentication and authorization, my security config in the backend is the same: https://ordina-jworks.github.io/security/2020/08/18/Securing-Applications-Azure-AD.html\n",
    "AcceptedAnswerId": 71068091,
    "AcceptedAnswer": "Post the discussion with clarity on the requirements. If you want to use have the following:\n\nAccept an Azure AD logged in user to consumer your web service\nYou would want to check if the user exists in your application database with minimal network latency.\n\nWith the requirement of not always hitting your Database, one option is to use a cache.\nThe ideal solution for this cache to work is:\n\nEnsure the cache is checked for every HTTP Request using Web Filter\nMake sure the cache is always updated with the latest users being logged in via Azure AD\n\nExample:\nImplement a CacheService.java\npackage com.example.springboot;\n\nimport java.util.Collections;\n\nimport org.apache.catalina.User;\nimport org.springframework.cache.CacheManager;\nimport org.springframework.cache.annotation.Cacheable;\nimport org.springframework.cache.concurrent.ConcurrentMapCache;\nimport org.springframework.cache.support.SimpleCacheManager;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.stereotype.Component;\n\n@Component\npublic class CacheService {\n\n  @Bean\n  public CacheManager cacheManager() {\n    SimpleCacheManager cacheManager = new SimpleCacheManager();\n    cacheManager.setCaches(Collections.singletonList(new ConcurrentMapCache(\"users\")));\n    return cacheManager;\n  }\n\n\n  @Cacheable(cacheNames = \"users\")\n  public User getUser(String username) {\n    // Code below will not execute after the first calling for the given username. \n    // So if one username is already cached, it would not invoke for the same user again from the DB.\n\n    // Get or Create a new user based on the Database call\n    return null;\n  }\n}\n\nThen implement a web filter like:\npackage com.example.springboot;\n\nimport java.io.IOException;\n\nimport javax.servlet.FilterChain;\nimport javax.servlet.ServletException;\nimport javax.servlet.ServletRequest;\nimport javax.servlet.ServletResponse;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Component;\nimport org.springframework.web.filter.GenericFilterBean;\n\n@Component\npublic class CredentialsInjectionFilter extends GenericFilterBean {\n\n  @Autowired\n  private CacheService cacheService;\n\n  @Override\n  public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse,\n      FilterChain filterChain) throws IOException, ServletException {\n\n    cacheService.getUser(\"my_username\");\n\n    filterChain.doFilter(servletRequest, servletResponse);\n  }\n}\n\nMore on Caching with Springboot: https://www.javadevjournal.com/spring/spring-caching/\n"
}
{
    "Id": 70914692,
    "PostTypeId": 1,
    "Title": "minio Unsupported OkHttp library found. Must use okhttp >= 4.8.1",
    "Body": "after using minio as instructions and fixing it with ways below, I failed.what can i do to solve this bug\n        \n        io.minio\n        minio\n        8.3.5\n        \n            \n                okhttp\n                com.squareup.okhttp3\n            \n        \n    \n    \n    \n        com.squareup.okhttp3\n        okhttp\n        4.9.3\n    \n\n\n",
    "AcceptedAnswerId": 71050627,
    "AcceptedAnswer": "I also experienced this issues with io.minio:minio:8.3.6, but was able to force a newer version of okhttp, which works with the MinIO client library. Here is the snippet of build.gradle (should work similar with Maven):\nimplementation(\"io.minio:minio:8.3.6\")    \nimplementation(\"com.squareup.okhttp3:okhttp:4.9.3\")\n\nIn my case it was probably caused by spring-boot-dependencies coming with the spring dependency plugin, which manages a lot of dependencies containing also okhttp and thus forces the downgrade.\nSee also:\n\nhttps://mvnrepository.com/artifact/org.springframework.boot/spring-boot-dependencies/2.6.3\nhttps://github.com/minio/minio-java/issues/1298\n\nUpdate\nWith Spring Boot 2.7.0, the fix is no longer required, since the version requirements for okhttp have been updated. The MinIO dependency should work now out of the box.\n"
}
{
    "Id": 71224833,
    "PostTypeId": 1,
    "Title": "Lambda expressions and anonymous classes don't work when loaded as hidden classes",
    "Body": "I am trying to compile and load dynamically generated Java code during runtime. Since both ClassLoader::defineClass and Unsafe::defineAnonymousClass have serious drawbacks in this scenario, I tried using hidden classes via Lookup::defineHiddenClass instead. This works fine for all classes that I tried to load, except for those that call lambda expressions or contain anonymous classes.\nCalling a lambda expression throws the following exception:\nException in thread \"main\" java.lang.NoClassDefFoundError: tests/HiddenClassLambdaTest$LambdaRunner/0x0000000800c04400\n    at tests.HiddenClassLambdaTest.main(HiddenClassLambdaTest.java:22)\nCaused by: java.lang.ClassNotFoundException: tests.HiddenClassLambdaTest$LambdaRunner.0x0000000800c04400\n    at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:636)\n    at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:182)\n    at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:519)\n    ... 1 more\n\nExecuting code that instantiates an anonymous class throws the following error:\nException in thread \"main\" java.lang.VerifyError: Bad type on operand stack\nException Details:\n  Location:\n    tests/HiddenClassLambdaTest$LambdaRunner+0x0000000800c00400.run()V @5: invokespecial\n  Reason:\n    Type 'tests/HiddenClassLambdaTest$LambdaRunner+0x0000000800c00400' (current frame, stack[2]) is not assignable to 'tests/HiddenClassLambdaTest$LambdaRunner'\n  Current Frame:\n    bci: @5\n    flags: { }\n    locals: { 'tests/HiddenClassLambdaTest$LambdaRunner+0x0000000800c00400' }\n    stack: { uninitialized 0, uninitialized 0, 'tests/HiddenClassLambdaTest$LambdaRunner+0x0000000800c00400' }\n  Bytecode:\n    0000000: bb00 1159 2ab7 0013 4cb1               \n\n    at java.base/java.lang.ClassLoader.defineClass0(Native Method)\n    at java.base/java.lang.System$2.defineClass(System.java:2193)\n    at java.base/java.lang.invoke.MethodHandles$Lookup$ClassDefiner.defineClass(MethodHandles.java:2446)\n    at java.base/java.lang.invoke.MethodHandles$Lookup$ClassDefiner.defineClassAsLookup(MethodHandles.java:2427)\n    at java.base/java.lang.invoke.MethodHandles$Lookup.defineHiddenClass(MethodHandles.java:2133)\n    at tests.HiddenClassLambdaTest.main(HiddenClassLambdaTest.java:25)\n\n\nThis is a short example that recreates the problem:\nimport java.lang.invoke.MethodHandles;\n\npublic class HiddenClassLambdaTest {\n    /** This class is to be loaded and executed as hidden class */\n    public static final class LambdaRunner implements Runnable {\n        @Override public void run() {\n            Runnable runnable = () -> System.out.println(\"Success\");\n            runnable.run();\n        }\n    }\n    \n    public static void main(String[] args) throws Throwable {\n        // Path to the class file of the nested class defined above\n        String nestedClassPath = HiddenClassLambdaTest.class.getTypeName().replace('.','/') + \"$LambdaRunner.class\";\n        // Class file content of the LambdaRunner class\n        byte[] classFileContents = HiddenClassLambdaTest.class.getClassLoader().getResourceAsStream(nestedClassPath).readAllBytes();\n        Class lambdaRunnerClass = MethodHandles.lookup().defineHiddenClass(classFileContents, true).lookupClass();\n        Runnable lambdaRunnerInstance = (Runnable) lambdaRunnerClass.getConstructor().newInstance();\n        lambdaRunnerInstance.run();\n    }\n}\n\nI've already tried compiling and running the code with different JDKs, using different ways to create new instances of the hidden class, searching for bugs at https://bugs.openjdk.java.net/, messing with the bytecode itself and several other things. I am not an expert on Java internals, so I am not sure whether I have not understood the JEP that introduced hidden classes correctly.\nAm I doing something wrong, is this just impossible or is this a bug?\nEdit: The JEP states\n\nMigration should take the following into account:\nTo invoke private nestmate instance methods from code in a hidden class, use invokevirtual or invokeinterface instead of invokespecial. Generated bytecode that uses invokespecial to invoke a private nestmate instance method will fail verification. invokespecial should only be used to invoke private nestmate constructors.\n\nThis might be the problem for the anonymous class. Is there a way to compile the code such that invokespecial is avoided in the bytecode?\n",
    "AcceptedAnswerId": 71242195,
    "AcceptedAnswer": "You can not turn arbitrary classes into hidden classes.\nThe documentation of defineHiddenClass contains the sentence\n\n\nOn any attempt to resolve the entry in the run-time constant pool indicated by this_class, the symbolic reference is considered to be resolved to C and resolution always succeeds immediately.\n\n\nWhat it doesn\u2019t spell out explicitly is that this is the only place where a type resolution ever ends up at the hidden class.\nBut it has been said unambiguously in bug report JDK-8222730:\n\nFor a hidden class, its specified hidden name should only be accessible through the hidden class's 'this_class' constant pool entry.\nThe class should not be accessible by specifying its original name in, for example, a method or field signature even within the hidden class.\n\nWhich we can check. Even a simple case like\npublic class HiddenClassLambdaTest {\n\n    public static void main(String[] args) throws Throwable {\n        byte[] classFileContents = HiddenClassLambdaTest.class\n            .getResourceAsStream(\"HiddenClassLambdaTest$LambdaRunner.class\")\n            .readAllBytes();\n        var hidden = MethodHandles.lookup()\n            .defineHiddenClass(classFileContents, true, ClassOption.NESTMATE);\n        Runnable lambdaRunnerInstance = (Runnable)hidden.findConstructor(\n            hidden.lookupClass(), MethodType.methodType(void.class)).invoke();\n        lambdaRunnerInstance.run();\n    }\n\n    static class LambdaRunner implements Runnable {\n        LambdaRunner field = this;\n\n        @Override\n        public void run() {\n        }\n    }\n}\n\nwill already fail. Note that it is a special case that the attempt to resolve the original class name LambdaRunner within the hidden class will not fail, as you used an existing class as template. So you get an IncompatibleClassChangeError or a VerifierError due to mismatches between the hidden class and the existing LambdaRunner class. When you don\u2019t use a class definition of an existing class, you\u2019d get a NoClassDefFoundError.\nThe same applies to\n    static class LambdaRunner implements Runnable {\n        static void method(LambdaRunner arg) {\n        }\n\n        @Override\n        public void run() {\n            method(this);\n        }\n    }\n\nAs the cited bug report said, neither field nor methods can refer to the hidden class in their signature.\nA less intuitive example is\n    static class LambdaRunner implements Runnable {\n        @Override\n        public void run() {\n            System.out.println(\"\" + this);\n        }\n    }\n\nwhich will fail depending on the compiler and options, as when the StringConcatFactory is used, the behavior is like an invocation of a method having all non-constant parts as parameters and returning a String. So this is another case of having the hidden class in a method signature.\n\nLambda expressions are special, as a class like\n    static class LambdaRunner implements Runnable {\n        @Override\n        public void run() {\n            Runnable runnable = () -> System.out.println(\"Success\");\n            runnable.run();\n        }\n    }\n\ngets compiled similar to\n    static class LambdaRunner implements Runnable {\n        @Override\n        public void run() {\n            Runnable runnable = LambdaRunner::lambdaBody;\n            runnable.run();\n        }\n        private static void lambdaBody() {\n            System.out.println(\"Success\");\n        }\n    }\n\nwhich doesn\u2019t have the hidden class in the method signature, but has to refer to the method holding the body of the lambda expression as a MethodReference. Within the constant pool, the description of this method refers to its declaring class using the this_class entry. So it gets redirected to the hidden class as described in the documentation.\nBut the construction of the MethodType as part of the MethodReference does not use this information to load a Class like a class literal would do. Instead, it tries to load the hidden class through the defining class loader, which fails with the NoClassDefFoundError you have posted.\nThis seems to be related to JDK-8130087 which suggests that ordinary method resolution differs from the way, MethodType works, which can make MethodType fail where just invoking the method would work.\nBut it\u2019s possible to demonstrate that even fixing this issue wouldn\u2019t solve the general problem:\n    static class LambdaRunner implements Runnable {\n        @Override\n        public void run() {\n            var lookup = MethodHandles.lookup();\n            var noArgVoid = MethodType.methodType(void.class);\n            try {\n                MethodHandle mh = LambdaMetafactory.metafactory(lookup, \"run\",\n                    MethodType.methodType(Runnable.class), noArgVoid,\n                    lookup.findStatic(LambdaRunner.class, \"lambdaBody\", noArgVoid),\n                    noArgVoid).getTarget();\n                System.out.println(\"got factory\");\n                Runnable runnable = (Runnable)mh.invokeExact();\n                System.out.println(\"got runnable\");\n                runnable.run();\n            }\n            catch(RuntimeException|Error e) {\n                throw e;\n            }\n            catch(Throwable e) {\n                throw new AssertionError(e);\n            }\n        }\n        private static void lambdaBody() {\n            System.out.println(\"Success\");\n        }\n    }\n\nThis bypasses the problem described above and calls the LambdaMetafactory manually. When being redefined as hidden class, it will print:\ngot factory\ngot runnable\nException in thread \"main\" java.lang.NoClassDefFoundError: test/HiddenClassLambdaTest$LambdaRunner/0x0000000800c01400\n    at test/test.HiddenClassLambdaTest.main(HiddenClassLambdaTest.java:15)\nCaused by: java.lang.ClassNotFoundException: test.HiddenClassLambdaTest$LambdaRunner.0x0000000800c01400\n    at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n    at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n    at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:521)\n    ... 1 more\n\nwhich shows that all obstacles have been circumvented, but when it comes to the actual invocation from the generated Runnable to the method holding the lambda body, it will fail due to the fact that the target class is hidden. A JVM with eager resolution of symbolic references might fail earlier, i.e. the example might not print got runnable then.\nUnlike the old JVM anonymous classes, there is no way to link to a hidden class, not even from another hidden class.\n\nThe bottom line is, as said at the beginning, you can not turn arbitrary classes into hidden classes. Lambda expressions are not the only feature not working with hidden classes. It\u2019s not a good idea to try and get surprised. Hidden classes should only be used in conjunction with bytecode generators carefully using only features known to work.\n"
}
{
    "Id": 71216665,
    "PostTypeId": 1,
    "Title": "build.gradle cannot resolve symbol 'groovy.json.JsonSlurper'",
    "Body": "I can't resolve the groovy.json.JsonSlurper in the build.gradle file with Intellij, does anyone know how to fix it?\n\nplugins {\n    id 'java'\n}\n\ngroup 'org.example'\nversion '1.0-SNAPSHOT'\n\nrepositories {\n    mavenCentral()\n}\n\ndependencies {\n    testImplementation 'org.junit.jupiter:junit-jupiter-api:5.8.1'\n    testRuntimeOnly 'org.junit.jupiter:junit-jupiter-engine:5.8.1'\n}\n\ntest {\n    useJUnitPlatform()\n}\n\n\n\ntask sample() {\n    doLast {\n        sample();\n    }\n}\n\nimport groovy.json.JsonSlurper\ndef sample(){\n    def json = new JsonSlurper().parseText('{\"a\":\"b\"}')\n    println(json);\n}\n\n\n\n",
    "AcceptedAnswerId": 71218832,
    "AcceptedAnswer": "You missing the needed dependency.\nAdd org.codehaus.groovy:groovy-json:3.0.9 in dependencies section so ti will look like\ndependencies {\n    testImplementation 'org.junit.jupiter:junit-jupiter-api:5.8.1'\n    testRuntimeOnly 'org.junit.jupiter:junit-jupiter-engine:5.8.1'\n    implementation 'org.codehaus.groovy:groovy-json:3.0.9'\n}\n\nAnd then you can test with CLI as gradle sample or ./gradlew sample and it will return {a=b}\n"
}
{
    "Id": 71020415,
    "PostTypeId": 1,
    "Title": "Manifest merger failed : android:exported needs to be explicitly specified for <receiver>",
    "Body": "\nMerging Errors: Error: android:exported needs to be explicitly specified for element\n.\nApps targeting Android 12 and higher are required to specify an\nexplicit value for android:exported when the corresponding component\nhas an intent filter defined. See\nhttps://developer.android.com/guide/topics/manifest/activity-element#exported\nfor details. test.app main manifest (this file), line 19\n\nI don't even know what to do. I struggled with this mistake for a whole week, but I couldn't.\nHere is my sdk version\ncompileSdkVersion 32\n    defaultConfig {\n        multiDexEnabled true\n        applicationId \"com.example.app\"\n        minSdkVersion 21\n        targetSdkVersion 32\n        versionCode 53\n        versionName \"2.0.4\"\n        ndk.abiFilters 'armeabi-v7a', 'arm64-v8a', 'x86', 'x86_64'\n        testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\"\n    }\n\nWrote android:exported on all intent-filter, service, and provider. Ah, I don't have the receiver mentioned in this error.\ndependencies {\n    implementation fileTree(dir: 'libs', include: ['*.jar'])\n\n    implementation 'androidx.appcompat:appcompat:1.4.1'\n    implementation 'com.google.android.material:material:1.5.0'\n    implementation 'androidx.constraintlayout:constraintlayout:2.1.3'\n\n    implementation \"com.android.billingclient:billing:4.0.0\"\n\n    implementation \"com.google.firebase:firebase-messaging:23.0.0\"\n    implementation \"com.google.firebase:firebase-crashlytics:18.2.7\"\n    implementation \"com.google.firebase:firebase-analytics:20.0.2\"\n    implementation \"com.google.firebase:firebase-perf:20.0.4\"\n    implementation \"com.google.firebase:firebase-dynamic-links:21.0.0\"\n\n    implementation 'com.google.firebase:firebase-core:20.0.2'\n    implementation 'com.google.firebase:firebase-database:20.0.3'\n    implementation 'com.google.firebase:firebase-auth:21.0.1'\n    implementation 'com.google.firebase:firebase-config:21.0.1'\n    implementation \"com.facebook.android:facebook-login:9.0.0\"\n    implementation \"com.facebook.android:facebook-share:[5,6)\"\n    implementation \"com.linecorp:linesdk:5.0.1\"\n\n    implementation 'org.jetbrains.kotlin:kotlin-stdlib:1.6.10'\n\n    implementation \"com.squareup.retrofit2:retrofit:2.8.1\"\n    implementation \"com.squareup.retrofit2:converter-gson:2.8.1\"\n    implementation 'com.squareup.retrofit2:adapter-rxjava:2.3.0'\n    implementation 'com.squareup.okhttp3:logging-interceptor:4.2.1'\n    implementation 'io.reactivex:rxandroid:1.2.1'\n\n    implementation 'com.google.code.gson:gson:2.8.6'\n\n    implementation 'com.sun.easysnackbar:easysnackbar:1.0.1'\n\n    implementation 'com.romandanylyk:pageindicatorview:1.0.3@aar'\n\n    implementation 'com.google.android.exoplayer:exoplayer:2.16.1'\n\n    //MULTI DEX\n    implementation \"androidx.multidex:multidex:2.0.1\"\n\n    implementation 'com.google.android:flexbox:2.0.1'\n\n    implementation 'com.github.florent37:diagonallayout:1.0.9'\n\n    implementation('io.socket:socket.io-client:1.0.0') {\n        exclude group: 'org.json', module: 'json'\n    }\n\n    implementation 'com.github.instacart.truetime-android:library:3.4'\n    implementation 'com.github.instacart.truetime-android:library-extension-rx:3.4'\n\n    implementation \"androidx.navigation:navigation-fragment-ktx:2.4.0\"\n    implementation \"androidx.navigation:navigation-ui-ktx:2.4.0\"\n\n    implementation \"com.github.bumptech.glide:glide:4.12.0\"\n    annotationProcessor \"com.github.bumptech.glide:compiler:4.12.0\"\n\n    implementation \"de.hdodenhof:circleimageview:3.1.0\"\n\n    implementation \"com.pixplicity.easyprefs:library:1.9.0\"\n\n    implementation \"com.jakewharton.timber:timber:4.7.1\"\n\n    implementation \"com.airbnb.android:lottie:3.4.0\"\n\n    implementation 'com.github.jinatonic.confetti:confetti:1.1.2'\n\n    implementation \"com.nabinbhandari.android:permissions:3.8\"\n\n    implementation 'androidx.legacy:legacy-support-v4:1.0.0'\n\n    implementation \"com.github.YarikSOffice:lingver:1.2.1\"\n\n    implementation 'com.github.mreram:showcaseview:1.2.0'\n    implementation 'com.github.shripal17:MaterialIntroView-v2:2.2.0'\n\n    implementation 'com.github.unsplash:unsplash-photopicker-android:1.0.0'\n\n    implementation 'com.giphy.sdk:ui:2.1.0'\n\n    testImplementation 'junit:junit:4.13.2'\n    testImplementation 'androidx.test:core:1.4.0'\n    androidTestImplementation 'androidx.test.espresso:espresso-core:3.4.0'\n    androidTestImplementation \"androidx.test.ext:junit:1.1.3\"\n}\n\n",
    "AcceptedAnswerId": 71020750,
    "AcceptedAnswer": "Found the issue with instacart.truetime library. You're using 3.4 version & they resolved this error in 3.5 as mentioned here: https://github.com/instacart/truetime-android/releases/tag/3.5\nSo you need to update these dependencies to the new version of 3.5\n    implementation 'com.github.instacart.truetime-android:library:3.5'\n    implementation 'com.github.instacart.truetime-android:library-extension-rx:3.5'\n\nBuild the app & it resolves the issue\n"
}
{
    "Id": 71296783,
    "PostTypeId": 1,
    "Title": "JUINT test giving error java.lang.reflect.InaccessibleObjectException: Unable to make protected void java.lang.Object.finalize()",
    "Body": "While running the test I am getting the error , I am not able to understand why am I getting this error , this code is working with fine in java 8 , while running it in java 17 it is giving error. googled this error but found nothing useful. Please help me to understand this error.\nThanks in advance:)\n@RunWith(PowerMockRunner.class)\n@PrepareForTest({PopulatedAuthorizedUser.class})\n@SpringBootTest(classes = MockServletContext.class)\n@PowerMockIgnore({\"javax.management.*\", \"javax.net.ssl.*\", \n\"jdk.internal.reflect.*\"})\npublic class ProjectUserControllerTest {\n\nprivate ProjectUserController controller;\n\nprivate UUID projectId = UUID.randomUUID();\nprivate UUID groupId = UUID.randomUUID();\nprivate String email = \"project.user@email.com\";\n\n@Mock\nprivate ProjectUserService projectUserService;\n\nprivate ObjectMapper objectMapper = new ObjectMapper();\n\n@Mock\nprotected AuthorizedUser au;\n\n@Before\npublic void setUp() throws Exception {\n    controller = new ProjectUserController();\n    FieldUtils.writeField(controller, \"projectUserService\", projectUserService, true);\n    FieldUtils.writeField(controller, \"objectMapper\", objectMapper, true);\n    PowerMockito.mockStatic(PopulatedAuthorizedUser.class);\n    Mockito.when(PopulatedAuthorizedUser.get()).thenReturn(mockAuthorizedUser());\n}\n\n@Test\npublic void testGetProjectUsers() {\n    Mockito.doReturn(Arrays.asList(mockProjectUser())).when(projectUserService)\n            .findProjectUsersByProjectId(projectId);\n    Mockito.doNothing().when(projectUserService).enrichUserDetails(any(ProjectUserDto.class));\n    ResponseEntity> response=controller.getProjectUsers(projectId);\n    assertNotNull(response);\n    ProjectUserDto projectUserDto = response.getBody().get(0);\n    assertEquals(groupId, projectUserDto.getGroupId());\n    assertEquals(email, projectUserDto.getUsername());\n    assertTrue(projectUserDto.getEmailNotification());\n    assertEquals(ProjectUserRole.OWNER.toString(), projectUserDto.getRole());\n   }\n\n }\n\nException:\n java.lang.reflect.InaccessibleObjectException: Unable to make protected void java.lang.Object.finalize() throws java.lang.Throwable accessible: module java.base does not \"opens java.lang\" to unnamed module @5ba23b66\n\nat java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:354)\nat java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:297)\nat java.base/java.lang.reflect.Method.checkCanSetAccessible(Method.java:199)\nat java.base/java.lang.reflect.Method.setAccessible(Method.java:193)\nat org.powermock.reflect.internal.WhiteboxImpl.doGetAllMethods(WhiteboxImpl.java:1492)\nat org.powermock.reflect.internal.WhiteboxImpl.getAllMethods(WhiteboxImpl.java:1467)\nat org.powermock.reflect.internal.WhiteboxImpl.findMethodOrThrowException(WhiteboxImpl.java:847)\nat org.powermock.reflect.internal.WhiteboxImpl.doInvokeMethod(WhiteboxImpl.java:807)\nat org.powermock.reflect.internal.WhiteboxImpl.invokeMethod(WhiteboxImpl.java:790)\nat org.powermock.reflect.Whitebox.invokeMethod(Whitebox.java:466)\nat org.powermock.modules.junit4.common.internal.impl.PowerMockJUnit4RunListener.testFinished(PowerMockJUnit4RunListener.java:55)\nat org.junit.runner.notification.SynchronizedRunListener.testFinished(SynchronizedRunListener.java:87)\nat org.junit.runner.notification.RunNotifier$9.notifyListener(RunNotifier.java:225)\nat org.junit.runner.notification.RunNotifier$SafeNotifier.run(RunNotifier.java:72)\nat org.junit.runner.notification.RunNotifier.fireTestFinished(RunNotifier.java:222)\nat org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.testAborted(PowerMockJUnit44RunnerDelegateImpl.java:229)\nat org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.invokeTestMethod(PowerMockJUnit44RunnerDelegateImpl.java:206)\nat org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.runMethods(PowerMockJUnit44RunnerDelegateImpl.java:160)\nat org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl$1.run(PowerMockJUnit44RunnerDelegateImpl.java:134)\nat org.junit.internal.runners.ClassRoadie.runUnprotected(ClassRoadie.java:34)\nat org.junit.internal.runners.ClassRoadie.runProtected(ClassRoadie.java:44)\nat org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.run(PowerMockJUnit44RunnerDelegateImpl.java:136)\nat org.powermock.modules.junit4.common.internal.impl.JUnit4TestSuiteChunkerImpl.run(JUnit4TestSuiteChunkerImpl.java:121)\nat org.powermock.modules.junit4.common.internal.impl.AbstractCommonPowerMockRunner.run(AbstractCommonPowerMockRunner.java:57)\nat org.powermock.modules.junit4.PowerMockRunner.run(PowerMockRunner.java:59)\nat org.junit.runner.JUnitCore.run(JUnitCore.java:137)\nat com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)\nat com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33)\nat com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:235)\nat com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:54)\n\n",
    "AcceptedAnswerId": 71296829,
    "AcceptedAnswer": "In Java 9 and above, the module system can cause these errors. I've had the same issues with JUnit 5 itself because I omit the public from my test classes and methods.\nHere's what I have in my POM to solve this:\n\n  org.apache.maven.plugins\n  maven-surefire-plugin\n  \n    \n    --add-opens /=ALL-UNNAMED\n  \n\n\nIn your case you probably need to use java.base/java.lang=ALL_UNNAMED.\n"
}
{
    "Id": 71044636,
    "PostTypeId": 1,
    "Title": "JMH using java 17, no dead code elimination",
    "Body": "I run sample JHM benchmark which suppose to show dead code elimination. Code is rewritten for conciseness from jhm github sample.\nimport org.openjdk.jmh.annotations.*;\nimport java.util.concurrent.TimeUnit;\n\n@State(Scope.Thread)\n@BenchmarkMode(Mode.AverageTime)\n@OutputTimeUnit(TimeUnit.NANOSECONDS)\n@Fork(1)\npublic class Sample08DeadCode {\n\n    private double x = Math.PI;\n\n    @Benchmark\n    public void benchmark() {}\n\n    @Benchmark\n    public void measureIncorrect() { Math.log(x); }\n\n    @Benchmark\n    public double measureCorrect() { return Math.log(x); }\n}\n\nRun using JDK 1.8.0_211, Java HotSpot(TM) 64-Bit Server VM, 25.211-b12 produces following results:\nBenchmark                          Mode  Cnt   Score   Error  Units\nSample08DeadCode.benchmark         avgt    5   0,229 \u00b1 0,018  ns/op\nSample08DeadCode.measureCorrect    avgt    5  12,013 \u00b1 0,047  ns/op\nSample08DeadCode.measureIncorrect  avgt    5   0,228 \u00b1 0,016  ns/op\n\nbut using java JDK 17.0.2, Java HotSpot(TM) 64-Bit Server VM, 17.0.2+8-LTS-86 the results have no sign of dead code elimination:\nBenchmark                          Mode  Cnt  Score   Error  Units\nSample08DeadCode.benchmark         avgt    5  0,341 \u00b1 0,004  ns/op\nSample08DeadCode.measureCorrect    avgt    5  6,244 \u00b1 0,072  ns/op\nSample08DeadCode.measureIncorrect  avgt    5  6,263 \u00b1 0,094  ns/op\n\nWhy does the measureIncorrect() method is not optimized using java 17?\n",
    "AcceptedAnswerId": 71053938,
    "AcceptedAnswer": "Those samples depend on JDK internals.\nLooks like since JDK 9 and JDK-8152907, Math.log is no longer intrinsified into C2 intermediate representation. Instead, a direct call to a quick LIBM-backed stub is made. This is usually faster for the code that actually uses the result. Notice how measureCorrect is faster in JDK 17 output in your case.\nBut for JMH samples, it limits the the compiler optimizations around the Math.log, and dead code / folding samples do not work properly. The fix it to make samples that do not rely on JDK internals without a good reason, and instead use a custom written payload.\nThis is being done in JMH here:\n\nhttps://bugs.openjdk.java.net/browse/CODETOOLS-7903094\nhttps://github.com/openjdk/jmh/pull/60\n\n"
}
{
    "Id": 71075781,
    "PostTypeId": 1,
    "Title": "How to add classpath dependencies in build.gradle project?",
    "Body": "After the Gradle update, every new project has this type of format in build.gradle (project:\"...\")\n// Top-level build file where you can add configuration options common to all sub-projects/modules.\nplugins {\n    id 'com.android.application' version '7.1.0' apply false\n    id 'com.android.library' version '7.1.0' apply false\n}\n\ntask clean(type: Delete) {\n    delete rootProject.buildDir\n}\n\nNow how can I add classpath dependencies here?\n",
    "AcceptedAnswerId": 71272079,
    "AcceptedAnswer": "If you are adding firebase to your Android App it needs to look something like below.\n\nbuildscript {\n    repositories {\n        // Check that you have the following line (if not, add it):\n        google()  // Google's Maven repository\n\n    }\n    dependencies {\n\n        // Add this line\n        classpath 'com.google.gms:google-services:4.3.10'\n\n    }\n}\n\n\n\nplugins {\n    id 'com.android.application' version '7.1.2' apply false\n    id 'com.android.library' version '7.1.2' apply false\n}\n\n\ntask clean(type: Delete) {\n    delete rootProject.buildDir\n}\n\n"
}
{
    "Id": 71494924,
    "PostTypeId": 1,
    "Title": "How does Java know which overloaded method to call with lambda expressions? (Supplier, Consumer, Callable, ...)",
    "Body": "First off, I have no idea how to decently phrase the question, so this is up for suggestions.\nLets say we have following overloaded methods:\nvoid execute(Callable callable) {\n    try {\n        callable.call();\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n}\n\n T execute(Supplier supplier) {\n    return supplier.get();\n}\n\nvoid execute(Runnable runnable) {\n    runnable.run();\n}\n\nGoing off from this table, I got from another SO question\nSupplier       ()    -> x\nConsumer       x     -> ()\nBiConsumer     x, y  -> ()\nCallable       ()    -> x throws ex\nRunnable       ()    -> ()\nFunction       x     -> y\nBiFunction     x,y   -> z\nPredicate      x     -> boolean\nUnaryOperator  x1    -> x2\nBinaryOperator x1,x2 -> x3\n\nThese are the results I get locally:\n// Runnable -> expected as this is a plain void  \nexecute(() -> System.out.println()); \n\n// Callable -> why is it not a Supplier? It does not throw any exceptions..\nexecute(() -> null);\n\n// Supplier -> this returns an Object, but how is that different from returning null?\nexecute(() -> new Object());\n\n// Callable -> because it can throw an exception, right?\nexecute(() -> {throw new Exception();});\n\nHow does the compiler know which method to call?\nHow does it for example make the distinction between what's a Callable and what's a Runnable?\n",
    "AcceptedAnswerId": 71496000,
    "AcceptedAnswer": "I believe I have found where this is described in official documentation, although a bit hard to read.\nHere is mentioned:\n\n15.27.3. Type of a Lambda Expression\nNote that while boxing is not allowed in a strict invocation context,\nboxing of lambda result expressions is always allowed - that is, the\nresult expression appears in an assignment context, regardless of the\ncontext enclosing the lambda expression. However, if an explicitly\ntyped lambda expression is an argument to an overloaded method, a\nmethod signature that avoids boxing or unboxing the lambda result is\npreferred by the most specific check (\u00a715.12.2.5).\n\nand then here (15.12.2.5) is described analytically how the most specific method is chosen.\nSo according to this for example as described\n\nOne applicable method m1 is more specific than another applicable\nmethod m2, for an invocation with argument expressions e1, ..., ek, if\nany of the following are true:\nm2 is generic, and m1 is inferred to be more specific than m2 for\nargument expressions e1, ..., ek\n\nSo\n// Callable -> why is it not a Supplier?\nexecute(() -> null);   <-- Callable shall be picked from 2 options as M2 is generic and M1 is inferred to be more specific\n\nvoid execute(Callable callable) {  // <------ M1 \n   try {\n    callable.call();\n  } catch (Exception e) {\n      e.printStackTrace();\n  }\n}\n\n\n  T execute(Supplier supplier) {  // <------ M2 is Generic\n    return supplier.get();\n }\n\nWhy M1 is inferred to be more specific can be traced down from this process described here (18.5.4 More Specific Method Inference)\n"
}
{
    "Id": 71500951,
    "PostTypeId": 1,
    "Title": "maven-checkstyle-plugin failed to parse Java 'record'",
    "Body": "I'm trying to setup checkstyle in our project - but seems like Maven (v3.8.3) or maven-checkstyle-plugin (v3.1.1) itself are not aware of Java 14's record (we use Java 17).\n\r\n\r\nCaused by: java.lang.IllegalStateException: /Users/dmitry.adonin/IdeaProjects/raap/src/main/java/com/xxx/web/dto/Request.java:3:8: unexpected token: record\n    at com.puppycrawl.tools.checkstyle.JavaParser$1.reportError (JavaParser.java:93)\n    at com.puppycrawl.tools.checkstyle.grammar.GeneratedJavaRecognizer.typeDefinition (GeneratedJavaRecognizer.java:411)\n    at com.puppycrawl.tools.checkstyle.grammar.GeneratedJavaRecognizer.compilationUnit (GeneratedJavaRecognizer.java:202)\n    at com.puppycrawl.tools.checkstyle.JavaParser.parse (JavaParser.java:99)\n    at com.puppycrawl.tools.checkstyle.TreeWalker.processFiltered (TreeWalker.java:159)\n    at com.puppycrawl.tools.checkstyle.api.AbstractFileSetCheck.process (AbstractFileSetCheck.java:85)\n    at com.puppycrawl.tools.checkstyle.Checker.processFile (Checker.java:329)\n    at com.puppycrawl.tools.checkstyle.Checker.processFiles (Checker.java:291)\n    at com.puppycrawl.tools.checkstyle.Checker.process (Checker.java:216)\n    at org.apache.maven.plugins.checkstyle.exec.DefaultCheckstyleExecutor.executeCheckstyle (DefaultCheckstyleExecutor.java:202)\n    at org.apache.maven.plugins.checkstyle.CheckstyleViolationCheckMojo.execute (CheckstyleViolationCheckMojo.java:545)\n    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:137)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:210)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:156)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:148)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:305)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:972)\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:293)\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:196)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:566)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:282)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:225)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:406)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:347)\nCaused by: antlr.NoViableAltException: unexpected token: record\n    at com.puppycrawl.tools.checkstyle.grammar.GeneratedJavaRecognizer.typeDefinitionInternal (GeneratedJavaRecognizer.java:584)\n    at com.puppycrawl.tools.checkstyle.grammar.GeneratedJavaRecognizer.typeDefinition (GeneratedJavaRecognizer.java:389)\n    at com.puppycrawl.tools.checkstyle.grammar.GeneratedJavaRecognizer.compilationUnit (GeneratedJavaRecognizer.java:202)\n    at com.puppycrawl.tools.checkstyle.JavaParser.parse (JavaParser.java:99)\n    at com.puppycrawl.tools.checkstyle.TreeWalker.processFiltered (TreeWalker.java:159)\n    at com.puppycrawl.tools.checkstyle.api.AbstractFileSetCheck.process (AbstractFileSetCheck.java:85)\n    at com.puppycrawl.tools.checkstyle.Checker.processFile (Checker.java:329)\n    at com.puppycrawl.tools.checkstyle.Checker.processFiles (Checker.java:291)\n    at com.puppycrawl.tools.checkstyle.Checker.process (Checker.java:216)\n    at org.apache.maven.plugins.checkstyle.exec.DefaultCheckstyleExecutor.executeCheckstyle (DefaultCheckstyleExecutor.java:202)\n    at org.apache.maven.plugins.checkstyle.CheckstyleViolationCheckMojo.execute (CheckstyleViolationCheckMojo.java:545)\n    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:137)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:210)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:156)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:148)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:305)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:972)\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:293)\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:196)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:566)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:282)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:225)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:406)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:347)\r\n\r\n\r\n\nThere are the following configs:\npom.xml:\n\r\n\r\n\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    4.0.0\n\n    \n        org.springframework.boot\n        spring-boot-starter-parent\n        2.6.2\n        \n    \n\n    ...\n    ...\n    0.0.1-SNAPSHOT\n    ...\n\n    \n        17\n    \n\n    \n    ...\n    \n\n    \n        \n            \n                org.springframework.boot\n                spring-boot-maven-plugin\n                \n                    \n                        \n                            org.projectlombok\n                            lombok\n                        \n                    \n                \n            \n            \n                org.apache.maven.plugins\n                maven-checkstyle-plugin\n                3.1.1\n                \n                    project-checks.xml\n                    UTF-8\n                    true\n                    true\n                    true\n                    false\n                \n                \n                    \n                        checkstyle-validation\n                        validate\n                        \n                            check\n                        \n                    \n                \n            \n        \n    \n\n\r\n\r\n\r\n\nproject-checks.xml:\n\r\n\r\n\n\n<!DOCTYPE module PUBLIC\n        \"-//Checkstyle//DTD Checkstyle Configuration 1.3//EN\"\n        \"https://checkstyle.org/dtds/configuration_1_3.dtd\">\n\n<!--\n    Checkstyle configuration that checks the Google coding conventions from Google Java Style\n    that can be found at https://google.github.io/styleguide/javaguide.html\n    Checkstyle is very configurable. Be sure to read the documentation at\n    https://checkstyle.org (or in your downloaded distribution).\n    To completely disable a check, just comment it out or delete it from the file.\n    To suppress certain violations please review suppression filters.\n    Authors: Max Vetrenko, Ruslan Diachenko, Roman Ivanov.\n -->\n\n\n    \n\n    \n\n    \n    \n    \n    \n        \n    \n    \n    \n    \n        \n        \n    \n\n    \n    \n    \n        \n    \n\n    \n        \n        \n        \n    \n\n    \n        \n        \n            \n            <property name=\"format\"\n                      value=\"\\\\u00(09|0(a|A)|0(c|C)|0(d|D)|22|27|5(C|c))|\\\\(0(10|11|12|14|15|42|47)|134)\"/>\n            <property name=\"message\"\n                      value=\"Consider using special escape sequence instead of octal value or Unicode escaped value.\"/>\n        \n        \n            \n            \n            \n        \n        \n        \n        \n        \n            \n        \n        \n            \n            <property name=\"tokens\"\n                      value=\"LITERAL_TRY, LITERAL_FINALLY, LITERAL_IF, LITERAL_ELSE, LITERAL_SWITCH\"/>\n        \n        \n            <property name=\"tokens\"\n                      value=\"LITERAL_DO, LITERAL_ELSE, LITERAL_FOR, LITERAL_IF, LITERAL_WHILE\"/>\n        \n        \n            <property name=\"tokens\"\n                      value=\"ANNOTATION_DEF, CLASS_DEF, CTOR_DEF, ENUM_CONSTANT_DEF, ENUM_DEF,\n                    INTERFACE_DEF, LAMBDA, LITERAL_CASE, LITERAL_CATCH, LITERAL_DEFAULT,\n                    LITERAL_DO, LITERAL_ELSE, LITERAL_FINALLY, LITERAL_FOR, LITERAL_IF,\n                    LITERAL_SWITCH, LITERAL_SYNCHRONIZED, LITERAL_TRY, LITERAL_WHILE, METHOD_DEF,\n                    OBJBLOCK, STATIC_INIT\"/>\n        \n        \n            \n            <property name=\"tokens\"\n                      value=\"LITERAL_TRY, LITERAL_CATCH, LITERAL_FINALLY, LITERAL_IF, LITERAL_ELSE,\n                    LITERAL_DO\"/>\n        \n        \n            \n            \n            <property name=\"tokens\"\n                      value=\"CLASS_DEF, METHOD_DEF, CTOR_DEF, LITERAL_FOR, LITERAL_WHILE, STATIC_INIT,\n                    INSTANCE_INIT, ANNOTATION_DEF, ENUM_DEF\"/>\n        \n        \n            \n            \n            <property name=\"query\" value=\"//RCURLY[parent::SLIST[count(./*)=1]\n                                                 or preceding-sibling::*[last()][self::LCURLY]]\"/>\n        \n        \n            \n            \n            \n            \n            \n            <property name=\"tokens\"\n                      value=\"ASSIGN, BAND, BAND_ASSIGN, BOR, BOR_ASSIGN, BSR, BSR_ASSIGN, BXOR,\n                    BXOR_ASSIGN, COLON, DIV, DIV_ASSIGN, DO_WHILE, EQUAL, GE, GT, LAMBDA, LAND,\n                    LCURLY, LE, LITERAL_CATCH, LITERAL_DO, LITERAL_ELSE, LITERAL_FINALLY,\n                    LITERAL_FOR, LITERAL_IF, LITERAL_RETURN, LITERAL_SWITCH, LITERAL_SYNCHRONIZED,\n                     LITERAL_TRY, LITERAL_WHILE, LOR, LT, MINUS, MINUS_ASSIGN, MOD, MOD_ASSIGN,\n                     NOT_EQUAL, PLUS, PLUS_ASSIGN, QUESTION, RCURLY, SL, SLIST, SL_ASSIGN, SR,\n                     SR_ASSIGN, STAR, STAR_ASSIGN, LITERAL_ASSERT, TYPE_EXTENSION_AND\"/>\n            <message key=\"ws.notFollowed\"\n                     value=\"WhitespaceAround: ''{0}'' is not followed by whitespace. Empty blocks may only be represented as '{}' when not part of a multi-block statement (4.1.3)\"/>\n            <message key=\"ws.notPreceded\"\n                     value=\"WhitespaceAround: ''{0}'' is not preceded with whitespace.\"/>\n        \n        \n        \n        \n        \n        \n        \n        \n        \n            <property name=\"tokens\"\n                      value=\"PACKAGE_DEF, IMPORT, STATIC_IMPORT, CLASS_DEF, INTERFACE_DEF, ENUM_DEF,\n                    STATIC_INIT, INSTANCE_INIT, METHOD_DEF, CTOR_DEF, VARIABLE_DEF\"/>\n            \n            \n            \n        \n        \n            \n            \n            \n        \n        \n            \n            \n            \n        \n        \n            \n            \n            \n            \n        \n        \n            \n            \n            \n            \n        \n        \n            \n            \n            \n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Package name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Type name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Member name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Parameter name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Lambda parameter name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Catch parameter name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Local variable name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Class type name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Method type name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Interface type name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Method name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n        \n            <message key=\"ws.followed\"\n                     value=\"GenericWhitespace ''{0}'' is followed by whitespace.\"/>\n            <message key=\"ws.preceded\"\n                     value=\"GenericWhitespace ''{0}'' is preceded with whitespace.\"/>\n            <message key=\"ws.illegalFollow\"\n                     value=\"GenericWhitespace ''{0}'' should followed by whitespace.\"/>\n            <message key=\"ws.notPreceded\"\n                     value=\"GenericWhitespace ''{0}'' is not preceded with whitespace.\"/>\n        \n        \n            \n            \n            \n            \n            \n            \n        \n        \n            \n            \n            <property name=\"tokens\"\n                      value=\"CLASS_DEF, INTERFACE_DEF, ENUM_DEF, ANNOTATION_DEF, ANNOTATION_FIELD_DEF,\n                    PARAMETER_DEF, VARIABLE_DEF, METHOD_DEF\"/>\n        \n        \n        \n        \n            \n            \n            \n            \n            \n            \n        \n        \n            <property name=\"tokens\"\n                      value=\"CTOR_DEF, LITERAL_NEW, METHOD_CALL, METHOD_DEF,\n                    SUPER_CTOR_CALL, ENUM_CONSTANT_DEF\"/>\n        \n        \n            <property name=\"tokens\"\n                      value=\"COMMA, SEMI, POST_INC, POST_DEC, DOT, ELLIPSIS, METHOD_REF\"/>\n            \n        \n        \n            <property name=\"tokens\"\n                      value=\"ANNOTATION, ANNOTATION_FIELD_DEF, CTOR_CALL, CTOR_DEF, DOT, ENUM_CONSTANT_DEF,\n                    EXPR, LITERAL_CATCH, LITERAL_DO, LITERAL_FOR, LITERAL_IF, LITERAL_NEW,\n                    LITERAL_SWITCH, LITERAL_SYNCHRONIZED, LITERAL_WHILE, METHOD_CALL,\n                    METHOD_DEF, QUESTION, RESOURCE_SPECIFICATION, SUPER_CTOR_CALL, LAMBDA\"/>\n        \n        \n            \n            <property name=\"tokens\"\n                      value=\"BAND, BOR, BSR, BXOR, DIV, EQUAL, GE, GT, LAND, LE, LITERAL_INSTANCEOF, LOR,\n                    LT, MINUS, MOD, NOT_EQUAL, PLUS, QUESTION, SL, SR, STAR, METHOD_REF \"/>\n        \n        \n            \n            <property name=\"tokens\"\n                      value=\"CLASS_DEF, INTERFACE_DEF, ENUM_DEF, METHOD_DEF, CTOR_DEF\"/>\n        \n        \n            \n            \n            \n        \n        \n        \n        \n        \n            <property name=\"forbiddenSummaryFragments\"\n                      value=\"^@return the *|^This method returns |^A [{]@code [a-zA-Z0-9]+[}]( is a )\"/>\n        \n        \n        \n            \n            <property name=\"target\"\n                      value=\"CLASS_DEF, INTERFACE_DEF, ENUM_DEF, METHOD_DEF, CTOR_DEF, VARIABLE_DEF\"/>\n        \n        \n            \n            \n            \n            \n            \n        \n        \n            \n        \n        \n            \n        \n        \n            \n        \n        \n        \n            \n            \n        \n    \n\r\n\r\n\r\n\nCould someone please suggest what should be adjusted to make it work?\nThank you!\n",
    "AcceptedAnswerId": 71501025,
    "AcceptedAnswer": "The plugin by default comes with Checkstyle version 8.29. Try explicitly defining the CheckStyle version (plus a small version bump to 3.1.2). For example, with version 9.2:\n\n    org.apache.maven.plugins\n    maven-checkstyle-plugin\n    3.1.2\n    \n       ...\n    \n    \n        \n            com.puppycrawl.tools\n            checkstyle\n            9.2\n        \n    \n    \n        ...\n    \n\n\n"
}
{
    "Id": 71361477,
    "PostTypeId": 1,
    "Title": "Targeting S+ (version 31 and above) requires that one of FLAG_IMMUTABLE or FLAG_MUTABLE",
    "Body": "when I launch my app in android 12, it crashed and it give me this error,\nmy project already have this dependency\nimplementation 'androidx.work:work-runtime-ktx:2.7.1'\n\nI updated\nimplementation 'com.google.firebase:firebase-messaging-ktx:23.0.0'\n\nfirebase messaging library too\nand I used pending intent in my project like this\n    val pendingIntent = PendingIntent.getActivity(\n        applicationContext,\n        0,\n        intent,\n        PendingIntent.FLAG_IMMUTABLE or PendingIntent.FLAG_UPDATE_CURRENT // setting the mutability flag\n    )\n\nerror :\nE/AndroidRuntime: FATAL EXCEPTION: OkHttp Dispatcher\nProcess: com.internal, PID: 11866\njava.lang.IllegalArgumentException: com.internal: Targeting S+ (version 31 and above) requires that one of FLAG_IMMUTABLE or FLAG_MUTABLE be specified when creating a PendingIntent.\nStrongly consider using FLAG_IMMUTABLE, only use FLAG_MUTABLE if some functionality depends on the PendingIntent being mutable, e.g. if it needs to be used with inline replies or bubbles.\n    at android.app.PendingIntent.checkFlags(PendingIntent.java:375)\n    at android.app.PendingIntent.getActivityAsUser(PendingIntent.java:458)\n    at android.app.PendingIntent.getActivity(PendingIntent.java:444)\n    at android.app.PendingIntent.getActivity(PendingIntent.java:408)\n    at com.chuckerteam.chucker.internal.support.NotificationHelper$transactionsScreenIntent$2.invoke(NotificationHelper.kt:47)\n    at com.chuckerteam.chucker.internal.support.NotificationHelper$transactionsScreenIntent$2.invoke(NotificationHelper.kt:19)\n    at kotlin.SynchronizedLazyImpl.getValue(LazyJVM.kt:74)\n    at com.chuckerteam.chucker.internal.support.NotificationHelper.getTransactionsScreenIntent(Unknown Source:2)\n    at com.chuckerteam.chucker.internal.support.NotificationHelper.show(NotificationHelper.kt:101)\n    at com.chuckerteam.chucker.api.ChuckerCollector.onRequestSent$com_github_ChuckerTeam_Chucker_library(ChuckerCollector.kt:65)\n    at com.chuckerteam.chucker.api.ChuckerInterceptor.intercept(ChuckerInterceptor.kt:111)\n    at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:109)\n    at com.android.core.helpers.interceptor.HeadersInterceptor.intercept(HeadersInterceptor.kt:41)\n    at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:109)\n    at com.android.core.helpers.AuthInterceptor.intercept(AuthInterceptor.kt:39)\n    at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:109)\n    at okhttp3.internal.connection.RealCall.getResponseWithInterceptorChain$okhttp(RealCall.kt:201)\n    at okhttp3.internal.connection.RealCall$AsyncCall.run(RealCall.kt:517)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)\n    at java.lang.Thread.run(Thread.java:920)\nE/WebEngage: App has crashed\n    java.lang.IllegalArgumentException: com.internal: Targeting S+ (version 31 and above) requires that one of FLAG_IMMUTABLE or FLAG_MUTABLE be specified when creating a PendingIntent.\n    Strongly consider using FLAG_IMMUTABLE, only use FLAG_MUTABLE if some functionality depends on the PendingIntent being mutable, e.g. if it needs to be used with inline replies or bubbles.\n\n",
    "AcceptedAnswerId": 71370528,
    "AcceptedAnswer": "I finally found the problem,\nI had chucker library and I updated it to the latest version and it fixed\n"
}
{
    "Id": 71063202,
    "PostTypeId": 1,
    "Title": "check valid date in java",
    "Body": "I tried to check a String input that is a valid date using the format dd/MM/yyyy like this:\nString input = Scanner.nextLine();\nDateTimeFormatter formater = DateTimeFormatter.ofPattern(\"dd/MM/yyyy\");\ntry{\n    LocaleDate.parse(input, formater);\n}\ncatch(Exception e)\n\nBut it can't check some rules below:\nLeap year, February 29 days.\n\nCommon year, February 28 days.\n\nMonth 1, 3, 5, 7, 8, 10, 12, max 31 days.\n\nMonth 4, 6, 9, 11, max 30 days.\n\nWhen I use input = \"30/02/2022\", it's legal.\nI use netbeans 8.2 and jdk 1.8. Do they support some methods for checking these rules?\n",
    "AcceptedAnswerId": 71063276,
    "AcceptedAnswer": "There are two things you need to change in your formatter:\n\nUse uuuu instead of yyyy. It's easy to try the latter, but y means \"year within ERA\". It doesn't know whether it's BC or AD. u means \"year\" including ERA information.\nThe default resolver style is SMART. Use .withResolverStyle(ResolverStyle.STRICT) to return a strict copy of the formatter.\n\n"
}
{
    "Id": 71250218,
    "PostTypeId": 1,
    "Title": "Java, project panama and how to deal with Hunspell 'suggest' result",
    "Body": "I'm experimenting with Hunspell and how to interact with it using Java Project Panama (Build 19-panama+1-13 (2022/1/18)). I was able to get some initial testing done, as in creating a handle to Hunspell and subsequently using that to perform a spell check. I'm now trying something more elaborate, letting Hunspell give me suggestions for a word not present in the dictionary. This is the code that I have for that now:\npublic class HelloHun {\n    public static void main(String[] args) {\n        MemoryAddress hunspellHandle = null;\n        try (ResourceScope scope = ResourceScope.newConfinedScope()) {\n            var allocator = SegmentAllocator.nativeAllocator(scope);\n\n            // Point it to US english dictionary and (so called) affix file\n            // Note #1: it is possible to add words to the dictionary if you like\n            // Note #2: it is possible to have separate/individual dictionaries and affix files (e.g. per user/doc type)\n            var en_US_aff = allocator.allocateUtf8String(\"/usr/share/hunspell/en_US.aff\");\n            var en_US_dic = allocator.allocateUtf8String(\"/usr/share/hunspell/en_US.dic\");\n\n            // Get a handle to the Hunspell shared library and load up the dictionary and affix\n            hunspellHandle = Hunspell_create(en_US_aff, en_US_dic);\n\n            // Feed it a wrong word\n            var javaWord = \"koing\";\n\n            // Do a simple spell check of the word\n            var word = allocator.allocateUtf8String(javaWord);\n            var spellingResult = Hunspell_spell(hunspellHandle, word);\n            System.out.println(String.format(\"%s is spelled %s\", javaWord, (spellingResult == 0 ? \"incorrect\" : \"correct\")));\n\n            // Hunspell also supports giving suggestions for a word - which is what we do next\n            // Note #3: by testing this `koing` word in isolation - we know that there are 4 alternatives for this word\n            // Note #4: I'm still investigating how to access individual suggestions\n\n            var suggestions = allocator.allocate(10);\n            var suggestionCount = Hunspell_suggest(hunspellHandle, suggestions, word);\n\n            System.out.println(String.format(\"There are %d suggestions for %s\", suggestionCount, javaWord));\n\n            // `suggestions` - according to the hunspell API - is a `pointer to an array of strings pointer`\n            // we know how many `strings` pointer there are, as that is the returned value from `suggest`\n            // Question: how to process `suggestions` to get individual suggestions\n\n\n        } finally {\n            if (hunspellHandle != null) {\n                Hunspell_destroy(hunspellHandle);\n            }\n        }\n    }\n}\n\nWhat I'm seeing is that a call to Hunspell_suggest (created from jextract) succeeds and gives me back (4) suggestions (which I verified using Hunspell from the commandline) - so no problem there.\nWhat is more challenging for me now is how do I unpack the suggestions element that comes back from this call? I've been looking at various examples, but none of them seem to go into this level of detail (and even if I find examples, they seem to be using outdated panama APIs).\nSo in essence, here is my question:\nHow do I unpack a structure that reportedly consists of a pointer to an array of strings pointer using panama JDK19 APIs to their respective collection of strings?\n",
    "AcceptedAnswerId": 71258371,
    "AcceptedAnswer": "Looking at the header here: https://github.com/hunspell/hunspell/blob/master/src/hunspell/hunspell.h#L80\n/* suggest(suggestions, word) - search suggestions\n * input: pointer to an array of strings pointer and the (bad) word\n *   array of strings pointer (here *slst) may not be initialized\n * output: number of suggestions in string array, and suggestions in\n *   a newly allocated array of strings (*slts will be NULL when number\n *   of suggestion equals 0.)\n */\nLIBHUNSPELL_DLL_EXPORTED int Hunspell_suggest(Hunhandle* pHunspell,\n                                              char*** slst,\n                                              const char* word);\n\nThe slst is a classic 'out' parameter. i.e. we pass a pointer to some value (in this case a char** i.e. an array of strings), and the function will set this pointer for us, as a way to return multiple results. (the first result being the number of suggestions)\nIn panama you use 'out' parameters by allocating a segment with the layout of the type the parameter is a pointer of. In this case char*** is a pointer to char**, so the layout is ADDRESS. We then pass the created segment to the function, and finally retrieve/use the value from that segment after the function call, which will have filled in the segment contents:\n// char***\nvar suggestionsRef = allocator.allocate(ValueLayout.ADDRESS); // allocate space for an address\nvar suggestionCount = Hunspell_suggest(hunspellHandle, suggestionsRef, word);\n// char** (the value set by the function)\nMemoryAddress suggestions = suggestionsRef.get(ValueLayout.ADDRESS, 0);\n\nAfter that, you can iterate over the array of strings:\nfor (int i = 0; i < suggestionCount; i++) {\n    // char* (an element in the array)\n    MemoryAddress suggestion = suggestions.getAtIndex(ValueLayout.ADDRESS, i);\n    // read the string\n    String javaSuggestion = suggestion.getUtf8String(suggestion, 0);\n}\n\n"
}
{
    "Id": 71587610,
    "PostTypeId": 1,
    "Title": "Micrometer @Timed annotation on simple public and private (service) methods",
    "Body": "I'm trying to apply Prometheus metrics using the micrometer @Timed annotations.\nI found out that they only work on controller endpoints and not \"simple\" public and private methods.\nGiven this example:\n@RestController\npublic class TestController {\n\n    @GetMapping(\"/test\")\n    @Timed(\"test-endpoint\") //does create prometheus metrics\n    public String test() {\n        privateMethod();\n        publicMethod();\n        return \"test\";\n    }\n\n    @Timed(\"test-private\") //does NOT create prometheus metrics\n    private void privateMethod() {System.out.println(\"private stuff\");}\n\n    @Timed(\"test-public\") //does NOT create prometheus metrics\n    public void publicMethod() {System.out.println(\"public stuff\");}\n}\n\ncreates the following metrics:\n...\n# HELP test_endpoint_seconds  \n# TYPE test_endpoint_seconds summary\ntest_endpoint_seconds_count{class=\"com.example.micrometerannotationexample.TestController\",exception=\"none\",method=\"test\",} 1.0\ntest_endpoint_seconds_sum{class=\"com.example.micrometerannotationexample.TestController\",exception=\"none\",method=\"test\",} 0.0076286\n# HELP test_endpoint_seconds_max  \n# TYPE test_endpoint_seconds_max gauge\ntest_endpoint_seconds_max{class=\"com.example.micrometerannotationexample.TestController\",exception=\"none\",method=\"test\",} 0.0076286\n...\n\nNo metrics found for @Timed(\"test-private\") and @Timed(\"test-public\"), why is that?\n\nNote: I've read on this github thread, that Spring Boot does not recognize @Timed annotations on arbitrary methods and that you need to manually configure a TimedAspect Bean in order for it to work. I've tried that but still it yields no results.\n@Configuration\n@EnableAspectJAutoProxy\npublic class MetricsConfig {\n    @Bean\n    public TimedAspect timedAspect(MeterRegistry registry) {\n        return new TimedAspect(registry);\n    }\n}\n\nTo try this locally see necessary gist here\n",
    "AcceptedAnswerId": 71602539,
    "AcceptedAnswer": "@Timed works only on public methods called by another class.\nSpring Boot annotations like @Timed / @Transactional need the so-called proxying which happens only between invocations of public methods.\nA good explanation is this one https://stackoverflow.com/a/3429757/2468241\n"
}
{
    "Id": 70938297,
    "PostTypeId": 1,
    "Title": "How to add classpath in new version of Android Studio",
    "Body": "I updated my android studio version to bumblebee version.\nNow I want add navigation component to my project.\nI want add classpath to gradle, but this file gradle has been changed and I don'y know how can I add this.\nI want add this        classpath(\"androidx.navigation:navigation-safe-args-gradle-plugin:$nav_version\") to gradle files!\nMy project gradle file is :\n    plugins {\n    id 'com.android.application' version '7.1.0' apply false\n    id 'com.android.library' version '7.1.0' apply false\n    id 'org.jetbrains.kotlin.android' version '1.6.10' apply false\n}\n\ntask clean(type: Delete) {\n    delete rootProject.buildDir\n}\n\nHow can I add this classpath to application gradle ?!\n",
    "AcceptedAnswerId": 71410793,
    "AcceptedAnswer": "In the latest version in February 2022 doesn't need to add buildscript anymore just add the id in build.gradle for project. It will be like this in build.gradle for project:\nplugins {\n    id 'com.android.application' version '7.1.2' apply false\n    id 'com.android.library' version '7.1.2' apply false\n    id 'org.jetbrains.kotlin.android' version '1.6.10' apply false\n\n    id 'androidx.navigation.safeargs' version '2.4.1' apply false\n    // classpath are changed, so no need to add classpath anymore just the id and the version\n}\n\nDon't forget add the id again in the build.gradle module,\nplugins {\n    id 'com.android.application'\n    id 'org.jetbrains.kotlin.android'\n    id 'androidx.navigation.safeargs'\n}\n\n"
}
{
    "Id": 71724227,
    "PostTypeId": 1,
    "Title": "When to use and not use @Mock annotation, @MockBean annotation, @InjectMock annotation & @Autowired annotation in a spring webflux reactive project",
    "Body": "Can you please explain when to use below annotations and when not to use those. I am pretty new to testing frameworks and confused with all the answers in the web.\n@Mock\nprivate Resource resource;\n@MockBean\nprivate Resource resource;\n@InjectMock\nprivate ProductService productService; \n@AutoWired\nPrivate ProductRepository productRepo;\n\n",
    "AcceptedAnswerId": 71724474,
    "AcceptedAnswer": "@Mock\nUsed to make Mockito create a mock object.\n@InjectMock\nWhen you want Mockito to create an instance of an object and use the mocks annotated with @Mock as its dependencies.\n@AutoWired\nUsed when you want to autowire a bean from the spring context, works exactly the same as in normal code but can only be used in tests that actually creates an application context, such as tests annotated with @WebMvcTest or @SpringBootTest.\n@MockBean\nCan be used to add mock objects to the Spring application context. The mock will replace any existing bean of the same type in the application context. If no bean of the same type is defined, a new one will be added. Often used together with @SpringBootTest\nSo normally you either:\n\nUse @Mock and @InjectMocks for running tests without a spring\ncontext, this is preferred as it's much faster.\nUse @SpringBootTest or @SpringMvcTest to start a spring context together with @MockBean to create mock objects and @Autowired to get an instance of class you want to test, the mockeans will be used for its autowired dependencies. You use this when writing integration tests for code that interact with a database or want to test your REST API.\n\n"
}
{
    "Id": 71029574,
    "PostTypeId": 1,
    "Title": "Firebase Push notification not receiving in Android12 in Samsung S10 Device After updating Patch Update",
    "Body": "I am using a Samsung Galaxy S10 mobile. On February 3rd Security patch was updated on my phone. After the update Push notification was not received in my App. Other App notifications are working fine. Anyone can answer my question, please? What was the reason for not receiving notification?\n",
    "AcceptedAnswerId": 71506283,
    "AcceptedAnswer": "The answer could be because the PendingIntent for that app's notifications hasn't had its mutability defined. Starting from Android 12, you have to define whether a PendingIntent is immutable or mutable for it to work properly:\nhttps://developer.android.com/about/versions/12/behavior-changes-12#pending-intent-mutability\nAnother thing to try to make notifications work again is to add the \"exported:false\" tag to the notifications service:\nhttps://developer.android.com/about/versions/12/behavior-changes-12#exported\nThat should help.\n"
}
{
    "Id": 71338792,
    "PostTypeId": 1,
    "Title": "java.lang.NoClassDefFoundError: Failed resolution of: Ljava/lang/Math8 when upgrading Gradle and Android Gradle Plugin",
    "Body": "I'm working on an Android app with a Gradle version of 7.1.1 and an Android Gradle Plugin version of 7.0.0. When I upgrade to Gradle version 7.2 and Android Gradle Plugin version 7.1.1, I get the following error.\n2022-03-02 17:15:47.072 25300-25300/... E/AndroidRuntime: FATAL EXCEPTION: main\n    Process: ..., PID: 25300\n    java.lang.NoClassDefFoundError: Failed resolution of: Ljava/lang/Math8;\n        at j$.time.Instant.ofEpochSecond(Instant.java:328)\n        at j$.time.Instant.(Instant.java:232)\n        at j$.time.Instant.ofEpochMilli(Instant.java:344)\n        ...\n        at kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)\n        at kotlinx.coroutines.DispatchedTask.run(DispatchedTask.kt:106)\n        at android.os.Handler.handleCallback(Handler.java:883)\n        at android.os.Handler.dispatchMessage(Handler.java:100)\n        at android.os.Looper.loop(Looper.java:214)\n        at android.app.ActivityThread.main(ActivityThread.java:7356)\n        at java.lang.reflect.Method.invoke(Native Method)\n        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:492)\n        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:930)\n     Caused by: java.lang.ClassNotFoundException: Didn't find class \"java.lang.Math8\" on path: DexPathList[[zip file \"/data/app/...-NbMXeOj8LumN03n4IMK5Cw==/base.apk\"],nativeLibraryDirectories=[/data/app/...-NbMXeOj8LumN03n4IMK5Cw==/lib/x86, /data/app/...-NbMXeOj8LumN03n4IMK5Cw==/base.apk!/lib/x86, /system/lib, /system/product/lib]]\n        at dalvik.system.BaseDexClassLoader.findClass(BaseDexClassLoader.java:196)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:379)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:312)\n        at j$.time.Instant.ofEpochSecond(Instant.java:328) \n        at j$.time.Instant.(Instant.java:232) \n        at j$.time.Instant.ofEpochMilli(Instant.java:344) \n        ...\n        at kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33) \n        at kotlinx.coroutines.DispatchedTask.run(DispatchedTask.kt:106) \n        at android.os.Handler.handleCallback(Handler.java:883) \n        at android.os.Handler.dispatchMessage(Handler.java:100) \n        at android.os.Looper.loop(Looper.java:214) \n        at android.app.ActivityThread.main(ActivityThread.java:7356) \n        at java.lang.reflect.Method.invoke(Native Method) \n        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:492) \n        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:930)\n\nThe error is coming from this code:\nfun toLocalStartOfDay(date: Long): Instant = Instant.ofEpochMilli(date)\n    .atZone(ZoneId.systemDefault())\n    .withHour(0)\n    .withMinute(0)\n    .withSecond(0)\n    .withNano(0)\n    .toInstant()\n\nThe build.gradle file is set to target JVM 1.8 with desugaring.\ncompileOptions {\n    coreLibraryDesugaringEnabled = true\n    sourceCompatibility JavaVersion.VERSION_1_8\n    targetCompatibility JavaVersion.VERSION_1_8\n}\n\nkotlinOptions {\n    jvmTarget = '1.8'\n}\n\nThe desugar_jdk_libs version is set to 1.0.9.\nversions.androidDesugaringVersion = '1.0.9'\nsupport.android_desugaring = \"com.android.tools:desugar_jdk_libs:$versions.androidDesugaringVersion\"\n\nWhy would upgrading cause this error?\n",
    "AcceptedAnswerId": 71340133,
    "AcceptedAnswer": "Desugaring effects \"a subset of java.time\" so upgrading to the latest version of desugar_jdk_libs should fix the issue. At the time of posting, the latest version is 1.1.5.\nReferences\n\nJava 8+ API desugaring support (Android Gradle Plugin 4.0.0+)\ndesugar_jdk_libs (Maven)\n\n"
}
{
    "Id": 71722390,
    "PostTypeId": 1,
    "Title": "Log4J2 AppenderLoggingException NoSuchMethodError StackLocatorUtil.getCurrentStackTrace()",
    "Body": "As soon as an exception/error occurs and is supposed to be logged, I get the following error/stack trace:\norg.apache.logging.log4j.core.appender.AppenderLoggingException: java.lang.NoSuchMethodError: 'java.util.Deque org.apache.logging.log4j.util.StackLocatorUtil.getCurrentStackTrace()'\n   at org.apache.logging.log4j.core.config.AppenderControl.tryCallAppender(AppenderControl.java:165)\n   at org.apache.logging.log4j.core.config.AppenderControl.callAppender0(AppenderControl.java:134)\n   at org.apache.logging.log4j.core.config.AppenderControl.callAppenderPreventRecursion(AppenderControl.java:125)\n   at org.apache.logging.log4j.core.config.AppenderControl.callAppender(AppenderControl.java:89)\n   at org.apache.logging.log4j.core.config.LoggerConfig.callAppenders(LoggerConfig.java:675)\n   at org.apache.logging.log4j.core.config.LoggerConfig.processLogEvent(LoggerConfig.java:633)\n   at org.apache.logging.log4j.core.config.LoggerConfig.log(LoggerConfig.java:616)\n   at org.apache.logging.log4j.core.config.LoggerConfig.log(LoggerConfig.java:552)\n   at org.apache.logging.log4j.core.config.AwaitCompletionReliabilityStrategy.log(AwaitCompletionReliabilityStrategy.java:82)\n   at org.apache.logging.log4j.core.Logger.log(Logger.java:161)\n   at org.apache.logging.log4j.spi.AbstractLogger.tryLogMessage(AbstractLogger.java:2205)\n   at org.apache.logging.log4j.spi.AbstractLogger.logMessageTrackRecursion(AbstractLogger.java:2159)\n   at org.apache.logging.log4j.spi.AbstractLogger.logMessageSafely(AbstractLogger.java:2142)\n   at org.apache.logging.log4j.spi.AbstractLogger.logMessage(AbstractLogger.java:2017)\n   at org.apache.logging.log4j.spi.AbstractLogger.logIfEnabled(AbstractLogger.java:1983)\n   at org.apache.logging.log4j.spi.AbstractLogger.fatal(AbstractLogger.java:1063)\n\nthe next at is whatever called Logger#fatal/error(String,Throwable)\nJava 11, Log4J 2.17.2 (-core and -api), project built using Gradle. removing Multi-Release: true from build.gradle doesn't seem to fix the issue (only adds the, to be expected, Reflection.getCallerClass() warning)\nWhat am I missing?\n",
    "AcceptedAnswerId": 71729253,
    "AcceptedAnswer": "Turns out a library had the dependency Log4J-api 2.17.1 (but not -core), my gradle file specified Log4J-core 2.17.2 so the older -api version overrid the latest one.\nApparently, from 2.17.1 to .2, StackLocatorUtil.getCurrentStackTrace()'s return was changed from Stack to Deque.\n"
}
{
    "Id": 71771423,
    "PostTypeId": 1,
    "Title": "React Native: 'compileJava' task (current target is 1.8) and 'compileKotlin' task (current target is 11) jvm target compat",
    "Body": "Hello everyone I am trying to create and run a react native app. I run\nnpx react-native init rn4 but when I run npm run android I have this error:\n> Task :react-native-gradle-plugin:compileKotlin\n'compileJava' task (current target is 1.8) and 'compileKotlin' task (current target is 11) jvm target compatibility should be set to the same Java version.\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\ReactExtension.kt: (10, 37): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\ReactExtension.kt: (119, 30): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\ReactExtension.kt: (135, 26): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\ReactExtension.kt: (155, 32): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\ReactExtension.kt: (161, 31): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\ReactExtension.kt: (169, 36): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\ReactPlugin.kt: (99, 48): 'reactRoot: DirectoryProperty' is deprecated. reactRoot was confusing and has been replace with rootto point to your root project and reactNativeDir to point to the folder of the react-native NPM package\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\TaskConfiguration.kt: (10, 37): 'ApplicationVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\TaskConfiguration.kt: (11, 37): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\TaskConfiguration.kt: (12, 37): 'LibraryVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\TaskConfiguration.kt: (28, 51): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\TaskConfiguration.kt: (131, 12): 'ApplicationVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\TaskConfiguration.kt: (132, 12): 'LibraryVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\TaskConfiguration.kt: (250, 14): 'BaseVariant' is deprecated. Deprecated in Java\n\n> Task :react-native-gradle-plugin:compileJava\n6 actionable tasks: 6 executed\nNote: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\java\\com\\facebook\\react\\codegen\\generator\\SchemaJsonParser.java uses or overrides a deprecated API.\nNote: Recompile with -Xlint:deprecation for details.\n\nFAILURE: Build failed with an exception.\n\n* Where:\nBuild file 'C:\\Users\\emanu\\App\\rn4\\android\\app\\build.gradle' line: 1\n\n* What went wrong:\nA problem occurred evaluating project ':app'.\n> Failed to apply plugin 'com.android.internal.application'.\n   > Android Gradle plugin requires Java 11 to run. You are currently using Java 1.8.\n     You can try some of the following options:\n       - changing the IDE settings.\n       - changing the JAVA_HOME environment variable.\n       - changing `org.gradle.java.home` in `gradle.properties`.\n\n* Try:\n> Run with --stacktrace option to get the stack trace.\n> Run with --info or --debug option to get more log output.\n> Run with --scan to get full insights.\n\n* Get more help at https://help.gradle.org\n\nBUILD FAILED in 59s\n\nerror Failed to install the app. Make sure you have the Android development environment set up: https://reactnative.dev/docs/environment-setup.\nError: Command failed: gradlew.bat app:installDebug -PreactNativeDevServerPort=8081\nNote: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\java\\com\\facebook\\react\\codegen\\generator\\SchemaJsonParser.java uses or overrides a deprecated API.\nNote: Recompile with -Xlint:deprecation for details.\n\nFAILURE: Build failed with an exception.\n\n* Where:\nBuild file 'C:\\Users\\emanu\\App\\rn4\\android\\app\\build.gradle' line: 1\n\n* What went wrong:\nA problem occurred evaluating project ':app'.\n> Failed to apply plugin 'com.android.internal.application'.\n   > Android Gradle plugin requires Java 11 to run. You are currently using Java 1.8.\n     You can try some of the following options:\n       - changing the IDE settings.\n       - changing the JAVA_HOME environment variable.\n       - changing `org.gradle.java.home` in `gradle.properties`.\n\n* Try:\n> Run with --stacktrace option to get the stack trace.\n> Run with --info or --debug option to get more log output.\n> Run with --scan to get full insights.\n\n* Get more help at https://help.gradle.org\n\nBUILD FAILED in 59s\n\n    at makeError (C:\\Users\\emanu\\App\\rn4\\node_modules\\execa\\index.js:174:9)\n    at C:\\Users\\emanu\\App\\rn4\\node_modules\\execa\\index.js:278:16\n    at processTicksAndRejections (node:internal/process/task_queues:96:5)\n    at async runOnAllDevices (C:\\Users\\emanu\\App\\rn4\\node_modules\\@react-native-community\\cli-platform-android\\build\\commands\\runAndroid\\runOnAllDevices.js:109:5)\n    at async Command.handleAction (C:\\Users\\emanu\\App\\rn4\\node_modules\\@react-native-community\\cli\\build\\index.js:192:9)\ninfo Run CLI with --verbose flag for more details.\n\nI also run cd android && ./gradlew clean and the output is:\nFAILURE: Build failed with an exception.\n\n* Where:\nBuild file 'C:\\Users\\emanu\\App\\rn4\\android\\app\\build.gradle' line: 1\n\n* What went wrong:\nA problem occurred evaluating project ':app'.\n> Failed to apply plugin 'com.android.internal.application'.\n   > Android Gradle plugin requires Java 11 to run. You are currently using Java 1.8.\n     You can try some of the following options:\n       - changing the IDE settings.\n       - changing the JAVA_HOME environment variable.\n       - changing `org.gradle.java.home` in `gradle.properties`.\n\nThis is the file in android/gradle/wrapper/gradle-wrapper.properties\ndistributionBase=GRADLE_USER_HOME\ndistributionPath=wrapper/dists\ndistributionUrl=https\\://services.gradle.org/distributions/gradle-7.3.3-all.zip\nzipStoreBase=GRADLE_USER_HOME\nzipStorePath=wrapper/dists\n\nand this is the output when I run ./gradlew --version\n------------------------------------------------------------\nGradle 7.3.3\n------------------------------------------------------------\n\nBuild time:   2021-12-22 12:37:54 UTC\nRevision:     6f556c80f945dc54b50e0be633da6c62dbe8dc71\n\nKotlin:       1.5.31\nGroovy:       3.0.9\nAnt:          Apache Ant(TM) version 1.10.11 compiled on July 10 2021\nJVM:          1.8.0_302 (Oracle Corporation 25.302-b08)\nOS:           Windows 10 10.0 amd64\n\nI read similar posts but I haven't been able to fix it. With folders that I created some days ago I have no problem when I run the app.\nSomeone can help me please?\nVery thanks!\n",
    "AcceptedAnswerId": 71800545,
    "AcceptedAnswer": "If you are using React Native witch Chocolatey, you must update JDK version to 11.\nIn order to do the update, execute this in PowerShell (with admin privileges):\nchoco install -y openjdk11\n\nAfter that, the first time (only the first time) you run npm android, you will get a lot of warnings, but the built of the project will work.\nIf you continue receiving an error, maybe you need to adjust the gradle version of your project to be compatible with the new JDK version.\nYou can achieve this by editing the file YOUR_PROJECT\\android\\gradle\\wrapper\\gradle-wrapper.properties\nUpdate the version of distributionUrl to 7.4.2\nI hope I have been helpful\n"
}
{
    "Id": 70725347,
    "PostTypeId": 1,
    "Title": "The application \u201cEclipse\u201d can\u2019t be opened. (macOS Monterey)",
    "Body": "I downloaded Eclipse on my Mac for school, following these instructions:\n\nIn your browser, go to Eclipse Downloads. Do not use the Eclipse Installer. Instead follow these steps to download and install Eclipse.\nFind the Eclipse IDE for Java Developers package (make sure you do not pick the wrong package) and click on the appropriate download link for your operating system (Windows, Mac, or Linux) and architecture (32-bit or 64-bit). There are many other packages but this is the one that you'll need in this class.\nOnce the download has completed, locate the downloaded file. This file will be a compressed (i.e., a \".zip\", or \".tar.gz\") file. Uncompress this file into the directory of your choice. It doesn't really matter where you put the Eclipse installation folder as long as you know how to retrieve it. You can optionally create a shortcut of the Eclipse IDE executable file (\"eclipse.exe\" on Windows, or \"eclipse\" on Linux, or \"Eclipse\" on Mac OS X) found in the directory that is created. To start Eclipse you just double-click on the executable file or the shortcut\n\nI downloaded the Eclipse macOS x86_64 version, and moved it into my applications folder. I was able to open Eclipse, and everything works perfectly, and I can work if it's open; but after I close Eclipse and a couple hours go by, I get the following messages once I try to reopen it. \"Eclipse quit unexpectedly\" and \"The application \u201cEclipse\u201d can\u2019t be opened.\"\nI had the .dmg file in my downloads folder, which might have been the problem. I moved it into my applications folder with Eclipse, and that still doesn't work.\nI have tried to delete and redownload Eclipse multiple times, and nothing works.\ndo you have any suggestions on how I can fix this?\n",
    "AcceptedAnswerId": 71740449,
    "AcceptedAnswer": "Faced the same issue each time I'm restarting the Macbook pro M1, and a random Reddit thread provided me with a way to fix it. Open a terminal and run,\nsudo codesign --force --deep --sign - /Applications/Eclipse.app\n\nNot sure why this codesigning fixes the problem. But seems to be a bug in the eclipse itself. Hope this helps someone.\n"
}
{
    "Id": 71377448,
    "PostTypeId": 1,
    "Title": "When I Update my Phone to Android 12, Installation did not succeed. The application could not be installed: INSTALL_PARSE_FAILED_MANIFEST_MALFORMED",
    "Body": "I was working on my project perfectly since I Update my phone to Android 12 unfortunately when I run the project to my phone this Error appears:\n\nInstallation did not succeed.\nThe application could not be installed: INSTALL_PARSE_FAILED_MANIFEST_MALFORMED\n\n\nList of apks:\n[0] 'C:\\Users\\Microsoft\\AndroidStudioProjects\\YmmyServer\\app\\build\\outputs\\apk\\debug\\app-debug.apk'\nInstallation failed due to: 'null'\nRetry\n\nThis is My build.gradle(Project) File:\n// Top-level build file where you can add configuration options common to all sub-projects/modules.\nbuildscript {\n    repositories {\n        google()\n        jcenter()\n    }\n    dependencies {\n        classpath 'com.google.gms:google-services:4.3.10'\n        classpath 'com.android.tools.build:gradle:4.0.0'\n        // NOTE: Do not place your application dependencies here; they belong\n        // in the individual module build.gradle files\n    }\n}\n\nallprojects {\n    repositories {\n        google()\n        jcenter()\n        maven { url \"https://jitpack.io\" }\n    }\n}\n\ntask clean(type: Delete) {\n    delete rootProject.buildDir\n}\n\nAnd this is My build.gradle(Module) File:\nplugins {\n    id 'com.android.application'\n}\n\nandroid {\n    compileSdkVersion 32\n    buildToolsVersion \"30.0.3\"\n\n    defaultConfig {\n        applicationId \"com.example.ymmyserver\"\n        minSdkVersion 30\n        targetSdkVersion 32\n        versionCode 1\n        versionName \"1.0\"\n\n        testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\"\n    }\n\n    buildTypes {\n        release {\n            minifyEnabled false\n            proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro'\n        }\n    }\n    compileOptions {\n        sourceCompatibility JavaVersion.VERSION_1_8\n        targetCompatibility JavaVersion.VERSION_1_8\n    }\n}\napply plugin: 'com.android.application'\napply plugin: 'com.google.gms.google-services'\ndependencies {\n\n    implementation 'com.github.jd-alexander:android-flat-button:v1.1'\n//    implementation 'info.hoang8f:fbutton:1.0.5'\n    implementation 'com.google.firebase:firebase-auth'\n    implementation 'com.google.firebase:firebase-storage'\n    implementation 'com.firebaseui:firebase-ui-database:8.0.0'\n    implementation 'com.squareup.picasso:picasso:2.71828'\n    implementation \"androidx.cardview:cardview:1.0.0\"\n    implementation \"androidx.recyclerview:recyclerview:1.2.1\"\n    implementation 'com.rengwuxian.materialedittext:library:2.1.4'\n    implementation 'com.google.firebase:firebase-core:10.2.0'\n    implementation 'com.google.firebase:firebase-database'\n    implementation 'com.google.firebase:firebase-analytics'\n    implementation platform('com.google.firebase:firebase-bom:29.1.0')\n    implementation 'androidx.appcompat:appcompat:1.4.1'\n    implementation 'com.google.android.material:material:1.5.0'\n    implementation 'androidx.constraintlayout:constraintlayout:2.1.3'\n    implementation 'androidx.navigation:navigation-fragment:2.4.1'\n    implementation 'androidx.navigation:navigation-ui:2.4.1'\n    implementation 'androidx.lifecycle:lifecycle-livedata-ktx:2.4.1'\n    implementation 'androidx.lifecycle:lifecycle-viewmodel-ktx:2.4.1'\n    testImplementation 'junit:junit:4.+'\n    androidTestImplementation 'androidx.test.ext:junit:1.1.3'\n    androidTestImplementation 'androidx.test.espresso:espresso-core:3.4.0'\n}\n\nAnd this is the Mainifest File:\n\n<manifest xmlns:android=\"http://schemas.android.com/apk/res/android\"\n    package=\"com.example.ymmyserver\">\n\n    <application\n        android:allowBackup=\"true\"\n        android:icon=\"@mipmap/ic_launcher\"\n        android:label=\"@string/app_name\"\n        android:roundIcon=\"@mipmap/ic_launcher_round\"\n        android:supportsRtl=\"true\"\n        android:theme=\"@style/Theme.Ymmy\">\n        \n        <activity\n            android:name=\".Home\"\n            android:label=\"@string/title_activity_home\"\n            android:theme=\"@style/Theme.Ymmy.NoActionBar\">\n        \n        \n            \n                \n\n                \n            \n        \n    \n\n\n\nWhat Should I do Please Help Me\n",
    "AcceptedAnswerId": 71381120,
    "AcceptedAnswer": "Try to use this tag in your AndroidManifest.xml file for the activity\n<activity \n   android:name=\".MainActivity\"\n   android:exported=\"true\">\n\n"
}
{
    "Id": 71966064,
    "PostTypeId": 1,
    "Title": "Java: FileOutputStream(\"NUL:\") not working after Java upgrade",
    "Body": "On Windows, NUL is the null output device similar to /dev/null on Linux.\nWith Oracle Java 8 Update 331, trying to get a new FileOutputStream(\"NUL:\") throws an exception. Previously (Java 8u321) it worked fine.\nThe problem seems to be the colon:\n\nnew FileOutputStream(\"NUL\") - OK\nnew FileOutputStream(\"NUL:\") - exception\n\nCan anyone point me to docs or JDK sources regarding this change? I can't change the code itself because it is in a 3rd party lib (xnio-api).\ntry\n{\n  new FileOutputStream(\"NUL:\");\n  System.out.println(\"OK\");\n}\ncatch (FileNotFoundException e)\n{\n  System.out.println(e);\n}\n\n",
    "AcceptedAnswerId": 71966125,
    "AcceptedAnswer": "I suspect this is the offending change.\nApparently it tries to avoid accessing ADS (alternate data streams), but seems to \"accidentally\" also prevent access to device-files like this.\nIf that's correct, then you can try setting the system property jdk.io.File.enableADS to true to re-enable the old behaviour.\n"
}
{
    "Id": 71429854,
    "PostTypeId": 1,
    "Title": "Could not find org.junit.jupiter:junit-jupiter:",
    "Body": "I was trying to learn how to use OkHTTP. I importetd the library to my project but when i compile the code it brings out this error.\nCould not find org.junit.jupiter:junit-jupiter:.\nRequired by:\nproject :app\nSearch in build.gradle files.\nplease what should i do. This is my build.gradle below\nplugins {\nid 'com.android.application'\n}\n\nandroid {\ncompileSdk 32\n\ndefaultConfig {\n    applicationId \"com.omolayoseun.saprktesterapp\"\n    minSdk 23\n    targetSdk 32\n    versionCode 1\n    versionName \"1.0\"\n\n    testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\"\n}\n\nbuildTypes {\n    release {\n        minifyEnabled false\n        proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard- \nrules.pro'\n    }\n}\ncompileOptions {\n    sourceCompatibility JavaVersion.VERSION_1_8\n    targetCompatibility JavaVersion.VERSION_1_8\n}\n}\n\ndependencies {\n\nimplementation 'androidx.appcompat:appcompat:1.4.1'\nimplementation 'com.google.android.material:material:1.5.0'\nimplementation 'androidx.constraintlayout:constraintlayout:2.1.3'\nimplementation 'org.junit.jupiter:junit-jupiter'\ntestImplementation 'junit:junit:4.13.2'\nandroidTestImplementation 'androidx.test.ext:junit:1.1.3'\nandroidTestImplementation 'androidx.test.espresso:espresso-core:3.4.0'\n\nimplementation 'com.squareup.okhttp3:okhttp:4.9.1'\n// https://mvnrepository.com/artifact/org.junit.jupiter/junit-jupiter-api\ntestImplementation 'org.junit.jupiter:junit-jupiter-api:5.8.2'\n\n}\n\n",
    "AcceptedAnswerId": 72124953,
    "AcceptedAnswer": "Seems that your problem is in the maven repository setting.\nPlace the code below to your build.gradle which is located in the project core folder.\nbuildscript {\nrepositories {\n    mavenCentral()\n    google()\n}}\n\nIf it not helps or this repositories already there - try to turn off offline mode.\nGo to Preferences > Gradle and uncheck \"Offline work\"\nIf Gradle is in offline mode, which means that it won't go to the network to resolve dependencies.\n"
}
{
    "Id": 72139334,
    "PostTypeId": 1,
    "Title": "Why onAdDismissedFullScreenContent is being called lately?",
    "Body": "I have created a function to show interstitial ad before showing another activity.\nIt's working but onAdDismissedFullScreenContent is being called 2-3 sec lately after closing the ad. It causes previous screen to stand-by.\nThere's a chance to re-click the button to show the wanted Activity.\nI really don't understand how to resolve this issue.\n\nHere is my code:\npublic class MainActivity extends AppCompatActivity {\n\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n        setContentView(R.layout.activity_main);\n        Button button = findViewById(R.id.button);\n        button.setOnClickListener(new View.OnClickListener() {\n            @Override\n            public void onClick(View view) {\n                AdManager.showInterstitial(MainActivity.this, () -> {\n                    Intent i = new Intent(MainActivity.this, MainActivity2.class);\n                    startActivity(i);\n                });\n            }\n        });\n        AdManager.loadInterstitial(this);\n    }\n}\n\n\nAnd this is Application Class:\n\npublic class App  extends Application {\n    private static Context mContext;\n\n\n    @Override\n    public void onCreate() {\n        super.onCreate();\n        mContext = getApplicationContext();\n        AdManager.Init(this);\n    }\n\n    public static Context getContext() {\n        return mContext;\n    }\n}\n\nAdManager Class:\npublic class AdManager {\n\n    private static InterstitialAd mInterstitialAd;\n    private static boolean loading, showing;\n\n\n    public static void Init(Context context) {\n\n        MobileAds.initialize(context, initializationStatus -> {\n            loadInterstitial(context);\n        });\n    }\n\n\n    public static void loadInterstitial(Context context) {\n\n        if (context == null)\n            context = App.getContext();\n\n        Context finalContext = context;\n        \n        if (mInterstitialAd != null) {\n            Toast.makeText(context,\"already loaded\",Toast.LENGTH_LONG).show();\n            return;\n        }\n        if (loading) {\n            Toast.makeText(context,\"already another request is processing\",Toast.LENGTH_LONG).show();\n            return;\n        }\n        Toast.makeText(context,\"requesting interstitial\",Toast.LENGTH_LONG).show();\n\n        loading = true;\n        AdRequest adRequest = new AdRequest.Builder().build();\n\n        InterstitialAd.load(context, \"Interstial Ad Unit ID\", adRequest, new InterstitialAdLoadCallback() {\n            @Override\n            public void onAdLoaded(@NonNull InterstitialAd interstitialAd) {\n                mInterstitialAd = interstitialAd;\n                Toast.makeText(finalContext,\"ad loaded\",Toast.LENGTH_LONG).show();\n                loading = false;\n            }\n\n            @Override\n            public void onAdFailedToLoad(@NonNull LoadAdError loadAdError) {\n                mInterstitialAd = null;\n                loading = false;\n                Toast.makeText(finalContext,\"ad failed to load\",Toast.LENGTH_LONG).show();\n            }\n\n        });\n    }\n\n    public static void showInterstitial(Activity activity, @NonNull AdListener listener) {\n        \n        if (showing) {\n            Toast.makeText(activity,\"already showing\",Toast.LENGTH_LONG).show();\n            listener.onCompleted();\n            return;\n        }\n\n        if (mInterstitialAd != null) {\n            showNow(activity, listener);\n\n        } else {\n            Toast.makeText(activity,\"mInterstitialAd is null\",Toast.LENGTH_LONG).show();\n            listener.onCompleted();\n            loadInterstitial(activity.getApplicationContext());\n        }\n\n    }\n\n    private static void showNow(Activity activity, AdListener listener) {\n\n        if (mInterstitialAd != null && !showing) {\n            showing = true;\n            mInterstitialAd.setFullScreenContentCallback(new FullScreenContentCallback() {\n                @Override\n                public void onAdDismissedFullScreenContent() {\n                    Toast.makeText(activity,\"Ad dismissed\",Toast.LENGTH_LONG).show();\n                    mInterstitialAd = null;\n                    listener.onCompleted();\n                    showing = false;\n                    // times to load an new interstitial ad content\n                    loadInterstitial(activity.getApplicationContext());\n                }\n\n                @Override\n                public void onAdFailedToShowFullScreenContent(@NonNull AdError adError) {\n                    Toast.makeText(activity,\"AdFailedToShowFullScreenContent\",Toast.LENGTH_LONG).show();\n                    mInterstitialAd = null;\n                    listener.onCompleted();\n                    showing = false;\n\n                    // times to load an new interstitial ad content\n                    loadInterstitial(activity.getApplicationContext());\n                }\n\n\n            });\n            //  Now show the ad\n            Toast.makeText(activity,\"call to show ad\",Toast.LENGTH_LONG).show();\n            mInterstitialAd.show(activity);\n        } else {\n            Toast.makeText(activity,\"either mInterstitialAd is null or ad already is showing\",Toast.LENGTH_LONG).show();\n            listener.onCompleted();\n        }\n    }\n\n        public interface AdListener {\n        void onCompleted();\n    }\n\n}\n\n\nPlease help.\n",
    "AcceptedAnswerId": 72150183,
    "AcceptedAnswer": "The delay problem\n\nYou can't really help it. The problem is from the admob. This will happen. But, to know more about it, we can post an issue abt that on the Google Issue Tracker.\nThe button problem\n\nI dont think this is any hard task. Just follow the steps:\n\nCreate a ProgressBar in your xml layout on top of the button and set its visibility to gone\n\nWhen the button is click and the ad is shown, you can set the button to invisible and the progress bar can be set to invisible.\n\nThen after a delay, the other activity opens without any harm to the activity from NullPointerException\n\n\n"
}
{
    "Id": 71956115,
    "PostTypeId": 1,
    "Title": "Why does jaxb2-maven-plugin xjc fail with Corretto jdk11.0.15_9 but not with Temurin jdk-11.0.14.1+1",
    "Body": "Since upgrading my jdk to Corretto jdk11.0.15_9 the xjc goal of jaxb2-maven-plugin fails.\nThe problem doesn't manifest when running with Temurin jdk-11.0.14.1+1. I'm running it on windows 10 with maven 3.8.5.\nCommand:\n> set JAVA_HOME=C:\\Corretto\\jdk11.0.15_9\n> mvn jaxb2:xjc\n\n[INFO] Scanning for projects...\n[INFO]\n[INFO] -----------------------------------\n[INFO] Building example 1.0.0-SNAPSHOT\n[INFO] --------------------------------[ jar ]---------------------------------\n[INFO]\n[INFO] --- jaxb2-maven-plugin:2.5.0:xjc (default-cli) @ example ---\n[INFO] Created EpisodePath [C:\\Workspace\\example\\target\\generated-sources\\jaxb\\META-INF\\JAXB]: true\n[INFO] Created EpisodePath [C:\\Workspace\\example\\target\\generated-sources\\jaxb\\META-INF\\JAXB]: true\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time:  0.764 s\n[INFO] Finished at: 2022-04-21T15:24:15+02:00\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal org.codehaus.mojo:jaxb2-maven-plugin:2.5.0:xjc (default-cli) on project example: \"file:\\C:\\Users\\johndoe\\.m2\\repository\\org\\glassfish\\jaxb\\jaxb-xjc\\2.3.2\\jaxb-xjc-2.3.2.jar!\\META-INF\\versions\\9\" is not a valid file name: {1}: Invalid file path -> [Help 1]\n[ERROR]\n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR]\n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException\n\nI have a bindings file here: src/main/xjb/jaxb-bindings.xjb and multiple xsd files in src/main/xsd.\nThis is the relevant piece of my pom.xml:\n\n    org.glassfish.jaxb\n    jaxb-runtime\n    2.3.6\n\n\n    org.jvnet.jaxb2_commons\n    jaxb2-basics-runtime\n    0.12.0\n    \n        \n        \n            com.sun.istack\n            istack-commons-runtime\n        \n    \n\n...\n\n    org.codehaus.mojo\n    jaxb2-maven-plugin\n    2.5.0\n    \n        \n            xjc\n            \n                xjc\n            \n        \n    \n    \n        com.example\n        \n            -Xequals\n            -XhashCode\n            -XtoString\n        \n        true\n    \n    \n        \n            org.jvnet.jaxb2_commons\n            jaxb2-basics\n            0.12.0\n        \n    \n\n\nRunning it again with -X gives me the following stacktrace which makes me think something must have changed in the java.io.File.toURL behavior.\n[ERROR] Failed to execute goal org.codehaus.mojo:jaxb2-maven-plugin:2.5.0:xjc (default-cli) on project example: \"file:\\C:\\Users\\johndoe\\.m2\\repository\\org\\glassfish\\jaxb\\jaxb-xjc\\2.3.2\\jaxb-xjc-2.3.2.jar!\\META-INF\\versions\\9\" is not a valid file name: {1}: Invalid file path -> [Help 1]\norg.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.codehaus.mojo:jaxb2-maven-plugin:2.5.0:xjc (default-cli) on project example: \"file:\\C:\\Users\\johndoe\\.m2\\repository\\org\\glassfish\\jaxb\\jaxb-xjc\\2.3.2\\jaxb-xjc-2.3.2.jar!\\META-INF\\versions\\9\" is not a valid file name: {1}\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute (MojoExecutor.java:306)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:211)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:165)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:157)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:121)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:127)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:294)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:960)\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:293)\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:196)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:566)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:282)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:225)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:406)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:347)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:566)\n    at org.apache.maven.wrapper.BootstrapMainStarter.start (BootstrapMainStarter.java:47)\n    at org.apache.maven.wrapper.WrapperExecutor.execute (WrapperExecutor.java:156)\n    at org.apache.maven.wrapper.MavenWrapperMain.main (MavenWrapperMain.java:72)\nCaused by: org.apache.maven.plugin.MojoExecutionException: \"file:\\C:\\Users\\johndoe\\.m2\\repository\\org\\glassfish\\jaxb\\jaxb-xjc\\2.3.2\\jaxb-xjc-2.3.2.jar!\\META-INF\\versions\\9\" is not a valid file name: {1}\n    at org.codehaus.mojo.jaxb2.javageneration.AbstractJavaGeneratorMojo.performExecution (AbstractJavaGeneratorMojo.java:555)\n    at org.codehaus.mojo.jaxb2.AbstractJaxbMojo.execute (AbstractJaxbMojo.java:337)\n    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:137)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute (MojoExecutor.java:301)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:211)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:165)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:157)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:121)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:127)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:294)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:960)\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:293)\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:196)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:566)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:282)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:225)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:406)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:347)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:566)\n    at org.apache.maven.wrapper.BootstrapMainStarter.start (BootstrapMainStarter.java:47)\n    at org.apache.maven.wrapper.WrapperExecutor.execute (WrapperExecutor.java:156)\n    at org.apache.maven.wrapper.MavenWrapperMain.main (MavenWrapperMain.java:72)\nCaused by: com.sun.tools.xjc.BadCommandLineException: \"file:\\C:\\Users\\johndoe\\.m2\\repository\\org\\glassfish\\jaxb\\jaxb-xjc\\2.3.2\\jaxb-xjc-2.3.2.jar!\\META-INF\\versions\\9\" is not a valid file name: {1}\n    at com.sun.tools.xjc.Options.parseArgument (Options.java:515)\n    at com.sun.tools.xjc.Driver$OptionsEx.parseArgument (Driver.java:502)\n    at com.sun.tools.xjc.Options.parseArguments (Options.java:827)\n    at com.sun.tools.xjc.Driver.run (Driver.java:231)\n    at org.codehaus.mojo.jaxb2.javageneration.AbstractJavaGeneratorMojo.performExecution (AbstractJavaGeneratorMojo.java:475)\n    at org.codehaus.mojo.jaxb2.AbstractJaxbMojo.execute (AbstractJaxbMojo.java:337)\n    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:137)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute (MojoExecutor.java:301)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:211)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:165)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:157)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:121)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:127)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:294)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:960)\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:293)\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:196)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:566)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:282)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:225)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:406)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:347)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:566)\n    at org.apache.maven.wrapper.BootstrapMainStarter.start (BootstrapMainStarter.java:47)\n    at org.apache.maven.wrapper.WrapperExecutor.execute (WrapperExecutor.java:156)\n    at org.apache.maven.wrapper.MavenWrapperMain.main (MavenWrapperMain.java:72)\nCaused by: java.net.MalformedURLException: Invalid file path\n    at java.io.File.toURL (File.java:695)\n    at com.sun.tools.xjc.Options.parseArgument (Options.java:512)\n    at com.sun.tools.xjc.Driver$OptionsEx.parseArgument (Driver.java:502)\n    at com.sun.tools.xjc.Options.parseArguments (Options.java:827)\n    at com.sun.tools.xjc.Driver.run (Driver.java:231)\n    at org.codehaus.mojo.jaxb2.javageneration.AbstractJavaGeneratorMojo.performExecution (AbstractJavaGeneratorMojo.java:475)\n    at org.codehaus.mojo.jaxb2.AbstractJaxbMojo.execute (AbstractJaxbMojo.java:337)\n    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:137)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute (MojoExecutor.java:301)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:211)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:165)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:157)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:121)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:127)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:294)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:960)\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:293)\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:196)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:566)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:282)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:225)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:406)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:347)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:566)\n    at org.apache.maven.wrapper.BootstrapMainStarter.start (BootstrapMainStarter.java:47)\n    at org.apache.maven.wrapper.WrapperExecutor.execute (WrapperExecutor.java:156)\n    at org.apache.maven.wrapper.MavenWrapperMain.main (MavenWrapperMain.java:72)\n\nMinimal reproducable scenario:\nhttps://github.com/Crydust/so71956115\n",
    "AcceptedAnswerId": 71979169,
    "AcceptedAnswer": "Switching to a newer version of jaxb2-maven-plugin required a switch to jaxb3,\nbut replacing jaxb2-maven-plugin by maven-jaxb2-plugin worked.\n\n    org.jvnet.jaxb2.maven2\n    maven-jaxb2-plugin\n    0.14.0\n    \n        \n            \n                generate\n            \n        \n    \n    \n        \n            -Xequals\n            -XhashCode\n            -XtoString\n        \n        com.example\n        ${project.basedir}/src/main/xsd\n        \n            \n                org.jvnet.jaxb2_commons\n                jaxb2-basics\n                0.12.0\n            \n        \n    \n\n\n\nBarry's suggestion (with some tweaks) works too.\n\n    org.codehaus.mojo\n    jaxb2-maven-plugin\n    2.5.0\n    \n        \n            \n                xjc\n            \n        \n    \n    \n        com.example.generated\n        \n            -Xequals\n            -XhashCode\n            -XtoString\n        \n        true\n    \n    \n        \n            org.jvnet.jaxb2_commons\n            jaxb2-basics\n            0.12.0\n        \n        \n            org.glassfish.jaxb\n            jaxb-runtime\n            2.3.6\n        \n        \n            org.glassfish.jaxb\n            jaxb-xjc\n            2.3.6\n        \n    \n\n\n"
}
{
    "Id": 71434304,
    "PostTypeId": 1,
    "Title": "Does Java Evaluate a Variable Declared as Final only Once?",
    "Body": "I'm writing a Java program that requires thousands of System.out.println() statements that will be printed hundreds of millions (or billions) of times throughout the lifecycle of the program for debugging purposes:\nif (GVar.runInDebugMode) System.out.println(\"Print debug message\");\n\nIn the real world, these statements can be deactivated in order to speed up a computational heavy calculation.\nIf I set:\npublic final static boolean runInDebugMode = false;\n\nDoes the compiler re-evaluate runInDebugMode each time it comes across a statement like: if (GVar.runInDebugMode) or since it was declared as final it will be evaluated once at the beginning of the program and won't put additional strain on the CPU? In other words, would I be better off commenting out all debug statements entirely once I deploy the app or is setting runInDebugMode  to false sufficient?\n",
    "AcceptedAnswerId": 71470775,
    "AcceptedAnswer": "When you declare a variable like\npublic final static boolean runInDebugMode = false;\n\nit\u2019s a compile-time constant.\n\nA constant variable is a final variable of primitive type or type String that is initialized with a constant expression (\u00a715.29).\n\nwhich means that\n\nA reference to a field that is a constant variable (\u00a74.12.4) must be resolved at compile time to the value V denoted by the constant variable's initializer.\nIf such a field is static, then no reference to the field should be present in the code in a binary file, including the class or interface which declared the field.\n\nIn other words, when you write if(runInDebugMode) anywhere and runInDebugMode is false at compile time, the behavior is as if you\u2019ve written if(false), as the value must be resolved at compile time and no reference to the field appears in the compiled class file.\nYour use case has been discussed specifically in \u00a714.22\n\nHowever, in order to allow the if statement to be used conveniently for \"conditional compilation\" purposes, the actual rules differ.\nAs an example, the following statement results in a compile-time error:\nwhile (false) { x=3; }\n\nbecause the statement x=3; is not reachable; but the superficially similar case:\nif (false) { x=3; }\n\ndoes not result in a compile-time error. An optimizing compiler may realize that the statement x=3; will never be executed and may choose to omit the code for that statement from the generated class file, but the statement x=3; is not regarded as \"unreachable\" in the technical sense specified here.\nThe rationale for this differing treatment is to allow programmers to define \"flag\" variables such as:\nstatic final boolean DEBUG = false;\n\nand then write code such as:\nif (DEBUG) { x=3; }\n\nThe idea is that it should be possible to change the value of DEBUG from false to true or from true to false and then compile the code correctly with no other changes to the program text.\nConditional compilation comes with a caveat. If a set of classes that use a \"flag\" variable - or more precisely, any static constant variable (\u00a74.12.4) - are compiled and conditional code is omitted, it does not suffice later to distribute just a new version of the class or interface that contains the definition of the flag.\n\nSo, this statement makes clear that this form of conditional compilation matches the intent of the language designers and that compilers are entitled to omit the code in question (all relevant compilers do). In principle, a compiler is not required to omit the code, but since it must not generate a reference to the field GVar.runInDebugMode in the compiled code, the code can\u2019t contain a real conditional. If the code is not omitted, it must be skipped in a de-facto unconditional way. Either, by a goto instruction or, when compiling in the most na\u00efve way imaginable, by literally testing false, iconst_0; ifeq \u2026. Both approaches would be on the nanosecond scale in interpreted execution mode and no challenge to the JIT compiler/ optimizer at all.\n\nIt\u2019s worth mentioning that static final fields are trusted fields which are normally not even changeable by Reflection. This is used, e.g. by the Assertion feature, as under the hood, a class containing an assert statement will have a static final boolean field initialized at class initialization time (so it\u2019s not a compile-time constant) and each assert statement will skip its check conditionally, depending on the state of the static final variable. It was as early as at Java\u00a01.4 time, when it was concluded that the necessary dead code elimination is commonplace in JVMs, to rely on it in this way.\nSo even if you turn your debug flag from compile-time constant to an initialization-time constant, the impact on the performance would be hardly noticeable. But the way you\u2019re using it now, the code is removed at compile-time already and doesn\u2019t rely on the JVM anyway.\n"
}
{
    "Id": 71095913,
    "PostTypeId": 1,
    "Title": "What is the difference between jaxb-impl and jaxb-runtime?",
    "Body": "Clearly the com.sun.xml.bind:jaxb-impl artifact is labelled \"Old JAXB Runtime module\" in the maven repository (see link below), and yet both of these artifacts are still getting new releases:\nhttps://mvnrepository.com/artifact/org.glassfish.jaxb/jaxb-runtime\nhttps://mvnrepository.com/artifact/com.sun.xml.bind/jaxb-impl\nThis answer Which artifacts should I use for JAXB RI in my Maven project?\ndoes not clarify the difference.\nThe accepted answer to both the above question and this one How to resolve java.lang.NoClassDefFoundError: javax/xml/bind/JAXBException conclude that for Java 9+ you should use:  org.glassfish.jaxb:jaxb-runtime\nBut I have code using com.sun.xml.bind:jaxb-impl and it appears to be working fine.  So what do I lose or gain by moving to jaxb-runtime?\nEven the latest (3.0.2 at the time I write this) version is available for the \"OLD\" jaxb-impl module.  If Oracle isn't doing this anymore, who makes the com.sun.xml.bind:jaxb-impl artifact? What is it for? Why doesn't it share the Maven group coordinates with jaxb-runtime?\nIs there any central location that clearly documents what the current state of affairs is with JAXB?\nThere is just so much confusion with JAXB now.\nP.S. I need to remain compatible with Java 8 for the time being - so I can't go to 3.x yet, and 2.4.x appears to be an abandoned attempt at fixing the modularity that they foolishly broke when it was split out of the JDK.\n",
    "AcceptedAnswerId": 72151763,
    "AcceptedAnswer": "The only difference between jaxb-impl and jaxb-runtime is packaging: jaxb-impl bundles istack/txw2 inside the jar, whereas jaxb-runtime provides them via separate dependencies.\nVersion Compatibility and the JakartaEE Migration\nI've been trying to make sense of this for the last day, and it's incredibly confusing. Particularly when you're trying to avoid the java.xml.bind to jakarta.xml.bind migration. There's out of date information everywhere and some broken releases in the jaxb-impl 2.3.x release line.\nBest I can tell, GlassFish was providing the JAXB reference implementation. It's since moved to EE4J, but releases continue from that project against both sets of coordinates. Appears that com.sun.xml.bind:jaxb-ri is where the latest full bundles are released:\nhttps://github.com/eclipse-ee4j/jaxb-ri/\nHaving figured out that piece of history, the real mess is that none of the artifacts reflect the javax.xml.bind to jakarta.xml.bind move in their artifact coordinates, only in the versions. This means if you're in ecosystem where you need both to exist, you're going to have a bad time.\nFor instance, the 2.3.3 release changed from depending on javax.xml.bind:jaxb-api to jakarta.xml.bind:jakarta.xml.bind-api because at 2.x, the jakarta artifacts provide the javax.xml.bind packages. At version 3.0.0 it provides jakarta.xml.bind.\nThe implementations are the same at 3.0.0 which means while the earlier versions could happily exist at runtime, you have no way of resolving them both in build tools and conflict resolution is going to break legacy uses of javax.xml.bind APIs.\nAllow javax.xml.bind and jakarta.xml.bind to coexist\nFor projects that need both APIs to coexist without migrating the legacy code:\n\nFor javax.xml.bind use com.sun.xml.bind:jaxb-impl:2.3.6. Ignore the 3.0.0 and later releases. Add an explicit dependency on javax.xml.bind:jaxb-api:2.3.1 so that you have a package providing the javax.xml.bind API\nFor jakarta.xml.bind use the latest org.glassfish.jaxb:jaxb-runtime. Ignore the releases earlier than 3.0.0\n\nRuntime compatibility with jakarta.xml.bind\nUse the tomcat-jakartaee-migration tool to rewrite classes for deployment.\nFor Gradle projects, you can use the gradle-jakartaee-migration-plugin, and get the benefit of capabilities and transforms at development time too.\nMigrate to jakarta.xml.bind\nYou can use either of the coordinates for the runtime based on your preferences for packaging:\n\ncom.sun.xml.bind:jaxb-impl:4.0.0\norg.glassfish.jaxb:jaxb-runtime:4.0.0\n\nBoth depend on jakarta.xml.bind:jakarta.xml.bind-api with the jakarta.xml.bind package namespace.\n"
}
{
    "Id": 72335789,
    "PostTypeId": 1,
    "Title": "Can not extract resource from com.android.aaptcompiler",
    "Body": "Can not extract resource from com.android.aaptcompiler.ParsedResource@636e1e76.\nExecution failed for task ':app:mergeDebugResources'.\n> A failure occurred while executing com.android.build.gradle.internal.res.ResourceCompilerRunnable\n   > Resource compilation failed (Failed to compile values resource file E:\\My Client\\Henkako\\HenkakoPlus\\app\\build\\intermediates\\incremental\\debug\\mergeDebugResources\\merged.dir\\values\\values.xml. Cause: java.lang.IllegalStateException: Can not extract resource from com.android.aaptcompiler.ParsedResource@636e1e76.). Check logs for more details.\n\n* Exception is:\norg.gradle.api.tasks.TaskExecutionException: Execution failed for task ':app:mergeDebugResources'.\n    at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.lambda$executeIfValid$1(ExecuteActionsTaskExecuter.java:145)\n    at org.gradle.internal.Try$Failure.ifSuccessfulOrElse(Try.java:282)\n    at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeIfValid(ExecuteActionsTaskExecuter.java:143)\n    at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:131)\n    at org.gradle.api.internal.tasks.execution.CleanupStaleOutputsExecuter.execute(CleanupStaleOutputsExecuter.java:77)\n    at org.gradle.api.internal.tasks.execution.FinalizePropertiesTaskExecuter.execute(FinalizePropertiesTaskExecuter.java:46)\n    at org.gradle.api.internal.tasks.execution.ResolveTaskExecutionModeExecuter.execute(ResolveTaskExecutionModeExecuter.java:51)\n    at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:57)\n    at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:56)\n    at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:36)\n    at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.executeTask(EventFiringTaskExecuter.java:77)\n    at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.call(EventFiringTaskExecuter.java:55)\n    at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.call(EventFiringTaskExecuter.java:52)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:204)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:199)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:66)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:59)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:157)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:59)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.call(DefaultBuildOperationRunner.java:53)\n    at org.gradle.internal.operations.DefaultBuildOperationExecutor.call(DefaultBuildOperationExecutor.java:73)\n    at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter.execute(EventFiringTaskExecuter.java:52)\n    at org.gradle.execution.plan.LocalTaskNodeExecutor.execute(LocalTaskNodeExecutor.java:74)\n    at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$InvokeNodeExecutorsAction.execute(DefaultTaskExecutionGraph.java:402)\n    at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$InvokeNodeExecutorsAction.execute(DefaultTaskExecutionGraph.java:389)\n    at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:382)\n    at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:368)\n    at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.lambda$run$0(DefaultPlanExecutor.java:127)\n    at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.execute(DefaultPlanExecutor.java:191)\n    at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.executeNextNode(DefaultPlanExecutor.java:182)\n    at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.run(DefaultPlanExecutor.java:124)\n    at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64)\n    at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48)\n    at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:61)\nCaused by: org.gradle.workers.internal.DefaultWorkerExecutor$WorkExecutionException: A failure occurred while executing com.android.build.gradle.internal.res.ResourceCompilerRunnable\n    at org.gradle.workers.internal.DefaultWorkerExecutor$WorkItemExecution.waitForCompletion(DefaultWorkerExecutor.java:342)\n    at org.gradle.internal.work.DefaultAsyncWorkTracker.waitForItemsAndGatherFailures(DefaultAsyncWorkTracker.java:142)\n    at org.gradle.internal.work.DefaultAsyncWorkTracker.waitForItemsAndGatherFailures(DefaultAsyncWorkTracker.java:94)\n    at org.gradle.internal.work.DefaultAsyncWorkTracker.waitForAll(DefaultAsyncWorkTracker.java:80)\n    at org.gradle.internal.work.DefaultAsyncWorkTracker.waitForCompletion(DefaultAsyncWorkTracker.java:68)\n    at org.gradle.api.internal.tasks.execution.TaskExecution$2.run(TaskExecution.java:247)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$1.execute(DefaultBuildOperationRunner.java:29)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$1.execute(DefaultBuildOperationRunner.java:26)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:66)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:59)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:157)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:59)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.run(DefaultBuildOperationRunner.java:47)\n    at org.gradle.internal.operations.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:68)\n    at org.gradle.api.internal.tasks.execution.TaskExecution.executeAction(TaskExecution.java:224)\n    at org.gradle.api.internal.tasks.execution.TaskExecution.executeActions(TaskExecution.java:207)\n    at org.gradle.api.internal.tasks.execution.TaskExecution.executeWithPreviousOutputFiles(TaskExecution.java:190)\n    at org.gradle.api.internal.tasks.execution.TaskExecution.execute(TaskExecution.java:168)\n    at org.gradle.internal.execution.steps.ExecuteStep.executeInternal(ExecuteStep.java:89)\n    at org.gradle.internal.execution.steps.ExecuteStep.access$000(ExecuteStep.java:40)\n    at org.gradle.internal.execution.steps.ExecuteStep$1.call(ExecuteStep.java:53)\n    at org.gradle.internal.execution.steps.ExecuteStep$1.call(ExecuteStep.java:50)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:204)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:199)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:66)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:59)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:157)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:59)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.call(DefaultBuildOperationRunner.java:53)\n    at org.gradle.internal.operations.DefaultBuildOperationExecutor.call(DefaultBuildOperationExecutor.java:73)\n    at org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:50)\n    at org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:40)\n    at org.gradle.internal.execution.steps.RemovePreviousOutputsStep.execute(RemovePreviousOutputsStep.java:68)\n    at org.gradle.internal.execution.steps.RemovePreviousOutputsStep.execute(RemovePreviousOutputsStep.java:38)\n    at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:48)\n    at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:36)\n    at org.gradle.internal.execution.steps.CancelExecutionStep.execute(CancelExecutionStep.java:41)\n    at org.gradle.internal.execution.steps.TimeoutStep.executeWithoutTimeout(TimeoutStep.java:74)\n    at org.gradle.internal.execution.steps.TimeoutStep.execute(TimeoutStep.java:55)\n    at org.gradle.internal.execution.steps.CreateOutputsStep.execute(CreateOutputsStep.java:51)\n    at org.gradle.internal.execution.steps.CreateOutputsStep.execute(CreateOutputsStep.java:29)\n    at org.gradle.internal.execution.steps.CaptureStateAfterExecutionStep.execute(CaptureStateAfterExecutionStep.java:61)\n    at org.gradle.internal.execution.steps.CaptureStateAfterExecutionStep.execute(CaptureStateAfterExecutionStep.java:42)\n    at org.gradle.internal.execution.steps.BroadcastChangingOutputsStep.execute(BroadcastChangingOutputsStep.java:60)\n    at org.gradle.internal.execution.steps.BroadcastChangingOutputsStep.execute(BroadcastChangingOutputsStep.java:27)\n    at org.gradle.internal.execution.steps.BuildCacheStep.executeWithoutCache(BuildCacheStep.java:188)\n    at org.gradle.internal.execution.steps.BuildCacheStep.lambda$execute$1(BuildCacheStep.java:75)\n    at org.gradle.internal.Either$Right.fold(Either.java:175)\n    at org.gradle.internal.execution.caching.CachingState.fold(CachingState.java:59)\n    at org.gradle.internal.execution.steps.BuildCacheStep.execute(BuildCacheStep.java:73)\n    at org.gradle.internal.execution.steps.BuildCacheStep.execute(BuildCacheStep.java:48)\n    at org.gradle.internal.execution.steps.StoreExecutionStateStep.execute(StoreExecutionStateStep.java:38)\n    at org.gradle.internal.execution.steps.StoreExecutionStateStep.execute(StoreExecutionStateStep.java:27)\n    at org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:36)\n    at org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:22)\n    at org.gradle.internal.execution.steps.SkipUpToDateStep.executeBecause(SkipUpToDateStep.java:109)\n    at org.gradle.internal.execution.steps.SkipUpToDateStep.lambda$execute$2(SkipUpToDateStep.java:56)\n    at org.gradle.internal.execution.steps.SkipUpToDateStep.execute(SkipUpToDateStep.java:56)\n    at org.gradle.internal.execution.steps.SkipUpToDateStep.execute(SkipUpToDateStep.java:38)\n    at org.gradle.internal.execution.steps.ResolveChangesStep.execute(ResolveChangesStep.java:73)\n    at org.gradle.internal.execution.steps.ResolveChangesStep.execute(ResolveChangesStep.java:44)\n    at org.gradle.internal.execution.steps.legacy.MarkSnapshottingInputsFinishedStep.execute(MarkSnapshottingInputsFinishedStep.java:37)\n    at org.gradle.internal.execution.steps.legacy.MarkSnapshottingInputsFinishedStep.execute(MarkSnapshottingInputsFinishedStep.java:27)\n    at org.gradle.internal.execution.steps.ResolveCachingStateStep.execute(ResolveCachingStateStep.java:89)\n    at org.gradle.internal.execution.steps.ResolveCachingStateStep.execute(ResolveCachingStateStep.java:50)\n    at org.gradle.internal.execution.steps.ValidateStep.execute(ValidateStep.java:114)\n    at org.gradle.internal.execution.steps.ValidateStep.execute(ValidateStep.java:57)\n    at org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:76)\n    at org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:50)\n    at org.gradle.internal.execution.steps.SkipEmptyWorkStep.lambda$execute$2(SkipEmptyWorkStep.java:93)\n    at org.gradle.internal.execution.steps.SkipEmptyWorkStep.execute(SkipEmptyWorkStep.java:93)\n    at org.gradle.internal.execution.steps.SkipEmptyWorkStep.execute(SkipEmptyWorkStep.java:34)\n    at org.gradle.internal.execution.steps.legacy.MarkSnapshottingInputsStartedStep.execute(MarkSnapshottingInputsStartedStep.java:38)\n    at org.gradle.internal.execution.steps.LoadPreviousExecutionStateStep.execute(LoadPreviousExecutionStateStep.java:43)\n    at org.gradle.internal.execution.steps.LoadPreviousExecutionStateStep.execute(LoadPreviousExecutionStateStep.java:31)\n    at org.gradle.internal.execution.steps.AssignWorkspaceStep.lambda$execute$0(AssignWorkspaceStep.java:40)\n    at org.gradle.api.internal.tasks.execution.TaskExecution$3.withWorkspace(TaskExecution.java:284)\n    at org.gradle.internal.execution.steps.AssignWorkspaceStep.execute(AssignWorkspaceStep.java:40)\n    at org.gradle.internal.execution.steps.AssignWorkspaceStep.execute(AssignWorkspaceStep.java:30)\n    at org.gradle.internal.execution.steps.IdentityCacheStep.execute(IdentityCacheStep.java:37)\n    at org.gradle.internal.execution.steps.IdentityCacheStep.execute(IdentityCacheStep.java:27)\n    at org.gradle.internal.execution.steps.IdentifyStep.execute(IdentifyStep.java:44)\n    at org.gradle.internal.execution.steps.IdentifyStep.execute(IdentifyStep.java:33)\n    at org.gradle.internal.execution.impl.DefaultExecutionEngine$1.execute(DefaultExecutionEngine.java:76)\n    at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeIfValid(ExecuteActionsTaskExecuter.java:142)\n    at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:131)\n    at org.gradle.api.internal.tasks.execution.CleanupStaleOutputsExecuter.execute(CleanupStaleOutputsExecuter.java:77)\n    at org.gradle.api.internal.tasks.execution.FinalizePropertiesTaskExecuter.execute(FinalizePropertiesTaskExecuter.java:46)\n    at org.gradle.api.internal.tasks.execution.ResolveTaskExecutionModeExecuter.execute(ResolveTaskExecutionModeExecuter.java:51)\n    at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:57)\n    at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:56)\n    at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:36)\n    at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.executeTask(EventFiringTaskExecuter.java:77)\n    at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.call(EventFiringTaskExecuter.java:55)\n    at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.call(EventFiringTaskExecuter.java:52)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:204)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:199)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:66)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:59)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:157)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:59)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.call(DefaultBuildOperationRunner.java:53)\n    at org.gradle.internal.operations.DefaultBuildOperationExecutor.call(DefaultBuildOperationExecutor.java:73)\n    at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter.execute(EventFiringTaskExecuter.java:52)\n    at org.gradle.execution.plan.LocalTaskNodeExecutor.execute(LocalTaskNodeExecutor.java:74)\n    at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$InvokeNodeExecutorsAction.execute(DefaultTaskExecutionGraph.java:402)\n    at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$InvokeNodeExecutorsAction.execute(DefaultTaskExecutionGraph.java:389)\n    at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:382)\n    at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:368)\n    at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.lambda$run$0(DefaultPlanExecutor.java:127)\n    at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.execute(DefaultPlanExecutor.java:191)\n    at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.executeNextNode(DefaultPlanExecutor.java:182)\n    at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.run(DefaultPlanExecutor.java:124)\n    at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64)\n    at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48)\n    at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:61)\nCaused by: com.android.aaptcompiler.ResourceCompilationException: Resource compilation failed (Failed to compile values resource file E:\\My Client\\Henkako\\HenkakoPlus\\app\\build\\intermediates\\incremental\\debug\\mergeDebugResources\\merged.dir\\values\\values.xml. Cause: java.lang.IllegalStateException: Can not extract resource from com.android.aaptcompiler.ParsedResource@636e1e76.). Check logs for more details.\n    at com.android.aaptcompiler.ResourceCompiler.compileResource(ResourceCompiler.kt:129)\n    at com.android.build.gradle.internal.res.ResourceCompilerRunnable$Companion.compileSingleResource(ResourceCompilerRunnable.kt:34)\n    at com.android.build.gradle.internal.res.ResourceCompilerRunnable.run(ResourceCompilerRunnable.kt:15)\n    at com.android.build.gradle.internal.profile.ProfileAwareWorkAction.execute(ProfileAwareWorkAction.kt:74)\n    at org.gradle.workers.internal.DefaultWorkerServer.execute(DefaultWorkerServer.java:63)\n    at org.gradle.workers.internal.NoIsolationWorkerFactory$1$1.create(NoIsolationWorkerFactory.java:66)\n    at org.gradle.workers.internal.NoIsolationWorkerFactory$1$1.create(NoIsolationWorkerFactory.java:62)\n    at org.gradle.internal.classloader.ClassLoaderUtils.executeInClassloader(ClassLoaderUtils.java:97)\n    at org.gradle.workers.internal.NoIsolationWorkerFactory$1.lambda$execute$0(NoIsolationWorkerFactory.java:62)\n    at org.gradle.workers.internal.AbstractWorker$1.call(AbstractWorker.java:44)\n    at org.gradle.workers.internal.AbstractWorker$1.call(AbstractWorker.java:41)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:204)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:199)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:66)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:59)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:157)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:59)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.call(DefaultBuildOperationRunner.java:53)\n    at org.gradle.internal.operations.DefaultBuildOperationExecutor.call(DefaultBuildOperationExecutor.java:73)\n    at org.gradle.workers.internal.AbstractWorker.executeWrappedInBuildOperation(AbstractWorker.java:41)\n    at org.gradle.workers.internal.NoIsolationWorkerFactory$1.execute(NoIsolationWorkerFactory.java:59)\n    at org.gradle.workers.internal.DefaultWorkerExecutor.lambda$submitWork$2(DefaultWorkerExecutor.java:206)\n    at org.gradle.internal.work.DefaultConditionalExecutionQueue$ExecutionRunner.runExecution(DefaultConditionalExecutionQueue.java:214)\n    at org.gradle.internal.work.DefaultConditionalExecutionQueue$ExecutionRunner.runBatch(DefaultConditionalExecutionQueue.java:164)\n    at org.gradle.internal.work.DefaultConditionalExecutionQueue$ExecutionRunner.run(DefaultConditionalExecutionQueue.java:131)\n    ... 3 more\nCaused by: com.android.aaptcompiler.ResourceCompilationException: Failed to compile values resource file E:\\My Client\\Henkako\\HenkakoPlus\\app\\build\\intermediates\\incremental\\debug\\mergeDebugResources\\merged.dir\\values\\values.xml\n    at com.android.aaptcompiler.ResourceCompiler.compileTable(ResourceCompiler.kt:192)\n    at com.android.aaptcompiler.ResourceCompiler.access$compileTable(ResourceCompiler.kt:1)\n    at com.android.aaptcompiler.ResourceCompiler$getCompileMethod$1.invoke(ResourceCompiler.kt:138)\n    at com.android.aaptcompiler.ResourceCompiler$getCompileMethod$1.invoke(ResourceCompiler.kt:138)\n    at com.android.aaptcompiler.ResourceCompiler.compileResource(ResourceCompiler.kt:123)\n    ... 27 more\nCaused by: java.lang.IllegalStateException: Can not extract resource from com.android.aaptcompiler.ParsedResource@636e1e76.\n    at com.android.aaptcompiler.TableExtractor.extractResourceValues(TableExtractor.kt:270)\n    at com.android.aaptcompiler.TableExtractor.extract(TableExtractor.kt:181)\n    at com.android.aaptcompiler.ResourceCompiler.compileTable(ResourceCompiler.kt:188)\n    ... 31 more\n\n",
    "AcceptedAnswerId": 72355635,
    "AcceptedAnswer": "Find and exchange all ' symbols in your strings.xml or somewhere else in your code with \\'\n"
}
{
    "Id": 71363302,
    "PostTypeId": 1,
    "Title": "Java sorting list of array vs sorting list of list",
    "Body": "I have a list of points where each point is a tiny list of size 2. I want to sort the list of points in increasing order of x and if x values are equal, I break tie by sorting in decreasing order of y.\nI wrote a custom comparator to sort the points like this:\nCollections.sort(points, (a, b) -> {\n    if (a.get(0) != b.get(0)) {\n        return a.get(0) - b.get(0);\n    } return b.get(1) - a.get(1); \n});\n\nHere's the input before sorting:\n(2, 1000)\n(9, -1000)\n(3, 15)\n(9, -15)\n(5, 12)\n(12, -12)\n(5, 10)\n(10001, -10)\n(19, 8)\n(10001, -8)\n\nHere's the result produced after sorting with the above comparator:\n(2, 1000)\n(3, 15)\n(5, 12)\n(5, 10)\n(9, -15)\n(9, -1000)\n(12, -12)\n(19, 8)\n(10001, -10)\n(10001, -8)\n\nObservations:\n\nThe input is sorted in ascending order on x.\n(5, 12) was correctly put before (5, 10).\n(9, -15) was correctly put before (9, -1000).\nHowever, (10001, -10) was put before (10001, -8). Even though -8 is larger than -10.\n\nFeel like I am missing something trivial. I experimented with a few other ways of writing the comparator like using Integer.compare(a, b) or just a.compareTo(t), but got the same result.\nFinally, I changed the representation of point from List to int[] and wrote the same comparator again. See results below:\nCollections.sort(points, (a, b) -> {\n    if (a[0] != b[0])\n        return a[0] - b[0];\n    return b[1] - a[1];\n});\n\nInput before sorting:\n(2, 1000)\n(9, -1000)\n(3, 15)\n(9, -150\n(5, 12)\n(12, -12)\n(5, 10)\n(10001, -10)\n(19, 8)\n(10001, -8)\n\nAfter sorting:\n(2, 1000)\n(3, 15)\n(5, 12)\n(5, 10)\n(9, -15)\n(9, -1000)\n(12, -12)\n(19, 8)\n(10001, -8)\n(10001, -10)\n\nSo list of arrays is getting sorted correctly as (10001, -8) was correctly put before (10001, -10).\nI am not able to understand why changing the representation of point resolved the issue and hence this question. I can give more details on how I am creating the List of points if required.\n",
    "AcceptedAnswerId": 71363726,
    "AcceptedAnswer": "\nI am missing something trivial\n\nMethod equals() should be used for object comparison. Double equals == checks whether two references point to the same object in memory.\nIf you change the condition inside the comparator to !a.get(0).equals(b.get(0)) it will work correctly.\n\nHowever, (10001, -10) was put before (10001, -8). Even though -8 is larger than -10.\n\nThe reason for such behavior is that JVM caches all the instances of Integer (as well as Byte, Short and Long) in the range [-128; 127]. I.e. these instances are reused, the result of autoboxing of let's say int with a value of 12 will be always the same object.\nBecause small values in your example like 3, 5, 12 will be represented by a single object, they were compared with == without issues. But the result of comparison with == for two Integer instances with a value of 10001 will be false because in this case there will be two distinct objects in the heap.\nThe approach of caching frequently used objects is called the Flyweight design pattern. It's very rarely used in Java because this pattern can bring benefits when tons of identical objects are being created and destroyed. Only in such a case caching these objects will pay off with a significant performance improvement. As far as I know, it's used in game development.\nUse the power of objects\nPoint must be an object, not a list, as Code-Apprentice has pointed out in his answer. Use the power of objects and don't overuse collections. It brings several advantages:\n\nclass provides you a structure, it's easier to organize your code when you are thinking in terms of objects;\nbehavior declared inside a class is reusable and easier to test;\nwith classes, you can use the power of polymorphism.\n\nCaution: objects could be also misused, one of the possible indicators of that is when a class doesn't declare any behavior apart from getters and its data is being processed somehow in the code outside this class.\nAlthough the notion of point (as a geometrical object) isn't complicated, there are some useful options with regard to methods. For example, you could make instances of the Point class to be able to check to whether they are aligned horizontally or vertically, or whether two points are within a particular radius. And Point class can implement Comparable interface so that points will be able to compare themselves without a Comparator.\nSorting\nWith Java 8 method sort()\nwas added to the List interface. It expects an instance of Comparator, and if element of the list implement comparable, and you want them to be sorted according to the natural order null can be passed as an argument.\n\nIf the specified comparator is null then all elements in this list must implement the Comparable interface and the elements' natural ordering should be used.\n\nSo instead of using utility class Collections you can invoke method sort() directly on a list of points (assuming that Point implements Comparable):\npoints.sort(null); // the same as   points.sort(Comparator.naturalOrder()); \n\nAlso, you can create multiple custom comparators by utilizing default and static methods from the Comparator interface like comparingInt() and thenComparing().\n(for more information on how to build comparators with Java 8 methods take a look at this tutorial)\n"
}
{
    "Id": 71463016,
    "PostTypeId": 1,
    "Title": "Find occurrence count of the longest common Prefix/Suffix in a List of Strings?",
    "Body": "Given a list of Strings:\nArrayList strList = new ArrayList();\nstrList.add(\"Mary had a little lamb named Willy\");\nstrList.add(\"Mary had a little ham\");\nstrList.add(\"Old McDonald had a farm named Willy\");\nstrList.add(\"Willy had a little dog named ham\");\nstrList.add(\"(abc)\");\nstrList.add(\"(xyz)\");\nstrList.add(\"Visit Target Store\");\nstrList.add(\"Visit Walmart Store\");\n\nThis should produce the output in the form of a HashMap prefixMap and suffixMap:\nPREFIX:\nMary had a -> 2\nMary had a little -> 2\n( -> 2\nVisit -> 2\n\nSUFFIX:\nnamed Willy -> 2\nham -> 2\n) -> 2\nStore -> 2\n\nSo far I'm able to generate a prefix that is present in all items in list using the following code:\npublic static final int INDEX_NOT_FOUND = -1;\n\npublic static String getAllCommonPrefixesInList(final String... strs) {\n    if (strs == null || strs.length == 0) {\n        return EMPTY_STRING;\n    }\n    \n    \n    final int smallestIndexOfDiff = getIndexOfDifference(strs);\n    if (smallestIndexOfDiff == INDEX_NOT_FOUND) {\n        \n        // All Strings are identical\n        if (strs[0] == null) {\n            return EMPTY_STRING;\n        }\n        return strs[0];\n    } else if (smallestIndexOfDiff == 0) {\n        \n        \n        // No common initial characters found, return empty String\n        return EMPTY_STRING;\n    } else {\n        \n        // Common initial character sequence found, return sequence\n        return strs[0].substring(0, smallestIndexOfDiff);\n    }\n}\n\n\n\n\n\n\npublic static int getIndexOfDifference(final CharSequence... charSequence) {\n    if (charSequence == null || charSequence.length <= 1) {\n        return INDEX_NOT_FOUND;\n    }\n    boolean isAnyStringNull = false;\n    boolean areAllStringsNull = true;\n    \n    \n    final int arrayLen = charSequence.length;\n    int shortestStrLen = Integer.MAX_VALUE;\n    int longestStrLen = 0;\n\n    // Find the min and max string lengths - avoids having to check that we are not exceeding the length of the string each time through the bottom loop.\n    for (int i = 0; i < arrayLen; i++) {\n        if (charSequence[i] == null) {\n            isAnyStringNull = true;\n            shortestStrLen = 0;\n        } else {\n            areAllStringsNull = false;\n            shortestStrLen = Math.min(charSequence[i].length(), shortestStrLen);\n            longestStrLen = Math.max(charSequence[i].length(), longestStrLen);\n        }\n    }\n\n    // Deals with lists containing all nulls or all empty strings\n    \n    if (areAllStringsNull || longestStrLen == 0 && !isAnyStringNull) {\n        return INDEX_NOT_FOUND;\n    }\n\n    // Handle lists containing some nulls or some empty strings\n    if (shortestStrLen == 0) {\n        return 0;\n    }\n\n    // Find the position with the first difference across all strings\n    int firstDiff = -1;\n    for (int stringPos = 0; stringPos < shortestStrLen; stringPos++) {\n        final char comparisonChar = charSequence[0].charAt(stringPos);\n        for (int arrayPos = 1; arrayPos < arrayLen; arrayPos++) {\n            if (charSequence[arrayPos].charAt(stringPos) != comparisonChar) {\n                firstDiff = stringPos;\n                break;\n            }\n        }\n        if (firstDiff != -1) {\n            break;\n        }\n    }\n\n    if (firstDiff == -1 && shortestStrLen != longestStrLen) {\n        \n        // We compared all of the characters up to the length of the\n        // shortest string and didn't find a match, but the string lengths\n        // vary, so return the length of the shortest string.\n        return shortestStrLen;\n    }\n    return firstDiff;\n}\n\nHowever, my goal is to include any prefix/suffix with at least 2+ occurrences into the resulting map.\nHow can this be achieved with Java?\n",
    "AcceptedAnswerId": 71507839,
    "AcceptedAnswer": "In my understanding of this problem the most suitable data structure for solving it is an acyclic disjointed Graph.\nIn general case, a graph will be comprised of several unconnected clusters. Each cluster will have a tree-like structure, in the edge case it'll form a linked list.\nBasically, the most simple naive approach on how to solve this problem is to create a bunch of linked list based on each line, and iterate over them. The drawbacks are: duplication of nodes (greater memory consumption), greater time-complexity (more operations required) and it's more error-prone because more manual actions are needed.\nThe description of the Graph\nSo I'll stick with the graph as the data structure for this problem and try to keep things as simple as possible.\nLet's consider the following input:\n\"Mary had a little lamb named Willy\"\n\"Mary had a little ham\"\n\"A B C\"\n\nThe graphical representation of the graph will look like this;\n\nThe two first lines will constitute a cluster formed from a linked list (the head part) and a tree (the tail part). The second cluster will be represented by a linked list, its vertices aren't connected with vertices formed from other strings.\nIt's not the only way the vertexes can be structured, the head could spawn an N-tree and a linked list could be observed somewhere in the middle.\nThe main takeaway is that in order to solve the problem, we need to track the chain of vertexes through all the branches until the vertexes overlap. In these parts of the graph, every prefix-strings and suffix-string that is common among two or more lines will be represented by a single vertex (node).\nTo maintain the number of strings that are mapped to a particular vertex, each vertex should have a variable (int groupCount in the code below), which is assigned with a default value of 1 when a vertex is being created and incremented each time a new string gets mapped to this vertex.\nEach vertex contains a map that holds references to its neighbours. When a new neighbour-vertex is being added, either new Vertex in being created based on the given string or the count of an existing vertex gets incremented.\nIn order to conform to this task, the graph should maintain references to all head-vertexes and tail-vertexes. For simplicity, instead of maintaining two groups of references to adjacent nodes, and two separate count variables (because suffix-count and prefix-count will differ) in each vertex, in this solution graph is actually comprised of two graph (suffix-graph and prefix-graph). And for that reason, the implementing class in named MultiGraph.\nIn order to populate both suffix-graph and prefix-graph with vertexes, method addCluster() iterates over the string of the given line by the means of Iterator in normal or reversed order, depending on which graph is being populated.\nDepth first search\nThe next step after the graphs are populated is to generate the maps of strings with the frequency of 2 and greater.\nFor that, the classical depth first search algorithm is being used.\nIn order to implement the DFS, a mutable container that will be used as a stack is required (ArrayDeque is being used for that purpose). The first element that is taken from the map of heads/tails will be placed on the top of the stack and an instance of StringBuilder holding the name of this element will be placed in the map.\nThen, to restore a string with a particular count, vertexes will be popped from the top of the stack and their neighbours with count > 1 in turn will be placed on top of the stack. A copy of the current prefix with the delimiter and the neighbour's name appended will get mapped to the neighbour-vertex.\nIf a count changes, that indicates that the current prefix represents the longest common string between at least two lines. In this case, prefix and count are being added to the resulting map.\nImplementation\nThe following implementation consists of two classes that are narrow-focused and self-contained. The MultiGraph class acts exclusively as data structure, maintaining two graphs. The pluming code, like splitting the lines of strings, is extracted into a separate class GraphManager.\nGraph\npublic class MultiGraph {\n    private final Map heads = new HashMap();\n    private final Map tails = new HashMap();\n\n    public void addCluster(Deque names) {\n        addCluster(heads, names.iterator());\n        addCluster(tails, names.descendingIterator());\n    }\n\n    private void addCluster(Map clusters, Iterator names) {\n        String rootName = names.next();\n        if (clusters.containsKey(rootName)) {\n            clusters.get(rootName).incrementGroupCount();\n        } else {\n            clusters.put(rootName, new Vertex(rootName));\n        }\n\n        Vertex current = clusters.get(rootName);\n        while (names.hasNext()) {\n            current = current.addNext(names.next());\n        }\n    }\n\n    public Map generatePrefixMap(String delimiter) {\n        Map countByPrefix = new HashMap();\n\n        for (Vertex next: heads.values()) {\n            if (next.getGroupCount() == 1) {\n                continue;\n            }\n            performDFS(heads, countByPrefix, delimiter, next);\n        }\n        return countByPrefix;\n    }\n\n    public Map generateSuffixMap(String delimiter) {\n        Map countBySuffix = new HashMap();\n\n        for (Vertex next: tails.values()) {\n            if (next.getGroupCount() == 1) {\n                continue;\n            }\n            performDFS(tails, countBySuffix, delimiter, next);\n        }\n        return countBySuffix;\n    }\n    // implementation of the Depth First Search algorithm\n    public void performDFS(Map clusters,\n                           Map countByPrefix,\n                           String delimiter, Vertex next) {\n\n        StringBuilder prefix = null;\n        Vertex current = next;\n        int count = next.getGroupCount();\n\n        Deque stack = new ArrayDeque(); // create as stack\n        Map prefixByVert = new HashMap();\n        stack.push(next); // place the first element on the stack\n        prefixByVert.put(current, new StringBuilder(current.getName()));\n\n        while (!stack.isEmpty()) {\n            current = stack.pop();\n            if (current.getGroupCount() < count) { // the number of strings mapped to the current Vertex has been changed\n                countByPrefix.put(prefix.toString(), count); // saving the result\n                count = current.getGroupCount();\n            }\n            prefix = prefixByVert.get(current);\n\n            for (Vertex neighbour: current.getNextVertByVal().values()) {\n                if (next.getGroupCount() == 1) {\n                    continue;\n                }\n                stack.push(neighbour);\n                prefixByVert.put(neighbour, new StringBuilder(prefix)\n                                    .append(delimiter)\n                                    .append(neighbour.getName()));\n            }\n        }\n\n        if (prefix != null && count > 1) {\n            countByPrefix.putIfAbsent(prefix.toString(), count);\n        }\n    }\n\n    private static class Vertex {\n        private final String name;\n        private int groupCount = 1;\n        private final Map nextVertByVal = new HashMap();\n\n        public Vertex(String name) {\n            this.name = name;\n        }\n\n        public Vertex addNext(String value) {\n            if (nextVertByVal.containsKey(value)) {\n                nextVertByVal.get(value).incrementGroupCount();\n            } else {\n                nextVertByVal.put(value, new Vertex(value));\n            }\n            return nextVertByVal.get(value);\n        }\n\n        public void incrementGroupCount() {\n            this.groupCount++;\n        }\n\n        public String getName() {\n            return name;\n        }\n\n        public int getGroupCount() {\n            return groupCount;\n        }\n\n        public Map getNextVertByVal() {\n            return nextVertByVal;\n        }\n    }\n}\n\nThe following class deals with the task of processing the input data: it splits the lines, takes care of discarding the empty string which might take place, and packs the input into a Deque to accommodate the iteration in both directions in a convenient way.\nIt also instantiates the graph and governs it's work. GraphManager takes care of providing the delimiter to the graph in order to restore the initial shape of strings while the resulting maps are being created. With that you can split the given lines on a white space, by empty string to process lines character by character or by punctuation marks without changing a single line in these two classes.\nGraphManager\npublic class GraphManager {\n    private MultiGraph graph = new MultiGraph();\n    private String delimiter;\n\n    private GraphManager(String delimiter) {\n        this.delimiter = delimiter;\n    }\n\n    public static GraphManager getInstance(Iterable lines, String delimiter) {\n        GraphManager gm = new GraphManager(delimiter);\n        gm.init(lines);\n        return gm;\n    }\n\n    private void init(Iterable lines) {\n        for (String line: lines) {\n            Deque names = new ArrayDeque();\n            for (String name: line.split(delimiter)) {\n                if (!name.isEmpty()) {\n                    names.add(name);\n                }\n            }\n            addCluster(names);\n        }\n    }\n\n    private void addCluster(Deque names) {\n        graph.addCluster(names);\n    }\n\n    public Map getPrefixMap() {\n        return graph.generatePrefixMap(delimiter);\n    }\n\n    public Map getSuffixMap() {\n        return graph.generateSuffixMap(delimiter);\n    }\n}\n\nmain()\npublic static void main(String[] args) {\n    List lines = List.of(\n            \"Mary had a little lamb named Willy\", \"Mary had a little ham\",\n            \"Old McDonald had a farm named Willy\", \"Willy had a little dog named ham\",\n            \"( abc )\", \"( xyz )\", \"Visit Target Store\", \"Visit Walmart Store\");\n\n    GraphManager gm = GraphManager.getInstance(lines, \" \");\n    \n    System.out.println(\"Prefixes:\");\n    for (Map.Entry entry: gm.getPrefixMap().entrySet()) {\n        System.out.println(entry.getValue() + \" \" + entry.getKey());\n    }\n\n    System.out.println(\"\\nSuffixes:\");\n    for (Map.Entry entry: gm.getSuffixMap().entrySet()) {\n        System.out.println(entry.getValue() + \" \" + entry.getKey());\n    }\n}\n\nOutput\nPrefixes:\n2 Mary had a little\n2 Visit\n2 (\n\nSuffixes:\n2 ham\n2 )\n2 Store\n2 Willy named\n\n"
}
{
    "Id": 72396628,
    "PostTypeId": 1,
    "Title": "Adding multiple products to productlist for queryProductDetailsAsync in android billing 5.0.0",
    "Body": "In the old android billing implementation you would build an sku list to query products:\nList skuList = new ArrayList();\n        skuList.add(SKU_POTION);\n        skuList.add(SKU_SWORD);\n        skuList.add(SKU_BOW);\n        SkuDetailsParams.Builder params = SkuDetailsParams.newBuilder();\n        params.setSkusList(skuList).setType(BillingClient.SkuType.INAPP);\n\nThe new billing implementation is more involved, and appears to limit you to adding just one product to a query list:\nImmutableList productList = ImmutableList.from(QueryProductDetailsParams.Product.newBuilder()\n                    .setProductId(SKU_POTION)\n                    .setProductType(BillingClient.ProductType.INAPP)\n                    .build());\n    \n            QueryProductDetailsParams params = QueryProductDetailsParams.newBuilder()\n                    .setProductList(productList)\n                    .build();\n    \n            billingClient.queryProductDetailsAsync(\n            params,\n            new ProductDetailsResponseListener() {\n                public void onProductDetailsResponse(BillingResult billingResult, List productDetailsList) {\n                    if (billingResult.getResponseCode() == BillingClient.BillingResponseCode.OK && productDetailsList != null) {\n                        for (ProductDetails skuDetails : productDetailsList) {                    \n                            mProductDetailsMap.put(skuDetails.getProductId(), skuDetails);                           \n                        }\n                    }\n                   \n                }\n            }\n    );\n\nIt makes you build the productList for the productDetailsList for the mProductDetailsMap that's needed to start the purchase flow:\npuchasestring=SKU_POTION;\ninitiatePurchaseFlow(mProductDetailsMap.get(puchasestring));\n\nHow would I add multiple products to the productList that begins the implementation? I don't want to have to repeat the entire code segment for each item to add to the mProductDetailsMap, which is the Primitive Pete method I'm using for now.\n",
    "AcceptedAnswerId": 72397831,
    "AcceptedAnswer": "For multiple products:\nImmutableList productList = ImmutableList.from(\nQueryProductDetailsParams.Product.newBuilder()\n                    .setProductId(SKU_POTION)\n                    .setProductType(BillingClient.ProductType.INAPP)\n                    .build(),\nQueryProductDetailsParams.Product.newBuilder()\n                    .setProductId(SKU_SWORD)\n                    .setProductType(BillingClient.ProductType.INAPP)\n                    .build(),\nQueryProductDetailsParams.Product.newBuilder()\n                    .setProductId(SKU_BOW)\n                    .setProductType(BillingClient.ProductType.INAPP)\n                    .build());\n\n"
}
{
    "Id": 71473553,
    "PostTypeId": 1,
    "Title": "Action requested: Declare your Ad ID permission",
    "Body": "Today i have got this email:\n\nLast July, we announced Advertising policy changes to help bolster\nsecurity and privacy. We added new restrictions on identifiers used by\napps that target children. When users choose to delete their\nadvertising ID in order to opt out of personalization advertising,\ndevelopers will receive a string of zeros instead of the identifier if\nthey attempt to access the identifier. This behavior will extend to\nphones, tablets, and Android TV starting April 1, 2022. We also\nannounced that you need to declare an AD_ID permission when you update\nyour app targeting API level to 31 (Android 12). Today, we are sharing\nthat we will give developers more time to ease the transition. We will\nrequire this permission declaration when your apps are able to target\nAndroid 13 instead of starting with Android 12.\nAction Items If you use an advertising ID, you must declare the AD_ID\nPermission when your app targets Android 13 or above. Apps that don\u2019t\ndeclare the permission will get a string of zeros. Note: You\u2019ll be\nable to target Android 13 later this year. If your app uses an SDK\nthat has declared the Ad ID permission, it will acquire the permission\ndeclaration through manifest merge. If your app\u2019s target audience\nincludes children, you must not transmit Android Advertising ID (AAID)\nfrom children or users of unknown age.\n\nMy app is not using the Advertising ID. Should i declare the AD_ID Permission in Manifest or not?\n",
    "AcceptedAnswerId": 71474159,
    "AcceptedAnswer": "If your app uses the Google Mobile Ads SDK(Admob) version\u00a020.4.0\u00a0or higher, you can skip setting up the permission manually since the SDK automatically declares it\nMore informations here:\nhttps://developers.google.com/admob/android/quick-start\n"
}
{
    "Id": 72227442,
    "PostTypeId": 1,
    "Title": "Unsupported class file major version 61",
    "Body": "I am trying to integrate Glowroot into my Java application. Unfortunately, I get the following error:\n2022-05-13 09:25:57.777 ERROR o.g.a.w.PointcutClassFileTransformer - Unsupported class file major version 61\njava.lang.IllegalArgumentException: Unsupported class file major version 61\n    at org.glowroot.agent.shaded.org.objectweb.asm.ClassReader.(ClassReader.java:196)\n\nNeither Glowroot nor my application seem to use gradle so I have no idea where this incompatibility is coming from.\nHave you got any idea on how I could find the source of the incompatibility and then how I could fix it?\nThank you!\nEDIT: I use Glowroot in the version 0.13.6 .\nSecond edit: Seems like the version of glowroot was the issue...\n",
    "AcceptedAnswerId": 72229157,
    "AcceptedAnswer": "(I incorrectly was zeroing in on the \"Unsupported class file major version 61\" message without looking at the stacktrace.)\nThe problem (as pointed out by @Mark Rotteveel) is that glowroot is failing while trying to do some code transformation using ASM.  Apparently the ClassReader in the version of ASM that is bundled in glowroot 0.13.6 doesn't understand version 61 (Java 17) class files.\nQ: How to solve this?\nA: Use glowroot 0.14.0-beta.2 or later; see https://github.com/glowroot/glowroot/issues/906.  Alternative, build your application and its dependencies (as required) for an earlier (target) version of Java, and (maybe1) run on an earlier version of Java.\n\n1 - It depends on whether the code transformations involve the ASM ClassReader reading Java SE classes.\n"
}
{
    "Id": 71548717,
    "PostTypeId": 1,
    "Title": "Differences in floating point between JDK 8 and JDK 13",
    "Body": "It seems that JDK 8 and JDK 13 have different floating points.\nI get on JDK 8, using Math:\ncos(2.3) = -0.666276021279824\n\nAnd on JDK 13:\ncos(2.3) = -0.6662760212798241\n\nHow does this happen? Difference shows on 11th Gen Intel and on AMD Ryzen using Windows 10.\nEdit 20.03.2022:\nUsing Long.toHexString(Double.doubleToRawLongBits()) I get different bit patterns:\nI get on JDK 8:\ncos(2.3) = 0xbfe5522217302fe0\n\nAnd I get on JDK 13:\ncos(2.3) = 0xbfe5522217302fe1\n\n",
    "AcceptedAnswerId": 71549434,
    "AcceptedAnswer": "This seems to be caused by a JVM intrinsic function for Math.cos, which is described in the related issue JDK-8242461. The behavior experienced there is not considered an issue:\n\nThe returned results reported in this bug are indeed adjacent floating-point values [this is the case here as well]\n[...]\nTherefore, while it is possible one or the other of the returned values is outside of the accuracy bounds, just have different return values for Math.cos is not in and of itself evidence of a problem.\nFor reproducible results, use the StrictMath.cos instead.\n\nAnd indeed, disabling the intrinsics using -XX:+UnlockDiagnosticVMOptions -XX:DisableIntrinsic=_dcos (as proposed in the linked issue), causes Math.cos to have the same (expected) result as StrictMath.cos.\nSo it appears the behavior you are seeing here is most likely compliant with the Math documentation as well.\n"
}
{
    "Id": 72478972,
    "PostTypeId": 1,
    "Title": "Stange behaviour since upgrade from 2.6.2 to 2.7.0",
    "Body": "I faced to a strange behaviour while upgrading my application from SpringBoot 2.6.2 to 2.7.0.\nI've a starter with autoconfiguration which is responsible of initializing JPA auditing :\n@Configuration\n@ConditionalOnBean(DataSource.class)\n@ConditionalOnClass({DataSource.class, AuditorAware.class, SecurityContextHolder.class})\n@AutoConfigureAfter({HibernateJpaAutoConfiguration.class, SecurityAutoConfiguration.class, ClockSpringConfiguration.class})\n@EnableJpaAuditing(auditorAwareRef = \"auditorProvider\", dateTimeProviderRef = \"dateTimeProvider\")\npublic class JpaAuditingSpringConfiguration {\n    @Bean\n    public AuditorAware auditorProvider() {\n        return () ->\n                Optional.ofNullable(SecurityContextHolder.getContext())\n                        .map(SecurityContext::getAuthentication)\n                        .map(Authentication::getName);\n    }\n\n    @Bean\n    public DateTimeProvider dateTimeProvider(Clock clock) {\n        return () ->\n                Optional.of(clock)\n                        .map(Clock::instant);\n    }\n}\n\nThis starter is fine in 2.6.2. But in 2.7.0 the @ConditionalOnBean(DataSource.class) avoid the starter to perform initialization.\nWhen i remove the statement all is fine again.\nI don't understand why it doesn't work since the update?\nMaybe i misused or forgot some statement. The behaviour i attempt to is the autoconfiguration apply only if a datasource bean is registred.\nIf someone can help me ?\nPS : sorry for my english :-)\n",
    "AcceptedAnswerId": 72531265,
    "AcceptedAnswer": "So i found the solution, it was a mistake from myself... I put the @AutoConfigureAfter on a @Configuration imported by the autoconfiguration entrypoint. So i move the statement on the autoconfiguration class and now all is fine.\nThe new annotation @AutoConfiguration will be very usefull to avoid this kinf of mistake.\n"
}
{
    "Id": 71473485,
    "PostTypeId": 1,
    "Title": "What is the difference between a final Class and a Record?",
    "Body": "In simple words what is the difference between a final class and a record in Java 17?\nIn which case should I use a record?\n",
    "AcceptedAnswerId": 71474203,
    "AcceptedAnswer": "Record is an immutable class, i.e. all its fields are final. Records are implicitly final, hence as well as regular final class record can't be extended.\nThere are a number of restrictions imposed on records (for more details, take a look at JEP 395).\nContrary to normal classes:\n\nit's forbidden to declare instance fields explicitly inside records (and reminder: all fields are final, which is a very impotent distinction);\nextends clause is not allowed with records, because every record implicitly extends abstract class Record;\nrecord can't be declared with any of these modifiers: abstract, sealed, or non-sealed (as a consequence of being implicitly final);\nrecords can't declare instance initializers and native methods.\n\nRecords are meant to be \"transparent carriers for immutable data\" as JEP 395 says.\nThey are designed to be concise, default constructor, getters, hashCode/equals and toString() will be generated by the compiler for you. So that inside a record you need to declare only your custom logic (if any) and record declaration can be literally a one-liner.\nRecords differ a lot from regular final classes.\nAlso, apart from the peculiarities mentioned above, the mechanism of serialization / deserialization was reimplemented for records, so that deserialization doesn't bypass the constructor.\n\nIn which case should I use a record?\n\nIn short, if your objects must be stateful, or you need to extend a particular class, then you can't utilize record in such a case.\nOn the other hand, if your objects are meant just carry the data, they are not intended to be modified or inherit from other classes, then it might be a good candidate to be implemented as a record.\n"
}
{
    "Id": 72259078,
    "PostTypeId": 1,
    "Title": "Invariant Generics don't seem working correctly",
    "Body": "I've read some articles about Covariance, Contravariance, and Invariance in Java, but I'm confused about them.\nI'm using Java 11, and I have a class hierarchy A => B => C (means that C is a subtype of B and A, and B is a subtype of A) and a class Container:\nclass Container {\n    public final T t;\n    public Container(T t) {\n        this.t = t;\n    }\n}\n\nfor example, if I define a function:\npublic Container method(Container param){\n  ...\n}\n\nhere is my confusion, why does the third line compile?\nmethod(new Container(new A())); // ERROR\nmethod(new Container(new B())); // OK\nmethod(new Container(new C())); // OK Why ?, I make a correction, this compiles OK\n\nif in Java Generics are invariant.\nWhen I define something like this:\nContainer conta =  new Container(new A()); // ERROR, Its OK!\nContainer contb =  new Container(new B()); // OK, Its OK!\nContainer contc =  new Container(new C()); // Ok, why ? It's not valid, because they are invariant\n\n",
    "AcceptedAnswerId": 72275673,
    "AcceptedAnswer": "One of the boons introduced with Java 7 is the so-called diamond operator .\nAnd it has been with us for so long, that it's easy to forget that every time when diamond is being used while instantiating a generic class the compiler should infer the generic type from the context.\nIf we define a variable which will hold a reference to a list of Person objects like this:\nList people = new ArrayList(); // effectively - ArrayList()\n\nthe compiler will infer the type of the ArrayList instance from the type of the variable people on the left.\nIn the Java language specification, the expression new ArrayList() is being described as a class instance creation expression and because it doesn't specify the generic type parameter and is used within a context, it should be classified as being a poly expression. A quote from the specification:\n\nA class instance creation expression is a poly expression (\u00a715.2) if\nit uses the diamond form for type arguments to the class, and it\nappears in an assignment context or an invocation context (\u00a75.2,\n\u00a75.3).\n\nI.e. when diamond  is used with a generic class instantiation, the actual type will depend on the context in which it appears.\nThe three statements below represent the case of so-called assignment context. And all three instances Container will be inferred as being of type B.\nContainer conta = new Container(new A()); // 1 - ERROR   because `B t = new A()` is incorrect\nContainer contb = new Container(new B()); // 2 - fine    because `B t = new B()` is correct\nContainer contc = new Container(new C()); // 3 - fine    because `B t = new C()` is also correct\n\nSince all instances of container are of type B and of parameter type expected by the contractor also will be B. I.e. can provide an instance of B or any of its subtypes. Therefore, in the case 1 we are getting a compilation error, meanwhile 2 and 3 (B and subtype of B) will compile correctly.\nAnd it in't a violation of invariant behavior. Think about it this way: we can store in a List instances of Integer, Byte, Double, etc., that would not lead to any problem since they all can represent their super type Number. But the compiler will not allow assigning this list to any list that is not of type List because otherwise it would be impossible to ensure that this assignment is safe. And that is what the invariance means - we can assign only List to a variable of type List (but we are free to store any subtype of Number in it, it's safe).\nAs an example, let's consider that there's a setter method in the Container class:\npublic class Container {\n    public T t;\n    public Container(T t) {\n        this.t = t;\n    }\n        \n    public void setT(T t) {\n        this.t = t;\n    }\n}\n\nNow let's use it:\nContainer contb =  new Container(null); // to avoid any confusion initialy `t` will be assigned to `null`\n\ncontb.setT(new A()); // compilation error - because expected type is `B` or it's subtype\ncontb.setT(new B()); // fine\ncontb.setT(new C()); // fine because C is a subtype of B\n\nWhen we deal with a class instance creation expression using diamond , which is passed to a method as an argument, the type will be inferred from the invocation context as the quote from the specification provided above states.\nBecause method() expects Container, all instances above will be inferred as being of type B.\nmethod(new Container(new A())); // Error\nmethod(new Container(new B())); // OK - because `B t = new B()` is correct\nmethod(new Container(new C())); // OK - because `B t = new C()` is also correct\n\nNote\nThe important thing to mention that prior to Java 8 (i.e. with Java 7, because we are using diamond) the expression new Container(new C()) will be interpreted by the compiler as a standalone expression (i.e. the context will be ignored) creating an instance of Container. It means your initial guess was somewhat correct: with Java 7 the below statement would not compile.\nContainer contc = new Container(new C()); // Container = Container - is an illegal assignment\n\nBut Java 8 has introduced a feature called target types and poly expressions (i.e. expressions that appear within a context) that insures that context will always be taken into account by the type inference mechanism.\n"
}
{
    "Id": 71642208,
    "PostTypeId": 1,
    "Title": "Parameter value [%Gabrek%] did not match expected type [java.lang.Character (n/a)];",
    "Body": "i've been writing wirting a program in Spring Boot Web with JPA and i'm using a query to access some data with a 'contains' and 'ignorecase' filter, i've done this before in other programs and it has worked fine, but now i'm getting this error, i'm completely lost at this point since i can't find anything in google, i went really far down the rabbit hole looking as to why it happens and so far i don't see anything out of place in my code, the type of variable declared seems to be okay but as i've said, i'm lost. It's important to mention that for some reason when I do the query on my website for the first time, everything works fine, i get the proper results and all, but when I go back to home and try with another query (or even the same) i get the error. Code below:\nModel\nimport javax.persistence.Column;\nimport javax.persistence.Entity;\nimport javax.persistence.GeneratedValue;\nimport javax.persistence.GenerationType;\nimport javax.persistence.Id;\n\n@Entity\npublic class Serie {\n    \n    @Id\n    @Column(columnDefinition = \"NUMERIC(19,0)\")\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Integer id;\n    private String title;\n    private String red;\n    @Column(columnDefinition = \"NUMERIC(19,0)\")\n    private double rating;\n\nRepository\nimport java.util.List;\n\nimport org.springframework.data.jpa.repository.JpaRepository;\n\nimport cl.desafiolatam.imdb.modelo.Serie;\n\npublic interface SerieRepository extends JpaRepository {\n\n    public List findByTitleContainingIgnoreCase(String title);\n    \n}\n\nService\nimport cl.desafiolatam.imdb.vo.SerieVO;\n\npublic interface SerieService {\n    \n    public SerieVO findByTitleContainingIgnoreCase(String title);\n\n}\n\nService implementation\nimport java.util.ArrayList;\nimport java.util.List;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Service;\nimport org.springframework.transaction.annotation.Transactional;\n\nimport cl.desafiolatam.imdb.dao.SerieRepository;\nimport cl.desafiolatam.imdb.modelo.Serie;\nimport cl.desafiolatam.imdb.service.SerieService;\nimport cl.desafiolatam.imdb.vo.SerieVO;\n\n@Service\npublic class SerieServiceImpl implements SerieService {\n    \n    private static final Logger logger = LoggerFactory.getLogger(SerieServiceImpl.class);\n    \n    @Autowired\n    SerieRepository dao;\n    SerieVO respuesta;\n\n    @Override\n    @Transactional(readOnly = true)\n    public SerieVO findByTitleContainingIgnoreCase(String title) {\n        \n        respuesta = new SerieVO(\"Ha ocurrido un error!\", \"104\", new ArrayList());\n\n        try {\n            List serie = dao.findByTitleContainingIgnoreCase(title);\n            System.out.println(serie);\n            if(serie.size() > 0) {\n                respuesta.setSeries(serie);\n                respuesta.setMensaje(\"Se ha encontrado el registro\");\n                respuesta.setCodigo(\"0\");\n            } else {\n                respuesta.setMensaje(\"No se ha encontrado el registro\");\n                respuesta.setCodigo(\"104\");\n            }\n        } catch (Exception e) {\n            logger.error(\"Error al buscar la serie\", e);\n        }\n        \n        return respuesta;\n    }\n\n}\n\nVisual object\nimport java.util.List;\n\nimport cl.desafiolatam.imdb.modelo.Serie;\n\npublic class SerieVO extends GenericVO {\n    \n    List series;\n\n    public SerieVO(String mensaje, String codigo, List series) {\n        super(mensaje, codigo);\n        this.series = series;\n    }\n\n    public SerieVO() {\n        super();\n    }\n\nController\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Controller;\nimport org.springframework.ui.Model;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.ModelAttribute;\nimport org.springframework.web.bind.annotation.PostMapping;\nimport org.springframework.web.bind.annotation.RequestParam;\nimport org.springframework.web.servlet.ModelAndView;\nimport org.springframework.web.servlet.mvc.support.RedirectAttributes;\n\nimport cl.desafiolatam.imdb.modelo.Serie;\nimport cl.desafiolatam.imdb.service.SerieService;\nimport cl.desafiolatam.imdb.vo.SerieVO;\n\n@Controller\npublic class SerieController {\n\n    private final static Logger logger = LoggerFactory.getLogger(SerieController.class);\n\n    @Autowired\n    private SerieService svc;\n\n@GetMapping(\"/buscarSerie\")\n    public ModelAndView buscarSerie(Model model, @RequestParam String nombreSerie) {\n        \n        SerieVO respuestaServicio = new SerieVO();\n        respuestaServicio.setMensaje(\"No se ha encontrado la serie\");\n        \n        try {\n            respuestaServicio = svc.findByTitleContainingIgnoreCase(nombreSerie);\n            model.addAttribute(\"listaSeries\", respuestaServicio.getSeries());\n            return new ModelAndView(\"resultadoserie\");\n        } catch (Exception e) {\n            logger.error(\"Error al buscar la serie\", e);\n        }\n        \n        return new ModelAndView(\"redirect:/user\");\n        \n    }\n}\n\nSearch input\n\n        \n            \n                \n                    Buscar serie\n                \n            \n            \n                \n                    \n                        \n                            \n                                <input type=\"text\" class=\"form-control\" id=\"floatingInputGrid\"\n                                    value=\"\" name=\"nombreSerie\" required> <label\n                                    for=\"floatingInputGrid\">Serie\n                            \n                        \n                    \n                    \n                        \n                    \n                \n            \n        \n    \n\nAs i've said, im really lost, researched everywhere, and checked the code in my last projects, i just can't find out why this one does me this dirty. Won't even fail at the start, it gives me a glimpse of hope and when i want to retry it, it crushes that little hope. :)\nI tried deleting my code and copy&paste from projects where i know it works as intended, changed the variable and param. names to make it work with the new program but didn't work. Did a side by side comparison, tried a @Query writing the specific instruction. Looking for info. only with the 'contains' filter and yet, nothing worked.\n",
    "AcceptedAnswerId": 71649782,
    "AcceptedAnswer": "According to the Spring Data JPA issue #2472 this seems to be a problem in Hibernate 5.6.6 and 5.6.7.\nThe Hibernate bug is HHH-15142.\nThe solution is to either downgrade to Hibernate 5.6.5 or wait for a Hibernate patch to solve this issue.\nUpdate: According to the bug report above this is resolved in version 5.6.9.\n"
}
{
    "Id": 72510274,
    "PostTypeId": 1,
    "Title": "Terminate a Stream when there is no incoming Data after certain Timeout",
    "Body": "I have an InputStream and OutputStream (there is no socket).\nI have a stream-based code that does some mapping/filtering/grouping/processing.\nMy main goal to terminate the stream if the maxDuration was exceeded:\nvoid fillStreamMap(BufferedReader reader) {\n    final Instant end = Instant.now().plusNanos(TimeUnit.NANOSECONDS.convert(maxDuration));\n\n    this.map = reader.lines()\n        .takeWhile(e -> checkTimeout(end))\n        .map(this::jsonToBuyerEventInput)\n        .filter(Objects::nonNull)\n        .filter(getFilter()::apply)\n        .limit(super.maxEvent)\n        .collect(Collectors.groupingBy(BuyerEventInput::getBuyer));\n}\n\nboolean checkTimeout(Instant end){\n    return Instant.now().getEpochSecond() <= end.getEpochSecond();\n}\n\nI'm using takeWhile which is a very useful function, but it checks the termination condition if there is an upcoming event.\nSo if there is no data sent, it doesn't check the condition because this function is built to take a Predicate as an argument.\nIs there any way to accomplish this goal?\n",
    "AcceptedAnswerId": 72553605,
    "AcceptedAnswer": "Here is an approach that operates on Streams. The core function is timedTake(Stream stream, long timeout, TimeUnit unit). The idea is to traverse the original stream using its raw Spliterator, which makes it possible to set a timeout.\nimport java.io.BufferedReader;\nimport java.io.InputStreamReader;\nimport java.util.Optional;\nimport java.util.Spliterator;\nimport java.util.concurrent.ExecutionException;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.Future;\nimport java.util.concurrent.ThreadFactory;\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.TimeoutException;\nimport java.util.function.Supplier;\nimport java.util.stream.Stream;\n\nclass Main {\n    static  Stream generateOrderedStream(Supplier> s) {\n        // Returns an ordered stream with the values of the Optionals returned by s.get(). An empty Optional ends the stream.\n        // As pseudocode:\n        //     for (Optional o = s.get(); o.isPresent(); o = s.get())\n        //         emit o.get();\n        return Stream.iterate(s.get(), Optional::isPresent, prev -> s.get())\n            .map(Optional::get);\n    }\n\n    static  Optional advance(Spliterator iter) {\n        // Returns an Optional with the next element of the iterator, or an empty Optional if there are no more elements.\n        // (This method is much nicer than calling iter.tryAdvance() directly.)\n        final var r = new Object() { T elem; };\n        return iter.tryAdvance(elem -> r.elem = elem) ? Optional.of(r.elem) : Optional.empty();\n    }\n\n    static ThreadFactory daemonThreadFactory() {\n        return (r) -> {\n            Thread thread = new Thread(r);\n            thread.setDaemon(true);\n            return thread;\n        };\n    }\n\n    static  Stream timedTake(Stream stream, long timeout, TimeUnit unit) {\n        // Traverses the stream until the timeout elapses and returns the traversed elements.\n        final long deadlineNanos = System.nanoTime() + unit.toNanos(timeout);\n        final ExecutorService executor = Executors.newSingleThreadExecutor(daemonThreadFactory());\n        final Spliterator iter = stream.spliterator();\n        return generateOrderedStream(() -> {\n            try {\n                Future> future = executor.submit(() -> advance(iter));\n                long remainingNanos = deadlineNanos - System.nanoTime();\n                Optional optElem = future.get(remainingNanos, TimeUnit.NANOSECONDS);\n                if (!optElem.isPresent()) { // this is the end of the input stream, so clean up\n                    executor.shutdownNow();\n                }\n                return optElem;\n            } catch (TimeoutException e) {\n                executor.shutdownNow();\n                return Optional.empty(); // mark this as the end of the result stream\n            } catch (ExecutionException e) {\n                executor.shutdownNow();\n                throw new RuntimeException(e.getCause());\n            } catch (InterruptedException e) {\n                executor.shutdownNow();\n                throw new RuntimeException(e);\n            }\n        });\n    }\n\n    static void fillStreamMap(BufferedReader reader) {\n        // streaming demo\n        long maxDurationSecs = 5;\n        timedTake(reader.lines(), maxDurationSecs, TimeUnit.SECONDS)\n            .takeWhile(line -> !line.contains(\"[stop]\"))\n            .map(line -> \"[mapped] \" + line)\n            .forEachOrdered(System.out::println);\n    }\n\n    public static void main(String[] args) {\n        BufferedReader reader = new BufferedReader(new InputStreamReader(System.in));\n        fillStreamMap(reader);\n    }\n}\n\n\nAnother approach is to operate at the Reader level, and read with a timeout from the BufferedReader (which presumably wraps System.in). Unfortunately, it's very hard to do this properly (see e.g. Set timeout for user's input, and the article Timeout on Console Input).\nOne idea from those linked pages is to poll BufferedReader.ready() until it returns true, and then call readLine(). This is ugly (because it uses polling) and unreliable, because readLine() can block even if ready() returned true \u2013 for example because an incomplete line is available (on Unix-like systems the user can achieve this by typing some text then pressing Ctrl+D instead of Enter).\nAnother idea is to create a background thread that repeatedly calls BufferedReader.readLine() and inserts the results into a BlockingQueue (such as ArrayBlockingQueue). Then the main thread can call take() or poll(timeout, unit) on the queue to obtain lines.\nA limitation of this approach is that if you later want to read from the BufferedReader directly (as opposed to through the queue), it's pretty much impossible to avoid losing (at least) one line of input. This is because a thread can't be interrupted cleanly when it's blocked on readLine(), so if the main thread decides to stop early (e.g. because of a timeout) it can't prevent the background thread from reading the line it is currently waiting for.\nYou could try to \"unread\" the last line using mark(readAheadLimit) and reset(), but synchronization will be difficult \u2013 another thread could try to read from the BufferedReader before the background thread calls reset(). You'd probably have to synchronize using the the lock field, however its access level is protected so you'd only be able to access it using reflection or by subclassing BufferedReader. Also, reset() will fail if the line to be unread is longer than readAheadLimit.\nHere is an implementation that assumes you only read lines via the queue.\nDISCLAIMER: Beware of bugs in these code snippets \u2013 multi-threading is tricky. I might try improve the code another time.\nimport java.io.BufferedReader;\nimport java.io.IOException;\nimport java.io.InputStreamReader;\nimport java.util.Optional;\nimport java.util.concurrent.ArrayBlockingQueue;\nimport java.util.concurrent.TimeUnit;\nimport java.util.function.Supplier;\nimport java.util.stream.Stream;\n\nclass InterruptibleLineReader {\n    private static final String EOF = new String(\"\");\n    BufferedReader reader;\n    ArrayBlockingQueue lines = new ArrayBlockingQueue(/* capacity: */ 2);\n    Thread backgroundThread;\n    IOException exception;\n\n    public InterruptibleLineReader(BufferedReader reader) {\n        this.reader = reader;\n        // start a background thread to read lines\n        backgroundThread = new Thread(this::backgroundTask);\n        backgroundThread.setDaemon(true);\n        backgroundThread.start();\n    }\n\n    public void close() {\n        backgroundThread.interrupt();\n        lines.clear();\n        lines.add(EOF);\n    }\n\n    private void backgroundTask() {\n        try {\n            try {\n                while (true) {\n                    String line = reader.readLine();\n                    if (Thread.interrupted()) {\n                        // nothing to do (close() is responsible for lines.put(EOF) etc. in this case)\n                        break;\n                    } else if (line == null) {\n                        lines.put(EOF);\n                        break;\n                    }\n                    lines.put(line);\n                }\n            } catch (IOException e) {\n                exception = e;\n                lines.put(EOF);\n            }\n        } catch (InterruptedException e) {\n            // nothing to do (close() is responsible for lines.put(EOF) etc. in this case)\n        }\n    }\n\n    public String readLine(long timeout, TimeUnit unit) throws IOException, InterruptedException {\n        String line = lines.poll(timeout, unit);\n        if (line == EOF) { // EOF or IOException\n            lines.put(EOF); // restore the EOF so that any concurrent (and future) calls to this method won't block\n            if (exception != null) {\n                throw exception;\n            } else {\n                return null;\n            }\n        }\n        return line;\n    }\n}\n\nclass Main {\n    static  Stream generateOrderedStream(Supplier> s) {\n        // Returns an ordered stream with the values of the Optionals returned by s.get(). An empty Optional ends the stream.\n        // As pseudocode:\n        //     for (Optional o = s.get(); o.isPresent(); o = s.get())\n        //         emit o.get();\n        return Stream.iterate(s.get(), Optional::isPresent, prev -> s.get())\n            .map(Optional::get);\n    }\n\n    static Stream timedReadLines(InterruptibleLineReader lineReader, long timeout, TimeUnit unit) {\n        // Reads lines until the timeout elapses and returns them as a stream.\n        final long deadlineNanos = System.nanoTime() + unit.toNanos(timeout);\n        return generateOrderedStream(() -> {\n            try {\n                long remainingNanos = deadlineNanos - System.nanoTime();\n                return Optional.ofNullable(lineReader.readLine(remainingNanos, TimeUnit.NANOSECONDS));\n            } catch (IOException|InterruptedException e) {\n                throw new RuntimeException(e);\n            }\n        });\n    }\n\n    static void fillStreamMap(InterruptibleLineReader lineReader) {\n        // streaming demo\n        long maxDurationSecs = 5;\n        timedReadLines(lineReader, maxDurationSecs, TimeUnit.SECONDS)\n            .takeWhile(line -> !line.contains(\"[stop]\"))\n            .map(line -> \"[mapped] \" + line)\n            .forEachOrdered(System.out::println);\n    }\n\n    public static void main(String[] args) {\n        BufferedReader reader = new BufferedReader(new InputStreamReader(System.in));\n\n        // stream lines\n        InterruptibleLineReader lineReader = new InterruptibleLineReader(reader);\n        fillStreamMap(lineReader);\n        lineReader.close();\n\n        /*\n        // attempt to use the BufferedReader directly\n        // NOTE: several lines may be lost (depending on the capacity of the ArrayBlockingQueue and how quickly the lines are consumed)\n        System.out.println(\"--- reading directly from BufferedReader ---\");\n        while (true) {\n            try {\n                String line = reader.readLine();\n                if (line == null) { break; }\n                System.out.println(\"[raw] \" + line);\n            } catch (IOException e) {\n                throw new RuntimeException(e);\n            }\n        }\n        */\n    }\n}\n\nHere is a more sophisticated implementation that only loses one line of input if you close the queue and read directly from the BufferedReader. It uses a custom \"0-capacity\" queue to ensure that at most one line will be lost.\nimport java.io.BufferedReader;\nimport java.io.IOException;\nimport java.io.InputStreamReader;\nimport java.util.NoSuchElementException;\nimport java.util.Optional;\nimport java.util.concurrent.TimeUnit;\nimport java.util.function.Supplier;\nimport java.util.stream.Stream;\n\nclass InterruptibleLineReader {\n    BufferedReader reader;\n    ZeroCapacityBlockingQueue lines = new ZeroCapacityBlockingQueue(); // a null line indicates EOF or IOException\n    Thread backgroundThread;\n    IOException exception;\n    boolean eof;\n\n    public InterruptibleLineReader(BufferedReader reader) {\n        this.reader = reader;\n        // start a background thread to read lines\n        backgroundThread = new Thread(this::backgroundTask);\n        backgroundThread.setDaemon(true);\n        backgroundThread.start();\n    }\n\n    private void markAsEOF() {\n        eof = true;\n        if (lines.poll() != null) { // markAsEOF() should not be called when there are unconsumed lines\n            throw new IllegalStateException();\n        }\n        lines.offer(null); // unblock threads that are waiting on the queue\n    }\n\n    public void close() {\n        backgroundThread.interrupt();\n        // warn if there is an unconsumed line, and consume it so we can indicate EOF\n        String line = lines.poll();\n        if (line != null) {\n            System.err.println(\"InterruptibleLineReader: warning: discarding unconsumed line during close(): '\" + line + \"'\");\n        }\n        markAsEOF();\n    }\n\n    private void backgroundTask() {\n        try {\n            while (true) {\n                String line = reader.readLine();\n                if (Thread.interrupted()) {\n                    if (line != null) {\n                        System.err.println(\"InterruptibleLineReader: warning: discarding line that was read after close(): '\" + line + \"'\");\n                    }\n                    // nothing further to do (close() is responsible for calling markAsEOF() in this case)\n                    break;\n                } else if (line == null) { // EOF\n                    markAsEOF();\n                    break;\n                }\n                lines.put(line); // this blocks until the line has been consumed (\"0-capacity\" behaviour)\n                if (Thread.interrupted()) {\n                    // nothing to do (close() is responsible for calling markAsEOF() in this case)\n                    break;\n                }\n            }\n        } catch (IOException e) {\n            exception = e;\n            markAsEOF();\n        } catch (InterruptedException e) {\n            // nothing to do (close() is responsible for calling markAsEOF() in this case)\n        }\n    }\n\n    public String readLine() throws IOException, InterruptedException {\n        String line = lines.take();\n        if (line == null) { // EOF or IOException\n            markAsEOF(); // restore the null so that any concurrent (and future) calls to this method won't block\n            if (exception != null) {\n                throw exception;\n            } else {\n                return null; // EOF\n            }\n        } else {\n            return line;\n        }\n    }\n\n    public String readLine(long timeout, TimeUnit unit) throws IOException, InterruptedException {\n        String line = lines.poll(timeout, unit);\n        if (line == null && eof) { // EOF or IOException (not timeout)\n            markAsEOF(); // restore the null so that any concurrent (and future) calls to this method won't block\n            if (exception != null) {\n                throw exception;\n            } else {\n                return null; // EOF\n            }\n        } else {\n            return line;\n        }\n    }\n}\n\nclass ZeroCapacityBlockingQueue {\n    int count;\n    T item;\n\n    public synchronized boolean add(T x) {\n        // does not block (i.e. behaves as if the capacity is actually 1)\n        if (count == 1) {\n            throw new IllegalStateException(\"Queue full\");\n        }\n        item = x;\n        count++;\n        notifyAll();\n        return true;\n    }\n\n    public synchronized boolean offer(T x) {\n        // does not block (i.e. behaves as if the capacity is actually 1)\n        if (count == 1) {\n            return false;\n        }\n        return add(x);\n    }\n\n    public synchronized void put(T x) throws InterruptedException {\n        // blocks until the item has been removed (\"0-capacity\" behaviour)\n        while (count == 1) {\n            wait();\n        }\n        add(x);\n        while (count == 1 && item == x) {\n            wait();\n        }\n    }\n\n    public synchronized T remove() {\n        if (count == 0) {\n            throw new NoSuchElementException();\n        }\n        T x = item;\n        item = null;\n        count--;\n        notifyAll();\n        return x;\n    }\n\n    public synchronized T poll() {\n        if (count == 0) {\n            return null;\n        }\n        return remove();\n    }\n\n    public synchronized T take() throws InterruptedException {\n        while (count == 0) {\n            wait();\n        }\n        return remove();\n    }\n\n    public synchronized T poll(long timeout, TimeUnit unit) throws InterruptedException {\n        long deadlineNanos = System.nanoTime() + unit.toNanos(timeout);\n        while (count == 0) {\n            long remainingNanos = deadlineNanos - System.nanoTime();\n            if (remainingNanos <= 0) {\n                return null;\n            }\n            TimeUnit.NANOSECONDS.timedWait(this, remainingNanos);\n        }\n        return remove();\n    }\n}\n\nclass Main {\n    static  Stream generateOrderedStream(Supplier> s) {\n        // Returns an ordered stream with the values of the Optionals returned by s.get(). An empty Optional ends the stream.\n        // As pseudocode:\n        //     for (Optional o = s.get(); o.isPresent(); o = s.get())\n        //         emit o.get();\n        return Stream.iterate(s.get(), Optional::isPresent, prev -> s.get())\n            .map(Optional::get);\n    }\n\n    static Stream timedReadLines(InterruptibleLineReader lineReader, long timeout, TimeUnit unit) {\n        // Reads lines until the timeout elapses and returns them as a stream.\n        final long deadlineNanos = System.nanoTime() + unit.toNanos(timeout);\n        return generateOrderedStream(() -> {\n            try {\n                long remainingNanos = deadlineNanos - System.nanoTime();\n                return Optional.ofNullable(lineReader.readLine(remainingNanos, TimeUnit.NANOSECONDS));\n            } catch (IOException|InterruptedException e) {\n                throw new RuntimeException(e);\n            }\n        });\n    }\n\n    static void fillStreamMap(InterruptibleLineReader lineReader) {\n        // streaming demo\n        long maxDurationSecs = 5;\n        timedReadLines(lineReader, maxDurationSecs, TimeUnit.SECONDS)\n            .takeWhile(line -> !line.contains(\"[stop]\"))\n            .map(line -> \"[mapped] \" + line)\n            .forEachOrdered(System.out::println);\n    }\n\n    public static void main(String[] args) {\n        BufferedReader reader = new BufferedReader(new InputStreamReader(System.in));\n\n        // stream lines\n        InterruptibleLineReader lineReader = new InterruptibleLineReader(reader);\n        fillStreamMap(lineReader);\n        lineReader.close();\n\n        /*\n        // attempt to use the BufferedReader directly\n        // NOTE: a line will be lost\n        System.out.println(\"--- reading directly from BufferedReader ---\");\n        while (true) {\n            try {\n                String line = reader.readLine();\n                if (line == null) { break; }\n                System.out.println(\"[raw] \" + line);\n            } catch (IOException e) {\n                throw new RuntimeException(e);\n            }\n        }\n        */\n    }\n}\n\nHere is an example run of the second implementation (with the last part of main() uncommented). The timestamps are in seconds and \">\" denotes input.\n0.06 --- streaming lines using InterruptibleLineReader for 5.0 sec  ---\n0.82 > one\n0.83 [mapped] one\n1.76 > two\n1.76 [mapped] two\n2.73 > three\n2.73 [mapped] three\n5.06 --- reading directly from BufferedReader ---\n6.93 > four\n6.94 InterruptibleLineReader: warning: discarding line that was read after close(): 'four'\n7.76 > five\n7.76 [raw] five\n8.60 > six\n8.60 [raw] six\n\nNote how the line \"four\" was lost. To avoid losing lines, don't use the underlying BufferedReader after the InterruptibleLineReader instance is created.\n(If you really need a BufferedReader after that point, you could write a dummy subclass of BufferedReader that wraps InterruptibleLineReader and forwards readLine() calls to it. The other BufferedReader methods, such as read() and mark(), can't be implemented easily.)\n"
}
{
    "Id": 71525731,
    "PostTypeId": 1,
    "Title": "java.lang.IllegalAccessError: class org.jetbrains.kotlin.kapt3.base.KaptContext Android",
    "Body": "I've been getting an error like this for days, but I couldn't find a solution. Can you please help me?\nWhat could the problem be caused by?\nError :\njava.lang.IllegalAccessError: class org.jetbrains.kotlin.kapt3.base.KaptContext (in unnamed module @0x6acdb135) cannot access class com.sun.tools.javac.util.Context (in module jdk.compiler) because module jdk.compiler does not export com.sun.tools.javac.util to unnamed module @0x6acdb135\n    at org.jetbrains.kotlin.kapt3.base.KaptContext.(KaptContext.kt:28)\n    at org.jetbrains.kotlin.kapt3.KaptContextForStubGeneration.(KaptContextForStubGeneration.kt:40)\n    at org.jetbrains.kotlin.kapt3.AbstractKapt3Extension.contextForStubGeneration(Kapt3Extension.kt:287)\n    at org.jetbrains.kotlin.kapt3.AbstractKapt3Extension.analysisCompleted(Kapt3Extension.kt:171)\n    at org.jetbrains.kotlin.kapt3.ClasspathBasedKapt3Extension.analysisCompleted(Kapt3Extension.kt:102)\n    at org.jetbrains.kotlin.cli.jvm.compiler.TopDownAnalyzerFacadeForJVM.analyzeFilesWithJavaIntegration$invokeExtensionsOnAnalysisComplete(TopDownAnalyzerFacadeForJVM.kt:112)\n    at org.jetbrains.kotlin.cli.jvm.compiler.TopDownAnalyzerFacadeForJVM.analyzeFilesWithJavaIntegration(TopDownAnalyzerFacadeForJVM.kt:122)\n    at org.jetbrains.kotlin.cli.jvm.compiler.TopDownAnalyzerFacadeForJVM.analyzeFilesWithJavaIntegration$default(TopDownAnalyzerFacadeForJVM.kt:86)\n    at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler$analyze$1.invoke(KotlinToJVMBytecodeCompiler.kt:252)\n    at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler$analyze$1.invoke(KotlinToJVMBytecodeCompiler.kt:243)\n    at org.jetbrains.kotlin.cli.common.messages.AnalyzerWithCompilerReport.analyzeAndReport(AnalyzerWithCompilerReport.kt:113)\n    at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler.analyze(KotlinToJVMBytecodeCompiler.kt:243)\n    at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler.compileModules$cli(KotlinToJVMBytecodeCompiler.kt:90)\n    at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler.compileModules$cli$default(KotlinToJVMBytecodeCompiler.kt:56)\n    at org.jetbrains.kotlin.cli.jvm.K2JVMCompiler.doExecute(K2JVMCompiler.kt:169)\n    at org.jetbrains.kotlin.cli.jvm.K2JVMCompiler.doExecute(K2JVMCompiler.kt:52)\n    at org.jetbrains.kotlin.cli.common.CLICompiler.execImpl(CLICompiler.kt:92)\n    at org.jetbrains.kotlin.cli.common.CLICompiler.execImpl(CLICompiler.kt:44)\n    at org.jetbrains.kotlin.cli.common.CLITool.exec(CLITool.kt:98)\n    at org.jetbrains.kotlin.incremental.IncrementalJvmCompilerRunner.runCompiler(IncrementalJvmCompilerRunner.kt:412)\n    at org.jetbrains.kotlin.incremental.IncrementalJvmCompilerRunner.runCompiler(IncrementalJvmCompilerRunner.kt:112)\n    at org.jetbrains.kotlin.incremental.IncrementalCompilerRunner.compileIncrementally(IncrementalCompilerRunner.kt:358)\n    at org.jetbrains.kotlin.incremental.IncrementalCompilerRunner.compileIncrementally$default(IncrementalCompilerRunner.kt:300)\n    at org.jetbrains.kotlin.incremental.IncrementalCompilerRunner.compileImpl$rebuild(IncrementalCompilerRunner.kt:119)\n    at org.jetbrains.kotlin.incremental.IncrementalCompilerRunner.compileImpl(IncrementalCompilerRunner.kt:170)\n    at org.jetbrains.kotlin.incremental.IncrementalCompilerRunner.compile(IncrementalCompilerRunner.kt:81)\n    at org.jetbrains.kotlin.daemon.CompileServiceImplBase.execIncrementalCompiler(CompileServiceImpl.kt:607)\n    at org.jetbrains.kotlin.daemon.CompileServiceImplBase.access$execIncrementalCompiler(CompileServiceImpl.kt:96)\n    at org.jetbrains.kotlin.daemon.CompileServiceImpl.compile(CompileServiceImpl.kt:1658)\n    at jdk.internal.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)\n    at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.base/java.lang.reflect.Method.invoke(Method.java:568)\n    at java.rmi/sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:360)\n    at java.rmi/sun.rmi.transport.Transport$1.run(Transport.java:200)\n    at java.rmi/sun.rmi.transport.Transport$1.run(Transport.java:197)\n    at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)\n    at java.rmi/sun.rmi.transport.Transport.serviceCall(Transport.java:196)\n    at java.rmi/sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:587)\n    at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:828)\n    at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:705)\n    at java.base/java.security.AccessController.doPrivileged(AccessController.java:399)\n    at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:704)\n    at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n    at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n    at java.base/java.lang.Thread.run(Thread.java:833)\n\n\nExecution failed for task ':app:kaptGenerateStubsMacellanDebugKotlin'.\n> Internal compiler error. See log for more details\n\n",
    "AcceptedAnswerId": 71527580,
    "AcceptedAnswer": "I found a solution and fixed this damn problem :D\nI recommend using, adding it to the root build.gradle. This will force using the given dependency in the whole project:\nbuild.gradle (Project)\nallprojects {\n    configurations.all {\n        resolutionStrategy {\n            force 'org.xerial:sqlite-jdbc:3.34.0'\n        }\n    }\n}\n\n"
}
{
    "Id": 71818173,
    "PostTypeId": 1,
    "Title": "How to handle NumberFormatException with Java StreamAPI",
    "Body": "Is there a way to filter out all values that are bigger than the max value that can be stored in a Long using Stream API?\nThe current situation is that you can search in the frontend with a simple search bar after some customers by using their ID.\nFor example: 123456789, 10987654321. If you put a \"separator\" between these two IDs, everything works. But if you forget the \"separator\" my code is trying to parse 12345678910987654321 into a Long and I guess there is the problem.\nThat causes a NumberFormatException after trying to search. Is there a way to filter these numbers out that can't be parsed into a Long because they are too big?\nString hyphen = \"-\";\n\nString[] customerIds = bulkCustomerIdProperty.getValue()\n              .replaceAll(\"[^0-9]\", hyphen)\n              .split(hyphen);\n...\ncustomerFilter.setCustomerIds(Arrays.asList(customerIds).stream()\n              .filter(n -> !n.isEmpty()) \n              .map(n -> Long.valueOf(n)) // convert to Long\n              .collect(Collectors.toSet()));\n\n",
    "AcceptedAnswerId": 71818306,
    "AcceptedAnswer": "You can either extract parsing into a separate method and wrap it with a try/catch, or use BigInteger to eliminate values that exceed the range of long.\nExample with BigInteger:\nSet result =  Stream.of(\"\", \"12345\", \"9999999999999999999999999999\")\n        .filter(n -> !n.isEmpty())\n        .map(BigInteger::new)\n        .filter(n -> n.compareTo(BigInteger.valueOf(Long.MAX_VALUE)) <= 0 &&\n                     n.compareTo(BigInteger.valueOf(Long.MIN_VALUE)) >= 0)\n        .map(BigInteger::longValueExact) // convert to Long\n        .peek(System.out::println) // printing the output\n        .collect(Collectors.toSet());\n\nExample with handling NumberFormatException in a separate method:\nSet result =  Stream.of(\"\", \"12345\", \"9999999999999999999999999999\")\n        .filter(n -> !n.isEmpty())\n        .map(n -> safeParse(n))\n        .filter(OptionalLong::isPresent)\n        .map(OptionalLong::getAsLong) // extracting long primitive and boxing it into Long\n        .peek(System.out::println) // printing the output\n        .collect(Collectors.toSet());\n\npublic static OptionalLong safeParse(String candidate) {\n    try {\n        return OptionalLong.of(Long.parseLong(candidate));\n    } catch (NumberFormatException e) {\n        return OptionalLong.empty();\n    }\n}\n\nOutput (from peek())\n12345\n\n"
}
{
    "Id": 71643702,
    "PostTypeId": 1,
    "Title": "Making sense of error message related to type inference when using a method reference",
    "Body": "I wanted to create a list of non-alphabetic characters from a string, so I wrote:\nstr.chars()\n        .mapToObj(c -> (char) c)\n        .filter(Predicate.not(Character::isAlphabetic))\n        .toList();\n\nHowever this throws the following error message:\n\nno instance(s) of type variable(s) exist so that Character conforms to\nInteger inference variable T has incompatible bounds: equality\nconstraints: Integer lower bounds: Character\n\nI didn't fully understand the error message, but I figured that it is caused by Character#isAlphabetic taking in int codePoint as a parameter instead of a char because replacing Character::isAlphabetic with Character::isUpperCase (for example) which takes in a char works fine.\nNow, if I write:\nstr.chars()\n        .mapToObj(c -> (char) c)\n        .filter(c -> !Character.isAlphabetic(c))\n        .toList();\n\nit compiles just fine, and I'm not even that surprised/confused. However, if I write\nstr.chars()\n        .mapToObj(c -> (char) c)\n        .filter(Predicate.not(c -> Character.isAlphabetic(c)))\n        .toList();\n\nit also compiles just fine, which definitely confuses me because isn't Character::isAlphabetic basically equivalent to c -> Character.isAlphabetic(c)? Well, apparently it isn't in all cases (because AFAIK it is in most)\nSo my 2 questions are:\n\nWhat exactly is this error message saying? I do understand it to an extent but definitely not completely\nWhy does the first version not work but the third does?\n\n",
    "AcceptedAnswerId": 71648220,
    "AcceptedAnswer": "The difference between Character::isAlphabetic and c -> Character.isAlphabetic(c) is that since Character.isAlphabetic(int) is not an overloaded method, the former is an exact method reference whereas the latter is an implicitly typed lambda expression.\nWe can show that an inexact method reference is accepted the same way as an implicitly typed lambda expression:\nclass SO71643702 {\n    public static void main(String[] args) {\n        String str = \"123abc456def\";\n        List l = str.chars()\n            .mapToObj(c -> (char) c)\n            .filter(Predicate.not(SO71643702::isAlphabetic))\n            .toList();\n        System.out.println(l);\n    }\n\n    public static boolean isAlphabetic(int codePoint) {\n        return Character.isAlphabetic(codePoint);\n    }\n\n    public static boolean isAlphabetic(Thread t) {\n      throw new AssertionError(\"compiler should never choose this method\");\n    }\n}\n\nThis is accepted by the compiler.\nHowever, this doesn\u2019t imply that this behavior is correct. Exact method references may help in overload selection where inexact do not, as specified by \u00a715.12.2.:\n\nCertain argument expressions that contain implicitly typed lambda expressions (\u00a715.27.1) or inexact method references (\u00a715.13.1) are ignored by the applicability tests, because their meaning cannot be determined until the invocation's target type is selected.\n\nIn contrast, when it comes to the 15.13.2. Type of a Method Reference, there is no difference between exact and inexact method references mentioned. Only the target type determines the actual type of the method reference (assuming that the target type is a functional interface and the method reference is congruent).\nConsequently, the following works without problems:\nclass SO71643702 {\n    public static void main(String[] args) {\n        String str = \"123abc456def\";\n        List l = str.chars()\n            .mapToObj(c -> (char) c)\n            .filter(Character::isAlphabetic)\n            .toList();\n        System.out.println(l);\n    }\n}\n\nOf course, that\u2019s not the original program logic\nHere, Character::isAlphabetic still is an exact method reference, but it\u2019s congruent with the target type Predicate, so it works not different to\nPredicate p = Character::isAlphabetic;\n\nor\nPredicate p = (Character c) -> Character.isAlphabetic(c);\n\nIt\u2019s not as if the insertion of a generic method into nesting of method invocations will stop the type inference from working in general. As discussed in this answer to a similar fragile type inference issue, we can insert a generic method not contributing to the resulting type without problems:\nclass SO71643702 {\n    static  X dummy(X x) { return x; }\n\n    public static void main(String[] args) {\n        String str = \"123abc456def\";\n        List l = str.chars()\n            .mapToObj(c -> (char) c)\n            .filter(dummy(Character::isAlphabetic))\n            .toList();\n        System.out.println(l);\n    }\n}\n\nand even \u201cfix\u201d the problem of the original code by inserting the method\nclass SO71643702 {\n    static  X dummy(X x) { return x; }\n\n    public static void main(String[] args) {\n        String str = \"123abc456def\";\n        List l = str.chars()\n            .mapToObj(c -> (char) c)\n            .filter(Predicate.not(dummy(Character::isAlphabetic)))\n            .toList();\n        System.out.println(l);\n    }\n}\n\nIt\u2019s important that there is no subtype relationship between Predicate and Predicate, so the dummy method can not translate between them. It\u2019s just returning exactly the same type as the compiler inferred for its argument.\nI consider the compiler error a bug, but as I said at the other answer, even if the specification backs up this behavior, it should get corrected, in my opinion.\n\nAs a side note, for this specific example, I\u2019d use\nvar l = str.chars()\n    .filter(c -> !Character.isAlphabetic(c))\n    .mapToObj(c -> (char)c)\n    .toList();\n\nanyway, as this way, you\u2019re not boxing int values to Character objects, just to unbox them to int again in the predicate, but rather, only box values after passing the filter.\n"
}
{
    "Id": 72300024,
    "PostTypeId": 1,
    "Title": "Does the use of Spring Webflux's WebClient in a blocking application design cause a larger use of resources than RestTemplate",
    "Body": "I am working on several spring-boot applications which have the traditional pattern of thread-per-request. We are using Spring-boot-webflux to acquire WebClient to perform our RESTful integration between the applications. Hence our application design requires that we block the publisher right after receiving a response.\nRecently, we've been discussing whether we are unnecessarily spending resources using a reactive module in our otherwise blocking application design. As I've understood it, WebClient makes use of the event loop by assigning a worker thread to perform the reactive actions in the event loop. So using webclient with .block() would sleep the original thread while assigning another thread to perform the http-request. Compared to the alternative RestTemplate, it seems like WebClient would spend additional resources by using the event loop.\nIs it correct that partially introducing spring-webflux in this way leads to additional spent resources while not yielding any positive contribution to performance, neither single threaded and concurrent? We are not expecting to ever upgrade our current stack to be fully reactive, so the argument of gradually upgrading does not apply.\n",
    "AcceptedAnswerId": 72311944,
    "AcceptedAnswer": "In this presentation Rossen Stoyanchev from the Spring team explains some of these points.\nWebClient will use a limited number of threads - 2 per core for a total of 12 threads on my local machine - to handle all requests and their responses in the application. So if your application receives 100 requests and makes one request to an external server for each, WebClient will handle all of those using those threads in a non-blocking / asynchronous manner.\nOf course, as you mention, once you call block your original thread will block, so it would be 100 threads + 12 threads for a total of 112 threads to handle those requests. But keep in mind that these 12 threads do not grow in size as you make more requests, and that they don't do I/O heavy lifting, so it's not like WebClient is spawning threads to actually perform the requests or keeping them busy on a thread-per-request fashion.\nI'm not sure if when the thread is under block it behaves the same as when making a blocking call through RestTemplate - it seems to me that in the former the thread should be inactive waiting for the NIO call to complete, while in the later the thread should be handling I/O work, so maybe there's a difference there.\nIt gets interesting if you begin using the reactor goodies, for example handling requests that depend on one another, or many requests in parallel. Then WebClient definitely gets an edge as it'll perform all concurrent actions using the same 12 threads, instead of using a thread per request.\nAs an example, consider this application:\n@SpringBootApplication\npublic class SO72300024 {\n\n    private static final Logger logger = LoggerFactory.getLogger(SO72300024.class);\n\n    public static void main(String[] args) {\n        SpringApplication.run(SO72300024.class, args);\n    }\n\n    @RestController\n    @RequestMapping(\"/blocking\")\n    static class BlockingController {\n\n        @GetMapping(\"/{id}\")\n        String blockingEndpoint(@PathVariable String id) throws Exception {\n            logger.info(\"Got request for {}\", id);\n            Thread.sleep(1000);\n            return \"This is the response for \" + id;\n        }\n\n        @GetMapping(\"/{id}/nested\")\n        String nestedBlockingEndpoint(@PathVariable String id) throws Exception {\n            logger.info(\"Got nested request for {}\", id);\n            Thread.sleep(1000);\n            return \"This is the nested response for \" + id;\n        }\n\n    }\n\n    @Bean\n    ApplicationRunner run() {\n        return args -> {\n            Flux.just(callApi(), callApi(), callApi())\n                    .flatMap(responseMono -> responseMono)\n                    .collectList()\n                    .block()\n                    .stream()\n                    .flatMap(Collection::stream)\n                    .forEach(logger::info);\n            logger.info(\"Finished\");\n        };\n    }\n\n    private Mono> callApi() {\n        WebClient webClient = WebClient.create(\"http://localhost:8080\");\n        logger.info(\"Starting\");\n        return Flux.range(1, 10).flatMap(i ->\n                        webClient\n                                .get().uri(\"/blocking/{id}\", i)\n                                .retrieve()\n                                .bodyToMono(String.class)\n                                .doOnNext(resp -> logger.info(\"Received response {} - {}\", I, resp))\n                                .flatMap(resp -> webClient.get().uri(\"/blocking/{id}/nested\", i)\n                                        .retrieve()\n                                        .bodyToMono(String.class)\n                                        .doOnNext(nestedResp -> logger.info(\"Received nested response {} - {}\", I, nestedResp))))\n                .collectList();\n    }\n}\n\nIf you run this app, you can see that all 30 requests are handled immediately in parallel by the same 12 (in my computer) threads. Neat! If you think you can benefit from such kind of parallelism in your logic, it's probably worth it giving WebClient a shot.\nIf not, while I wouldn't actually worry about the \"extra resource spending\" given the reasons above, I don't think it would be worth it adding the whole reactor/webflux dependency for this - besides the extra baggage, in day to day operations it should be a lot simpler to reason about and debug RestTemplate and the thread-per-request model.\nOf course, as others have mentioned, you ought to run load tests to have proper metrics.\n"
}
{
    "Id": 71884469,
    "PostTypeId": 1,
    "Title": "Unable to find /oauth/device/code Auth0 Java API",
    "Body": "Is there an API to fetch the device code via Auth0 Java API, we use the following snippet in Go, the question is if there is a standard API or should we make a HTTP request call\nurl := \"https://dev-foo.us.auth0.com/oauth/device/code\"\n\npayload := strings.NewReader(\"client_id=RO6N7mr&scope=openid&audience=https://dev-foo.us.auth0.com/api/v2/\")\n\nreq, _ := http.NewRequest(\"POST\", url, payload)\n\n",
    "AcceptedAnswerId": 71909729,
    "AcceptedAnswer": "The documentation tells you that you need to send a POST request like the following:\n\nPOST https://YOUR_DOMAIN/oauth/device/code\n\n\nContent-Type:\n\n\napplication/x-www-form-urlencoded\nclient_id=YOUR_CLIENT_ID&scope=SCOPE&audience=API_IDENTIFIER\n\nand the response would look like\nHTTP/1.1 200 OK\nContent-Type: application/json\n{\n  \"device_code\":\"GmRh...k9eS\",\n  \"user_code\":\"WDJB-MJHT\",\n  \"verification_uri\":\"https://YOUR_DOMAIN/device\",\n  \"verification_uri_complete\":\"https://YOUR_DOMAIN/device?user_code=WDJB-MJHT\",\n  \"expires_in\":900, //in seconds\n  \"interval\":5\n}\n\n\n"
}
{
    "Id": 72401149,
    "PostTypeId": 1,
    "Title": "limit set by 'FEATURE_SECURE_PROCESSING'",
    "Body": "I used my own xlst transformator in java (XSLTTransformator) but transformation is very big and I have got error:\nCaused by: javax.xml.transform.TransformerConfigurationException: JAXP0801002: the compiler encountered an XPath expression containing '107' operators that exceeds the '100' limit set by 'FEATURE_SECURE_PROCESSING'.\n                at com.sun.org.apache.xalan.internal.xsltc.trax.TransformerFactoryImpl.newTemplates(TransformerFactoryImpl.java:990)\n                at com.aspp.dms.ruleengine.transformation.TemplatesCache.retrieveUncached(TemplatesCache.java:44)\n                at com.aspp.dms.ruleengine.transformation.TemplatesCache.retrieveUncached(TemplatesCache.java:21)\n                at com.gratex.java.util.SoftValueCache.get(SoftValueCache.java:41)\n                at com.aspp.dms.ruleengine.transformation.XSLTTransformator.transform(XSLTTransformator.java:73)\n\nCan you please help me find correct argument for java to solve my problem? Something like -DxpathOperatorsLimit=150\nthank you\n",
    "AcceptedAnswerId": 72833393,
    "AcceptedAnswer": "That behaviour seems to come from new FEATURE_SECURE_PROCESSING, which Oracle introduced in a recent \"update\" of their Java. See: https://www.oracle.com/java/technologies/javase/11-0-15-relnotes.html\nIt is 3 parameters they introduced:\n\njdk.xml.xpathExprGrpLimit Description: Limits the number of groups\nan XPath expression can contain. Default 10.\njdk.xml.xpathExprOpLimit Description: Limits the number of operators\nan XPath expression can contain. Default 100.\njdk.xml.xpathTotalOpLimit Description: Limits the total number of\nXPath operators in an XSL Stylesheet. Default 10000.\n\nYour problem is on #2 (JAXP0801002, default 100).\nWe got a very similar issue on #3 (JAXP0801003, default 10.000), with this message (quoted, so google will find it):\nERROR:  'JAXP0801003: the compiler encountered XPath expressions with an accumulated '10.002' operators that exceeds the '10.000' limit set by 'FEATURE_SECURE_PROCESSING'.'\nFATAL ERROR:  'JAXP0801003: the compiler encountered XPath expressions with an accumulated '10.002' operators that exceeds the '10.000' limit set by 'FEATURE_SECURE_PROCESSING'.'\n\nWe wasted 2 days in getting away of that sh*t.\nWe added some parameters to the java call:\n    java -Djdk.xml.xpathExprGrpLimit=0 -Djdk.xml.xpathExprOpLimit=0 -Djdk.xml.xpathTotalOpLimit=0 -Xmx2g -Xms512m -XX:-UseGCOverheadLimit ....\n\n\nParameters 1,2,3 to to solve the issue. Values \"0\" set the limits to \"off\". As XPath can now get huge, it might be advisable to set the heap and stack size and change behaviour of the garbage collection (parameters 4-6).\nI hope it will help you too. Have fun!\n"
}
{
    "Id": 72388741,
    "PostTypeId": 1,
    "Title": "Android manifest POST_NOTIFICATIONS missing import",
    "Body": "Trying to implement the notification permission for android 13 or \"Tiramisu\" but failed to get the import for that permission.\nCurrently:\ntargeted SDK version is 32\ncompile SDK version is 32\nI've declared it also in manifiest as below:\n <uses-permission android:name=\"android.permission.POST_NOTIFICATIONS\"\n\nimport i'm using:\nimport android.Manifest\n\n\nBut even not getting import in my fragment.\n\n\n",
    "AcceptedAnswerId": 72390497,
    "AcceptedAnswer": "     android {\n     namespace 'com.example.myapplication'\n    compileSdkVersion 33//update this\n\n     defaultConfig {\n        applicationId \"com.example.myapplication\"\n        minSdk 23\n        targetSdkVersion 33//update this\n        versionCode 1\n        versionName \"1.0\"\n        \n        testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\"\n    }\n\n"
}
{
    "Id": 72025894,
    "PostTypeId": 1,
    "Title": "List differences: DTO, VO, Entity, Domain, Model",
    "Body": "Now I study about the Spring Boot that with JAVA platform.\nA problem I faced is how can you tell the difference between DTO, VO, Entity, Domain, and Model.\nHonestly it all look too similar to tell the difference.\nI already checked some stackoverflow answers about \"Difference between DTO and VO\" and something like that.\nHowever, I am still wondering how do they different each other in terms of developer with Spring Boot.\n",
    "AcceptedAnswerId": 72027443,
    "AcceptedAnswer": "\nEntity - is a class with an ID. In the case of relational DB it's usually a class that's mapped to a DB table with some primary key.\nDTO (Data Transfer Object) - is a class that maps well on what you're sending over the network. E.g. if you exchange JSON or XML data, it usually has fields just enough to fill those requests/responses. Note, that it may have fewer or more fields than Entity.\nVO (Value Object) is a class-value. E.g. you could create class like Grams or Money - it will contain some primitives (e.g. some double value) and it's possible to compare Value Objects using these primitives. They don't have a database ID. They help replacing primitives with more object-oriented classes related to our particular domain.\nDomain Model contains all Entities and Value Objects. And some other types of classes depending on the classification you use.\n\nIn order to get acquainted with these you should read:\n\nEnterprise Application Patterns by Fowler. Mentions Value Object and Domain Model.\nDomain Driven Design by Eric Evans. Mentions Entity, Value Object and Domain Model.\nAnd maybe get acquainted with Java EE design patterns. They mention DTO. But these are pretty badly written articles (if they are still even available on the internet). Confusingly, they also had Value Object which was defined very similarly to DTO, but no one uses that definition of VO.\n\n"
}
{
    "Id": 71810594,
    "PostTypeId": 1,
    "Title": "Spring Boot 2.6.4 -> 2.6.6 : strange NullPointerException within Logback when logging a mock Exception",
    "Body": "while upgrading from Spring Boot 2.6.4 to 2.6.6 , one of my tests (written in Kotlin), fails :\n    @Test\n    fun shouldLogProperMessageIfNotAbleToHitAPI() {\n\n        val configValidator = ConfigValidator(GitHubCrawlerProperties(SourceControlConfig(url = \"someIncorrectURL\",organizationName=\"someOrg\")),mockRemoteSourceControl)\n\n        `when`(mockRemoteSourceControl.validateRemoteConfig(\"someOrg\")).thenThrow(NoReachableRepositories(\"problem !\",mock(Exception::class.java)))\n\n        val validationErrors=configValidator.getValidationErrors()\n\n        assertThat(validationErrors).hasSize(1);\n\n    }\n\n\nthe build passes with Spring Boot 2.6.4. It works in Spring Boot 2.6.6 when I run the test individually in my IDE, but fails during the maven build.\nthe stacktrace was not showing by default, but after surrounding the call by a try/catch, I am able to get it, and it points to Logback :\njava.lang.NullPointerException: null\n        at ch.qos.logback.classic.spi.ThrowableProxy.(ThrowableProxy.java:99)\n        at ch.qos.logback.classic.spi.ThrowableProxy.(ThrowableProxy.java:89)\n        at ch.qos.logback.classic.spi.ThrowableProxy.(ThrowableProxy.java:62)\n        at ch.qos.logback.classic.spi.LoggingEvent.(LoggingEvent.java:119)\n        at ch.qos.logback.classic.Logger.buildLoggingEventAndAppend(Logger.java:419)\n        at ch.qos.logback.classic.Logger.filterAndLog_0_Or3Plus(Logger.java:383)\n        at ch.qos.logback.classic.Logger.error(Logger.java:538)\n        at com.societegenerale.githubcrawler.ConfigValidator.getValidationErrors(ConfigValidator.kt:48)\n\nLogback version doesn't seem to change, I still get v 1.2.11 .\nLooking at Logback source code, in ThrowableProxy :\n        if (GET_SUPPRESSED_METHOD != null) {\n            // this will only execute on Java 7\n            Throwable[] throwableSuppressed = extractSupressedThrowables(throwable);\n            \n            if (throwableSuppressed.length > 0) {\n                List suppressedList = new ArrayList(throwableSuppressed.length);\n                for (Throwable sup : throwableSuppressed) {\n...\n\nnote : I build with Java 11, so the comment saying in Logback source code that this will only execute on Java 7 , seems wrong.\nIt seems that throwableSuppressed is null, and I get the NPE when throwableSuppressed.size is called.\nThe test passes if instead of using a mock in NoReachableRepositories(\"problem !\",mock(Exception::class.java)) , I use NoReachableRepositories(\"problem !\",Exception())\nI realize it's probably better to use a real Exception rather than a mock, so my problem is solved in a way (after spending 2 hours on this..).\nHowever, I am curious : what could cause this issue after upgrading to Spring Boot 2.6.6 which should be a a minor change ?\n",
    "AcceptedAnswerId": 71823439,
    "AcceptedAnswer": "This issue was introduced in logback:1.2.11 by this commit. It is tracked in this Jira ticket.\nLogback was upgraded to 1.2.11 from spring boot 2.6.5, you can refer to this changelog. So you would have encountered this same error if you upgraded to 2.6.5.\nWhat we can do now is override the version of logback to 1.2.10 by adding this line in build.gradle file.\next[\"logback.version\"] = \"1.2.10\"\n\nIf you're using Maven dependencyManagement section for Spring Boot dependencies instead of the starter parent then you can try this:\n\n\n  \n    \n    \n      ch.qos.logback\n      logback-access\n      1.2.10\n    \n    \n      ch.qos.logback\n      logback-classic\n      1.2.10\n    \n    \n      ch.qos.logback\n      logback-core\n      1.2.10\n    \n\n    \n      org.springframework.boot\n      spring-boot-dependencies\n      2.7.5\n      pom\n      import\n    \n\n\n\nUpdate: Spring Boot 2 latest version (2.7.5) is still using logback:1.2.11.\n"
}
{
    "Id": 72598626,
    "PostTypeId": 1,
    "Title": "Official recommendation / coding style guide on using multiple @throws tags for the same exception in JavaDoc",
    "Body": "I just recently found out that one can use multiple @throws tags for the same exception in Javadoc.\nOne of my students used it to document one of his methods in Connect Four:\n/*\n * ...\n * @throws IllegalArgumentException if the number of rows or columns is invalid \n * @throws IllegalArgumentException if one of the players has {@link Stone#None} as stone\n * @throws IllegalStateException if both players use the same stone color\n */\npublic void doSomething(...) { ... }\n\nNow my (and his) question: Is there an official style guide or a general recommendation on whether to use a single @throws tag or \"is it fine\" to use multiple ones per exception type?\n",
    "AcceptedAnswerId": 72600530,
    "AcceptedAnswer": "There is an Oracle style guide for javadocs:\n\nHow to Write Doc Comments for the Javadoc Tool.\n\nWhether that counts as \"official\" depends on your point of view.  Either way, I cannot see any mention in that document of multiple tags for the same exception.\nHowever, according to the following Q&A, multiple @throws tags for the same exception is supported by the standard Javadoc tool chain; i.e. each of them will result in an entry in the generated HTML.\n\nCan I use multiple @throws tags for the same exception in Javadoc?\n\n(My personal opinion is the javadocs will be more readable if you don't do this, but that is just my opinion.)\n"
}
{
    "Id": 73163378,
    "PostTypeId": 1,
    "Title": "\"Suspicious assignment in copy constructor\" for byte[] - What is suspicious?",
    "Body": "I have a copy constructor for class, but Android Studio code inspection throws a warning I don't understand:\n\nSuspicious assignment in copy constructor of\n'java.util.Arrays.copyOf(other.value, other.value.length)' to field\nvalue\n\npublic class CpuVariable extends BaseIdentifier {\n    private int memoryType;\n    private byte[] value;\n\n    public CpuVariable(@NonNull CpuVariable other) {\n        super(other);\n        this.memoryType = other.memoryType;\n        if (other.value != null) {\n            this.value = java.util.Arrays.copyOf(other.value, other.value.length);\n        }\n    }\n}\n\nChanging code to\nthis.value = other.value\n\nwould remove the warning, but this is not an option since I need to create a deep copy or a clone for the field.\nAm I coding something wrong or is it safe to ignore or suppress the warning?\n",
    "AcceptedAnswerId": 73163884,
    "AcceptedAnswer": "It is clearly a false positive.  There is nothing actually wrong with your constructor.\nI think that the code that produced this warning is based on this code.  Note that this is not the real Android Studio code, but there are clues to suggest that Android Studio may have \"borrowed\" it via some path.\nIf you look at the constructorAssignsAllFields method (line 63), the intent of the code seems to be to look for code bugs where a copy constructor is copying the wrong fields; e.g. something like this:\nMyClass(MyClass other) {\n   this.x = other.x;\n   this.y = other.x; // Ooops\n}\n\nBut the method is not correctly dealing with the case where the copy constructor is transforming one of the fields.\nLooking at the code, you need to write this.value =  in a way that makes the checker not realize that it is assigning to a field.  For example, if you used a setter method something like this:\npublic CpuVariable(@NonNull CpuVariable other) {\n    super(other);\n    this.memoryType = other.memoryType;\n    this.value = other.value;  // Dummy\n    if (other.value != null) {\n        this.setValue(java.util.Arrays.copyOf(other.value, other.value.length));\n    }\n}\n\n"
}
{
    "Id": 72089617,
    "PostTypeId": 1,
    "Title": "How to write a method that takes in a List of Integer, Float, Double and calculate the average?",
    "Body": "I am trying to write a method that takes in a list of numeric values - eg List, List, List etc - and give me the average.\npublic double getAverage(List stats) {\n    double sum = 0.00;\n    if(!stats.isEmpty()) {\n        // sum = stats.stream()\n        //            .reduce(0, (a, b) -> a + b);\n        // return sum / stats.size();\n    }\n}\n\nThese are the errors I get:\n\nOperator '+' cannot be applied to 'capture', 'capture'\n\n",
    "AcceptedAnswerId": 72089958,
    "AcceptedAnswer": "\nOptionalDouble average()\nWhere, OptionalDouble is a container object  which may or may not\ncontain a double value.\n\n  public class Test {\n\n    public static OptionalDouble getAverage(List stats) {\n        return stats.\n                stream().\n                 mapToDouble(d -> d.doubleValue()).\n                    average();\n            \n    }\n    \n    public static void main(String[] args) throws IOException {\n\n        List list = Arrays.asList(1, 4, 5, 67, 3);\n        if(getAverage(list).isPresent());\n        {\n            Double average = getAverage(list).getAsDouble();\n            System.out.println(average);\n        }\n        \n    }\n}\n\nor\nUsing Goolge Guava\n Double averge = Stats.meanOf(list);\n\n      \n\nit gets syntactically simplified\n"
}
{
    "Id": 71737495,
    "PostTypeId": 1,
    "Title": "Getting the oracle database host name at runtime",
    "Body": "There is a Springboot application which connects to the Oracle data. The URL for the database is configured as\nspring.datasource.url=jdbc:oracle:thin:@(DESCRIPTION=\\\n  (LOAD_BALANCE=OFF)(FAILOVER=ON)\\\n  (ADDRESS=(PROTOCOL=TCP)(HOST=domainName1.com) (PORT=1521))\\\n  (ADDRESS=(PROTOCOL=TCP)(HOST=domainName2.com)(PORT=1521))\\\n  (CONNECT_DATA=(SERVICE_NAME=xyz)))\n\nThis URL is configured so that when one host is down then the application connects to second database.\nThe URL to the database is printed in the application healthcheck as shown below\nHello \nversion    : 4.0.0\nbuild      : 2022-03-3 \ndatasource :    oracle.jdbc.OracleDriver\ndb url     :    jdbc:oracle:thin:@(DESCRIPTION=(LOAD_BALANCE=OFF)(FAILOVER=ON)(ADDRESS=(PROTOCOL=TCP)(HOST=domainName1.com) (PORT=1521))(ADDRESS=(PROTOCOL=TCP)(HOST=domainName2.com)(PORT=1521))(CONNECT_DATA=(SERVICE_NAME=xyz)))\ndb status  :    ok \n\nMy question is how can I get just the host name of the database being used, that means how can I get the host currently being used (domainName1 or domainName2) by the application and display it on healthcheck? For example as shown below.\nHello \nversion    : 4.0.0\nbuild      : 2022-03-3\ndatasource :    oracle.jdbc.OracleDriver\ndb url     :    jdbc:oracle:thin:@domainName1.com: 1521/coldv1\ndb status  :    ok (LVZ count = 379)\n\nThe java code I used for this healthcheck is as shown below.\n@GetMapping(path = \"/healthcheck\",\n            produces = MediaType.APPLICATION_JSON_VALUE\n    )\n    public String getServiceStatus(){\n        String[] activeProfiles = environment.getActiveProfiles();\n        final BeanWrapper accessor = PropertyAccessorFactory.forBeanPropertyAccess(dataSource);\n        final String driverClassName = String.valueOf(accessor.getPropertyValue(\"driverClassName\"));\n        String url = null;\n\n        if(activeProfiles[1].equals(\"external_tomcat\")) {\n            url = String.valueOf(accessor.getPropertyValue(\"url\"));\n        }else{\n            try {\n                String[] dataSourceProperties = nameService.getDataSource();\n                url = dataSourceProperties[0];\n            } catch (SQLException ex) {\n//                throwables.printStackTrace();\n                log.error(ex.getMessage(), ex);\n            }\n        }\n\n        String version = buildProperties.getVersion();\n        String buildTimestamp = String.valueOf(buildProperties.getTime());\n        BigDecimal count = nameService.getCount(\"Table_name_of_database\");\n\n        StringBuilder result = new StringBuilder(\"Hello\")\n                .append(\"\\nversion    :\\t\")\n                .append(version)\n                .append(\"\\nbuild      :\\t\")\n                .append(buildTimestamp)\n                .append(\"\\ndatasource :\\t\")\n                .append(driverClassName)\n                .append(\"\\ndb url     :\\t\")\n                .append(url)\n                .append(\"\\ndb status  :\\tok  \")\n                .append(count.intValue())\n                .append(\")\");\n        return result.toString();\n    }\n\nNameService.java\n @Override\n    public String[] getDataSource() throws SQLException {\n        return getDataSourceProperties();\n    }\n\n\n   \n\n    public String[] getDataSourceProperties() {\n        String[] dataSourceProperties = new String[2];\n        HikariDataSource dataSource = getDataSourceFromHibernateEntityManager();\n        if(dataSource.getJdbcUrl() != null){\n            dataSourceProperties[0] = dataSource.getJdbcUrl();\n            dataSourceProperties[1] = dataSource.getDataSourceClassName();\n        }\n        return dataSourceProperties;\n    }\n\n",
    "AcceptedAnswerId": 71841619,
    "AcceptedAnswer": "@Olivier and @ik_zelf both answers works for me.\nAnd the way I implemented in spring boot application is using the following code snippet.\npublic String getHostNameFromUrl() {\n        String sql = \"SELECT host_name FROM v$instance\";\n//        String sql = \"SELECT sys_context('USERENV','SERVER_HOST') server_host FROM dual\"; this also works\n        Query query = entityManager.createNativeQuery(sql);\n        return query.getSingleResult().toString();\n}\n\nand later in the controller I call this method to display in the healthcheck.\n"
}
{
    "Id": 71737901,
    "PostTypeId": 1,
    "Title": "How to upgrade spring framework version in spring boot",
    "Body": "I am using spring-boot 2.3.3.RELEASE with the according spring-boot-starter-parent in maven.\n\n   org.springframework.boot\n   spring-boot-starter-parent\n   2.3.3.RELEASE\n    \n \n\nDue to the spring4shell CVE I wanted to upgrade the spring-framework to 5.2.20.RELEASE instead of the already included 5.2.8.RELEASE. I tried overriding the spring-framework.version property from spring-boot-dependencies.\n    5.2.20.RELEASE\n\nBut it did not work. I also looked up the spring-boot-starter-web-2.3.3.RELEASE.pom and it has the spring-web dependency hardcoded to 5.2.8.RELEASE.\nAre there any other ways of upgrading the spring-framework version in spring-boot besides  adding all the new versions as dependencies to the dependencyManagement section?\nThx\nFull POM:\n\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" \n  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 \n  http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n4.0.0\n\n\n  org.springframework.boot\n  spring-boot-starter-parent\n  2.3.3.RELEASE\n   \n\n\ngroup\napp\n3.1.0-SNAPSHOT\nwar\n\n\n  4.1.2\n  2.4.20\n  5.2.20.RELEASE\n  Hoxton.SR7\n  1.4.196\n\n\n\n\n\n  \n    org.springframework.cloud\n    spring-cloud-dependencies\n    ${spring-cloud.version}\n    pom\n    import\n  \n\n\n\n\n\n\n\n  org.springframework.boot\n  spring-boot-starter-actuator\n\n\n\n  org.springframework.boot\n  spring-boot-starter-jdbc\n\n\n\n  org.springframework.boot\n  spring-boot-starter-data-rest\n\n\n\n  org.springframework.boot\n  spring-boot-starter-webflux\n\n\n\n  org.springframework.boot\n  spring-boot-starter-web\n\n\n\n  org.springframework.boot\n  spring-boot-starter-test\n  test\n\n\n\n  org.springframework.boot\n  spring-boot-starter-tomcat\n  provided\n\n\n\n  org.springframework.boot\n  spring-boot-configuration-processor\n  true\n\n\n\n  org.mockito\n  mockito-core\n\n\n\n\n  org.codehaus.groovy\n  groovy-all\n  ${groovy.version}\n\n\n\n\n  com.fasterxml.jackson.dataformat\n  jackson-dataformat-xml\n\n\n\n\napp\n\n  \n    src/main/resources\n    true\n    \n      **/version.json\n      **/**.properties\n    \n  \n\n  \n    src/main/resources\n    false\n    \n      **/*.*\n    \n    \n      **/version.json\n      **/**.properties\n    \n  \n\n\n\n\nEDIT:\nThis is a part of mvn dependency:tree:\n+- org.springframework.boot:spring-boot-starter-webflux:jar:2.3.3.RELEASE:compile\n[INFO] |  +- org.springframework.boot:spring-boot-starter-json:jar:2.3.3.RELEASE:compile\n[INFO] |  |  +- com.fasterxml.jackson.datatype:jackson-datatype-jdk8:jar:2.11.2:compile\n[INFO] |  |  \\- com.fasterxml.jackson.module:jackson-module-parameter-names:jar:2.11.2:compile\n[INFO] |  +- org.springframework.boot:spring-boot-starter-reactor-netty:jar:2.3.3.RELEASE:compile\n[INFO] |  +- org.springframework:spring-web:jar:5.2.8.RELEASE:compile\n[INFO] |  +- org.springframework:spring-webflux:jar:5.2.8.RELEASE:compile\n[INFO] |  \\- org.synchronoss.cloud:nio-multipart-parser:jar:1.1.0:compile\n[INFO] |     \\- org.synchronoss.cloud:nio-stream-storage:jar:1.1.3:compile\n\nIf you have a look at the spring-boot-starter-webflux-2.3.3.RELEASE.pom which includes the problematic spring-web 5.2.8.RELEASE you will find that the spring version is hardcoded to 5.2.8.RELEASE. So setting the spring.framework property in maven will have no effect.\n    \n      org.springframework\n      spring-web\n      5.2.8.RELEASE\n      compile\n    \n\nOutput of mvn help:effective-pom:\n \n        org.springframework  \n        spring-web  \n        5.2.8.RELEASE  \n      \n      \n        org.springframework  \n        spring-webflux  \n        5.2.8.RELEASE  \n      \n\nEdit after Solution by @Inthai2002:\nI have additonally an internal lib pom imported in my pom.xml\n\n        \n            \n                internal\n                lib\n                4.4.0\n                import\n                pom\n            \n\n            \n                org.springframework.cloud\n                spring-cloud-dependencies\n                ${spring-cloud.version}\n                pom\n                import\n            \n\n        \n    \n\nand this internal lib has the spring-boot-dependencies pom directly imported which leads to the fact that spring-framework.version property is ignored:\n          \n                org.springframework.boot\n                spring-boot-dependencies\n                2.3.3.RELEASE\n                import\n                pom\n            \n\n",
    "AcceptedAnswerId": 72173843,
    "AcceptedAnswer": "I just tried your pom (with and without the spring-framework.version property) on a clean m2 repo. Without the property, spring-framework is 5.2.8, with the property, it is 5.2.20. Can you try on a clean repo?\nThe spring-framework-bom at version X is hardcoded to all the spring packages for version X (see https://repo1.maven.org/maven2/org/springframework/spring-framework-bom/5.2.8.RELEASE/spring-framework-bom-5.2.8.RELEASE.pom)\nThe spring-framework.version property is declared and used to pull the spring-framework-bom in spring-boot-dependencies and inherited by its descendants (see https://repo1.maven.org/maven2/org/springframework/boot/spring-boot-dependencies/2.3.3.RELEASE/spring-boot-dependencies-2.3.3.RELEASE.pom).\nspring-boot-dependencies is parent of spring-boot-starter-parent (see https://repo1.maven.org/maven2/org/springframework/boot/spring-boot-starter-parent/2.3.3.RELEASE/spring-boot-starter-parent-2.3.3.RELEASE.pom).\nBecause the property is inherited by descendant, you can override its value at the pom of your application. By overriding it with 5.2.20, you are swapping out spring-framework-bom 5.2.8 for 5.2.20 which effectively pull most of the spring packages for 5.2.20\n"
}
{
    "Id": 72169818,
    "PostTypeId": 1,
    "Title": "Sometime video buffering very slowly in exoplayer?",
    "Body": "I don't know why, but sometimes Exoplayer buffers my video very slowly. My server is responding properly and the internet is also fast but sometimes Exoplayer buffers my video slowly for less than 1 second. And it buffering always after every 1-2 seconds on playing.\n        int MIN_BUFFER_DURATION = 3000;\n        int MAX_BUFFER_DURATION = 8000;\n        int MIN_PLAYBACK_RESUME_BUFFER = 1500;\n        int MIN_PLAYBACK_START_BUFFER = 500;\n        LoadControl loadControl = new DefaultLoadControl.Builder()\n                .setAllocator(new DefaultAllocator(true, 16))\n                .setBufferDurationsMs(MIN_BUFFER_DURATION,\n                        MAX_BUFFER_DURATION,\n                        MIN_PLAYBACK_START_BUFFER,\n                        MIN_PLAYBACK_RESUME_BUFFER)\n                .setTargetBufferBytes(-1)\n                .setPrioritizeTimeOverSizeThresholds(true).createDefaultLoadControl();\n        TrackSelector trackSelector = new DefaultTrackSelector();\n        simpleExoPlayer = new ExoPlayer.Builder(this).setTrackSelector(trackSelector).setLoadControl(loadControl).build();\n        binding.exoPlayerView.setPlayer(simpleExoPlayer);\n        mediaItem = MediaItem.fromUri(getVid);\n        simpleExoPlayer.addMediaItem(mediaItem);\n        simpleExoPlayer.prepare();\n        simpleExoPlayer.play();\n\nI'm testing my video in my Exoplayer and Chrome Browser player. Chrome browserplayer plays my video 4X faster than my appExoplayer`? And I'm playing the same video and the same time. Someone also asked this question in exoplayer git but not got a good answer or result see their question exoplayer issue github this same issue causing me!\nDoes anyone know why this happens? Your answer will helpful for me.\n",
    "AcceptedAnswerId": 72293324,
    "AcceptedAnswer": "\nMake sure you are using the latest version of Exoplayer. As of this writing, that is 2.10.4.\n\nTry increasing the buffer duration values in your LoadControl:\n\n\nint MIN_BUFFER_DURATION = 3000; // 3 seconds \nint MAX_BUFFER_DURATION = 8000; // 8 seconds \nint MIN_PLAYBACK_RESUME_BUFFER = 1500; // 1.5 seconds \nint MIN_PLAYBACK_START_BUFFER = 500; // 0.5 seconds \nLoadControl loadControl = new DefaultLoadControl.Builder() .setAllocator(new DefaultAllocator(true, 16)) .setBufferDurationsMs(MIN_BUFFER_DURATION, MAX_BUFFER_DURATION, MIN_PLAYBACK_START_BUFFER, MIN_PLAYBACK_RESUME_BUFFER) .setTargetBufferBytes(-1) .setPrioritizeTimeOverSizeThresholds(true).createDefaultLoadControl()\n\n\nTry using a different LoadControl. For example, you could use DefaultLoadControl with a smaller target buffer (e.g. 25% of the video bitrate):\n\nint TARGET_BUFFER_BYTES = (int) (0.25 * videoBitrate); // 25% of the video bitrate in bytes \nLoadControl loadControl = new DefaultLoadControl(new DefaultAllocator(true, 16), TARGET_BUFFER_BYTES , DEFAULT _MIN _REBUFFER _MS , DEFAULT _MAX LOADING _MS, DEFAULT __MIN ELAPSED __MS_BEFORE STOPPING , false); \n\n\nTry using a different Allocator. For example, you could use a larger one:\n\nint allocatorSize = 2 * 1024 * 1024; // 2MB \nAllocator allocator = new DefaultAllocator(true, allocatorSize); \nLoadControl loadControl = new DefaultLoadControl(allocator , DEFAULT _TARGET_BUFFER _BYTES , DEFAULT __MIN REBUFFER MS , DEFAULT MAX LOADING MS , DEFAULT MIN ELAPSED MS BEFORE STOPPING , false); \n\n"
}
{
    "Id": 73126185,
    "PostTypeId": 1,
    "Title": "What is overhead of Java Native Memory Tracking in \"summary\" mode?",
    "Body": "I'm wondering what is the real/typical overhead when NMT is enabled via \u2011XX:NativeMemoryTracking=summary (the full command options I'm after are -XX:+UnlockDiagnosticVMOptions \u2011XX:NativeMemoryTracking=summary \u2011XX:+PrintNMTStatistics)\nI could not find much information anywhere - either on SO, blog posts or the official docs.\nThe docs say:\n\nNote: Enabling NMT causes a 5% -10% performance overhead.\n\nBut they do not say which mode is expected to have this performance overhead (both summary and detail?)\nand what this overhead really is (CPU, memory, ...).\nIn Native Memory Tracking guide they claim:\n\nEnabling NMT will result in a 5-10 percent JVM performance drop, and memory usage for NMT adds 2 machine words to all malloc memory as a malloc header. NMT memory usage is also tracked by NMT.\n\nBut again, is this true for both summary and detail mode?\nWhat I'm after is basically whether it's safe to add \u2011XX:NativeMemoryTracking=summary permanently for a production app (similar to continuous JFR recording) and what are potential costs.\nSo far, when testing this on our app, I didn't spot a difference but it's difficult to\nIs there an authoritative source of information containing more details about this performance overhead?\nDoes somebody have experience with enabling this permanently for production apps?\n",
    "AcceptedAnswerId": 73167790,
    "AcceptedAnswer": "The overhead of Native Memory Tracking obviously depends on how often the application allocates native memory. Usually, this is not something too frequent in a Java application, but cases may differ. Since you've already tried and didn't notice performance difference, your application is apparently not an exception.\nIn the summary mode, Native Memory Tracking roughly does the following things:\n\nincreases every malloc request in the JVM by 2 machine words (16 bytes);\nrecords the allocation size and flags in these 2 words;\natomically increments (or decrements on free) the counter corresponding to the given memory type;\nbesides malloc and free, it also handles changes in virtual memory reservation and allocations of new arenas, but these are even less frequent than malloc/free calls.\n\nSo, to me, the overhead is quite small; 5-10% is definitely a large overestimation (the numbers would make sense for detail mode which collects and stores stack traces, which is expensive, but summary doesn't do that).\nWhen many threads concurrently allocate/free native memory, the update of an atomic counter could become a bottleneck, but again, that's more like an extreme case. In short, if you measured a real application and didn't notice any degradation, you're likely safe to enable NMT summary in production.\n"
}
{
    "Id": 72596066,
    "PostTypeId": 1,
    "Title": "\"error: package R does not exist\" in Navigation after adding Assets folder: Android Studio",
    "Body": "Since adding an Assets folder to my project I now get:\nerror: package R does not exist\n\"return new ActionOnlyNavDirections(R.id.action_newAlarmFragment_to_homeFragment);\"\n\nwhich is from this auto generated code:\nimport androidx.annotation.NonNull;\nimport androidx.navigation.ActionOnlyNavDirections;\nimport androidx.navigation.NavDirections;\n\npublic class SetNewAlarmFragmentDirections {\n  private SetNewAlarmFragmentDirections() {\n  }\n\n  @NonNull\n  public static NavDirections actionNewAlarmFragmentToHomeFragment() {\n    return new ActionOnlyNavDirections(R.id.action_newAlarmFragment_to_homeFragment);\n  }\n}\n\nI have tried cleaning and rebuilding the project and tried \"Invalidate caches and restart\" as suggested in the comments\nLooking through other answered questions here it seems it can be an import of R. somewhere causing this, but I can't find anything..\nThe NavDirection itself comes from this fragment:\nimport android.os.Bundle\nimport android.view.LayoutInflater\nimport android.view.View\nimport android.view.ViewGroup\nimport android.widget.CompoundButton\nimport androidx.fragment.app.Fragment\nimport androidx.lifecycle.ViewModelProvider\nimport androidx.navigation.Navigation\nimport com.pleavinseven.alarmclockproject.alarmmanager.AlarmManager\nimport com.pleavinseven.alarmclockproject.data.model.Alarm\nimport com.pleavinseven.alarmclockproject.data.viewmodel.AlarmViewModel\nimport com.pleavinseven.alarmclockproject.databinding.FragmentSetNewAlarmBinding\nimport com.pleavinseven.alarmclockproject.util.TimePickerUtil\nimport java.util.*\n\n\nclass SetNewAlarmFragment : Fragment() {\n\n    private val timePickerUtil = TimePickerUtil()\n    lateinit var binding: FragmentSetNewAlarmBinding\n    private lateinit var alarmViewModel: AlarmViewModel\n\n\n    override fun onCreateView(\n        inflater: LayoutInflater, container: ViewGroup?,\n        savedInstanceState: Bundle?\n    ): View {\n\n        binding = FragmentSetNewAlarmBinding.inflate(inflater, container, false)\n\n           binding.fragmentCreateAlarmRecurring.setOnCheckedChangeListener(CompoundButton.OnCheckedChangeListener { _, isChecked ->\n        if (isChecked) {\n            binding.fragmentCreateAlarmRecurring.visibility = View.VISIBLE\n        } else {\n            binding.fragmentCreateAlarmRecurring.visibility = View.GONE\n        }\n    })\n\n    alarmViewModel = ViewModelProvider(this)[AlarmViewModel::class.java]\n\n\n    binding.fragmentBtnSetAlarm.setOnClickListener(View.OnClickListener { _ ->\n        scheduleAlarm()\n        Navigation.findNavController(requireView())\n            .navigate(com.pleavinseven.alarmclockproject.R.id.action_newAlarmFragment_to_homeFragment)\n    })\n    return binding.root\n\n\n}\n\nnav xml:\n?xml version=\"1.0\" encoding=\"utf-8\"?>\n<navigation xmlns:android=\"http://schemas.android.com/apk/res/android\"\nxmlns:app=\"http://schemas.android.com/apk/res-auto\"\nxmlns:tools=\"http://schemas.android.com/tools\"\nandroid:id=\"@+id/alarm_nav\"\napp:startDestination=\"@id/homeFragment\">\n\n<fragment\n    android:id=\"@+id/homeFragment\"\n     android:name=\"com.pleavinseven.alarmclockproject.fragments.HomeFragment\"\n    android:label=\"fragment_home\"\n    tools:layout=\"@layout/fragment_home\" >\n    <action\n        android:id=\"@+id/action_homeFragment_to_newAlarmFragment\"\n        app:destination=\"@id/newAlarmFragment\" />\n    <action\n        android:id=\"@+id/action_homeFragment_to_updateFragment\"\n        app:destination=\"@id/updateFragment\" />\n\n<fragment\n    android:id=\"@+id/newAlarmFragment\"\n    android:name=\"com.pleavinseven.alarmclockproject.fragments.SetNewAlarmFragment\"\n    android:label=\"NewAlarmFragment\" >\n    <action\n        android:id=\"@+id/action_newAlarmFragment_to_homeFragment\"\n        app:destination=\"@id/homeFragment\" />\n\n<fragment\n    android:id=\"@+id/updateFragment\"\n    android:name=\"com.pleavinseven.alarmclockproject.fragments.UpdateFragment\"\n    android:label=\"UpdateFragment\" >\n    <action\n        android:id=\"@+id/action_updateFragment_to_homeFragment\"\n        app:destination=\"@id/homeFragment\" />\n    <argument\n        android:name=\"currentAlarm\"\n        app:argType=\"com.pleavinseven.alarmclockproject.data.model.Alarm\" />\n\n\n\n",
    "AcceptedAnswerId": 72627732,
    "AcceptedAnswer": "Just move package name from build.gradle app level to manifest.\nfrom\nandroid  { \n    namespace 'com.example.app' //remove this\n}\n\nto\n<manifest xmlns:android=\"http://schemas.android.com/apk/res/android\"\n    package=\"com.example.app\"> //add this\n\n"
}
{
    "Id": 72668718,
    "PostTypeId": 1,
    "Title": "How to create Context using traceId in Open Telemetry",
    "Body": "I try to get all spans created in the following chain associated to the same trace context/traceId by context propagation:\nservice1 -> aws sqs queue -> service2\nAuto. context propagation is not working with aws sqs and aws sdk v2 atm (https://github.com/open-telemetry/opentelemetry-java-instrumentation/issues/3684), even though the AwsTraceHeader is actually set in the sqs message, I have to take care for it explicitly by\n\nservice1: Writing traceId in sqs message user attribute\ntraceId=Span.current().getSpanContext().getTraceId()\nservice2: Reading traceId from sqs message user attribute traceId and overwriting current span.traceId / essentially creating Context of service1\n\nHowever, it is now unclear how to actually overwrite span.traceId in the span that service2 created which is confusing because for example with Golang it seems to be straightforward: How to create opentelemetry span from a string traceid\nI see only getters e.g. Span.current().getSpanContext().getTraceId()\nbut no setters or builder methods.\nUpdate:\nEven by creating a new span and making it current (not sure if this goes in the right direction)  the tracer.spanBuilder does no offer setters for traceId AFAIU)\n@Inject\nio.opentelemetry.api.trace.Tracer tracer;\n\nSpan consumeMessageSpan = tracer.spanBuilder(\"consumeMessage\").startSpan();\n\nconsumeMessage.makeCurrent();\n\nUpdate 2\nThis snippet from otel official docs looks promising\n\nTo link spans from remote processes, it is sufficient to set\nthe\u00a0Remote Context\u00a0as parent.\n\nSpan childRemoteParent = tracer.spanBuilder(\"Child\").setParent(remoteContext).startSpan(); \n\nHowever, also no examples or ideas how to create remoteContext and setting traceId to the one extracted from the sqs message\nAny hints how to do that?\n",
    "AcceptedAnswerId": 72826169,
    "AcceptedAnswer": "I've done the following for a child JVM\n(that is running using the OTel auto-instrumentation agent):\n    public static void main(String[] args) {\n        Span span = createSpanLinkedToParent();\n        try (Scope scope = span.makeCurrent()) {\n            // do stuff\n        } finally {\n            span.end();\n        }\n    }\n\n    private static Span createSpanLinkedToParent() {\n        // Fetch the trace and span IDs from wherever you've stored them\n        String traceIdHex = System.getProperty(\"otel.traceid\");\n        String spanIdHex = System.getProperty(\"otel.spanid\");\n\n        SpanContext remoteContext = SpanContext.createFromRemoteParent(\n                traceIdHex,\n                spanIdHex,\n                TraceFlags.getSampled(),\n                TraceState.getDefault());\n\n        return GlobalOpenTelemetry.getTracer(\"\")\n                .spanBuilder(\"root span name\")\n                .setParent(Context.current().with(Span.wrap(remoteContext)))\n                .startSpan();\n    }\n\nThe next improvement I plan to make it to serialise the flags and state, perhaps using code here in Context Propagation https://opentelemetry.io/docs/instrumentation/java/manual/#context-propagation but the above works for now.\n"
}
{
    "Id": 72345283,
    "PostTypeId": 1,
    "Title": "getDeclaredMethods() return inherited methods if superclass is default",
    "Body": "I have two classes\n// BaseClass.java\nclass BaseClass {\n \n   public String getTest(){\n       return \"one\";\n   }\n \n   public String getTest2(T t){\n       return \"two\";\n   }\n   public String getTest3(T t){\n       return \"three\";\n   }\n}\n \n// OverrideClass.java\npublic class OverrideClass extends BaseClass{\n}\n \n\nI tried to run the following code\n// Test.java\npublic class Test {\n   public static void main(String[] args) {\n       Class overrideClass = OverrideClass.class;\n       Method[] declaredMethods = overrideClass.getDeclaredMethods();\n       System.out.println(Arrays.toString(declaredMethods));\n   }\n}\n\nand I think it should output\n[]\n\nbut in fact the output is\n[public java.lang.String OverrideClass.getTest()]\n\nThrough the bytecode, I thought this a bridge method, but I don't know why it generates, and if I make BaseClass public it will disappear.\n  // access flags 0x1041\n  public synthetic bridge getTest()Ljava/lang/String;\n   L0\n    LINENUMBER 1 L0\n    ALOAD 0\n    INVOKESPECIAL BaseClass.getTest ()Ljava/lang/String;\n    ARETURN\n   L1\n    LOCALVARIABLE this LOverrideClass; L0 L1 0\n    MAXSTACK = 1\n    MAXLOCALS = 1\n}\n\nMy question is:\n\nWhy getTest() generate a bridge method if BaseClass is default?\nWhy getTest2() and getTest3() did not generate their bridge method? This seems to be related to generics.\n\n",
    "AcceptedAnswerId": 72345557,
    "AcceptedAnswer": "I have analyzed the issue and here is the results. I have simplified a bit the example from the question.\nThis answer handles the first question of OP\n\nWhy getTest() generate a bridge method if BaseClass is default?\n\nFor second question regarding the inconsistency appearing with generics you can read Denis answer\nExample 1\nclass BaseClass {\n\n    public String getTest(){\n        return \"one\";\n    }\n\n    public String getTest2(){\n        return \"two\";\n    }\n    public String getTest3(){\n        return \"three\";\n    }\n}\n\n\npublic class OverrideClass extends BaseClass{}\n\n\npublic class Application {\n\npublic static void main(String[] args) throws Exception {\n    Class overrideClass1 = OverrideClass.class;\n    Method[] declaredMethods1 = overrideClass1.getDeclaredMethods();\n    System.out.println(Arrays.toString(declaredMethods1));\n   }\n}\n\nThe execution of this either with JDK 8 or with JDK 17 has always the same result\n[public java.lang.String OverrideClass.getTest(), public java.lang.String OverrideClass.getTest2(), public java.lang.String OverrideClass.getTest3()]\n\nExample 2\nJust modify the above example into\npublic class BaseClass {\n\n    public String getTest(){\n        return \"one\";\n    }\n\n    public String getTest2(){\n        return \"two\";\n    }\n    public String getTest3(){\n        return \"three\";\n    }\n}\n\nNote that the change is in the access modifier on Base class which now is public!\nThe execution of this produces the expected behavior of  []\nThis however is not a bug of JDK. It is intended to be this way.\nExplanation\nThe reason that in the example1 the getDeclaredMethods() has returned the same methods of the parent class is not because those methods are printed as inherited. It is because those are bridge methods that actually belong to that child class (OverrideClass).\nThis functionality has been added long ago and the explanation as you can see here from developers of oracle was\n\nThe proposal is to add bridge methods in these very rare cases to fix\na problem in reflection with no other forseen fix or workaround.\nSpecifically, we would generate a bridge method when a public method\nis inherited from a nonpublic class into a public class.\n\nAnd as you can also see here, the most recent comment from oracle developers was\n\nThe bridge methods are added in a case like this where a public class\npublic methods from a non-public superclass to allow for the\npossibility of reflective access of the subclasses methods\nJDK-6342411).\nClosing this issue as not a bug.\n\nSo this is happening only in non public parent classes because in this case the public methods that are inherited need to be added as bridge methods in that children class.\nIn the example 2 where bridge methods do not exist, if you try to print out the disassembled code using javap -c OverrideClass you will see the following\npublic class OverrideClass extends BaseClass {\n      public OverrideClass();\n        Code:\n           0: aload_0\n           1: invokespecial #1                  // Method BaseClass.\"\":()V\n           4: return\n    }\n\nIn the example 1 with bridge methods existing, if you try to print out the disassembled code using javap -c OverrideClass you will see the following\npublic class OverrideClass extends BaseClass {\n  public OverrideClass();\n    Code:\n       0: aload_0\n       1: invokespecial #1                  // Method BaseClass.\"\":()V\n       4: return\n\n  public java.lang.String getTest3();\n    Code:\n       0: aload_0\n       1: invokespecial #7                  // Method BaseClass.getTest3:()Ljava/lang/String;\n       4: areturn\n\n  public java.lang.String getTest2();\n    Code:\n       0: aload_0\n       1: invokespecial #11                 // Method BaseClass.getTest2:()Ljava/lang/String;\n       4: areturn\n\n  public java.lang.String getTest();\n    Code:\n       0: aload_0\n       1: invokespecial #14                 // Method BaseClass.getTest:()Ljava/lang/String;\n       4: areturn\n}\n\n"
}
{
    "Id": 73281636,
    "PostTypeId": 1,
    "Title": "Java Generics: Stream.map() returns \"capture of ?\" instead of \"?\"",
    "Body": "I'm trying to build a List of Classes that implement a certain interface called Interface:\nList> myList= myMap.entrySet().stream()\n    .filter(entry -> entry.getValue().equals(myValue))\n    .map(Map.Entry::getKey)   // Stream\n    .map(Interface::getClass) // Stream>\n    .distinct()\n    .toList();\n\nI added as comment the type of the elements in the Stream after map() is called.\nThe code iterates over all the entries in the map, and if their value is equal to myValue, then:\n\nfirst, gets the instance of type Interface (which is the key of the entry)\nthen, gets the Class implementing the Interface.\n\nmyMap is defined as:\nMap myMap = new HashMap()\n\nThe error I'm getting :\nIncompatible types.\nFound: 'java.util.List>>',\nrequired: 'java.util.List>'\n\nI am clearly missing something about how Generics work in Java, but I am at a loss here. I suppose it's something related to the fact that the compiler cannot correctly reify my ? wildcard.\n",
    "AcceptedAnswerId": 73281848,
    "AcceptedAnswer": "As @Slaw has pointed out in the comments, in this case getClass() is capable to provide the information about the generic type to the compiler.\nAccording to the documentation:\n\nThe actual result type is Class where |X| is the erasure of the static type of the expression on which getClass is called.\n\nHence, at compile time, we would have a type ? extends Interface and the reason of the observed behavior is related solely to peculiarities of type inference in Java.\nIn this case, when we are chaining methods after map() operation, the compiler fails to infer the type of the method reference Interface::getClass correctly based on the resulting type returned by the stream.\nIf we substitute toList, which expects elements of type T and produces List, with collect(Collectors.toList()), in which collector is of type Collector, the compiler would be able to do its job (here's a proof):\nList> myList = myMap.entrySet().stream()\n    .filter(entry -> Objects.equals(entry.getValue(), myValue))\n    .map(Map.Entry::getKey)   // Stream\n    .map(Interface::getClass) // Stream>\n    .distinct()\n    .collect(Collectors.toList());\n\nBut to make type inference working with toList() we need to provide the generic type explicitly.\nFor instance, this code would compile, because the type of Interface::getClass could be inferred from the assignment context (here there are no operations after map(), hence myStream directly says what should be the return type of map()):\nStream> myStream = myMap.entrySet().stream()\n    .filter(entry -> Objects.equals(entry.getValue(), myValue))\n    .map(Map.Entry::getKey)\n    .map(Interface::getClass);\n\nList> myList = myStream.distinct().toList();\n\nA more handy way would be to use a so-called Type Witness:\nMap myMap = Map.of(new ClasA(), 1, new ClasB(), 1);\n        \nint myValue = 1;\n        \nList> myList = myMap.entrySet().stream()\n    .filter(entry -> Objects.equals(entry.getValue(), myValue))\n    .map(Map.Entry::getKey)                               // Stream\n    .>map(Interface::getClass) // Stream>\n    .distinct()\n    .toList();\n        \nmyList.forEach(c -> System.out.println(c.getSimpleName()));\n\nOutput:\nClasA\nClasB\n\nDummy classes:\ninterface Interface {}\nclass ClasA implements Interface {}\nclass ClasB implements Interface {}\n\n"
}
{
    "Id": 73336136,
    "PostTypeId": 1,
    "Title": "Does having a wrapper object return value (e.g. Integer) cause auto boxing in Java?",
    "Body": "I couldn't find a definitive answer for this seemingly simple question. If I write a method like this:\npublic Integer getAnInt() {\n  int[] i = {4};\n  return i[0];\n}\n\nis the return value autoboxed into an Integer, or does it depend on what happens to the value after it's returned (e.g. whether the variable it is assigned to is declared as an Integer or int)?\n",
    "AcceptedAnswerId": 73336170,
    "AcceptedAnswer": "Yes, boxed\nIt will be (auto)boxed in the bytecode (.class file) because it's part of the public API, so other code might depend on the return value being an Integer.\nThe boxing and unboxing might be removed at runtime by the JITter under the right circumstances, but I don't know if it does that sort of thing.\n"
}
{
    "Id": 72841549,
    "PostTypeId": 1,
    "Title": "Container Fails to Start: Insufficient memory for the Java Runtime Environment to continue",
    "Body": "We have an enterprise application running on Java 8. The deployment environment is built & updated through Bitbucket pipelines. I have a graphic showing the high-level architecture of the environment.  We have two app servers running identical configurations apart from some application specific environment variables.\nIt was all working well until a week ago when after a successful pipeline run, the 2 app instances on one of the servers stopped working with the following error:\nThere is insufficient memory for the Java Runtime Environment to continue.\nCannot create GC thread. Out of system resources.\n\nBoth the instances are working fine on the other server. In contrast, the containers fail to start on this server.\nSolutions Tried\nThe error accompanies the following information:\nPossible reasons:\nThe system is out of physical RAM or swap space\nThe process is running with CompressedOops enabled, and the Java Heap may be blocking the growth of the native heap.\nPossible solutions:\n\nReduce memory load on the system\nIncrease physical memory or swap space\nCheck if swap backing store is full\nDecrease Java heap size (-Xmx/-Xms)\nDecrease number of Java threads\nDecrease Java thread stack sizes (-Xss)\nSet larger code cache with -XX:ReservedCodeCacheSize=\n\nWe have tried:\n\nAdding more swap memory. The server has 8GB of RAM while we have tried the swap from 4GB to 9GB.\nPlayed with the heap sizes Xms & Xmx from 128m to 4096m.\nIncreased the RAM on this server to 16GB while the other server that works still does on 8GB.\n\nHere is how the memory & swap consumption looks like:\nfree -mh\n              total        used        free      shared  buff/cache   available\nMem:           15Gi       378Mi        12Gi       1.0Mi       2.9Gi        14Gi\nSwap:           9Gi          0B         9Gi\n\nI have links to several related artifacts.  These include the complete docker logs output and the output of docker info on the failing server and the operational server.\nThis is what docker ps -a gets us:\n:~$ docker ps -a\nCONTAINER ID   IMAGE                                                                                  COMMAND                  CREATED        STATUS                    PORTS                                       NAMES\nd29747bf2ad3   :a7608a838625ae945bd0a06fea9451f8bf11ebe4   \"catalina.sh run\"        10 hours ago   Exited (1) 10 hours ago                                               jbbatch\n0951b6eb5d42   :a7608a838625ae945bd0a06fea9451f8bf11ebe4   \"catalina.sh run\"        10 hours ago   Exited (1) 10 hours ago                                               jbapp\n\nWe are out of ideas right now as we have tried almost all the solutions on stack overflow. What are we missing?\n",
    "AcceptedAnswerId": 72841934,
    "AcceptedAnswer": "I see that your Docker image uses Ubuntu 22.04 LTS as its base. Recently base Java images were rebuilt on top of this LTS version, which caused a lot of issues on older Docker runtimes. Most likely this is what you're experiencing. It has nothing to do with memory, but rather with Docker incompatibility with a newer Linux version used as a base image.\nYour operational server has Docker server version 20.10.10, while the failing server has version 20.10.09. The incompatibility issue was fixed exactly in Docker 20.10.10. Some more technical details on the incompatibility issue are available here.\nThe solution would be to upgrade the failing server to at least Docker 20.10.10.\n"
}
{
    "Id": 73337717,
    "PostTypeId": 1,
    "Title": "IntelliJ Idea debugger's evaluator gives different results than normal program for comparing Scala Long and Float variables",
    "Body": "\nAs the screenshot shows, While I'm comparing the same literal values with type of Float and Long, Scala says it's not equal\nBut the evaluator says they are equal to each other!\nI suspect this is a bug in Intellij Idea, since the same code will yield different results in a normal Scala runtime than in a evaluator runtime.\nIf the Evaluator's result is untrustworthy, this may cause trouble for developers.\nI wonder if there is anything wrong with my thinking and hope someone can point it out.\n",
    "AcceptedAnswerId": 73338149,
    "AcceptedAnswer": "I could not reproduce your example using the Intellij evaluator (though I don't use a Mac, this might be a bug on the Mac version of Intellij), but what I can say is that Java and Scala treat this differently. Actually, in Scala 2.13.x those values are equal.\nJava treats this code differently based on their types (primitive vs wrapper types):\n    long vl = 32294629407L;\n    float vf = 32294629407f;\n    Boolean res11 = vl == vf;\n    System.out.println(res11); // true\n\n    Long vl1 = 32294629407L;\n    Float vf1 = 32294629407f;\n    Boolean res22 = vl1.equals(vf1);\n    System.out.println(res22); // false\n\nSince Scala was designed to be a more regular language, such discrepancies were removed from the language, by special casing the == method for these classes:\n  val vl: Long  = 32294629407L\n  val vf: Float = 32294629407f\n  val res11     = vl == vf // true \n\n  println(res11) // true\n\n\nThe only case where == does not directly call equals is for Java's\nboxed numeric types.\n\nNOTE:\nFor prior versions of Scala, this does not hold, as it seems in Scala 2.12 this is not valid.\n"
}
{
    "Id": 71832118,
    "PostTypeId": 1,
    "Title": "sbt assembly cannot create jar getting java.lang.UnsupportedOperationException",
    "Body": "I am using\nscala 1.12.10\nakka 2.6.3\naddSbtPlugin(\"io.spray\" % \"sbt-revolver\" % \"0.9.1\")\naddSbtPlugin(\"com.eed3si9n\" % \"sbt-assembly\" % \"1.1.0\")\n\nHowever when executing sbt assembly I am getting:\njava.lang.UnsupportedOperationException: The Security Manager is deprecated and will be removed in a future release\n    at java.base/java.lang.System.setSecurityManager(System.java:416)\n    at sbt.TrapExit$.installManager(TrapExit.scala:53)\n    at sbt.StandardMain$.runManaged(Main.scala:109)\n    at sbt.xMain.run(Main.scala:76)\n    at xsbt.boot.Launch$$anonfun$run$1.apply(Launch.scala:111)\n    at xsbt.boot.Launch$.withContextLoader(Launch.scala:131)\n    at xsbt.boot.Launch$.run(Launch.scala:111)\n    at xsbt.boot.Launch$$anonfun$apply$1.apply(Launch.scala:37)\n    at xsbt.boot.Launch$.launch(Launch.scala:120)\n    at xsbt.boot.Launch$.apply(Launch.scala:20)\n    at xsbt.boot.Boot$.runImpl(Boot.scala:56)\n    at xsbt.boot.Boot$.main(Boot.scala:18)\n    at xsbt.boot.Boot.main(Boot.scala)\n[error] [launcher] error during sbt launcher: java.lang.UnsupportedOperationException: The Security Manager is deprecated and will be removed in a future release\n\nrunning java 18\njava -version\nopenjdk version \"18\" 2022-03-22\nOpenJDK Runtime Environment (build 18+36-2087)\nOpenJDK 64-Bit Server VM (build 18+36-2087, mixed mode, sharing)\n\n",
    "AcceptedAnswerId": 71847512,
    "AcceptedAnswer": "Using java 8 solved this issue as AminMal suggested\n"
}
{
    "Id": 72878610,
    "PostTypeId": 1,
    "Title": "Is there a reason to create the string variable before input?",
    "Body": "Newly learning java and for input, we did\nScanner scan = new Scanner(System.in);\nString name;\nSystem.out.println(\"What is your  name?\");\nname = scan.nextLine();\nSystem.out.println(name);\n\nHowever, I found that\nScanner scan = new Scanner(System.in);\nString name = scan.nextLine();\nSystem.out.println(name);\n\nworks the same. Is this being taught to me in the bigger form because it's more generally used/is clearer or am I just being taught the bigger form since I'm a beginner to avoid too much confusion? (Basically, are there any reasons why people would use the expanded version rather than the condensed version?)\n",
    "AcceptedAnswerId": 72878772,
    "AcceptedAnswer": "In your case its one and the same thing. It is more useful though when used in the context of variable scoping.\nCreating a reference variable before initializing it with a value is the preferred way while using code blocks, so that the reference can be used outside of the block as well. Check out this example:\nint sum = 0;\nfor(int idx=0; idx<5; idx++) {\n   sum+=idx;\n}\nreturn sum;\n\n"
}
{
    "Id": 73456148,
    "PostTypeId": 1,
    "Title": "Unit test: Collection being processed with for-loop but not with streams",
    "Body": "Issue with unit test is that the same collection is processed differently in a stream and in a for loop.\nThe collection in both cases is empty (data.size() = 0), but in the Case 1 that collection is somehow processed, in other words it will step in the for-loop.\nIn Case 2, that collection is just skipped (which is expected since it's empty).\nTests are using Mockito, and Result is comming for JOOQ.\nThe tests are old and unchanged, the only change is going from for-loop to stream.\nCase 1\nprivate SearchResult iterateData(\n      Result data, ...) {\n\n      for (Record record : data) {\n           doSomething(record);\n    }\n\nCase 2\nprivate SearchResult iterateData(\n      Result data, ...) {\n      data.stream().forEach(record -> doSomething(record)); \n\nScreenshot of Case 1\nfor loop example\nMocked Result object\nprivate DefaultSearchRequestModel rowSpecificValuesTestSetup(\n      parameters...) {\n    \n\n    DefaultSearchRequestModel searchRequest = new DefaultSearchRequestModel(\n        Arrays.asList(....),\n        Collections.singletonList(\n            new SearchFilter(\n                \"test\",\n                Collections.singletonList(...)));\n\n    List columns =\n        this.searchService.filterUserAllowedColumns(...);\n\n    Condition searchCondition =\n        this.searchRepositoryMock.getSearchConditions(...);\n\n    List joinMappings = ColumnHelper.getColumnTranslateDeviceJoinMappings(\n        columns,\n        searchRequest.getFilters());\n\n    Result deviceDataResultMock = Mockito.mock(Result.class);\n    Iterator resultIterator = Mockito.mock(Iterator.class);\n    final Table fromTableMock = Mockito.mock(Table.class);\n    when(resultIterator.hasNext()).thenReturn(true, false);\n    Record recordMock = Mockito.mock(Record.class);\n    when(resultIterator.next()).thenReturn(recordMock);\n    when(deviceDataResultMock.iterator()).thenReturn(resultIterator);\n    when(recordMock.get(CONTRACTID)).thenReturn(contractId);\n   ...\nwhen(this.userPermissions.getAccessPermissions()).thenReturn(searchRequest.getColumns().stream().map\n        (name -> Column.findByName(name).getId()).collect(\n        Collectors.toList()));\n    when(this.searchRepositoryMock.getCurrentTable(companyId))\n        .thenReturn(fromTableMock);\n    when(recordMock.get(TYPEID)).thenReturn(financialTypeId);\n    when(this.searchRepositoryMock.getDeviceData(\n        ArgumentMatchers.anyList(),\n        ArgumentMatchers.anyList(),\n        any(),\n        any(),\n        eq(searchRequest.getPageSize()),\n        eq(searchRequest.getPage()),\n        eq(searchRequest.getSortCriterias()),\n        eq(fromTableMock),\n        ArgumentMatchers.anyList(),\n        eq(Optional.empty()),\n        eq(this.dslContextMock)))\n        .thenReturn(deviceDataResultMock);\n\n    return searchRequest;\n  }```\n\n",
    "AcceptedAnswerId": 73469713,
    "AcceptedAnswer": "Why it didn't work\nYou're mocking Result.iterator():\nwhen(deviceDataResultMock.iterator()).thenReturn(resultIterator);\n\nBut you didn't mock Result.spliterator(), or at least I didn't see it, which is what's being called by Result.stream(), which is just Collection.stream():\ndefault Stream stream() {\n    return StreamSupport.stream(spliterator(), false);\n}\n\nSo, you'll have to mock the spliterator() method as well, and probably a few others, too! Alternatively, tell Mockito to call default methods:\nCan you make mockito (1.10.17) work with default methods in interfaces?\nA comment on mocking in general\nI'm not convinced that mocking the jOOQ API is a very good idea. The jOOQ API is vast, and you'll likely forget to mock this or that method as this question here has aptly shown. With your current setup, you're planning on updating your mock every time you project a new column? E.g. you're doing this:\nwhen(recordMock.get(DEVICEID.getName()).thenReturn(deviceId);\n\nWhat if the column is renamed? Or another column is projected? You'll have to update this test. That feels like quite the chore, and it's very error prone.\nWhile jOOQ itself has JDBC mocking capabilities, please consider the bold disclaimer on that manual page:\n\nDisclaimer: The general idea of mocking a JDBC connection with this jOOQ API is to provide quick workarounds, injection points, etc. using a very simple JDBC abstraction. It is NOT RECOMMENDED to emulate an entire database (including complex state transitions, transactions, locking, etc.) using this mock API. Once you have this requirement, please consider using an actual database product instead for integration testing, rather than implementing your test database inside of a MockDataProvider\n\nWhen working with databases, it's usually best to resort to running integration tests, see the following resources for some details:\n\nIntegration testing with Jooq\nUsing H2 as a Test Database Product with jOOQ\nHow to Integration Test Stored Procedures with jOOQ\nUsing Testcontainers to Generate jOOQ Code\n\nOf course, you can write a few smoke tests to ensure jOOQ works correctly if you don't trust jOOQ (jOOQ being an external dependency). But the jOOQ unit and integration tests are vast, so in general, you should be able to trust core types like Result or Record to do the right thing for you. What you really want to test is your query correctness, and that, you can only integration test against an actual database instance.\n"
}
{
    "Id": 73654810,
    "PostTypeId": 1,
    "Title": "Why does String creation using `newInstance()` method behave different when using `var` compared to using explicit type `String`?",
    "Body": "I am learning about reflection in Java. By accident, I discovered the following, for me unexpected behavior.\nBoth tests as written below succeed.\nclass NewInstanceUsingReflection {\n    @Test\n    void testClassNewInstance()\n        throws NoSuchMethodException, InvocationTargetException,\n        InstantiationException, IllegalAccessException\n    {\n        final var input = \"A string\";\n        final var theClass = input.getClass();\n        final var constructor = theClass.getConstructor();\n        final String newString = constructor.newInstance();\n\n        assertEquals(\"\", newString);\n    }\n\n    @Test\n    void testClassNewInstanceWithVarOnly()\n        throws NoSuchMethodException, InvocationTargetException,\n        InstantiationException, IllegalAccessException\n    {\n        final var input = \"A string\";\n        final var theClass = input.getClass();\n        final var constructor = theClass.getConstructor();\n        final var newString = constructor.newInstance();\n\n        assertEquals(\"A string\", newString);\n    }\n}\n\nThe only difference apart from the assertion is that the newString variable type is explicit in the first test and declared as var in the second test.\nI'm using java 17 and the junit5 test framework.\nWhy is the value of newString an empty string in the first test and the input string value in the second test?\nDoes it have something todo with the string-pool?\nOr is something else going on?\n",
    "AcceptedAnswerId": 73655162,
    "AcceptedAnswer": "Java17, same problem. The explanation is clearly: bug.\ndecompiling it, the relevant section:\n        20: anewarray     #2                  // class java/lang/Object\n        23: invokevirtual #35                 // Method java/lang/reflect/Constructor.newInstance:([Ljava/lang/Object;)Ljava/lang/Object;\n        26: checkcast     #41                 // class java/lang/String\n        29: astore        4\n        31: ldc           #23                 // String A string\n        33: ldc           #23                 // String A string\n        35: invokevirtual #43                 // Method java/lang/String.equals:(Ljava/lang/Object;)Z\n\nastore 4 is where the result goes, which is nowhere: slot 4 is not used any further. Instead, the same string constant is loaded twice, trivially resulting in, effectively, \"A string\".equals(\"A string\"), which is of course true.\nReplacing var with String, recompiling, and rerunning javap:\n        20: anewarray     #2                  // class java/lang/Object\n        23: invokevirtual #35                 // Method java/lang/reflect/Constructor.newInstance:([Ljava/lang/Object;)Ljava/lang/Object;\n        26: checkcast     #41                 // class java/lang/String\n        29: astore        4\n        31: ldc           #23                 // String A string\n        33: aload         4\n        35: invokevirtual #43                 // Method java/lang/String.equals:(Ljava/lang/Object;)Z\n\nIdentical in every way, except the second ldc is the correct aload 4.\nI'm having a hard time figuring out what's happening here. It feels more like the var is somehow causing that ldc to duplicate (in contrast to an analysis incorrectly thinking that the values are guaranteed to be identical; javac intentionally does very little such optimizations).\nI'm having a really hard time figuring out how this has been in 2 LTS releases. Impressive find.\nNext step is to verify on the latest JDK (18), and then to file a bug. I did a quick look if it has been reported already, but I'm not sure what search terms to use. I didn't find any report in my search, though.\nNB: The decompilation traces were produced using javap -c -v NewInstanceUsingReflection.\nEDIT: Just tried on ecj (Eclipse Compiler for Java(TM) v20210223-0522, 3.25.0, Copyright IBM Corp 2000, 2020. All rights reserved.) - bug doesn't happen there.\n"
}
{
    "Id": 72349380,
    "PostTypeId": 1,
    "Title": "How can I create a Locale with a specific script code?",
    "Body": "I'm trying to convert this String az_AZ_#Latn, found here, to a Locale but I'm unable to parse the #Latn part.\nIf I do new Locale(\"az_AZ_#Latn\") I lose the #Latn part (the Script code).\nI've tried as well using the LocaleUtils from commons-lang but I get an error saying that it's an invalid format.\n",
    "AcceptedAnswerId": 72349890,
    "AcceptedAnswer": "As written in the docs:\n\nIt is not possible to set a script code on a Locale object in a\nrelease earlier than JDK 7.\n\nBut you can use the Locale builder to make it like this:\nLocale locale = new Locale.Builder().setLanguage(\"az\").setRegion(\"AZ\").setScript(\"Latn\").build();\n\nYou can get the Script it by calling locale.getScript()\nEdit:\nHere's a method I made for converting a string into a locale (doesn't work for extensions):\npublic static Locale stringToLocale(String locale){\n    if(locale == null || locale.isEmpty()) return null;\n    String[] parts = locale.split(\"_\");\n    if(parts.length == 1) return new Locale(parts[0]);\n    if(parts.length == 2) return new Locale(parts[0],parts[1]);\n    if(parts.length == 3) \n        if(parts[2].charAt(0) != '#') return new Locale(parts[0],parts[1],parts[2]);\n        else return new Locale.Builder().setLanguage(parts[0]).setRegion(parts[1]).setScript(parts[2].substring(1)).build();\n    if(parts.length == 4) return new Locale.Builder().setLanguage(parts[0]).setRegion(parts[1]).setVariant(parts[2]).setScript(parts[3].charAt(0)=='#'? parts[3].substring(1):null).build();\n    return null;\n}\n    //works for the toString output expect for extensions. test: for(Locale l:  Locale.getAvailableLocales()) System.out.println(l.equals(stringToLocale(l.toString())));\n   // output : true true true...\n\nusage:\nLocale l = stringToLocale(\"az_AZ_#Latn\");\n\n"
}
{
    "Id": 71641264,
    "PostTypeId": 1,
    "Title": "How can I solve this issue on Mac M1 Caused by: java.lang.Exception: No native library is found for os.name=Mac and os.arch=aarch64",
    "Body": "I solved this issue with the code below in my build.gradle\n  allprojects {\nconfigurations.all {\n    resolutionStrategy {\n        force 'org.xerial:sqlite-jdbc:3.34.0'\n      }\n   }\n } \n\nBut it has an effect on the project I am working on. for some reason, it is not working with room sql implemented on the project.\nI get this error when i removed the code above.\nIs there a better approach to solve this.\nCaused by: java.lang.ExceptionInInitializerError\nat androidx.room.processor.DatabaseProcessor.doProcess(DatabaseProcessor.kt:82)\nat androidx.room.processor.DatabaseProcessor.process(DatabaseProcessor.kt:57)\nat androidx.room.RoomProcessor$DatabaseProcessingStep.process(RoomProcessor.kt:134)\nat com.google.auto.common.BasicAnnotationProcessor.process(BasicAnnotationProcessor.java:330)\nat com.google.auto.common.BasicAnnotationProcessor.process(BasicAnnotationProcessor.java:181)\nat org.jetbrains.kotlin.kapt3.base.incremental.IncrementalProcessor.process(incrementalProcessors.kt)\nat org.jetbrains.kotlin.kapt3.base.ProcessorWrapper.process(annotationProcessing.kt:161)\nat \n\n \n\njdk.compiler/com.sun.tools.javac.processing.JavacProcessingEnvironment.callProcessor(JavacProcessingEnvironment.java:980)\n... 39 more\nCaused by: java.lang.Exception: No native library is found for os.name=Mac and \nos.arch=aarch64. path=/org/sqlite/native/Mac/aarch64\nat org.sqlite.SQLiteJDBCLoader.loadSQLiteNativeLibrary(SQLiteJDBCLoader.java:333)\nat org.sqlite.SQLiteJDBCLoader.initialize(SQLiteJDBCLoader.java:64)\nat androidx.room.verifier.DatabaseVerifier.(DatabaseVerifier.kt:68)\n... 47 more\n\n",
    "AcceptedAnswerId": 71898182,
    "AcceptedAnswer": "update your room library\n   implementation \"androidx.room:room-runtime:2.4.2\"\n   implementation \"androidx.room:room-ktx:2.4.2\"\n   kapt \"androidx.room:room-compiler:2.4.2\"\n\nHere is Reference\n"
}
{
    "Id": 73038137,
    "PostTypeId": 1,
    "Title": "What's the best way to encode and decode parameter in springboot?",
    "Body": "I use @RequestParam to get the parameter value,but I find the if I pass the value like 'name=abc&def&id=123',I will get the name value 'abc' instead of 'abc&def'. I find the encode and decode the parameter value can solve my problem.But I have to write the encode and decode mehtod in every controller method,Do spring have the global mehtod that decode every  @RequestParam value?When using @RequestParam, is it necessary to encode and decode every value?\nHere is my code:\n@PostMapping(\"/getStudent\")\npublic Student getStudent(\n        @RequestParam String name,\n        @RequestParam String id) { \n        name= URLDecoder.decode(name, \"UTF-8\");  \n        //searchStudent\n        return Student;\n}\n\n@PostMapping(\"/getTeacher\")\npublic teacher getTeacher(\n        @RequestParam String name,\n        @RequestParam String teacherNo) { \n        name= URLDecoder.decode(name, \"UTF-8\");  \n        //searchTeacher\n        return teacher;\n}\n\nSomebody say the the Spring will have already done this,but I have try,the result is not right.Only use curl cmd is ok,but java code is not ok.\n@PostMapping(value = \"/example\")\npublic String handleUrlDecode1(@RequestParam String param) { \n    //print ello%26test\n    System.out.println(\"/example?param received: \" + param); \n    return \"success\";\n}\n\n@GetMapping(value = \"/request\")\npublic String request() {\n    String url =  \"http://127.0.0.1:8080/example?param=ello%26test\";\n    System.out.println(url);\n    RestTemplate restTemplate = new RestTemplate();\n    return restTemplate.postForObject(url, null, String.class);\n}\n\n",
    "AcceptedAnswerId": 73053590,
    "AcceptedAnswer": "You must create an HTTP entity and send the headers and parameter in body.\n@GetMapping(value = \"/request\")\npublic String request()  {\n    String url =  \"http://127.0.0.1:8080/example\";\n    System.out.println(url);\n    RestTemplate restTemplate = new RestTemplate(); \n    HttpHeaders headers = new HttpHeaders();\n    headers.setContentType(MediaType.APPLICATION_FORM_URLENCODED);\n    MultiValueMap map= new LinkedMultiValueMap();\n    map.add(\"param\",\"ello&test\");\n    map.add(\"id\",\"ab&c=def\");\n    HttpEntity> request = new HttpEntity>(map, headers); \n    return restTemplate.postForObject(url, request, String.class);\n}\n\n"
}
{
    "Id": 72362798,
    "PostTypeId": 1,
    "Title": "ZonedDateTime format and parsing exception with \u201cz\u201d in format pattern",
    "Body": "I have a problem with parsing ZonedDateTime:\nDateTimeFormatter format = DateTimeFormatter.ofPattern(\"yyyy-MM-ddzhh:mm\");\nZonedDateTime.parse(s, formatter);\n\nThis results in an error:\njava.time.format.DateTimeParseException:\n    Text '2022-05-24UTC12:15' could not be parsed at index 10\n\nwhats wrong with this code?\n",
    "AcceptedAnswerId": 72362956,
    "AcceptedAnswer": "The character z should be able to parse \"UTC\" (in most Locales) because UTC is considered a time-zone ID and a time-zone name in java.time. A VV can parse time-zone ids while zcan parse time-zone-names according to the JavaDocs of java.time.DateTimeFormatter, here's the relevant part of the docs:\nSymbol  Meaning                     Presentation      Examples\n------  -------                     ------------      -------\n(\u2026)\n\nV       time-zone ID                zone-id           America/Los_Angeles; Z; -08:30\nz       time-zone name              zone-name         Pacific Standard Time; PST\n\n(\u2026)\n\nThat means you can parse it using the character V without providing a specific Locale to your DateTimeFormatter. You will have to put two of them (VV) or you will get a nice IllegalArgumentException with the following message:\njava.lang.IllegalArgumentException: Pattern letter count must be 2: V\n\nIf you still want to use z, provide a Locale that considers UTC an abbreviation of Universal Time Coordinated, the Central European Summer Time is an abbreviation that definitely changes among different Locales, e.g.\n\nEnglish: CEST\nGerman:  MESZ\n\nOther Locales might have different abbreviations, which makes me wonder if your Locale actually even has a different one for UTC.\nProvide Locale.ENGLISH, for example and it should parse successfully.\nYou should provide one anyway because if you don't, the DateTimeFormatter will implicitly use the default Locale of your (Java Virtual) machine.\nSo you can try this:\nDateTimeFormatter format = DateTimeFormatter.ofPattern(\"uuuu-MM-ddVVHH:mm\");\n\nor this:\nDateTimeFormatter format = DateTimeFormatter.ofPattern(\"uuuu-MM-ddzHH:mm\", Locale.ENGLISH);\n\nboth should be able to parse an input like \"2022-05-24UTC12:15\" if you use HH instead of hh for hours of day (hh = 12h format, HH = 24h format).\n"
}
{
    "Id": 72046624,
    "PostTypeId": 1,
    "Title": "Firebase Tools and Java 11",
    "Body": "This question falls somewhere between Firebase Tools, MacOS and Java. Probably 75% Java, 20% Firebase Tools and 5% MacOS.\nStarting with v10.5, firebase-tools started stating that 'Support for Java version \nI run macOS v11.6.5 on a Macbook Pro from mid-2014. When I go to Java's Downloads page, it recommends Java 'Version 8 Update 331'. Not Java 11.\nInformation on downloading Java 11 seems to be scarce. Oracle's page of certified configurations includes MacOS 11, but I can't find anywhere obvious where Java 11 can be readily downloaded.\nA big part of the problem seems to be the terminology used. If I run java -version, I get:\njava version \"1.8.0_331\"\nJava(TM) SE Runtime Environment (build 1.8.0_331-b09)\nJava HotSpot(TM) 64-Bit Server VM (build 25.331-b09, mixed mode)\n\nOkay, I have build 1.8 of the Java Runtime Environment, aka the JRE if you are a Java enthusiast. That is apparently what is triggering the warning in Firebase Tools.\nThere is also a Java product out there called 'Java SE 11'. The product itself is ambiguous, but the checksums all say 'SDK'. (A Software Development Kit: a thing that enables developers to develop Java programs. The name doesn't imply a Runtime Environment: a thing that enables Java to run on an operating system.) There is an article out there which claims that, if you install Java SE 11 and run java -version, it will spit out java version \"11.0.7\". That will probably satisfy Firebase Tools.\nBut Oracle's release notes say: 'In Windows and macOS, installing the JDK in previous releases optionally installed a JRE. In JDK 11, this is no longer an option.' No longer an option... as in now you implicitly get JRE 11 with SDK 11? Or as in the SDK and JRE are now fully divorced, and the JRE must be ferreted out of its hiding like a wild beast?\nUPDATE 6/5/22: Java's checksums page now says 'JDK', and I guess that is better than 'SDK' because it implies 'Java Development Kit', which this Wikipedia article claims to include both a JRE ('java') and SDK (most of the other files).\n",
    "AcceptedAnswerId": 72046625,
    "AcceptedAnswer": "To install Java SE:\nGo here.\n\nScroll down to find your product. I chose Java SE 11. (Oracle will probably list later versions as they are made available.)\nChoose your operating system. I chose MacOS.\nChoose your file set. I chose the DMG installer.\nDownload your chosen file set.\n\n\n5. Do whatever is required by your platform to install Java SE using the downloaded file set from #5.\nAfter installing Java SE 11, java -version now says \"11.0.14\" and Firebase Tools is now satisfied. My best guess is that JRE 11 was implicitly downloaded, and that developers need to start ignoring the main Download page used by everyone else. (Why didn't the main Download page recommend Java 11 from the start?) Hopefully someone will see this question and clarify whether in the future, the 'Java SE' product implicitly includes both the JRE and SDK, and that the numbering system will always encompass both. In other words, hopefully when someone says we need 'Java 11', it means that we need to download SE 11, containing JRE 11 and SDK 11.\n"
}
{
    "Id": 72140664,
    "PostTypeId": 1,
    "Title": "Azure build error: \"Android Gradle plugin requires Java 11 to run. You are currently using Java 1.8\"",
    "Body": "When building Flutter app in azure devOps, I receive this error:\nBuild file 'D:\\a\\1\\s\\android\\app\\build.gradle' line: 24\n\n* What went wrong:\nA problem occurred evaluating project ':app'.\n> Failed to apply plugin 'com.android.internal.application'.\n   > Android Gradle plugin requires Java 11 to run. You are currently using Java 1.8.\n     You can try some of the following options:\n       - changing the IDE settings.\n       - changing the JAVA_HOME environment variable.\n       - changing `org.gradle.java.home` in `gradle.properties`.\n\nI've tried, these solutions:\n\nCreating jitpack.yml file, with - openjdk11 value.\nAdding below lines to app/build.gradle file inside android {} block:\n\n...\ncompileOptions {\n\nsourceCompatibility JavaVersion.VERSION_11\n\n    targetCompatibility JavaVersion.VERSION_11\n}\n\nkotlinOptions {\n    jvmTarget = JavaVersion.VERSION_11.toString()\n}\n\nAnd another solutions, but my error doesn't solve. By the way, I easily run app and build apk, locally on my mac without any errors, but when I push my code, Azure gives those build error.\n",
    "AcceptedAnswerId": 72140711,
    "AcceptedAnswer": "My error is solved by adding below lines into azure-pipelines.yml file:\nsteps:\n - task: JavaToolInstaller@0\n    inputs:\n      versionSpec: '11'\n      jdkArchitectureOption: 'x64'\n      jdkSourceOption: 'PreInstalled'\n\n"
}
{
    "Id": 73187929,
    "PostTypeId": 1,
    "Title": "Android Studio Chipmunk (2021.2.1) Java 8 library desugaring in D8 and R8 Build Error: \"Unsupported desugared library configuration version\"",
    "Body": "After updating my apps build gradle and dependencies (I did not update Android Studio itself), Android Studio is giving me this error: Error: Unsupported desugared library configuration version, please upgrade the D8/R8 compiler.\nBefore the update everything compiled fine.\nI am using:\n\ncom.android.tools:desugar_jdk_libs:1.2.0 (This was the newest version I could find)\nGradle plugin version 7.2.0\nGradle version 7.5\nAndroid Studio version Chipmunk (2021.2.1)\n\nDid I configuration something wrong? How can I fix this? Thanks in advance!\n",
    "AcceptedAnswerId": 73189430,
    "AcceptedAnswer": "According to this page, the minimum version of Android Gradle plugin required is 7.3.0-beta03 to be able to upgrade the desugar library to 1.2.0, and 7.3.x is not yet available for Android Studio Chipmunk.\n"
}
{
    "Id": 71080814,
    "PostTypeId": 1,
    "Title": "How to let JPArepository.save() do insert only and prevent update?",
    "Body": "I am using JPArepository.save() to insert the record to the database but it will automatically update the existing record in the database. What I want to do is let it throw exception if there are records with same primary key in the database.\nI searched the solution in Google and find a solution that said use saveAndFlush instead of save can solve it. However, it still update the existing record after I used saveAndFlush.\n",
    "AcceptedAnswerId": 73328759,
    "AcceptedAnswer": "Finally, I've found the solution.\nI just implement Persistable interface and ovrride the isNew() to be always true.\nExample:\n@Entity\npublic class ChessGame implements Persistable {\n \n    @Id\n    private Long id;\n\n \n    @Override\n    public boolean isNew() {\n        return true;\n    }\n}\n\n"
}
{
    "Id": 72508332,
    "PostTypeId": 1,
    "Title": "Android Studio: \"attempting to assign weaker access privileges\" error on Room Database implementation",
    "Body": "I am trying to implement room database, I have gone through steps on Official Website, and 'AppDatabase.java' file is like this:\nimport android.content.Context;\nimport androidx.room.Database;\nimport androidx.room.Room;\nimport androidx.room.RoomDatabase;\n\n@Database(entities = {User.class}, version = 1)\npublic abstract class AppDatabase extends RoomDatabase {\n\n    public static AppDatabase instance;\n    public static synchronized AppDatabase getInstance(Context context){\n        if (instance==null){\n            instance = Room.databaseBuilder(context.getApplicationContext(),\n                    AppDatabase.class, \"app_database\").fallbackToDestructiveMigration().build();\n        }\n        return instance;\n    }\n}\n\nAnd dependencies I have used for room:\n    // Room Database\n    def room_version = \"2.4.2\"\n\n    implementation \"androidx.room:room-runtime:$room_version\"\n    annotationProcessor \"androidx.room:room-compiler:$room_version\"\n\n    // optional - RxJava2 support for Room\n    implementation \"androidx.room:room-rxjava2:$room_version\"\n\n    // optional - RxJava3 support for Room\n    implementation \"androidx.room:room-rxjava3:$room_version\"\n\n    // optional - Guava support for Room, including Optional and ListenableFuture\n    implementation \"androidx.room:room-guava:$room_version\"\n\n    // optional - Test helpers\n    testImplementation \"androidx.room:room-testing:$room_version\"\n\n    // optional - Paging 3 Integration\n    implementation \"androidx.room:room-paging:2.5.0-alpha02\"\n\n    // Room Database\n\nIt returns 2 errors here:\nonCreate(SupportSQLiteDatabase) in  cannot override onCreate(SupportSQLiteDatabase) in Delegate\nattempting to assign weaker access privileges; was public\n\nonValidateSchema(SupportSQLiteDatabase) in  cannot override onValidateSchema(SupportSQLiteDatabase) in Delegate\nattempting to assign weaker access privileges; was public\n\nIt was working before the 'Chipmunk' version (was working in 'Bumblebee'), but it started throwing these errors.\nWhat is going on here?\n",
    "AcceptedAnswerId": 72518409,
    "AcceptedAnswer": "To fix this error for Jetpack Compose and Paging 3 you only need to use only this libraries\n//ROOM\nimplementation \"androidx.room:room-runtime:2.4.2\"\nkapt \"androidx.room:room-compiler:2.4.2\"\nimplementation \"androidx.room:room-ktx:2.4.2\"\nimplementation \"androidx.room:room-paging:2.4.2\"\n\n// Paging 3.0\nimplementation 'androidx.paging:paging-compose:1.0.0-alpha15'\n\n"
}
{
    "Id": 73330135,
    "PostTypeId": 1,
    "Title": "Regex for finding only single alphabets in a string and ignore consecutive double",
    "Body": "I have searched a lot but I am unable to find a regex that could select only single alphabets and double them while those alphabets which are already double, should remain untouched.\nI tried\nString str = \"yahoo\";\nstr = str.replaceAll(\"(\\\\w)\\\\1+\", \"$0$0\");\n\nBut since this (\\\\w)\\\\1+ selects all double elements, my output becomes yahoooo. I tried to add negation to it !(\\\\w)\\\\1+ but didn't work and output becomes same as input. I have tried\nstr.replaceAll(\".\", \"$0$0\");\n\nBut that doubles every character including which are already doubled.\nPlease help to write an regex that could replace all single character with double while double character should remain untouched.\nExample\nabc -> aabbcc\nyahoo -> yyaahhoo (o should remain untouched)\nopinion -> ooppiinniioonn\naaaaaabc -> aaaaaabbcc\n\n",
    "AcceptedAnswerId": 73330294,
    "AcceptedAnswer": "You can match using this regex:\n((.)\\2+)|(.)\n\nAnd replace it with:\n$1$3$3\n\nRegEx Demo\nRegEx Explanation:\n\n((.)\\2+): Match a character and capture in group #2 and using \\2+ next to it to make sure we match all multiple repeats of captured character. Capture all the repeated characters in group #1\n|: OR\n(.): Match any character and capture in group #3\n\nCode Demo:\nimport java.util.List;\n \nclass Ideone {\n \n    public static void main(String[] args) {\n        List input = List.of(\"aaa\", \"abc\", \"yahoo\",\n                \"opinion\", \"aaaaaabc\");\n \n        for (String s: input) {\n            System.out.println( s + \" => \" +\n                  s.replaceAll(\"((.)\\\\2+)|(.)\", \"$1$3$3\") );\n        }\n    }\n}\n\nOutput:\naaa => aaa\nabc => aabbcc\nyahoo => yyaahhoo\nopinion => ooppiinniioonn\naaaaaabc => aaaaaabbcc\n\n"
}
{
    "Id": 71281032,
    "PostTypeId": 1,
    "Title": "Spring Security exposing AuthenticationManager without WebSecurityConfigurerAdapter",
    "Body": "I'm trying incoming Spring Boot 2.7.0-SNAPSHOT, which uses Spring Security 5.7.0, which deprecate WebSecurityConfigurerAdapter.\nI read this blog post, but I'm not sure to understand how I can expose the default implementation of AuthenticationManager to my JWT authorization filter.\nThe old WebSecurityConfig, using WebSecurityConfigurerAdapter (works fine) :\n@Configuration\n@EnableGlobalMethodSecurity(prePostEnabled = true)\npublic class WebSecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Autowired\n    private JWTTokenUtils jwtTokenUtils;\n\n    @Bean\n    protected AuthenticationManager getAuthenticationManager() throws Exception {\n        return authenticationManager();\n    }\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http\n                // disable CSRF as we do not serve browser clients\n                .csrf().disable()\n                // allow access restriction using request matcher\n                .authorizeRequests()\n                // authenticate requests to GraphQL endpoint\n                .antMatchers(\"/graphql\").authenticated()\n                // allow all other requests\n                .anyRequest().permitAll().and()\n                // JWT authorization filter\n                .addFilter(new JWTAuthorizationFilter(getAuthenticationManager(), jwtTokenUtils))\n                // make sure we use stateless session, session will not be used to store user's state\n                .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS);\n    }\n\n}\n\nThe new WebSecurityConfig :\n@Configuration\n@EnableGlobalMethodSecurity(prePostEnabled = true)\npublic class WebSecurityConfig {\n\n    @Autowired\n    private JWTTokenUtils jwtTokenUtils;\n\n    @Bean\n    public SecurityFilterChain filterChain(HttpSecurity http) throws Exception {\n        final AuthenticationManager authenticationManager = http.getSharedObject(AuthenticationManager.class);\n        http\n                // disable CSRF as we do not serve browser clients\n                .csrf().disable()\n                // allow access restriction using request matcher\n                .authorizeRequests()\n                // authenticate requests to GraphQL endpoint\n                .antMatchers(\"/graphql\").authenticated()\n                // allow all other requests\n                .anyRequest().permitAll().and()\n                // JWT authorization filter\n                .addFilter(new JWTAuthorizationFilter(authenticationManager, jwtTokenUtils))\n                // make sure we use stateless session, session will not be used to store user's state\n                .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS);\n        return http.build();\n    }\n\n}\n\nAs you see I have no AuthenticationManager exposed bean anymore. I cannot get it from the WebSecurityConfigurerAdapter. So I tried to get it directly from the HttpSecurity in the filterChain method, so I can pass it to my JWT filter directly.\nBut I still need an AuthenticationManager bean to be exposed to my JWTAuthorizationFilter :\n\nParameter 0 of constructor in com.example.config.security.JWTAuthorizationFilter required a bean of type 'org.springframework.security.authentication.AuthenticationManager' that could not be found.\n\nHow can I expose it?\nHere is the JWT authorization filter (checks the token and authenticate the user, I have a custom UserDetailsService which do the credentials check in the database) :\n@Component\npublic class JWTAuthorizationFilter extends BasicAuthenticationFilter {\n\n    private final JWTTokenUtils jwtTokenUtils;\n\n    public JWTAuthorizationFilter(AuthenticationManager authManager, JWTTokenUtils jwtTokenUtils) {\n        super(authManager);\n        this.jwtTokenUtils = jwtTokenUtils;\n    }\n\n    @Override\n    protected void doFilterInternal(HttpServletRequest req, HttpServletResponse res, FilterChain chain) throws IOException, ServletException {\n\n        // retrieve request authorization header\n        final String authorizationHeader = req.getHeader(\"Authorization\");\n\n        // authorization header must be set and start with Bearer\n        if (authorizationHeader != null && authorizationHeader.startsWith(\"Bearer \")) {\n\n            // decode JWT token\n            final JWTTokenPayload jwtTokenPayload = jwtTokenUtils.decodeToken(authorizationHeader);\n\n            // if user e-mail has been retrieved correctly from the token and if user is not already authenticated\n            if (jwtTokenPayload.getEmail() != null && SecurityContextHolder.getContext().getAuthentication() == null) {\n\n                // authenticate user\n                final UsernamePasswordAuthenticationToken authentication = new UsernamePasswordAuthenticationToken(jwtTokenPayload.getEmail(), null, Collections.singletonList(jwtTokenPayload.getRole()));\n\n                // set authentication in security context holder\n                SecurityContextHolder.getContext().setAuthentication(authentication);\n\n            } else {\n                log.error(\"Valid token contains no user info\");\n            }\n        }\n        // no token specified\n        else {\n            res.setStatus(HttpServletResponse.SC_BAD_REQUEST);\n        }\n\n        // pass request down the chain, except for OPTIONS requests\n        if (!\"OPTIONS\".equalsIgnoreCase(req.getMethod())) {\n            chain.doFilter(req, res);\n        }\n\n    }\n\n}\n\nEDIT :\nI realized I can manage to get the authenticationManager in my JWT filter using the method provided in this issue, but still I need an AuthenticationManager to be exposed globally because I also need it in my controller.\nHere is the authentication controller which need the authenticationManager to be injected :\n@RestController\n@CrossOrigin\n@Component\npublic class AuthController {\n\n    @Autowired\n    private JWTTokenUtils jwtTokenUtils;\n\n    @Autowired\n    private AuthenticationManager authenticationManager;\n\n    @RequestMapping(value = \"/authenticate\", method = RequestMethod.POST)\n    public ResponseEntity authenticate(@RequestBody JWTRequest userRequest) {\n\n        // try to authenticate user using specified credentials\n        final Authentication authentication = authenticationManager.authenticate(new UsernamePasswordAuthenticationToken(userRequest.getEmail(), userRequest.getPassword()));\n\n        // if authentication succeeded and is not anonymous\n        if (authentication != null && !(authentication instanceof AnonymousAuthenticationToken) && authentication.isAuthenticated()) {\n\n            // set authentication in security context holder\n            SecurityContextHolder.getContext().setAuthentication(authentication);\n\n            // get authorities, we should have only one role per member so simply get the first one\n            final GrantedAuthority grantedAuthority = authentication.getAuthorities().iterator().next();\n\n            // generate new JWT token\n            final String jwtToken = jwtTokenUtils.generateToken(authentication.getPrincipal(), grantedAuthority);\n\n            // return response containing the JWT token\n            return ResponseEntity.ok(new JWTResponse(jwtToken));\n        }\n\n        return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).build();\n\n    }\n\n}\n\n",
    "AcceptedAnswerId": 72598317,
    "AcceptedAnswer": "If you want the AuthenticationManager bean to be in the spring context, you can use the following solution.\n@Bean\npublic AuthenticationManager authenticationManager(AuthenticationConfiguration authenticationConfiguration) throws Exception {\n     return authenticationConfiguration.getAuthenticationManager();\n}\n\nThis approach has solved the problem for me and you can inject AuthenticationManager wherever you need.\n"
}
{
    "Id": 72111416,
    "PostTypeId": 1,
    "Title": "Error inflating class com.google.android.material.button.MaterialButton",
    "Body": "What i'm trying to achieve is having a gridview with some materialButton inside.\nI tried to create the gridview like :\n<GridView\n            android:id=\"@+id/login_gridview_code_input\"\n            android:layout_width=\"match_parent\"\n            android:layout_height=\"wrap_content\"\n            android:numColumns=\"3\"\n            android:horizontalSpacing=\"15dp\"\n            android:verticalSpacing=\"15dp\">\n        \n\nAnd the element to be inflated like:\n\n<androidx.constraintlayout.widget.ConstraintLayout xmlns:android=\"http://schemas.android.com/apk/res/android\"\n    xmlns:app=\"http://schemas.android.com/apk/res-auto\"\n    android:layout_width=\"match_parent\"\n    android:layout_height=\"match_parent\">\n\n        <com.google.android.material.button.MaterialButton\n            android:id=\"@+id/button_code_digit\"\n            style=\"@style/Widget.MaterialComponents.Button.OutlinedButton.Icon\"\n            android:layout_width=\"50dp\"\n            android:layout_height=\"50dp\"\n            android:insetLeft=\"0dp\"\n            android:insetTop=\"0dp\"\n            android:insetRight=\"0dp\"\n            android:insetBottom=\"0dp\"\n            android:padding=\"0dp\"\n            app:iconGravity=\"textStart\"\n            app:iconPadding=\"0dp\"\n            app:iconSize=\"40dp\"\n            app:layout_constraintBottom_toBottomOf=\"parent\"\n            app:layout_constraintEnd_toEndOf=\"parent\"\n            app:layout_constraintStart_toStartOf=\"parent\"\n            app:layout_constraintTop_toTopOf=\"parent\"\n            app:shapeAppearanceOverlay=\"@style/ShapeAppearanceOverlay.pswStorer.Button.Circle\" />\n\n\n\nthe adapter inflates the button :\ninflter = (LayoutInflater.from(applicationContext)); \nview = inflter.inflate(R.layout.button_code, null); // inflate the layout\n\nbut I always receive this stacktrace :\nError inflating class com.google.android.material.button.MaterialButton\nCaused by: java.lang.IllegalArgumentException: The style on this component requires your app theme to be Theme.MaterialComponents (or a descendant).\n\nI checked the appTheme but seems correct to me:\n\n        \n        @color/colorPrimary\n        @color/colorPrimaryDark\n        @color/colorAccent\n        @style/AlertDialogMaterialTheme\n    \n\nAny ideas?\nEDIT: I tried to check and my app has the correct theme\nandroid:theme=\"@style/AppTheme\"\n\nI also changed the theme to Theme.MaterialComponents.DayNight.NoActionBar.Bridge but nothing changed\n",
    "AcceptedAnswerId": 72169923,
    "AcceptedAnswer": "The issue is here.\ninflter = (LayoutInflater.from(applicationContext)); \n\nThe Application context doesn't have your app theme.\nYou have to use a themed context like an Activity.\n"
}
{
    "Id": 72684930,
    "PostTypeId": 1,
    "Title": "Convert List<char[]> into an Array char[] without using System.arraycopy()",
    "Body": "What's a simple way to convert/flatten a List to char[] in Java?\nI know I can do it by iterating the List and using System.arraycopy,  but I'm wondering is there a simpler way to do it using Java 8 streams?\nMaybe something like this, but without having to box the primitive char to Character:\nList listOfCharArrays = ...\n\nCharacter[] charArray =\n    Stream.of(listOfCharArrays )\n        .flatMap(List::stream)\n        .toArray(Character[]::new);\n\n",
    "AcceptedAnswerId": 72685373,
    "AcceptedAnswer": "I can think of only one thing, and that is to use CharBuffer. For efficiency reasons I would always first calculate the right size, and then perform the copy. Any solution that performs multiple copies and/or performs string handling will be inefficient.\nHere's the code. The first line calculates the total size of the array required, and then allocates just enough memory for it. The second line performs the copying using the aforementioned put method. The final line returns the char[] that is backing the CharBuffer.\nCharBuffer fullBuffer = CharBuffer.allocate(\n        listOfCharArrays.stream().mapToInt(array -> array.length).sum());\nlistOfCharArrays.forEach(fullBuffer::put);\nchar[] asCharArray = fullBuffer.array();\n\nOf course, I cannot guarantee that it won't use System.arrayCopy somewhere inside of the CharBuffer#put method. I would strongly expect that it will use System.arrayCopy or similar code internally. That probably goes for most solutions provided here though.\nIt is possible to avoid the first size calculation by using a large enough buffer if you can estimate a maximum size, but it would require an additional copy of the data in the buffer; CharBuffer#array simply returns the correctly sized backing array, which means that the data is copied only once.\n\nYou can also use CharBuffer directly if you want to use object oriented code. Beware that you need to make sure that you flip it after writing to it though, and that CharBuffer is mutable (you can pass copies using the duplicate or asReadOnly methods - the returned instances reference the same buffer, but have independent, mutable \"position\" and \"limit\" fields).\nThe Buffer and Java NIO classes are slightly tricky to understand, but once you do you get great benefits from them, e.g. when using them for CharEncoder or memory mapped files.\n"
}
{
    "Id": 74011238,
    "PostTypeId": 1,
    "Title": "Understanding Java 17 Vector slowness and performance with pow operator",
    "Body": "I have a question relating to the pow() function in Java's 17 new Vector API feature. I'm trying to implement the black scholes formula in a vectorized manner, but I'm having difficulty in obtaining the same performance as the scalar implementation\nThe code is as follows:\n\nI create an array of doubles (currently, just 5.0)\nI loop over elements of that array (different looping syntax for scalar and vector)\nI create DoubleVectors from the double arrays within and do calculations (or just calculations for scalar) I am trying to do e^(value), and I believe that is the problem\n\nHere are some code snippets:\n    public static double[] createArray(int arrayLength)\n    {\n        double[] array0 = new double[arrayLength];\n        for(int i=0;i<arrayLength;i++)\n        {\n            array0[i] = 2.0;\n        }\n        return array0;\n    } \n\n    @Param({\"256000\"})\n    int arraySize;\n    public static final VectorSpecies SPECIES = DoubleVector.SPECIES_PREFERRED;\n    DoubleVector vectorTwo =  DoubleVector.broadcast(SPECIES,2);\n    DoubleVector vectorHundred =  DoubleVector.broadcast(SPECIES,100);\n\n    double[] scalarTwo = new double[]{2,2,2,2};\n    double[] scalarHundred  = new double[]{100,100,100,100};\n\n    @Setup\n    public void Setup()\n    {\n        javaSIMD = new JavaSIMD();\n        javaScalar = new JavaScalar();\n        spotPrices = createArray(arraySize);\n        timeToMaturity = createArray(arraySize);\n        strikePrice = createArray(arraySize);\n        interestRate = createArray(arraySize);\n        volatility = createArray(arraySize);\n        e = new double[arraySize];\n        for(int i=0;i<arraySize;i++)\n        {\n            e[i] = Math.exp(1);\n        }\n        upperBound = SPECIES.loopBound(spotPrices.length);\n    }\n    @Benchmark\n    @BenchmarkMode(Mode.Throughput)\n    @OutputTimeUnit(TimeUnit.MILLISECONDS)\n    public void testVectorPerformance(Blackhole bh) {\n        var upperBound = SPECIES.loopBound(spotPrices.length);\n        for (var i=0;i<upperBound; i+= SPECIES.length())\n        {\n            bh.consume(javaSIMD.calculateBlackScholesSingleCalc(spotPrices,timeToMaturity,strikePrice,\n                    interestRate,volatility,e, i));\n        }\n    }\n\n    @Benchmark\n    @BenchmarkMode(Mode.Throughput)\n    @OutputTimeUnit(TimeUnit.MILLISECONDS)\n    public void testScalarPerformance(Blackhole bh) {\n        for(int i=0;i<arraySize;i++)\n        {\n            bh.consume(javaScalar.calculateBlackScholesSingleCycle(spotPrices,timeToMaturity,strikePrice,\n                    interestRate,volatility, i,normDist));\n        }\n    }\n\n    public DoubleVector calculateBlackScholesSingleCalc(double[] spotPrices, double[] timeToMaturity, double[] strikePrice,\n                                                        double[] interestRate, double[] volatility, double[] e,int i){\n...(skip lines)\n        DoubleVector vSpot = DoubleVector.fromArray(SPECIES, spotPrices, i);\n...(skip lines)\n        DoubleVector powerOperand = vRateScaled\n                .mul(vTime)\n                .neg();\n        DoubleVector call  = (vSpot\n                .mul(CDFVectorizedExcelOptimized(d1,vE)))\n                .sub(vStrike\n                .mul(vE\n                        .pow(powerOperand))\n                .mul(CDFVectorizedExcelOptimized(d2,vE)));\n        return call;\n\nHere are some JMH benchmarks (2 forks,2 warmups,2 iterations) on a Ryzen 5800X using WSL: Overall, it seems ~2x slower vs the scalar version.  I ran a simple time before vs time after separately, of the method without JMH and it seems inline.\nResult \"blackScholes.TestJavaPerf.testScalarPerformance\":\n  0.116 \u00b1(99.9%) 0.002 ops/ms [Average]\n       89873915287      cycles:u                  #    4.238 GHz                      (40.43%)\n      242060738532      instructions:u            #    2.69  insn per cycle   \n\n      \nResult \"blackScholes.TestJavaPerf.testVectorPerformance\":\n  0.071 \u00b1(99.9%) 0.001 ops/ms [Average]\n       90878787665      cycles:u                  #    4.072 GHz                      (39.25%)\n      254117779312      instructions:u            #    2.80  insn per cycle  \n\nI also enabled diagnostic options for the JVM. I see the following:\n\"-XX:+UnlockDiagnosticVMOptions\", \"-XX:+PrintIntrinsics\",\"-XX:+PrintAssembly\"\n\n  0x00007fe451959413:   call   0x00007fe451239f00           ; ImmutableOopMap {rsi=Oop }\n                                                            ;*synchronization entry\n                                                            ; - jdk.incubator.vector.DoubleVector::arrayAddress@-1 (line 3283)\n                                                            ;   {runtime_call counter_overflow Runtime1 stub}\n  0x00007fe451959418:   jmp    0x00007fe4519593ce\n  0x00007fe45195941a:   movabs $0x7fe4519593ee,%r10         ;   {internal_word}\n  0x00007fe451959424:   mov    %r10,0x358(%r15)\n  0x00007fe45195942b:   jmp    0x00007fe451193100           ;   {runtime_call SafepointBlob}\n  0x00007fe451959430:   nop\n  0x00007fe451959431:   nop\n  0x00007fe451959432:   mov    0x3d0(%r15),%rax\n  0x00007fe451959439:   movq   $0x0,0x3d0(%r15)\n  0x00007fe451959444:   movq   $0x0,0x3d8(%r15)\n  0x00007fe45195944f:   add    $0x40,%rsp\n  0x00007fe451959453:   pop    %rbp\n  0x00007fe451959454:   jmp    0x00007fe451231e80           ;   {runtime_call unwind_exception Runtime1 stub}\n  0x00007fe451959459:   hlt    \n   \n[Exception Handler]\n  0x00007fe451959460:   call   0x00007fe451234580           ;   {no_reloc}\n  0x00007fe451959465:   movabs $0x7fe46e76df9a,%rdi         ;   {external_word}\n  0x00007fe45195946f:   and    $0xfffffffffffffff0,%rsp\n  0x00007fe451959473:   call   0x00007fe46e283d40           ;   {runtime_call}\n  0x00007fe451959478:   hlt    \n[Deopt Handler Code]\n  0x00007fe451959479:   movabs $0x7fe451959479,%r10         ;   {section_word}\n  0x00007fe451959483:   push   %r10\n  0x00007fe451959485:   jmp    0x00007fe4511923a0           ;   {runtime_call DeoptimizationBlob}\n  0x00007fe45195948a:   hlt    \n\n--------------------------------------------------------------------------------\n\n============================= C2-compiled nmethod ==============================\n  ** svml call failed for double_pow_32\n                                            @ 3   jdk.internal.misc.Unsafe::loadFence (0 bytes)   (intrinsic)\n                                            @ 3   jdk.internal.misc.Unsafe::loadFence (0 bytes)   (intrinsic)\n                                          @ 2   java.lang.Math::pow (6 bytes)   (intrinsic)\n\nInvestigations/Questions:\n\nIm writing different implementations of the formula, it is not 1:1 - could this be the cause? Looking at the number of instructions according to JMH, there is roughly a 12billion difference in num of instructions. With vectorization the processor runs at a lower clock rate as well.\nIs the choice of input numbers a problem? I've tried i+10/(array.Length) as well.\nIs there a reason I see that the SVML call fail for double_pow_32 ? I don't see this problem for smaller input array sizes BTW\nI changed the pow to mul (for both,obviously the eq is now very different) but it seems to be much faster as a result, results are as expected scalar vs vector\n\nNote: I believe it is using 256bit width vectors (checked during debugging)\n",
    "AcceptedAnswerId": 74017185,
    "AcceptedAnswer": "This might be related to JDK-8262275, Math vector stubs are not called for double64 vectors\n\nFor Double64Vector, the svml math vector stubs intrinsification is failing and they are not being called from jitted code.\nBut we do have svml double64 vectors.\n\nYou might try alternative operations, e.g. instead of vE.pow(powerOperand) with vE being a vector of e, you can use powerOperand.lanewise(VectorOperators.EXP) to perform ex for all lanes.\nKeep in mind that this API is work in progress in incubator state\u2026\n"
}
{
    "Id": 72192789,
    "PostTypeId": 1,
    "Title": "CteInsertStrategy can only be used with Dialects that support CTE that can take UPDATE or DELETE statements as well",
    "Body": "Hibernate 6.0.1 with PostgreSQL JDBC driver 42.3.5 causes the following exception:\njava.lang.UnsupportedOperationException:\nCteInsertStrategy can only be used with Dialects that support CTE that can take UPDATE or DELETE statements as well\nat org.hibernate.query.sqm.mutation.internal.cte.CteInsertStrategy.(CteInsertStrategy.java:123)\nat org.hibernate.query.sqm.mutation.internal.cte.CteInsertStrategy.(CteInsertStrategy.java:107)\nat org.hibernate.dialect.PostgreSQLDialect.getFallbackSqmInsertStrategy(PostgreSQLDialect.java:704)\n...\n\nWhat's wrong and how can I fix the issue?\nMyEntity.java\nimport jakarta.persistence.*;\n\n@Entity\n@Table(name = \"my_entity\")\npublic class MyEntity {\n\n    private Long id;\n\n    @Id\n    @SequenceGenerator(name = \"id_sequence\", sequenceName = \"my_id_sequence\")\n    @GeneratedValue(strategy = GenerationType.AUTO, generator = \"id_sequence\")\n    public Long getId() {\n        return this.id;\n    }\n    public void setId(Long id) {\n        this.id = id;\n    }\n\n}\n\nMyTest.java\nimport static org.junit.Assert.assertNotNull;\n\nimport org.hibernate.*;\nimport org.hibernate.cfg.*;\nimport org.junit.*;\n\npublic class MyTest {\n\n    private static Configuration configuration;\n    private static SessionFactory sessionFactory;\n\n    @BeforeClass\n    public static void setUpBeforeClass() throws Exception {\n        configuration = new Configuration().configure();\n        sessionFactory = configuration.buildSessionFactory();\n    }\n\n    @AfterClass\n    public static void tearDownAfterClass() throws Exception {\n        sessionFactory.close();\n    }\n\n    private Session session;\n\n    @Before\n    public void setUp() throws Exception {\n        session = sessionFactory.openSession();\n    }\n\n    @After\n    public void tearDown() throws Exception {\n        session.close();\n    }\n\n    @Test\n    public void test() {\n        Transaction transaction = session.beginTransaction();\n        MyEntity entity = new MyEntity();\n        session.persist(entity);\n        assertNotNull(entity.getId());\n        transaction.commit();\n    }\n\n}\n\nhibernate.cfg.xml\n\n\n\n  \n    org.postgresql.Driver\n    org.hibernate.dialect.PostgreSQLDialect  \n    jdbc:postgresql://localhost:5432/mydb\n    update\n    postgres\n    false\n    1\n    30\n    120\n    100\n    \n  \n\n\nbuild.gradle\nplugins {\n    id 'java-library'\n}\n\nrepositories {\n    mavenCentral()\n}\n\next {\n    hibernateVersion = '6.0.1.Final'\n}\n\ndependencies {\n    implementation 'org.postgresql:postgresql:42.3.5'\n    implementation 'org.hibernate.orm:hibernate-c3p0:' + hibernateVersion\n    implementation 'org.hibernate.orm:hibernate-core:' + hibernateVersion\n    testImplementation 'junit:junit:4.13.2'\n}\n\nSee the full source code here.\n",
    "AcceptedAnswerId": 72207378,
    "AcceptedAnswer": "The configuration property use_jdbc_metadata_defaults must be true for Hibernate to detect the correct version of the PostgreSQL dialect.\nRemoving this line\nfalse\n\nfrom hibernate.cfg.xml resolves the issue.\n(Thanks to Christian at Hibernate Zulip channel for sorting this out.)\n"
}
{
    "Id": 72712390,
    "PostTypeId": 1,
    "Title": "Defining additional placeholder/property only in beans.xml",
    "Body": "I have a list of strings, that i would like to define in beans.xml.\n\n    #{ T(com.myapp.longname.verylong.WelcomeController).RED_FRACTION }\n    #{ T(com.myapp.longname.verylong.WelcomeController).BLUE_FRACTION }\n    #{ T(${my.prefix}).GREEN_FRACTION }\n\n\nIt works fine, but each time I need to write the full qualified constant's name com.myapp.longname.verylong.WelcomeController. I would like to write it only once. One solution I have found is to replace it with a property like my.prefix so I can write only my short prefix instead of the real full path. But then I will need to pollute the global \"namespace\" with property that is only needed once. I would like to define a placeholder only for this list or at least only for this beans.xml file. I have already tried to define a property directly in beans.xml with PropertyPlaceholderConfigurer and it works, but then all my inital properties are not available anymore.\nSo how can I avoid to  writing com.myapp.longname.verylong.WelcomeController each time in a list as a prefix and only define it once? Ideally something like\n\n    \n    #{ T(${my.prefix}).RED_FRACTION }\n    #{ T(${my.prefix}).BLUE_FRACTION }\n    #{ T(${my.prefix}).GREEN_FRACTION }\n\n\n",
    "AcceptedAnswerId": 72776113,
    "AcceptedAnswer": "Please give a try on this\n\n\n\n    com.myapp.longname.verylong.WelcomeController\n\n\n\n    #{ T(${shorthandHelperConstants['my.prefix']}).RED_FRACTION }\n    #{ T(${shorthandHelperConstants['my.prefix']}).BLUE_FRACTION }\n    #{ T(${shorthandHelperConstants['my.prefix']}).GREEN_FRACTION }\n\n\n"
}
{
    "Id": 74356407,
    "PostTypeId": 1,
    "Title": "How to get the date and time in format 2022-10-03T19:45:47.844Z in Java",
    "Body": "I need the current system date and time in 2022-10-03T19:45:47.844Z format in a java class.\nI tried using the zoneddatetime and simple date format but couldn't get the write syntax or code from online. I'm beginner in Java, any help is appreciated.\nThanks.\n",
    "AcceptedAnswerId": 74356572,
    "AcceptedAnswer": "I hope this solves your problem:\nimport java.time.ZoneId;\nimport java.time.ZonedDateTime;\nimport java.time.format.DateTimeFormatter;\n\npublic class Main {\n    public static void main(String[] args) {\n        ZonedDateTime zdt = ZonedDateTime.now(ZoneId.of(\"UTC\"));\n        DateTimeFormatter formatter =\n                DateTimeFormatter.ofPattern(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\");\n        System.out.println(zdt.format(formatter));\n    }\n}\n\n"
}
{
    "Id": 72989618,
    "PostTypeId": 1,
    "Title": "Does the order of if else matter for performance? e.g. put the most likely condition in the front is better",
    "Body": "I'm trying to measure if the order of if else affects performance.\nFor example, if\nif (condition == more likely condition) {}\nelse /** condition == rare condition **/ {}\n\nis faster than\nif (condition == rare condition) {}\nelse /** condition == more likely condition **/ {}\n\nI think maybe JIT should be able to optimise it no matter which order I put it? Couldn't find any documentation on this though.\nI tried to test it out myself with following benchmark. Based on it, I don't see strong evidence that the order matters. Because if it does, I think the throughput when bias=0.9 (probability of if (zeroOrOne == 1) is true is 0.9) should be higher than when bias=0.1 (else probability is 0.9).\npublic class BranchBench {\n    @Param({ \"0.02\", \"0.1\", \"0.9\", \"0.98\", })\n    private double bias;\n\n    @Param(\"10000\")\n    private int count;\n\n    private final List randomZeroOnes = new ArrayList(count);\n\n    @Setup\n    public void setup() {\n        Random r = new Random(12345);\n\n        for (int c = 0; c < count; c++) {\n            byte zeroOrOne = (byte) (c < (bias * count) ? 1 : 0);\n            randomZeroOnes.add(zeroOrOne);\n        }\n        Collections.shuffle(randomZeroOnes, r);\n    }\n\n    @Benchmark\n    public int static_ID_ifElse() {\n        int i = 0;\n        for (final Byte zeroOrOne : randomZeroOnes) {\n            if (zeroOrOne == 1) {\n                i++;\n            } else {\n                i--;\n            }\n        }\n        return i;\n    }\n}\n\nBenchmark                     (bias)  (count)   Mode  Cnt    Score   Error   Units\nBranchBench.static_ID_ifElse    0.02    10000  thrpt   15  137.409 \u00b1 1.376  ops/ms\nBranchBench.static_ID_ifElse     0.1    10000  thrpt   15  129.277 \u00b1 1.552  ops/ms\nBranchBench.static_ID_ifElse     0.9    10000  thrpt   15  125.640 \u00b1 5.858  ops/ms\nBranchBench.static_ID_ifElse    0.98    10000  thrpt   15  137.427 \u00b1 2.396  ops/ms\n\n",
    "AcceptedAnswerId": 72989924,
    "AcceptedAnswer": "On modern processors I don't think the order of your conditionals really matter that much anymore. As part of the instruction pipeline, processors will do what is called branch prediction; where it guesses which condition will be true and pre-loads the instructions into the pipeline.\nThese days, processors guess correctly >90% of the time, so any hand-written conditional tweaking is less important.\nThere are quite a lot of literature on branch prediction:\nhttps://dzone.com/articles/branch-prediction-in-java\nhttps://www.baeldung.com/java-branch-prediction\n"
}
{
    "Id": 72434319,
    "PostTypeId": 1,
    "Title": "entityManagerFactory bean not configured issue with hibernate 6.0.2.Final and spring boot 2.7.0",
    "Body": "so recently i thought of upgrading few dependency of my spring boot project project\nspecifically these components\n\njakarat ee 9\nspring boot 2.7\nhibernate 6.0.2.Final\n\nafter doing this all updates and code refraction: updating imports javax to jakarta, and for few hibernate annotations\nI removed the old hibernate from my local .m2 repository and run this command this mvn clean install test package\nand started the project in intellij and it gave be below error:\n16:15:42.410 [Thread-0] DEBUG org.springframework.boot.devtools.restart.classloader.RestartClassLoader - Created RestartClassLoader org.springframework.boot.devtools.restart.classloader.RestartClassLoader@429054cc\n\n  .   ____          _            __ _ _\n /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\n( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\n \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\n  '  |____| .__|_| |_|_| |_\\__, | / / / /\n =========|_|==============|___/=/_/_/_/\n :: Spring Boot ::                (v2.7.0)\n\n2022-05-30 16:15:42.787  INFO 99522 --- [  restartedMain] com.zee.oms.order.Order                  : Starting Order using Java 17.0.2 on ZL-BLR-MAC170.local with PID 99522 (/Users/manish.prasad/Documents/ZEE-Services/github/zee5-order/target/classes started by manish.prasad in /Users/manish.prasad/Documents/ZEE-Services/github/zee5-order)\n2022-05-30 16:15:42.787 DEBUG 99522 --- [  restartedMain] com.zee.oms.order.Order                  : Running with Spring Boot v2.7.0, Spring v5.3.20\n2022-05-30 16:15:42.787  INFO 99522 --- [  restartedMain] com.zee.oms.order.Order                  : No active profile set, falling back to 1 default profile: \"default\"\n2022-05-30 16:15:42.818  INFO 99522 --- [  restartedMain] .e.DevToolsPropertyDefaultsPostProcessor : Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable\n2022-05-30 16:15:42.818  INFO 99522 --- [  restartedMain] .e.DevToolsPropertyDefaultsPostProcessor : For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'\n2022-05-30 16:15:43.347  INFO 99522 --- [  restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.\n2022-05-30 16:15:43.433  INFO 99522 --- [  restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 81 ms. Found 4 JPA repository interfaces.\n2022-05-30 16:15:43.862  INFO 99522 --- [  restartedMain] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)\n2022-05-30 16:15:43.868  INFO 99522 --- [  restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]\n2022-05-30 16:15:43.868  INFO 99522 --- [  restartedMain] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.63]\n2022-05-30 16:15:43.902  INFO 99522 --- [  restartedMain] o.a.c.c.C.[.[localhost].[/order-srv]     : Initializing Spring embedded WebApplicationContext\n2022-05-30 16:15:43.902  INFO 99522 --- [  restartedMain] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 1084 ms\n2022-05-30 16:15:44.059  WARN 99522 --- [  restartedMain] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'orderController': Unsatisfied dependency expressed through field 'orderService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'orderServiceImpl': Unsatisfied dependency expressed through field 'orderRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'orderRepository' defined in com.zee.oms.order.repository.OrderRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Cannot create inner bean '(inner bean)#14203bc' of type [org.springframework.orm.jpa.SharedEntityManagerCreator] while setting bean property 'entityManager'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name '(inner bean)#14203bc': Cannot resolve reference to bean 'entityManagerFactory' while setting constructor argument; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'entityManagerFactory' available\n2022-05-30 16:15:44.061  INFO 99522 --- [  restartedMain] o.apache.catalina.core.StandardService   : Stopping service [Tomcat]\n2022-05-30 16:15:44.072  INFO 99522 --- [  restartedMain] ConditionEvaluationReportLoggingListener : \n\nError starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.\n2022-05-30 16:15:44.080 ERROR 99522 --- [  restartedMain] o.s.b.d.LoggingFailureAnalysisReporter   : \n\n***************************\nAPPLICATION FAILED TO START\n***************************\n\nDescription:\n\nField orderRepository in com.oms.order.service.impl.OrderServiceImpl required a bean named 'entityManagerFactory' that could not be found.\n\nThe injection point has the following annotations:\n    - @org.springframework.beans.factory.annotation.Autowired(required=true)\n\n\nAction:\n\nConsider defining a bean named 'entityManagerFactory' in your configuration.\n\n\nProcess finished with exit code 0 \n\nthis is my pom:\n\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0\n                             http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    4.0.0\n    \n        org.springframework.boot\n        spring-boot-starter-parent\n        2.7.0\n        \n    \n\n    com.zee\n    zee5-order\n    0.0.1-SNAPSHOT\n    order\n    Spring Boot project for order-service\n    \n        17\n        6.0.2.Final\n    \n\n    \n\n        \n            org.springframework.boot\n            spring-boot-starter-web\n        \n\n        \n            org.springframework.boot\n            spring-boot-devtools\n            runtime\n            true\n        \n        \n        \n            org.springframework.boot\n            spring-boot-starter-actuator\n        \n\n        \n            org.projectlombok\n            lombok\n            provided\n        \n        \n            org.springframework.boot\n            spring-boot-starter-test\n            test\n        \n        \n        \n            org.mockito\n            mockito-all\n            1.10.19\n            test\n        \n        \n            org.postgresql\n            postgresql\n            runtime\n        \n        \n            org.springframework.boot\n            spring-boot-starter-data-jpa\n        \n        \n            org.hibernate\n            hibernate-validator\n            7.0.4.Final\n        \n        \n            jakarta.validation\n            jakarta.validation-api\n            3.0.2\n        \n        \n            org.springdoc\n            springdoc-openapi-ui\n            1.6.8\n        \n        \n            org.springdoc\n            springdoc-openapi-data-rest\n            1.6.8\n        \n        \n            org.springdoc\n            springdoc-openapi-webmvc-core\n            1.6.8\n        \n        \n            org.springdoc\n            springdoc-openapi-webflux-ui\n            1.6.8\n        \n        \n            org.flywaydb\n            flyway-core\n            8.5.10\n        \n        \n            com.common-utility\n            common-utility\n            1.0\n        \n        \n            com.amazonaws\n            aws-java-sdk-secretsmanager\n            1.12.220\n        \n        \n            com.h2database\n            h2\n            2.1.212\n            test\n        \n        \n            com.vladmihalcea\n            hibernate-types-60\n            2.16.2\n        \n    \n\n    \n        \n            \n                org.springframework.boot\n                spring-boot-maven-plugin\n                \n                    \n                        \n                            org.projectlombok\n                            lombok\n                        \n                    \n                \n            \n        \n    \n\n\n\nattaching few screen shots for the added dependencies:\nspring and spring boot dependencies\njakarta dependencies\nany idea or solution if anybody have also upgraded to this version and able to run the project successfully.\nalso iam confused why javax-persistence is still there and not replaced when jakarata-persistence is already added/there.\n",
    "AcceptedAnswerId": 72434705,
    "AcceptedAnswer": "Hibernate 6 (and Hibernate Validator 7 as well) are JakartaEE implementations of respectivly the Jakarta Persistence API and Jakarta Validation API. None of which are currently supported by Spring nor Spring Boot.\nSupport for JakartaEE is coming in Spring Framework 6 and Spring Boot 3 which are scheduled for release later this year.\nFor now keep using the JavaEE versions. In your case you need to do 2 things\n\nRemove the hibernate.version property\nReplace the hibernate-validator and jakarta-validation-api with the spring-boot-starter-validation dependency.\n\nWhen you apply both fixes and later this year upgrade to Spring Boot 3 you will get the proper versions which are compatible.\n"
}
{
    "Id": 73377190,
    "PostTypeId": 1,
    "Title": "Bytecode transforming record class to be mutable",
    "Body": "I just saw that EBean does bytecode transformation of record class files in a way that feels odd to me and I seek an answer about whether this is legal from a JVM point of view.\nApparently, it is possible to have a class file, where the class extends java.lang.Record and defines record component attributes (so it's a \"record\" like javac would create it), but with the following additional \"features\" which javac would not allow:\n\nMake fields for record components non-final\nAdd additional fields that are not set through the canonical constructor, nor exposed through record component attributes\n\nTo me, this seems illegal and I would have expected a JVM verification error. I would like to know if this is something that is \"supported\", which I can build upon, or if the lack of verification is a JVM bug. Are records just a Java language feature without JVM support?! I read that final fields of records are \"truly final\" and can't be changed even through reflection and assumed there must be special JVM support that makes sure records match the Java language semantics...\n",
    "AcceptedAnswerId": 73390758,
    "AcceptedAnswer": "Your question posits a false dichotomy.  Records are a language feature, with some degree of JVM support (primarily for reflection), but that doesn't mean that the JVM will (or even can) enforce all the requirements on records that the language requires.  (Gaps like this are inevitable, as the JVM is a more general computing substrate, and which services other languages besides Java; for example, the JVM permits methods to be overloaded on return type, but the language does not.)\nThat said, the behavior you describe is a pretty serious party foul, and those who engage in it should be shamed out of the community.  (It is also possible they are doing so out of ignorance, in which case they might be educable.)  Most likely, these people think they are being \"clever\" in subverting rules they don't like, but in the process, poisoning the well by promoting behaviors that users may find astonishing.\nEDIT\nThe author of the transformer posted some further context here about what they were trying to accomplish.  I'll give them credit for making a good faith effort to conform with the semantics of records, but it undermines the final field semantics, and only appears to work for records that do not customize the constructor, accessors, equals, or hashCode methods.  This describes a lot of records, but not all.  This is a good cautionary tale; even when trying to preserve the semantics of a class while transforming it, it is easy to make questionable assumptions about what the class does or does not do that can get in the way.\nThe author waves away the concern about the final field semantics as \"not likely to cause a problem.\"  But this is not the bar.  The language provides certain semantics for records.  This transformation undermines those semantics, and yet still tells the user they are records.  Even if they are \"minor\" and \"unlikely\", you are breaking the semantics that the Java language promises.  \"99% compatible\" rounds to zero in this case.  So I stand by my assertion that this framework is taking inappropriate liberties with the language semantics.  They may have been well-intentioned, they may have tried hard to not break things, but break things they did.\n"
}
{
    "Id": 73035944,
    "PostTypeId": 1,
    "Title": "Best way to retrieve K largest elements from large unsorted arrays?",
    "Body": "I recently had a coding test during an interview. I was told:\n\nThere is a large unsorted array of one million ints. User wants to retrieve K largest elements. What algorithm would you implement?\n\nDuring this, I was strongly hinted that I needed to sort the array.\nSo, I suggested to use built-in sort() or maybe a custom implementation if performance really mattered. I was then told that using a Collection or array to store the k largest and for-loop it is possible to achieve approximately O(N), in hindsight, I think it's O(N*k) because each iteration needs to compare to the K sized array to find the smallest element to replace, while the need to sort the array would cause the code to be at least O(N log N).\nI then reviewed this link on SO that suggests priority queue of K numbers, removing the smallest number every time a larger element is found, which would also give O(N log N). Write a program to find 100 largest numbers out of an array of 1 billion numbers\nIs the for-loop method bad? How should I justify pros/cons of using the for-loop or the priorityqueue/sorting methods? I'm thinking that if the array is already sorted, it could help by not needing to iterate through the whole array again, i.e. if some other method of retrieval is called on the sorted array, it should be constant time. Is there some performance factor when running the actual code that I didn't consider when theorizing pseudocode?\n",
    "AcceptedAnswerId": 73036179,
    "AcceptedAnswer": "Another way of solving this is using Quickselect. This should give you a total average time complexity of O(n). Consider this:\n\nFind the kth largest number x using Quickselect (O(n))\nIterate through the array again (or just through the right-side partition) (O(n)) and save all elements \u2265 x\nReturn your saved elements\n\n(If there are repeated elements, you can avoid them by keeping count of how many duplicates of x you need to add to the result.)\nThe difference between your problem and the one in the SO question you linked to is that you have only one million elements, so they can definitely be kept in memory to allow normal use of Quickselect.\n"
}
{
    "Id": 73299265,
    "PostTypeId": 1,
    "Title": "Java Stream Collect() classifier can't detect type",
    "Body": "I have the following code reading lines from a text file:\ntry (BufferedReader br = new BufferedReader(new InputStreamReader(Uio.decodeFrom(url)))) {\n        return br.lines()\n                .parallel()\n                .map(s -> s.split(\"\\\\s+\")) // split by whitespace\n                .collect(\n                        Collectors.groupingByConcurrent(\n                                arr -> arr[0], // String 1\n                                Collectors.groupingByConcurrent(\n                                        arr -> arr[arr.length-1], // String 2\n                                        Collectors.counting()\n                                )\n                        )\n                );\n    } catch (IOException e) {\n        throw new UncheckedIOException(e);\n    }\n\nThe text file has data like\nString1     ... cols      ... String2\nstring1data ... otherdata ... string2data\n...\n\nAnd I'm trying to group by String1 and String2 and get their counts. Then end result should be a Map>. However, with the code above, the compiler is saying that the collect() returns a  ConcurrentMap >.\nWhy are the keys not Strings?\n",
    "AcceptedAnswerId": 73299327,
    "AcceptedAnswer": "I can duplicate this error message, but the replacement of String with Object in the error message appears to be a red herring.  The real problem is that Java's generics are invariant.\nIf the call to collect is returning a ConcurrentMap>, that doesn't match Map>, even though a ConcurrentMap is a Map.  The inner Map type must match exactly without a wildcard and bounds.\nIf you introduce an upper-bounded wildcard to the return type, it will compile without error.  Have it return the type Map>, so that the inner ConcurrentMap will match.\nA return type of Map> will also work.\nIt's unclear why String wasn't captured until the generics invariant issue was worked out.  Just a guess: the compiler didn't capture String yet, because it found the invariant generics issue first.  Once the invariant generics issue is resolved, it compiles without error, implying String does get inferred.\n"
}
{
    "Id": 73480342,
    "PostTypeId": 1,
    "Title": "Manifest for java:8-jre-alpine not found: manifest unknown: manifest unknown",
    "Body": "I'm facing this error while building on Ubuntu server:\n\nStep 1/10 : FROM java:8-jre-alpine\nERROR: Service 'XXXX' failed to build: manifest for java:8-jre-alpine not found: manifest unknown: manifest unknown\n\nIt was working fine since months, suddenly now its not working. What could be the reason?\n",
    "AcceptedAnswerId": 73490179,
    "AcceptedAnswer": "I change java:8 to openjdk:8 and it works.\n"
}
{
    "Id": 74377433,
    "PostTypeId": 1,
    "Title": "What is the difference between \".\" and \"/\" in java classname?",
    "Body": "I'm new to java. When I try to learn Maven in 5 minutes, I found that this command\njava -cp target/my-app-1.0-SNAPSHOT.jar com.mycompany.app.App\n\nworked the same way as\njava -cp target/my-app-1.0-SNAPSHOT.jar com/mycompany/app/App\n\nIt drives me crazy because the last argument in the second command is actually a path. What is the difference between \".\" and \"/\" in java classname?\nI have looked up some articles but still don't get it.\n",
    "AcceptedAnswerId": 74377496,
    "AcceptedAnswer": "This is an implementation detail leaking out.  Class names in the language are dot-separated; class names in the classfile format are slash-separated.  (https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-4.html#jvms-4.2.)  For the most part, internal names are not visible to users, but they do leak in some circumstances.  Many tools that deal with classfiles will convert from the external (dotted) to internal (slashed) name using something like replace('.', '/'), which has the effect that internal names are also accepted by the tool.  That's what's going on here.\n"
}
{
    "Id": 74500889,
    "PostTypeId": 1,
    "Title": "Serve response of an HTTP request after receiving another request",
    "Body": "My use case is to serve response of an HTTP request after receiving another request from separate server.\n\n\nI want to do this best possible way keeping scaling in mind.\nWe are using Golang 1.19 with Gin Framework.\nServer will have multiple pods thus channels will not work.\nThere will be timeouts for all request making initial request timed out after 60 seconds.\n\nMy current solution is to use a shared cache where each pod will keep checking the cache. I believe, I can optimize this with channels where rather than checking in cache one by one, system periodically checks for any completed response.\nI would also like to know how it could have been achieved in other programming languages.\nPS: This is design based query, I have some reputation here to share bounty thus asking here. Please feel free to edit if question is not clear.\n",
    "AcceptedAnswerId": 74503580,
    "AcceptedAnswer": "tl;dr\nproblem description\nSo assuming your server application called server_app for instance, has 3 pods:\n     +---------------------+\n     |  server_app_service |\n     +---------------------+\n     |  server_app_pod_a   |\n     |  server_app_pod_b   |\n     |  server_app_pod_c   |\n     +---------------------+\n\nyour service receives a request called \"request A\", and decides to pass it to server_app_pod_a. Now your server_app_pod_a forwards the request to some gateway, and waits for some sort of notification, to continue the processing of client's response. And as you already know, there's no assurance that when gateway does the request B, the service passes it to server_app_pod_a again. And even if it did so, your application's state management would become a difficult task to do.\nMessaging\nAs you might've noticed, I bolded the word \"notification\" in the past paragraph, that's because if you really think about it, the request \"B\" looks more like a notification with some message rather than a request for some resource. So my number 1 choice would be a message queue like kafka (there are plenty of those, again, as you know). And the idea is, if you could define an algorithm to calculate unique keys for your requests, you can expect the resulting notifications in your exact same pod. This way, state management would be much simpler, and also, the chance of getting the notification in the same pod would be much higher (this depends on many factors of course, like the state of the message queue). Taking a look at your questions:\n\n\nI want to do this best possible way keeping scaling in mind.\n\n\nSure thing, you can use these message queues like kafka, to achieve scaling and fewer data loss, both for the message queue and your application.\n\n\nThere will be timeouts for all request making initial request timed out after 60 seconds.\n\n\nThis one depends on how you manage timeouts in your codebase, using contexts would be a good idea.\n\nI would also like to know how it could have been achieved in other programming languages.\n\nUsing message queues is a general idea, which would be applicable to almost any programming language, but depending on the programming paradigms of a language, and language-specific libraries and tools, there might be some other approaches to this problem. For instance in Scala, if you use some specific tool called akka (which provides actor model programming paradigm), you can use something so called akka-cluster-sharding, to handle this problem. And the idea is pretty simple, we know that there must be some sort of superviser, which knows the exact location and state of its own subscribers. So when it receives some message, it just knows where and which actor (we're talking about actor model programming) to forward the request to. In other words, it can be used to share state between actors spawned on a cluster, either on the same machine or not. But as a personal preference, I wouldn't go for language-specific communications, and would stick to general ideas, because of the problems it might cause in the future.\nWrap-up\nLong enough explanations :). Just to make some sense of what I'm talking about, let's follow up the exact same scenario, with a difference in communication model:\n\nClient sends request \"A\" to server_app service.\nThe service, choses one of the pods (server_app_pod_b for instance) to handle the request.\nThe pod then tries to define some key for the request, and passes it to the gateway, along with the request, and waits for a message with the key, to be published in the queue.\nThe gateway does what it's supposed to, and sends a message with the key, to the message queue.\nThe exact same pod serer_app_pod_b receives the message with the key, fetches the data of the message, and continues to process the client's request.\n\nThere are probably other approaches available to address this issue, but this is what I would go for. Hope that it helps!\n"
}
{
    "Id": 73707768,
    "PostTypeId": 1,
    "Title": "upgrade to SnakeYaml 1.31 in spring-boot-starter-parent 2.7.3",
    "Body": "Have springboot project in which wanted to either exclude snakeyaml 1.30 or upgrade it 1.31 inorder to avoid fortify issue reporting\nwith snakeyaml 1.30 version there is security vulnerability\n\n        org.springframework.boot\n        spring-boot-starter-parent\n        2.7.3\n\n\nBelow is seen on the effective pom.xml of the project\n  \n          org.yaml\n          snakeyaml\n          1.30\n          compile\n        \n\nIs there any possibility to upgrade as the remediation says to upgrade the version to snakeyaml 1.31 ?\nRef : https://security.snyk.io/vuln/SNYK-JAVA-ORGYAML-2806360\n",
    "AcceptedAnswerId": 73708060,
    "AcceptedAnswer": "You can always change the version number through the  block in your pom.xml:\n\n    \n\n      \n        org.yaml\n        snakeyaml\n        1.31\n      \n\n   \n\n\nThis will automatically change the version your project will use. You can test this by running mvn dependency:tree afterwards. It should only show version 1.31 of snakeyaml.\nImportant remark: Make sure that you remove this block as soon as you integrate the next version of Spring Boot as it will very likely contain the increased version. Otherwise you may downgrade the version unintentionally after future updates.\nPlease also note that there may be incompatibilities between certain lib versions and Spring Boot, hence it may not always be possible to update the version this way.\n"
}
{
    "Id": 73749383,
    "PostTypeId": 1,
    "Title": "Why does LambdaMetafactory fail when using a custom functional interface (but Function works fine)?",
    "Body": "Given:\nimport java.lang.invoke.LambdaMetafactory;\nimport java.lang.invoke.MethodHandle;\nimport java.lang.invoke.MethodHandles;\nimport java.lang.invoke.MethodType;\nimport java.util.function.Function;\n\nclass Testcase\n{\n    @FunctionalInterface\n    public interface MyBuilder1\n    {\n        R apply(String message);\n    }\n\n    @FunctionalInterface\n    public interface MyBuilder2\n    {\n        R apply(Object message);\n    }\n\n    public static void main(String[] args) throws Throwable\n    {\n        Class clazz = IllegalArgumentException.class;\n\n        MethodHandles.Lookup lookup = MethodHandles.lookup();\n        MethodHandle mh = lookup.findConstructor(clazz, MethodType.methodType(void.class, String.class));\n        MethodHandle myFunctionConstructor = LambdaMetafactory.metafactory(\n            lookup,\n            \"apply\",\n            MethodType.methodType(Function.class),\n            mh.type().erase(),\n            mh,\n            mh.type()\n        ).getTarget();\n\n        MethodHandle myBuilderConstructor1 = LambdaMetafactory.metafactory(\n            lookup,\n            \"apply\",\n            MethodType.methodType(MyBuilder1.class),\n            mh.type().erase(),\n            mh,\n            mh.type()\n        ).getTarget();\n\n        MethodHandle myBuilderConstructor2 = LambdaMetafactory.metafactory(\n            lookup,\n            \"apply\",\n            MethodType.methodType(MyBuilder2.class),\n            mh.type().erase(),\n            mh,\n            mh.type()\n        ).getTarget();\n\n        @SuppressWarnings(\"unchecked\")\n        Function functionFactory =\n            (Function) myFunctionConstructor.invokeExact();\n\n        @SuppressWarnings(\"unchecked\")\n        MyBuilder1 myBuilder1Factory =\n            (MyBuilder1) myBuilderConstructor1.invokeExact();\n\n        @SuppressWarnings(\"unchecked\")\n        MyBuilder2 myBuilder2Factory =\n            (MyBuilder2) myBuilderConstructor2.invokeExact();\n\n        IllegalArgumentException runFunction = functionFactory.apply(\"test\");\n//      IllegalArgumentException runBuilder1 = myBuilder1Factory.apply(\"test\");\n        IllegalArgumentException runBuilder2 = myBuilder2Factory.apply(\"test\");\n\n    }\n}\n\nWhy do runFunction and runBuilder2 work while runBuilder1 throws the following exception?\n\njava.lang.AbstractMethodError: Receiver class Testcase$$Lambda$233/0x0000000800d21d88 does not define or inherit an implementation of the resolved method 'abstract java.lang.Object apply(java.lang.String)' of interface MyBuilder1.\n\nGiven that the IllegalArgumentException constructor takes a String parameter, not an Object, shouldn't the JVM accept runBuilder1 and complain about the parameter type of the other two?\n",
    "AcceptedAnswerId": 73749785,
    "AcceptedAnswer": "Your MyBuilder1 has a functional method\nR apply(String message);\n\nwhose erased type is\nObject apply(String message);\n\nIn other words, unlike Function or MyBuilder2, the erased parameter type is String, rather than Object. The erase() method of MethodType just replaces all reference types with Object, which was handy for Function and MyBuilder2 but is not suitable for MyBuilder1 anymore. There is no similarly simple method for non-trivial types. You have to include type transformation code specifically for your case (unless you want to lookup the interface method via Reflection).\nFor example, we can just change the return type to Object and keep the parameter types:\nclass Testcase\n{\n    @FunctionalInterface\n    public interface MyBuilder1\n    {\n        R apply(String message);\n    }\n\n    public static void main(String[] args) throws Throwable\n    {\n        Class clazz = IllegalArgumentException.class;\n\n        MethodHandles.Lookup lookup = MethodHandles.lookup();\n        MethodHandle mh = lookup.findConstructor(clazz,\n            MethodType.methodType(void.class, String.class));\n\n        MethodHandle myBuilderConstructor1 = LambdaMetafactory.metafactory(\n            lookup,\n            \"apply\",\n            MethodType.methodType(MyBuilder1.class),\n            mh.type().changeReturnType(Object.class), // instead of erase()\n            mh,\n            mh.type()\n        ).getTarget();\n\n        @SuppressWarnings(\"unchecked\")\n        MyBuilder1 myBuilder1Factory =\n            (MyBuilder1) myBuilderConstructor1.invokeExact();\n\n        IllegalArgumentException runBuilder1 = myBuilder1Factory.apply(\"test\");\n\n        runBuilder1.printStackTrace();\n    }\n\n\nRegarding your last question, the erased type is the type to implement, whereas the last parameter to metafactory determines the intended type, i.e. derived from the Generic interface type. The generated code may have type casts from the erased type to this type when necessary. Since this type matches the constructor signature in all cases, all variants can invoke the constructor.\n"
}
{
    "Id": 73492733,
    "PostTypeId": 1,
    "Title": "How to properly spy on an input stream",
    "Body": "My understanding is, that Mockito.spy(object) wraps a proxy around an existing object. This proxy delegates the method calls to the spied object and allows further verification (So it's different to a mock which provides no implementation).\nI want to spy on an input stream to ensure the close/read methods are properly called. But the following (simple) spy code doesn't work:\n// Create a spy input stream object\nString testData = \"Hello\";\nInputStream inputStream = new ByteArrayInputStream(testData.getBytes(StandardCharsets.UTF_8));\nInputStream spiedInputStream = spy(inputStream);\nassertEquals(testData.getBytes(StandardCharsets.UTF_8).length, spiedInputStream.available()); // Fails: Expected 5, Actual 0\n\n// Read the input stream\nbyte [] readData = new byte[testData.length()];\nassertEquals(testData.getBytes(StandardCharsets.UTF_8).length, spiedInputStream.read(readData)); // Fails: Expected 5, Actual -1\nassertEquals(testData, new String(readData, StandardCharsets.UTF_8)); // Fails, readData is fully zeroed\n\nSo what am I doing wrong (Ubuntu 22.04, Java 17, Mockito 4.7.0)\n",
    "AcceptedAnswerId": 73496579,
    "AcceptedAnswer": "The behaviour you described is reproducible only on the following configuration:\n\nmockito-core\nJDK 17+\n\nThe simplest way for you to proceed is to switch to mockito-inline.\nIn case of mockito-core and JDK 17, the fields in the spy are not properly initialized:\npublic ByteArrayInputStream(byte buf[]) {\n    this.buf = buf;\n    this.pos = 0;\n    this.count = buf.length;\n}\n\nThe count variable should be equal to buf.length, but in the spy it is set to 0.\nThe problem stems from the fact that subclass mock maker is fundamentally limited on JDK17, mockito team seems to be aware of the problem and even considers switching to inline mock maker as default on JDK 17:\nSwitch the default mockmaker to the inline mockmaker on JDK 17+ #2589:\n\nTLDR: more and more use cases are broken (by default) with Mockito and JDK 17. That's because the subclass mockmaker runs into fundamental limitations on JDK 17, but the inline mockmaker works as expected.\n\n"
}
{
    "Id": 72446186,
    "PostTypeId": 1,
    "Title": "Why doesn't instanceof pattern matching work with else if in this particular case?",
    "Body": "The following snippet does not compile on javac, version 17 (Temurin)\nclass Instanceof {\n    static void doesNotWork(Object o) {\n        if (o == null) {\n            throw new Error();\n        } else if (!(o instanceof String s)) {\n            throw new Error();\n        }   \n        System.out.println(s); // error here\n    }\n}\n\nIt generates this error: cannot find symbol\ncannot find symbol\nsymbol:   variable s\nlocation: class Instanceof\n\nHowever, the following (in my opinion) equivalent variations work:\nWith an explicit else block:\nstatic void doesWork(Object o) {\n    if (o == null) {\n        throw new Error();\n    } else if (!(o instanceof String s)) {\n        throw new Error();\n    } else {\n        System.out.println(s);\n    }\n}\n\nOr without an else:\nstatic void doesWork(Object o) {\n    if (o == null) {\n        throw new Error();\n    }\n    if (!(o instanceof String s)) {\n        throw new Error();\n    }\n    System.out.println(s);\n}\n\nOr with a single if:\nstatic void doesWork(Object o) {\n    if (o == null || !(o instanceof String s)) {\n        throw new Error();\n    }\n    System.out.println(s);\n}\n\nIs this a bug in javac?\nIf yes, should I report this, but where exactly?\n",
    "AcceptedAnswerId": 72446910,
    "AcceptedAnswer": "The doesNotWork case is equivalent to this:\nstatic void doesNotWork(Object o) {\n    if (o == null) {\n        throw new Error();\n    } else {\n        if (!(o instanceof String s)) {\n            throw new Error();\n        }\n    }\n    System.out.println(s); // error here\n}\n\nThis makes it more obvious that String s is inside a block bounded by curly brackets and is therefore out of scope in the same way that this doesn't work either:\nstatic void doesNotWork(Object o) {\n    {\n        if (!(o instanceof String s)) {\n            throw new Error();\n        }\n    }\n    System.out.println(s); // error here\n}\n\nIn the case where it does work, with the println inside the else, it's equivalent to this:\nif (o == null) {\n    throw new Error();\n} else {\n    if (!(o instanceof String s)) {\n        throw new Error();\n    } else {\n        System.out.println(s);\n    }\n}\n\nWhich shows the println being in scope.\n"
}
{
    "Id": 72453890,
    "PostTypeId": 1,
    "Title": "Why am I seeing a one-off error with Math.pow(11, 16)?",
    "Body": "I have to compute 11^16 for a project at my Uni. Somehow Math.pow(11,16) computes a solution exactly 1 less than WolframAlpha or my other computation method.\n\nMy code is:\npublic class Test {\n    public static void main(String args[]) {\n        long a = 11;\n        long b = 16;\n        System.out.println(\"\" + (long)Math.pow(a, b));\n        System.out.println(\"\" + squareAndMultiply(a, b));\n    }\n\n    public static long squareAndMultiply(long b, long e){\n        long result = 1;\n        long sq = b;\n        while(e>0){\n            if(e%2==1){\n                result *= sq;\n            }\n            sq = sq * sq;\n            e /= 2;\n        }\n        return result;\n    }\n}\n\nThe result from the code is:\nmath.pow(11,16):\n\n45949729863572160\n\nsquareAndMultiply(11,16):\n\n45949729863572161\n\n",
    "AcceptedAnswerId": 72454107,
    "AcceptedAnswer": "With floating-point arithmetic, you're in that gray zone where the precision of a double is less than that of a long (even if the range of a double is much bigger).\nA double has 53 bits of precision, whereas a long can devote all 64 bits to precision.  When you're dealing with values as high as 1116, the difference between one double value and the next one up becomes noticeable.\nJava has a built-in method Math.ulp (\"unit in last place\") that effectively gives the difference in values between consecutive representable values.  (There's a double version and a float version.)\nSystem.out.println(Math.ulp(Math.pow(11, 16)));\n\n\n8.0\n\nThat means the least possible double value greater than 45949729863572160 is 45949729863572168.\nThe long value 45949729863572161 is correct, but the value you're getting with Math.pow, 45949729863572160, is as close as a double can get to the true answer, given its limited (but still large) precision.\nCasting to a long makes no difference, because Math.pow already computes the result as a double, so the answer is off by one already.  Your long method of computing the value is correct.\nIf you're computing values that would overflow long, then instead of using double, you can use BigDecimal, which has its own pow method to retain a precision of 1.0.\n"
}
{
    "Id": 74264850,
    "PostTypeId": 1,
    "Title": "LocalBroadcastManager is now deprecated, how to send data from service to activity?",
    "Body": "I have a service that needs to notify the main activity. I use LocalBroadcastManager, and it works fine, but LocalBroadcastManager has been deprecated.\nThis is my actual code in the service:\npublic void onTokenRefresh() {\n      \n    /* build the intent */\n    Intent intent = new Intent(ACTION_TOKENREFRESHED);\n    intent.putExtra(\"token\", \"xxx\");\n    \n    /* send the data to registered receivers */\n    try{\n      LocalBroadcastManager.getInstance(this).sendBroadcast(intent);\n    } catch (Throwable e){\n      //no exception handling\n    }  \n  \n  }\n\nIn the main activity, I get informed of the notification like this :\ncontext.registerReceiver(broadcastReceiver, intentFilter);\n\nWhat can I use now to remove the deprecated warning? All examples I found regarding sending data from service to activity use LocalBroadcastManager. Can someone give me a workable model for migrating my existing code?\nNOTE\nIn my example, The onTokenRefresh is called from inside a background thread. That is very important because it means I can simultaneously receive several onTokenRefresh, and I must forward all these tokens to the activity. Most of the offered solutions use live data but make a declaration like :\npublic static final MutableLiveData tokenLiveData = new MutableLiveData();\n\nBackground Thread1:\ntokenLiveData.postValue(Token1);\n\nBackground Thread2 (at same time):\ntokenLiveData.postValue(Token2);\n\nWill forward ALL tokens received simultaneously to the main activity that observes the tokenLiveData? Will the main activity always receive for sure token1 and token2?\n",
    "AcceptedAnswerId": 74545041,
    "AcceptedAnswer": "Make a service class and define a LiveData to replace the LocalBroadcastManager responsibility like so:\n//This service sends an example token ten times to its observers\npublic class MyService extends Service {\n    //Define a LiveData to observe in activity\n    public static final MutableLiveData tokenLiveData = new MutableLiveData();\n\n    @Override\n    public IBinder onBind(Intent intent) {\n        return null;\n    }\n\n    @Override\n    public int onStartCommand(Intent intent, int flags, int startId) {\n        //You need a separate thread if you don not use IntentService\n\n        Thread thread1 = new Thread() {\n            public void run() {\n                for (int i = 0; i < 10; i++) {\n                    //send random strings az an example token ten times.\n                    //You can remove this loop and replace it with your logic\n                    String token1 = UUID.randomUUID().toString();\n                    new Handler(Looper.getMainLooper()).post(() -> sendTokenToObserver(\"Thread1: \" + token1));\n\n                }\n            }\n        };\n        thread1.start();\n\n        Thread thread2 = new Thread() {\n            public void run() {\n                for (int i = 0; i < 10; i++) {\n                    String token2 = UUID.randomUUID().toString();\n                    new Handler(Looper.getMainLooper()).post(() -> sendTokenToObserver(\"Thread2: \" + token2));\n                }\n            }\n        };\n        thread2.start();\n        return START_STICKY;\n    }\n\n    //Post token to observers\n    public void sendTokenToObserver(String token) {\n        tokenLiveData.setValue(token);\n\n    }\n}\n\nThen start the service in the activity and observe the LiveData like below:\npublic class MainActivity extends AppCompatActivity {\n\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n        setContentView(R.layout.activity_main);\n\n        //You can observe the emitted token here and do what you want(Show in view or notification). \n        //I've just logged it to the console.\n        startService(new Intent(this,MyService.class));\n        MyService.tokenLiveData.observe(this, token -> Log.d(\"token\", token));\n    }\n}\n\nYou can also start the service from another activity and observe it in the MainActivity;\n"
}
{
    "Id": 72040055,
    "PostTypeId": 1,
    "Title": "Wildfly org.jboss.nio -> FileNotFoundException: Invalid file path with Windows Java JDK 11.0.15+10",
    "Body": "Since the update to Eclipse Tamurin JDK 11.0.15+10 we notice a problem as soon a HTTP request reaches Wildfly 20.0.1.Final. The same behaviour exsists in Wildfly 26.1.0.Final This only happens with the JDK Windows version, the Linux JDK works fine.\nAs it is an \"Invalid file path\" error, an OS dependent BUG seems possible.\nUntil now SAP Machine is the only JDK that does not encounter this failure.\nI'm still not sure if this is a JDK or a Wildfly problem...\nYou can check that when opening the Wildfly Management Interface.\nERROR [io.undertow.request] (External Management Request Threads -- 1) UT005071: Undertow request failed HttpServerExchange{ GET /management}: java.io.IOError: java.io.FileNotFoundException: Invalid file path\n    at org.jboss.xnio@3.8.1.Final//org.xnio.channels.Channels$4.run(Channels.java:1103)\n    at org.jboss.xnio@3.8.1.Final//org.xnio.channels.Channels$4.run(Channels.java:1093)\n    at java.base/java.security.AccessController.doPrivileged(Native Method)\n    at org.jboss.xnio@3.8.1.Final//org.xnio.channels.Channels.(Channels.java:1093)\n    at io.undertow.core@2.1.3.Final//io.undertow.io.UndertowOutputStream.write(UndertowOutputStream.java:231)\n    at io.undertow.core@2.1.3.Final//io.undertow.io.BlockingSenderImpl.writeBuffer(BlockingSenderImpl.java:245)\n    at io.undertow.core@2.1.3.Final//io.undertow.io.BlockingSenderImpl.writeBuffer(BlockingSenderImpl.java:238)\n    at io.undertow.core@2.1.3.Final//io.undertow.io.BlockingSenderImpl.send(BlockingSenderImpl.java:75)\n    at io.undertow.core@2.1.3.Final//io.undertow.io.BlockingSenderImpl.send(BlockingSenderImpl.java:107)\n    at org.jboss.as.domain-http-interface@12.0.3.Final//org.jboss.as.domain.http.server.DomainUtil.writeResponse(DomainUtil.java:89)\n    at org.jboss.as.domain-http-interface@12.0.3.Final//org.jboss.as.domain.http.server.DomainApiHandler$1.doSendResponse(DomainApiHandler.java:177)\n    at org.jboss.as.domain-http-interface@12.0.3.Final//org.jboss.as.domain.http.server.ResponseCallback.sendResponse(ResponseCallback.java:32)\n    at org.jboss.as.domain-http-interface@12.0.3.Final//org.jboss.as.domain.http.server.DomainApiHandler.handleRequest(DomainApiHandler.java:232)\n    at io.undertow.core@2.1.3.Final//io.undertow.server.handlers.encoding.EncodingHandler.handleRequest(EncodingHandler.java:72)\n    at org.jboss.as.domain-http-interface@12.0.3.Final//org.jboss.as.domain.http.server.DomainApiCheckHandler.handleRequest(DomainApiCheckHandler.java:91)\n    at org.jboss.as.domain-http-interface@12.0.3.Final//org.jboss.as.domain.http.server.security.ElytronIdentityHandler.lambda$handleRequest$0(ElytronIdentityHandler.java:62)\n    at org.wildfly.security.elytron-private@1.12.1.Final//org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:328)\n    at org.wildfly.security.elytron-private@1.12.1.Final//org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:285)\n    at org.jboss.as.controller@12.0.3.Final//org.jboss.as.controller.AccessAuditContext.doAs(AccessAuditContext.java:254)\n    at org.jboss.as.controller@12.0.3.Final//org.jboss.as.controller.AccessAuditContext.doAs(AccessAuditContext.java:225)\n    at org.jboss.as.domain-http-interface@12.0.3.Final//org.jboss.as.domain.http.server.security.ElytronIdentityHandler.handleRequest(ElytronIdentityHandler.java:61)\n    at io.undertow.core@2.1.3.Final//io.undertow.server.handlers.BlockingHandler.handleRequest(BlockingHandler.java:56)\n    at io.undertow.core@2.1.3.Final//io.undertow.server.Connectors.executeRootHandler(Connectors.java:370)\n    at io.undertow.core@2.1.3.Final//io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830)\n    at org.jboss.threads@2.3.3.Final//org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35)\n    at org.jboss.threads@2.3.3.Final//org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:1982)\n    at org.jboss.threads@2.3.3.Final//org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1486)\n    at org.jboss.threads@2.3.3.Final//org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1348)\n    at java.base/java.lang.Thread.run(Thread.java:829)\n    at org.jboss.threads@2.3.3.Final//org.jboss.threads.JBossThread.run(JBossThread.java:485)\nCaused by: java.io.FileNotFoundException: Invalid file path\n    at java.base/java.io.FileOutputStream.(FileOutputStream.java:231)\n    at java.base/java.io.FileOutputStream.(FileOutputStream.java:126)\n    at org.jboss.xnio@3.8.1.Final//org.xnio.channels.Channels$4.run(Channels.java:1098)\n    ... 29 more\n\n\n\n\n\nJDK\nWorks with Wildfly\n\n\n\n\nEclipse Tamurin\nno\n\n\nAmazon Coretto\nno\n\n\nAzul Zulu\nno\n\n\nBellsoft\nno\n\n\nOracle OpenJDK\nno\n\n\nOracle JDK\nno\n\n\nSAP Machine\nyes\n\n\n\n",
    "AcceptedAnswerId": 72465068,
    "AcceptedAnswer": "This is an issue in the JDK. You can wait for JDK 11.0.16 or downgrade to a lower version like JDK 11.0.14.\n"
}
{
    "Id": 73878386,
    "PostTypeId": 1,
    "Title": "Lock-free array expansion in Java",
    "Body": "I have an array to which many threads are writing. However each thread has a pre-assigned range of indices which it may write to. Further, nothing will be reading from the array until all threads are done.\nSo far, so thread-safe. The problem arises when I need to expand the array, by which of course I mean swap it out for a larger array which copies the first. This is only done occasionally (similar to an ArrayList).\nCurrently I'm acquiring a lock for every single write to the array. Even though there is no need to lock in order to keep the array consistent, I'm having to lock in case the array is currently being copied/swapped.\nAs there are very many writes I don't want to require a lock for them. I'm okay with a solution which requires locking for writer threads only while the array is being copied and swapped, as this is infrequent.\nBut I can't just impose write locks only when the copy/swap is in progress, as threads may already be committing writes to the old array.\nI think I need some variety of barrier which waits for all writes to complete, then pauses the threads while I copy/swap the array. But CyclicBarrier would require me to know exactly how many threads are currently active, which is non-trivial and possibly susceptible to edge-cases in which   the barrier ends up waiting forever, or lowers itself too early. In particular I'm not sure how I'd deal with a new thread coming in while the barrier is already up, or how to deal with threads which are currently polling a job queue, so will never decrement the barrier count while there are no new jobs.\nI may have to implement something which (atomically) counts active threads and tries to pre-empt all the edge cases.\nBut this may well be a \"solved\" problem that I don't know about, so I'm hoping there may be a simpler (therefore better) solution than the Cyclic barrier/thread counting. Ideally one which uses an existing utility class.\nBy the way, I've considered CopyOnWriteArray. This is no use to me, as it copies for every write (a lot of them), not just array expansions.\nAlso note the structure written to pretty much has to be an array, or array-based.\nThanks\n",
    "AcceptedAnswerId": 73878933,
    "AcceptedAnswer": "Although it's technically not correct, you can probably use a ReadWriteLock. The threads that are writing to a single portion all use a read lock (this is the technically incorrect part, they're not reading...), and the resize uses a write lock. That way, all writing threads can work together. A resize has to wait until all portioned writes are done, which then blocks the entire array. Once that is done, all portioned writes can continue.\n"
}
{
    "Id": 74910066,
    "PostTypeId": 1,
    "Title": "@EnableGlobalMethodSecurity is deprecated in the new spring boot 3.0",
    "Body": "I use Spring Boot 3.0, and when I work on security configuration, I get a warning that the @EnableGlobalMethodSecurity is deprecated.\n@Configuration\n@EnableWebSecurity\n@AllArgsConstructor\n@EnableGlobalMethodSecurity(prePostEnabled = true)\npublic class SecurityConfig {\n\nWith what do I replace can replace @EnableGlobalMethodSecurity in Spring boot 3.0?\n",
    "AcceptedAnswerId": 74910079,
    "AcceptedAnswer": "You can use now:\n@EnableMethodSecurity\n\nCheck the documentation\nNote that you can avoid using prePostEnabled = true, because by default is true.\nboolean prePostEnabled() default true;\nboolean jsr250Enabled() default false;\nboolean proxyTargetClass() default false;\n\n"
}
{
    "Id": 73864285,
    "PostTypeId": 1,
    "Title": "What's the point of a write-only collection?",
    "Body": " makes for a read-only collection\n makes for a write-only collection\nI somehow get why use a read-only collection,for instance to use it in a multithreaded environment (any other cases?)\nBut why use a write-only collection? What's the point if you cannot read from it and use its values at some point? I know that you can get an Object out of it but that defies type safety.\nEdit:\n@Thomas the linked question (Difference between  and  in Java) does show how to make a write only collection but does not answer 'why' would you need one in the first place.So it's not a duplicate\n",
    "AcceptedAnswerId": 73864712,
    "AcceptedAnswer": "Note that \"write only collection\" depends on the point of view.\nLets write a method that adds a bunch of numbers to a collection:\npublic static void addNumbers(List target, int count) {\n    for (int i = 0; i < count; i++) {\n        target.add(i);\n    }\n}\n\nFor this method the list target is a write only list: the method can only add numbers to it, it can not use the values that it added to the list.\nOn the other side there is the caller:\npublic static void caller() {\n    List myList = new ArrayList();\n    addNumbers(myList, 10);\n    double sum = 0;\n    for (Number n: myList) {\n        sum += n.doubleValue();\n    }\n    System.out.println(sum);\n}\n\nThis method works with a specific list (myList) and therefore can read the values that addNumbers stuffed into it.\nFor this method the list is not a write only list, for this method it is an ordinary list.\n"
}
{
    "Id": 72506950,
    "PostTypeId": 1,
    "Title": "Flutter Error : Could not resolve all artifacts for configuration ':image_picker_android:debugUnitTestRuntimeClasspath'",
    "Body": "The application which I am working on is debugging fine in emulator or in mobiles but when I try to build the apk it gives the following Error:\nBuilding without sound null safety\nFor more information see https://dart.dev/null-safety/unsound-null-safety\n\nRunning Gradle task 'assembleRelease'...                        \n\n\nFAILURE: Build failed with an exception.\n\n* What went wrong:\nExecution failed for task ':app:lintVitalRelease'.\n> Could not resolve all artifacts for configuration ':image_picker_android:debugUnitTestRuntimeClasspath'.\n   > Failed to transform bcprov-jdk15on-1.68.jar (org.bouncycastle:bcprov-jdk15on:1.68) to match attributes {artifactType=processed-jar, org.gradle.category=library, org.gradle.libraryelements=jar, org.gradle.status=release, org.gradle.usage=java-runtime}.\n      > Execution failed for JetifyTransform: /home/cicada/.gradle/caches/modules-2/files-2.1/org.bouncycastle/bcprov-jdk15on/1.68/46a080368d38b428d237a59458f9bc915222894d/bcprov-jdk15on-1.68.jar.\n         > Failed to transform '/home/cicada/.gradle/caches/modules-2/files-2.1/org.bouncycastle/bcprov-jdk15on/1.68/46a080368d38b428d237a59458f9bc915222894d/bcprov-jdk15on-1.68.jar' using Jetifier. Reason: IllegalArgumentException, message: Unsupported class file major version 59. (Run with --stacktrace for more details.)\n           Suggestions:\n            - Check out existing issues at https://issuetracker.google.com/issues?q=componentid:460323&s=modified_time:desc, it's possible that this issue has already been filed there.\n            - If this issue has not been filed, please report it at https://issuetracker.google.com/issues/new?component=460323 (run with --stacktrace and provide a stack trace if possible).\n\n* Try:\nRun with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.\n\n* Get more help at https://help.gradle.org\n\nBUILD FAILED in 19s\nRunning Gradle task 'assembleRelease'...                           20.7s\nGradle task assembleRelease failed with exit code 1\nProcess finished with exit code 1\n\n",
    "AcceptedAnswerId": 72518904,
    "AcceptedAnswer": "This was my solution which I recommend to be the 2nd option:\nSolution 1:\nI added following lines in the android directory of app level build.gradle i.e android/app/build.gradle of my  project.\n   lintOptions {\n        disable 'InvalidPackage'\n        disable \"Instantiatable\"\n        checkReleaseBuilds false\n        abortOnError false\n    }\n\nAnd every thing started to work fine.\nCheck out my Gradle File\nSolution 2:\nHowever I suggest you people by the solution of @Vinadon and agree with the comment of @raiderOne:\n1st recommended solution should be:\nThe issues lies in image_picker_android being updated to gradle 7.1.2. See their changelog. Following an issue on GitHub you have to update your gradle version like so:\nIn android/gradle/wrapper/gradle-wrapper.properties update your distributionUrl to\ndistributionUrl=https\\://services.gradle.org/distributions/gradle-7.2-all.zip\n\nand in android/build.gradle change the gradle version to at least 7.1.2\nclasspath 'com.android.tools.build:gradle:7.1.2\n\nIn @Vinadon case, He had to update his Android Studio for a newer Java version too.\nUpvote Vindadon answer below for this solution. Thanks!\n"
}
{
    "Id": 74916107,
    "PostTypeId": 1,
    "Title": "ConcurrentHashMap computeIfAbsent tell if first time or not",
    "Body": "It's complicated for me to articulate a proper title for this. But an example should make it far simpler. Suppose I have this:\nfinal class Cache {\n   private static final ConcurrentHashMap> CACHE = ...\n\n   static List byName(String name) {\n      return CACHE.computeIfAbsent(name, x -> // some expensive operation)\n   }\n\n}\n\nThe idea is probably trivial, this acts as a LoadingCache, much like guava or caffeine (in reality it is more complicated, but that is irrelevant to the question).\nI would like to be able to tell if this was the first load into the CACHE, or it was a read of an existing mapping. Currently, I do this:\nfinal class Cache {\n   private static final ConcurrentHashMap> CACHE = ...\n\n   static List byName(String name) {\n      boolean b[] = new boolean[1];\n      List result = CACHE.computeIfAbsent(name, x -> {\n            b[0] = true;\n            // some expensive operation)\n      });\n\n      if(b[0]) {\n         // first load into the cache, do X\n      } else {\n         // do Y\n      }\n\n      return result;\n   }\n\n}\n\nThis works, but I am afraid I am missing something that ConcurrentHashMap can offer for me that would allow me to do the same. Thank you.\n",
    "AcceptedAnswerId": 74919640,
    "AcceptedAnswer": "If you want to avoid your single-element array to pass data out of the lambda (which I would rather do with an AtomicReference or AtomicBoolean), you could use a stateful callback object. It doesn't change the behavior or design of your code, but could be considered a little bit cleaner and more OOP-y.\nclass LoadingAction {\n  private boolean called = false;\n\n  public V load(final K key) {\n    called = true;\n    // load data\n    return ...;\n  }\n\n  public void executePostLoad() {\n    if (called) {\n      // loaded into cache, do X\n    } else {\n      // do Y\n    }\n  }\n}\n\nfinal class Cache {\n   private static final ConcurrentHashMap> CACHE = new ConcurrentHashMap();\n\n   static List byName(String name) {\n      final LoadingAction> loader = new LoadingAction();\n      final List result = CACHE.computeIfAbsent(name, loader::load);\n\n      loader.executePostLoad();\n\n      return result;\n   }\n\n}\n\nOr turn it inside-out:\nclass Loader {\n  private boolean called = false;\n\n  public V load(final Map map, final K key) {\n    final V result = map.computeIfAbsent(key, this::load);\n    this.executePostLoad();\n    return result;\n  }\n\n  private V load(final K key) {\n    called = true;\n    // load data\n    return ...;\n  }\n\n  private void executePostLoad() {\n    if (called) {\n      // loaded into cache, do X\n    } else {\n      // do Y\n    }\n  }\n}\n\nfinal class Cache {\n   private static final ConcurrentHashMap> CACHE = new ConcurrentHashMap();\n\n   static List byName(String name) {\n      final Loader> loader = new Loader();\n      return loader.load(CACHE, name);\n   }\n\n}\n\nConstruction and loading could be encapsulated in a static method:\nclass Loader {\n  private boolean called = false;\n\n  public static  V load(final Map map, final K key) {\n      final Loader loader = new Loader();\n      return loader.doLoad(map, key);\n  }\n\n  private V doLoad(final Map map, final K key) {\n    final V result = map.computeIfAbsent(key, this::load);\n    this.executePostLoad();\n    return result;\n  }\n\n  private V load(final K key) {\n    called = true;\n    // load data\n    return ...;\n  }\n\n  private void executePostLoad() {\n    if (called) {\n      // loaded into cache, do X\n    } else {\n      // do Y\n    }\n  }\n}\n\nfinal class Cache {\n   private static final ConcurrentHashMap> CACHE = new ConcurrentHashMap();\n\n   static List byName(String name) {\n      return Loader.load(CACHE, name);\n   }\n\n}\n\n"
}
{
    "Id": 72615382,
    "PostTypeId": 1,
    "Title": "Cannot resolve method 'of' in 'ImmutableList",
    "Body": "Debugging Details: Following tutorial to migrate from Android Billing 4.0 to 5.0 https://developer.android.com/google/play/billing/migrate-gpblv5, specifically in the section \"Showing products available to buy\"\nThe 'of' in ImmutableList is flagged red and the error in Android Studio is\n\nCannot resolve method 'of' in 'ImmutableList'\"\n\nHow can I resolve?\nMinimal reproducible code to get the Compilation Error:\nQueryProductDetailsParams queryProductDetailsParams =\n        QueryProductDetailsParams.newBuilder()\n                .setProductList(\n                        ImmutableList.of(\n                                QueryProductDetailsParams.Product.newBuilder()\n                                        .setProductId(PREMIUM_MONTHLY_VERSION_ID)\n                                        .setProductType(BillingClient.ProductType.SUBS)\n                                        .build()))\n                .build();\n\nHere are the specific details:\nDesired Behaviour: Code compiles fine.\nSpecific Problem or Error: Compilation error.\n",
    "AcceptedAnswerId": 72616597,
    "AcceptedAnswer": "ImmutableList, in context of 'a tutorial for Android Billing 5.0', is clearly referring to guava's ImmutableList - the full name of this type is com.google.common.collect.ImmutableList.\nThis class is baked into android as far as I remember (but not in plain java). It has always had an of method. Thus:\n\nMost likely you have some type in your package or source file called ImmutableList. Don't do that. Rename yours to something else.\nAlternatively, check your imports - you imported something else also named ImmutableList. You should have an import com.google.common.collect.ImmutableList; at the top, or possibly import com.google.common.collect.*; - if that is missing, consider adding it.\n\nAndroid doesn't \"have\" java 9 or java 11 - you just need java1 for this, the point is: It is not a java core class at all - only stuff that starts with java.* is. However, android is not (quite) java.\nI'm just not sure: I thought guava (the library that contains ImmutableList) is available by default on android, which means your IDE\"s setup is broken. Or perhaps it is not, in which case you need to add the 'guava' dependency. How? Well, that depends - I think android builds are based on gradle, which would mean: Look it up on search.maven.org and follow the gradle instructions.\n"
}
{
    "Id": 73817318,
    "PostTypeId": 1,
    "Title": "SSE core task scheduler startup problem in eclipse",
    "Body": "Whenever I'm launching my eclipse IDE with my project workspace, there is one popup window showing some internal error with the task scheduler. I'm attaching the picture of that popup window here.\n\nMy project is all in java language and also uses spring boot in it.\nThe error says something like\nAn internal error occurred during: \"SSE core task scheduler startup\"\nSorry I'm not able to add a direct image for this as Stack overflow is not allowing me to do that.\n",
    "AcceptedAnswerId": 73970552,
    "AcceptedAnswer": "I had the same problem today.\nUpdating Eclipse solved it for me:\nHelp -> About Eclipse -> Installation Details -> Update\n"
}
{
    "Id": 72703351,
    "PostTypeId": 1,
    "Title": "Java 19 Pattern Matching Compilation Error: \"the switch statement does not cover all possible input values\"",
    "Body": "Using the Brian Goetz article: https://www.infoq.com/articles/data-oriented-programming-java/\nsealed interface Opt { \n    record Some(T value) implements Opt { }\n    record None() implements Opt { }\n}\n\nThis compiles and runs as expected. The exhaustive pattern matching works:\nOpt optValue = doCalc(value);\nswitch (optValue) {\n  case Opt.Some some -> System.out.printf(\"got string: %s%n\", some.value());\n  case Opt.None none -> System.out.printf(\"got none%n\");\n};\n\nThis variation where I use the new Record patterns preview feature, breaks the exhaustive pattern matching, where this won't compile without adding a default case statement:\nOpt optValue = doCalc(value);\nswitch (optValue) {\n    case Opt.Some(String v) -> System.out.printf(\"got string: %s%n\", v);\n    case Opt.None none -> System.out.printf(\"got none%n\");\n};\n\nWith OpenJDK Runtime Environment (build 19-ea+32-2220), I get the compilation error: the switch statement does not cover all possible input values.\nWhen I add a default case statement, and the program works, but I don't get exhaustive pattern matching.\nIf I remove the record pattern matching, the program works.\nIf I create a variation of this without generics, that uses sealed classes, exhaustive pattern matching, and record patterns, it works.\nHowever, it seems the combination of record patterns, generics and exhaustive pattern matching does not work.\n",
    "AcceptedAnswerId": 73977879,
    "AcceptedAnswer": "This is a known bug in Java 19. This was confirmed by Brian Goetz himself on the amber-dev mailing list.\nUPDATE: This issue is completely fixed in Java 20.\n"
}
{
    "Id": 73999566,
    "PostTypeId": 1,
    "Title": "How to construct PickVisualMediaRequest for ActivityResultLauncher",
    "Body": "I am trying to use the Activity Result APIs to handle the picking of a single photo for an app I am developing. I am trying to use one of the predefined contracts to keep things simple. So, I am attempting to use the ActivityResultContracts.PickVisualMedia() contract.\nI am setting the Activity Result Launcher up as follows:\nprivate ActivityResultLauncher pickVisualMediaActivityResultLauncher;\n\n@Override\nprotected void onCreate(@Nullable Bundle savedInstanceState) {\n    pickVisualMediaActivityResultLauncher = registerForActivityResult(\n            new ActivityResultContracts.PickVisualMedia(),\n            this::onPickVisualMediaActivityResult\n    );\n}\n\nAnd I am attempting to construct a PickVisualMediaRequest and launch the Activity Result Launcher here:\nprivate void onSelectNewPhotoButtonClick() {\n    PickVisualMediaRequest request = new PickVisualMediaRequest.Builder()\n            .setMediaType(new ActivityResultContracts.PickVisualMedia.ImageOnly())\n            .build();\n    pickVisualMediaActivityResultLauncher.launch(request);\n}\n\nIssue is that Android Studio is complaining about ActivityResultContracts.PickVisualMedia.ImageOnly() not having proper visibility to be used, even though it is a valid VisualMediaType and the docs imply that it should be used this way:\n\nI can't really find any code samples on this particular scenario. Am I missing something? Does the API have a visibility defect or am I just dumb today?\n",
    "AcceptedAnswerId": 74000104,
    "AcceptedAnswer": "After some help from CommonsWare, I determined that setMediaType() accepts a Kotlin object instance. So, the above bad function I had should be:\nprivate void onSelectNewPhotoButtonClick() {\n    ActivityResultContracts.PickVisualMedia.VisualMediaType mediaType = (ActivityResultContracts.PickVisualMedia.VisualMediaType) ActivityResultContracts.PickVisualMedia.ImageOnly.INSTANCE;\n    PickVisualMediaRequest request = new PickVisualMediaRequest.Builder()\n            .setMediaType(mediaType)\n            .build();\n    pickVisualMediaActivityResultLauncher.launch(request);\n}\n\nAndroid Studio complains about the type casting, but the code does compile and work as expected. Very bizarre.\n\n\n"
}
{
    "Id": 72520506,
    "PostTypeId": 1,
    "Title": "How does spring create proxy for a final class?",
    "Body": "Maybe I have some outdated knowledge but it is the same as described here\nhttps://stackoverflow.com/a/2657465/2674303\nBut now I noticed that this example works without any exceptions:\n@Service\n@EnableScheduling\npublic final class MyService {\n    @PostConstruct\n    public void init(){\n        System.out.println(\"MyService started\");\n    }\n    @Scheduled(fixedDelay= 1000)\n    public void scheduleCall() {\n        System.out.println(\"scheduleCall\");    \n \n  }\n}\n\nCould you pease provide how does it work ?\n",
    "AcceptedAnswerId": 72624573,
    "AcceptedAnswer": "@Scheduled annotation does not require proxy creation. The mechanism is different. After bean initialization Spring called post-processor ScheduledAnnotationBeanPostProcessor. Post processor searches for all methods annotated with @Scheduled and registers them to TaskScheduller for execution. Method execution will be performed via reflection.\nSee ScheduledAnnotationBeanPostProcessor source code.\n@Scheduled\n\nProcessing of @Scheduled annotations is performed by registering a\nScheduledAnnotationBeanPostProcessor. This can be done manually or,\nmore conveniently, through the task:annotation-driven/ XML element\nor @EnableScheduling annotation.\n\nScheduledAnnotationBeanPostProcessor\n\nBean post-processor that registers methods annotated with @Scheduled\nto be invoked by a TaskScheduler according to the \"fixedRate\",\n\"fixedDelay\", or \"cron\" expression provided via the annotation. This\npost-processor is automatically registered by Spring's\ntask:annotation-driven XML element, and also by the\n@EnableScheduling annotation.\nAutodetects any SchedulingConfigurer instances in the container,\nallowing for customization of the scheduler to be used or for\nfine-grained control over task registration (e.g. registration of\nTrigger tasks). See the @EnableScheduling javadocs for complete usage\ndetails.\n\n@PostConstruct also implemented via post-processor InitDestroyAnnotationBeanPostProcessor when dependency injection performed for bean, method which marked @PostConstruct will be executed thru reflection without proxy.\nSee InitDestroyAnnotationBeanPostProcessor source code\nSummary:\nIn your example, Spring will create bean without proxy.\nIn case you will add a proxy-specific annotation, for example, @Transactional you will get an exception that proxy can not be created due to final class java.lang.IllegalArgumentException: Cannot subclass final class com.test.services.MyService\n@Service\n@EnableScheduling\npublic final class MyService {\n    @PostConstruct\n    public void init(){\n        System.out.println(\"MyService started\");\n    }\n    @Scheduled(fixedDelay= 1000)\n    @Transactional\n    public void scheduleCall() {\n        System.out.println(\"scheduleCall\");\n\n    }\n}\n\nBut the current problem you also can solve to force use JDK dynamic proxy. We need to create an interface for class and set property spring.aop.proxy-target-class = false according to Proxying mechanisms\n"
}
{
    "Id": 74240190,
    "PostTypeId": 1,
    "Title": "Numeric comparing option for Java Collator",
    "Body": "Problem:\nLet's say we have the following list of strings {\"Test1.txt\", \"Test2.txt\", \"Test11.txt\", \"Test22.txt\"}, sorting them using String::compareTo or Collator::compare would result in following order:\nTest1.txt\nTest2.txt\nTest22.txt\nTest3.txt\n\nWhich is inconvenient(arguably), while a more human-friendly outcome is:\nTest1.txt\nTest2.txt\nTest3.txt\nTest22.txt\n\nTo resolve this issues we can write our own compare method which is numeric sensitive.\nBut what if we want numeric sensitive sort as well as the benefit of using existing implementation of Collator (or to avoid implementing one) for internationalization?\nIs there a right way to handle this? or maybe a reliable library that addresses this problem?\nOther Languages:\nIn Javascript world the Intl.Collator's constructors accepts a CollatorOption which allows you to set configs to achieve such functionality and more:\nconst usCollator = Intl.Collator(\"us\", { numeric: true });\nconst list = [\"Test1.txt\", \"Test2.txt\", \"Test3.txt\", \"Test22.txt\"];\nlist.sort(usCollator.compare);\nconsole.log(list);\n\n",
    "AcceptedAnswerId": 74302933,
    "AcceptedAnswer": "You can use alphanumeric-comparator, which is available in Maven.\n"
}
{
    "Id": 74337681,
    "PostTypeId": 1,
    "Title": "Is the permits relationship of Java Sealed classes/interfaces transitive",
    "Body": "If I read the JLS \u00a78.1.6 and \u00a79.1.4 correctly, the classes that a sealed class/interface permits, are just the direct subclasses/interfaces.\nTo illustrate this, consider the following example:\npublic sealed interface I1 permits I2, C, D { /*...*/ }\npublic final class C implements I1 { /*...*/ }\npublic final class D implements I1 { /*...*/ }\n\npublic sealed interface I2 extends I1 permits E, F { /*...*/ }\npublic final class E implements I2 { /*...*/ }\npublic final class F implements I2 { /*...*/ }\n\nIf I understand the specification correctly, I1 obviously permits C and D but not E and F (via the extends hierarchy of I2 from I1). Is this correct?\nThe reason I'm asking is what patterns are allowed for switch expressions of the following kind:\nI1 i1 = // ...\nreturn switch (i1) {\n    case C c -> \"1\";\n    case D d -> \"2\";\n    case E e -> \"3\"; // Can we match over E?\n    case F f -> \"4\"; // Can we match over F?\n    default  -> \"5\";\n};\n\n",
    "AcceptedAnswerId": 74339207,
    "AcceptedAnswer": "\nI1 obviously permits C and D but not E and F. Is this correct?\n\nMore accurately, you can say that C and D are in the set of permitted direct subclasses of I1, which is a term defined in section 9.1.4. The JLS doesn't really define what \"I1 permits C and D\" means though.\nAs for your switch expression, the reason why it works is two-fold. First, you are able to write a type pattern in a switch label if the type of the switch selector expression is downcast-convertible to that type.\n14.11.1\n\nA pattern case element p is switch compatible with T if p is applicable at type T (14.30.3).\n\n14.30.3:\n\nA pattern p is said to be applicable at a type T if one of the following rules apply:\n\nA type pattern that declares a pattern variable of a reference type U is applicable at another reference type T if T is downcast convertible to U (5.5).\n\n\nObviously, E is downcast-convertible to I1 through a widening reference conversion, because E implements I1. Note that this fact has nothing to do with permits. It is simply a result of E implements I2 and I2 extends I1. Surely you would agree that implements and extends are transitive!\nSecond, switch expressions need to be exhaustive. Your switch expression is always exhaustive because it has a default case. However, it is still exhaustive even without the default case.\nFrom now on, we will consider your switch expression but without the default case, because that is where permits plays a role. The rules to determine whether the set of case labels you wrote are exhaustive are specified in 14.11.1.1. The important bit of your case is (this is kind of an inductive definition):\n\n\nA set of case elements is exhaustive for a type T if it contains a pattern that is unconditional at type T (14.30.3).\nA set of case elements is exhaustive for a type T that includes an abstract and sealed class or interface named C, if it is exhaustive\nfor every applicable permitted direct subtype of T.\n\n\n\"applicable permitted direct subtype of T\" in your case is really just the same as \"permitted direct subtype of T\". You can also treat \"a type T that includes an abstract and sealed class or interface named C\" as the same as T - the \"includes\" relationship isn't relevant to your case. With T=I1 in mind, we can start \"running\" this algorithm.\nWe use the second rule first - the permitted direct subtypes of I1 are I2, C and D. Since we have a C c and D d in the case elements, we know that our set of case elements is exhaustive for C and D (first rule). Is it also exhaustive for I2? To determine that, we use the second rule again. The permitted direct subtypes of I2 are E and F. Using the first rule, we know that the case elements E e and F f are exhaustive for E and F respectively. We have now proven that that the set of case elements are exhaustive for I2, C and D, so it is exhaustive for I1, according to the second rule.\nSo if you are talking about how switch patterns work, I think \"inductive\" is a better word to describe how the exhaustiveness of switch case labels are verified.\n"
}
{
    "Id": 72628636,
    "PostTypeId": 1,
    "Title": "How to create a new pom file with additional dependencies and add it during build time?",
    "Body": "I am currently using formsflow.ai opensource version 4.0.5.\nI want to include a new Listener to the bpm module which has a new library dependency which is not currently in the solution. Although, I managed to add the new library in main pom.xml, since the requirement is for one of my client I just cannot modify the root pom.xml file. Is their an option available in formsflow / maven to include profiles and choose pom?\nIf it already available in formsflow, then how can I configure the same?\nPlease give me a solution.\n",
    "AcceptedAnswerId": 72629089,
    "AcceptedAnswer": "You can checkout how to add profile on a pom.xml file from maven documentation how to add profile in maven.\nIn formsflow.ai we let our users manage the additional library dependency using an extra pom.xml (pom-.xml).\nYou can always refer to our internal documentation and also provided with a pom-default.xml to start with.\nThe facts about these profiling are.\n\nyou can add as many as number of unique profiling in pom.xml by mapping the default configuration.\nYou can add only 1 module per profile, since the docker build look up for the pom in the base directory and adding more than one module will override target.\nYou need to change profile param in Dockerfile before building it if you want to go with a profile other than default.\n\nHope this helps\n"
}
{
    "Id": 72683786,
    "PostTypeId": 1,
    "Title": "Error while importing Springboot 2.7 projects in intellij Idea with maven 3.8.5",
    "Body": "when Using start.spring.io\nprojects generated with springboot 2.7 comes with MavenProject 3.8.5 which when imported in intellij causes an error that is quite difficult to debug or not self speaking by itself.\nThe error\njava.lang.RuntimeException: org.codehaus.plexus.component.repository.exception.ComponentLookupException: com.google.inject.ProvisionException: Unable to provision, see the following errors:\n\n1) Error injecting constructor, java.lang.NoSuchMethodError: org.apache.maven.model.validation.DefaultModelValidator: method 'void ()' not found\n  at org.jetbrains.idea.maven.server.embedder.CustomModelValidator.(Unknown Source)\n  while locating org.jetbrains.idea.maven.server.embedder.CustomModelValidator\n  at ClassRealm[maven.ext, parent: ClassRealm[plexus.core, parent: null]] (via modules: org.eclipse.sisu.wire.WireModule -> org.eclipse.sisu.plexus.PlexusBindingModule)\n  while locating org.apache.maven.model.validation.ModelValidator annotated with @com.google.inject.name.Named(value=\"ide\")\n\n1 error\n      role: org.apache.maven.model.validation.ModelValidator\n  roleHint: ide\n\n",
    "AcceptedAnswerId": 72686220,
    "AcceptedAnswer": "That should have been fixed in 2022.1 in the scope of this bug\nPlease update your IDE\n"
}
{
    "Id": 74330854,
    "PostTypeId": 1,
    "Title": "OpenJDK 19 and compressed pointers",
    "Body": "I have a hard time understanding how compressed pointers works in Java 19, help is appreciated.\nIn Java 11 the reference size is 4 for heaps below 32GiB (compressed pointers) and 8 for a larger heap. In Java 19 they seem to take 4 bytes even for larger heaps (how?).\nDetails:\nJava versions: OpenJDK Java 11.0.12 and OpenJDK Java 19.0.1\nCommand lines:\n\n-XX:+UnlockExperimentalVMOptions -XX:+UseEpsilonGC  -Xlog:gc -Xlog:gc+heap+coops -Xms41g -Xmx41g -XX:+AlwaysPreTouch\n\n\n-XX:+UnlockExperimentalVMOptions -XX:+UseEpsilonGC  -Xlog:gc -Xlog:gc+heap+coops -Xms31g -Xmx31g -XX:+AlwaysPreTouch\n\nCode: https://github.com/cornelcreanga/fun/blob/master/src/main/java/com/ccreanga/various/RandomAllocate.java - the code is taken from https://shipilev.net/jvm/anatomy-quarks/23-compressed-references/\nRun this code with both Java 11 and 19 and you can see that the memory size is lower in Java 19 than in Java 11 for a heap > 32 GiB. For a smaller heap the size is almost identical.\n",
    "AcceptedAnswerId": 74349384,
    "AcceptedAnswer": "You are looking at the layout of a byte[] array and an instance of java.lang.Object. Neither of them contains a reference to an object inside the heap.\nThe difference you are seeing, is in the size of the class pointer which is not pointing to a location inside the heap memory. But for historical reasons, the option -XX:+UseCompressedClassPointers was bound to the presence of the -XX:+UseCompressedOops option. So when the heap size disallowed compressed object pointers, the compressed class pointers were disabled as a side effect.\nJDK-8241825, Make compressed oops and compressed class pointers independent addresses this and has been solved with JDK\u00a015.\nSo when I change your program to\nSystem.out.println(ClassLayout.parseInstance(new Object[3]).toPrintable());\n\nand run it with a 41GB heap, I get\n[Ljava.lang.Object; object internals:\nOFF  SZ               TYPE DESCRIPTION               VALUE\n  0   8                    (object header: mark)     0x0000000000000001 (non-biasable; age: 0)\n  8   8                    (object header: class)    0x000001f54bec41e0\n 16   4                    (array length)            3\n 20   4                    (alignment/padding gap)\n 24  24   java.lang.Object Object;.        N/A\nInstance size: 48 bytes\nSpace losses: 4 bytes internal + 0 bytes external = 4 bytes total\n\nprior to JDK\u00a015 and\n[Ljava.lang.Object; object internals:\nOFF  SZ               TYPE DESCRIPTION               VALUE\n  0   8                    (object header: mark)     0x0000000000000001 (non-biasable; age: 0)\n  8   4                    (object header: class)    0x000020fc\n 12   4                    (array length)            3\n 16  24   java.lang.Object Object;.        N/A\nInstance size: 40 bytes\nSpace losses: 0 bytes internal + 0 bytes external = 0 bytes total\n\nwith JDK\u00a015 or newer.\nThe difference is clearly caused by the class pointer and the padding, but the three object references require 24 bytes in each JVM version.\n"
}
{
    "Id": 74753700,
    "PostTypeId": 1,
    "Title": "Cannot resolve method 'antMatchers()' in AuthorizationManagerRequestMatcherRegistry",
    "Body": "I am currently following the Spring Documentation and some tutorials on Web Security. But now I have a problem, that I can't call the method antMatchers. This is the error I'm getting when building the project:\njava: cannot find symbol\n  symbol:   method antMatchers(java.lang.String)\n  location: variable requests of type org.springframework.security.config.annotation.web.configurers.AuthorizeHttpRequestsConfigurer.AuthorizationManagerRequestMatcherRegistry\n\nIn terms of my understanding, I should be able to use this method, so I can permit or not permit HTTP Requests to a certain URL. So my question is, why can't I use the antMatchers() method?\nSecurityConfiguration class:\npackage de.gabriel.vertretungsplan.security;\n\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.security.config.annotation.web.builders.HttpSecurity;\nimport org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;\nimport org.springframework.security.web.SecurityFilterChain;\n\n@Configuration\n@EnableWebSecurity\npublic class SecurityConfiguration {\n\n    @Bean\n    public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {\n        http\n                .authorizeHttpRequests((requests) -> requests\n                        .antMatchers(\"/vertretungsplan\").hasAnyRole(\"SCHUELER\", \"LEHRER\", \"VERWALTUNG\")\n                        .anyRequest().authenticated()\n                )\n                .formLogin((form) -> form\n                        .loginPage(\"/login\")\n                        .permitAll()\n                )\n                .logout((logout) -> logout.permitAll());\n\n        return http.build();\n    }\n\n}\n\npom.xml:\n\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    4.0.0\n    \n        org.springframework.boot\n        spring-boot-starter-parent\n        3.0.0\n         \n    \n    de.gabriel\n    vertretungsplan\n    0.0.1-SNAPSHOT\n    vertretungsplan\n    Demo project for Spring Boot\n    \n        17\n    \n    \n        \n            org.springframework.boot\n            spring-boot-starter-data-jpa\n        \n        \n            org.springframework.boot\n            spring-boot-starter-security\n        \n        \n            org.springframework.boot\n            spring-boot-starter-web\n        \n        \n            com.mysql\n            mysql-connector-j\n            runtime\n        \n\n        \n            org.springframework.boot\n            spring-boot-starter-test\n            test\n        \n        \n            org.springframework.security\n            spring-security-test\n            test\n        \n    \n\n    \n        \n            \n                org.springframework.boot\n                spring-boot-maven-plugin\n            \n        \n    \n\n\n\n",
    "AcceptedAnswerId": 74753955,
    "AcceptedAnswer": "In antMatchers() (as well as mvcMathcers() and regexMatchers()) have been deprecated and removed with Spring Security 6.0. Thus, you can't use them in a Spring Boot 3 project.\nHave a look at this link if you wonder what was the rationale behind this change: Deprecate trailing slash match.\nOverloaded method requestMatchers() was provided as a uniform mean for securing requests. It facilitates all the functionality of the configuration methods that have been removed from the API.\n@Bean\npublic SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {\n    http\n        .authorizeHttpRequests(requests -> requests\n            .requestMatchers(\"/vertretungsplan\").hasAnyRole(\"SCHUELER\", \"LEHRER\", \"VERWALTUNG\")\n            .anyRequest().authenticated()\n        )\n        .formLogin(form -> form\n            .loginPage(\"/login\")\n            .permitAll()\n        )\n        .logout(logout -> logout\n            .permitAll());\n    \n    return http.build();\n}\n\n"
}
{
    "Id": 72724816,
    "PostTypeId": 1,
    "Title": "Running unit tests with Spark 3.3.0 on Java 17 fails with IllegalAccessError: class StorageUtils cannot access class sun.nio.ch.DirectBuffer",
    "Body": "According to the release notes, and specifically the ticket Build and Run Spark on Java 17 (SPARK-33772), Spark now supports running on Java 17.\nHowever, using Java 17 (Temurin-17.0.3+7) with Maven (3.8.6) and maven-surefire-plugin (3.0.0-M7), when running a unit test that uses Spark (3.3.0) it fails with:\n\njava.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x1e7ba8d9) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x1e7ba8d9\n\nThe stack is:\njava.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x1e7ba8d9) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x1e7ba8d9\n  at org.apache.spark.storage.StorageUtils$.(StorageUtils.scala:213)\n  at org.apache.spark.storage.StorageUtils$.(StorageUtils.scala)\n  at org.apache.spark.storage.BlockManagerMasterEndpoint.(BlockManagerMasterEndpoint.scala:114)\n  at org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:353)\n  at org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:290)\n  at org.apache.spark.SparkEnv$.create(SparkEnv.scala:339)\n  at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:194)\n  at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:279)\n  at org.apache.spark.SparkContext.(SparkContext.scala:464)\n  at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2704)\n  at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:953)\n  at scala.Option.getOrElse(Option.scala:189)\n  at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:947)\n  [...]\n\nThe question Java 17 solution for Spark - java.lang.NoClassDefFoundError: Could not initialize class org.apache.spark.storage.StorageUtils was asked only 2 months ago, but this pre-dated the Spark 3.3.0 release, and thus predated official support for Java 17.\nWhy can't I run my Spark 3.3.0 test with Java 17, and how can we fix it?\n",
    "AcceptedAnswerId": 72724817,
    "AcceptedAnswer": "Even though Spark now supports Java 17, it still references the JDK internal class sun.nio.ch.DirectBuffer:\n  // In Java 8, the type of DirectBuffer.cleaner() was sun.misc.Cleaner, and it was possible\n  // to access the method sun.misc.Cleaner.clean() to invoke it. The type changed to\n  // jdk.internal.ref.Cleaner in later JDKs, and the .clean() method is not accessible even with\n  // reflection. However sun.misc.Unsafe added a invokeCleaner() method in JDK 9+ and this is\n  // still accessible with reflection.\n  private val bufferCleaner: DirectBuffer => Unit = [...]\n\nUnder the Java module system, access to this class is restricted.  The Java 9 migration guide says:\n\nIf you must use an internal API that has been made inaccessible by default, then you can break encapsulation using the --add-exports command-line option.\n\nWe need to open access to our module.  To do this for Surefire, we add this configuration to the plugin:\n\n  org.apache.maven.plugins\n  maven-surefire-plugin\n  3.0.0-M7\n  \n    --add-exports java.base/sun.nio.ch=ALL-UNNAMED\n  \n\n\nBased on a discussion with one of the Spark developers, Spark adds the following in order to execute all of its internal unit tests.\n\nThese options are used to pass all Spark UTs, but maybe you don't need all.\n\n--add-opens=java.base/java.lang=ALL-UNNAMED\n--add-opens=java.base/java.lang.invoke=ALL-UNNAMED\n--add-opens=java.base/java.lang.reflect=ALL-UNNAMED\n--add-opens=java.base/java.io=ALL-UNNAMED\n--add-opens=java.base/java.net=ALL-UNNAMED\n--add-opens=java.base/java.nio=ALL-UNNAMED\n--add-opens=java.base/java.util=ALL-UNNAMED\n--add-opens=java.base/java.util.concurrent=ALL-UNNAMED\n--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED\n--add-opens=java.base/sun.nio.ch=ALL-UNNAMED\n--add-opens=java.base/sun.nio.cs=ALL-UNNAMED\n--add-opens=java.base/sun.security.action=ALL-UNNAMED\n--add-opens=java.base/sun.util.calendar=ALL-UNNAMED\n\nIt was also commented:\n\nHowever, these Options needn't explicit add when using spark-shell, spark-sql and spark-submit\n\n"
}
{
    "Id": 74683791,
    "PostTypeId": 1,
    "Title": "Java CompletableFuture for sequential code",
    "Body": "My new team is writing a Java gRPC service and to ensure that we never block the request thread we ended-up wrapping more or less ALL methods inside a CompletableFuture even if those endpoints are conceptually a sequential list of operation (no parallelism).\nSo the code look something like (a Java example is available at the end if needed) :\n  methodA()\n    methodB()\n      methodD() (let say this one is a 15ms RPC call)\n      methodE()\n    methodC()\n      methodF() (let say this one is a 5ms CPU intensive work)\n      methodG()\n \n\nContext:\n\nIn practice the application is much bigger and there're many more layers of functions\nEach application host need to handle 1000 QPS, so you can imagine that methodA is called at that rate\nSome function (few) make a RPC call that can take 5-30ms (IO)\nSome function (very few) run CPU intensive work (\n\nEdit 1: After more reading online yesterday, I understand that if, and only if, we are using true non-blocking HTTP and DB Client (and it doesn't seem like JDBC is non-blocking), this pattern can reduce the total number of threads required. My understanding is that if we have enough memory to keep one thread per request, using a synchronous code would still probably be the most efficient implementation (reduce the overhead of switching threads and loading data), but if we didn't have enough memory to keep that many threads alive, then this notion of making the whole code non-blocking can reduce the number of thread and thus allow the application to scale to more request.\nQuestion 1:\nI understand this unblocks the \"request thread\", but in practice what's the advantage? Are we truly saving CPU time? In the example below, it feels like \"some\" thread will be alive the whole time anyways (in the example below, mostly the thread from CompletableFuture.supplyAsync in methodD), it just happens that it\u2019s not the same thread as the one who received the initial request.\nQuestion 2:\nIs that pattern truly a \"best practice\" and all services should follow a similar pattern? Outside of making the code a bit harder to read I feel, per request 50+ methods gets invoked and 50+ times we call a mix of CompletableFuture .thenCompose() or .supplyAsync. It seems like it's would be adding some overhead. Was CompletableFuture designed to be used that way across the whole code base in every method?\nAnnex (java example):\n  public void myEndpoint(MyRequest request, StreamObserver responseObserver) {\n    methodA(10)\n        .thenApply((response) -> responseObserver.next(response));\n    \n  }\n\n  public CompletableFuture methodA(Integer input) {\n    return CompletableFuture.completedFuture(input)\n        .thenCompose(this::methodB)\n        .thenCompose(this::methodC)\n        .thenApply((i) -> {\n          System.out.println(\"MethodA executed by \".concat(Thread.currentThread().getName() + \": \" + i));\n          return i;\n        });\n  }\n\n  public CompletableFuture methodB(Integer input) {\n    return CompletableFuture.completedFuture(input)\n        .thenCompose(this::methodD)\n        .thenCompose(this::methodE)\n        .thenApply((i) -> {\n          System.out.println(\"MethodB executed by \".concat(Thread.currentThread().getName() + \": \" + i));\n          return i;\n        });\n  }\n\n  public CompletableFuture methodC(Integer input) {\n    return CompletableFuture.completedFuture(input)\n        .thenCompose(this::methodF)\n        .thenCompose(this::methodG)\n        .thenApply((i) -> {\n          System.out.println(\"MethodC executed by \".concat(Thread.currentThread().getName() + \": \" + i));\n          return i;\n        });\n  }\n\n  public CompletableFuture methodD(Integer input) {\n    return CompletableFuture.supplyAsync(() -> {\n      try {\n        // Assume it's a RPC call that takes 5-30ms\n        Thread.sleep(20);\n        System.out.println(\"MethodD executed by \".concat(Thread.currentThread().getName() + \": \" + input));\n      } catch (InterruptedException e) {\n        throw new RuntimeException(e);\n      }\n      return input + 1;\n    });\n  }\n\n  public CompletableFuture methodE(Integer input) {\n    return CompletableFuture.supplyAsync(() -> {\n      System.out.println(\"MethodE executed by \".concat(Thread.currentThread().getName() + \": \" + input));\n      return input + 1;\n    });\n  }\n\n  public CompletableFuture methodF(Integer input) {\n    return CompletableFuture.supplyAsync(() -> {\n      try {\n        // Let's assume it's a CPU intensive work that takes 2-5ms\n        Thread.sleep(5);\n        System.out.println(\"MethodF executed by \".concat(Thread.currentThread().getName() + \": \" + input));\n      } catch (InterruptedException e) {\n        throw new RuntimeException(e);\n      }\n      return input + 1;\n    });\n  }\n\n  public CompletableFuture methodG(Integer input) {\n    return CompletableFuture.supplyAsync(() -> {\n      System.out.println(\"MethodG executed by \".concat(Thread.currentThread().getName() + \": \" + input));\n      return input + 1;\n    });\n  }\n\n",
    "AcceptedAnswerId": 74796834,
    "AcceptedAnswer": "The premise is that threads are a scarce resource, which is not intrinsic to threads but a consequence of using a pool of threads with a configured maximum. The reason today\u2019s frameworks use a pool is that threads, as implemented today, are expensive and creating too many of them can cause significant performance problems.\nYou wrote\n\nMy understanding is that if we have enough memory to keep one thread per request, using a synchronous code would still probably be the most efficient implementation\u2026\n\nwhich is going into the right direction, but it\u2019s important to keep in mind that there might be more constraints than memory. Some operating system\u2019s schedulers become significantly less efficient with a large number of threads, some may even have a fixed limit on how many threads a process is allowed to create.\nSo, when you block a thread by waiting for another, you are limiting the parallel processing capabilities of the thread pool. This applies if you are using, as you put it, a \u201ctrue non-blocking\u201d API, or just any already existing API that returns futures. Submitting your own operations via supplyAsync has no point as the supplier\u2019s code still is executed by a thread, as you correctly pointed out.\nBut when you have an existing future returned by an operation, you should rather chain dependent processing steps instead of waiting for its result via join and friends. Note that calling join() on existing futures can make things even worse than just blocking threads:\nWhen you call join() on a CompletableFuture, it tries to compensate the problem. When the caller is a worker thread of a Fork/Join pool, one of two things can happen:\n\nInstead of doing nothing, it may try to fetch pending jobs and execute them in-place, similar to awaitQuiescence.\n\nIn the best case, it will directly pick up the job you just scheduled with supplyAsync (if using the same pool) and execute it, almost as if you executed it without CompletableFuture (just consuming far more stack space).\nIn the worst case, the thread will be busy executing a long running, entirely unrelated job while the job it\u2019s actually waiting for has been completed long ago. Imagine what happens if that unrelated job also calls join.\n\n\nIt may end up actually blocking the thread but using ForkJoinPool.managedBlock(\u2026), which may start a new worker thread to ensure that the pool\u2019s configured parallelism is kept. Great to solve the problem of reduced parallelism, but on the other hand, reintroducing the very problem of resource consumption you actually wanted to solve with thread pools.\n\nThe worst of all is that you can\u2019t even predict which of the two things will happen.\n\nThere are, however, cases where not blocking a request thread by utilizing other threads has a point. Most notably when the response time for the request itself matters and the results of the background computation are delivered independent of the initial response. The most prominent example of this pattern is the event dispatch thread of GUI frameworks which must be kept free of long running operations, to be able to process subsequent user input.\n\nNote that there is a general solution on the way, to make 99% of all future chains obsolete. Virtual Threads, which are in preview state in JDK\u00a019, are cheap to create and allow to create one thread per request, just like you envisioned in the cite above. When a virtual thread gets blocked, it will release the underlying platform thread for the next virtual thread, so there is no reason to hesitate to call join() on any future, even those belonging to \u201ctrue non-blocking\u201d APIs.\nThe best way to interoperate with this concept and the status quo is to design methods to not return futures, but perform the operation in-place. It\u2019s still possible to design a future chain when necessary, i.e. by using .thenApplyAsync(this::inPlaceEvalMethod) instead of .thenCompose(this::futureReturningMethod). But at the same time, you can write a plain sequential version just calling these methods, which can be executed by a virtual thread. In fact, you could even add the plain sequential version today and benchmark both approaches. The results might convince your team members that \u201cnot blocking the request thread\u201d is not necessarily an improvement.\n"
}
{
    "Id": 74816992,
    "PostTypeId": 1,
    "Title": "Why does Spring Security 6 not create sessions when authenticating with curl and basic auth?",
    "Body": "I recently upgraded to Spring Security 6, and have found that authenticating using basic auth from JS or from curl no longer works but authenticating with basic auth using Java's HttpClient does work. My goal is to be able to authenticate with all approaches.\nThe app uses Java 17, Spring Security 6, and Spring Session 3. It has a \"login\" endpoint which is just a convenience endpoint that is expected to be hit with basic auth and create a session, and it returns a User object. The session id should be used for subsequent requests to other endpoints.\nThe curl command is like so:\n curl -kv --user admin:admin \"https://localhost:9000/login\"\n\nVS the HttpClient is configured like so and calling HttpClient.get(loginUrl)\nHttpClient.newBuilder()\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.connectTimeout(Duration.ofSeconds(300))\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.cookieHandler(new CookieManager())\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.authenticator(new BasicAuthenticator(username, password))\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.sslContext(createSsl())\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.build();\n\npublic class BasicAuthenticator extends Authenticator {\n\n\u00a0\u00a0\u00a0private PasswordAuthentication authentication;\n\n\u00a0\u00a0\u00a0public BasicAuthenticator(String username, String password) {\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0authentication = new PasswordAuthentication(username, password.toCharArray());\n\u00a0\u00a0\u00a0}\n\n\u00a0\u00a0\u00a0@Override\n\u00a0\u00a0\u00a0public PasswordAuthentication getPasswordAuthentication() {\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return authentication;\n\u00a0\u00a0\u00a0}\n}\n\nThe security configuration is the block below... In upgrading to SpringSecurity 6 I added the requireExplicitSave() method, I have suspicions around this because my trouble is around saving sessions, but the added code is supposed to have spring security using the old functionality.\nhttp\n\u00a0\u00a0\u00a0.securityContext( securityContext -> securityContext.requireExplicitSave(false))\n\u00a0\u00a0\u00a0.authorizeHttpRequests((authz) -> authz\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.requestMatchers(openEndpoints).permitAll()\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.anyRequest().authenticated()\n\u00a0\u00a0\u00a0)\n\u00a0\u00a0\u00a0.httpBasic()\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.and()\n\u00a0\u00a0\u00a0.csrf()\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.disable()\n\u00a0\u00a0\u00a0.exceptionHandling()\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.accessDeniedHandler((req, resp, e) -> e.printStackTrace() )\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.and()\n\u00a0\u00a0\u00a0.logout()\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.invalidateHttpSession(true)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.clearAuthentication(true);\n\nI turned on request logging, security logging, and SQL logging. The SQL is all the same, and the basic auth request is always authenticated for all scenarios. The headers are different, but I can't see the headers for the HttpClient preflight call, and of the headers I do see, I don't know why authentication or session creation would work for one set of headers but not the other.\nThe core of the problem seems to be that the login request from the HttpClient ends with a session being created and the request from curl does not. Note that the big difference in the server logs when using curl is \"Failed to create a session, as response has been committed. Unable to store SecurityContext.\" However even stepping through the spring security code I can't tell what is causing the difference.\u00a0\nSee logs here:\nCURL\n2022-12-14T16:38:07.594-05:00 DEBUG 92726 --- [nio-9000-exec-1] o.s.security.web.FilterChainProxy        : Securing GET /login\n2022-12-14T16:38:07.597-05:00 DEBUG 92726 --- [nio-9000-exec-1] s.s.w.c.SecurityContextPersistenceFilter : Set SecurityContextHolder to empty SecurityContext\n2022-12-14T16:38:07.704-05:00 DEBUG 92726 --- [nio-9000-exec-1] org.hibernate.SQL                        : select u1_0.id,u1_0.display_name,u1_0.email,u1_0.enabled,u1_0.password,u1_0.registration_time,r1_0.user_id,r1_0.role_id,u1_0.username from app_user u1_0 join user_role r1_0 on u1_0.id=r1_0.user_id where u1_0.username=?\n2022-12-14T16:38:07.797-05:00 DEBUG 92726 --- [nio-9000-exec-1] o.s.s.a.dao.DaoAuthenticationProvider    : Authenticated user\n2022-12-14T16:38:07.799-05:00 DEBUG 92726 --- [nio-9000-exec-1] o.s.s.w.a.www.BasicAuthenticationFilter  : Set SecurityContextHolder to UsernamePasswordAuthenticationToken [Principal=org.springframework.security.core.userdetails.User [Username=admin, Password=[PROTECTED], Enabled=true, AccountNonExpired=true, credentialsNonExpired=true, AccountNonLocked=true, Granted Authorities=[ROLE_ADMIN, ROLE_USER]], Credentials=[PROTECTED], Authenticated=true, Details=WebAuthenticationDetails [RemoteIpAddress=127.0.0.1, SessionId=null], Granted Authorities=[ROLE_ADMIN, ROLE_USER]]\n2022-12-14T16:38:07.801-05:00 DEBUG 92726 --- [nio-9000-exec-1] o.s.security.web.FilterChainProxy        : Secured GET /login\n2022-12-14T16:38:07.805-05:00 DEBUG 92726 --- [nio-9000-exec-1] o.s.w.f.CommonsRequestLoggingFilter      : Before request [GET /login, headers=[host:\"localhost:9000\", authorization:\"Basic YWRtaW46YWRtaW4=\", user-agent:\"curl/7.84.0\", accept:\"*/*\"]]\n2022-12-14T16:38:07.816-05:00 DEBUG 92726 --- [nio-9000-exec-1] horizationManagerBeforeMethodInterceptor : Authorizing method invocation ReflectiveMethodInvocation: public com.seebie.dto.User com.seebie.server.controller.UserController.login(java.security.Principal); target is of class [com.seebie.server.controller.UserController]\n2022-12-14T16:38:07.822-05:00 DEBUG 92726 --- [nio-9000-exec-1] horizationManagerBeforeMethodInterceptor : Authorized method invocation ReflectiveMethodInvocation: public com.seebie.dto.User com.seebie.server.controller.UserController.login(java.security.Principal); target is of class [com.seebie.server.controller.UserController]\n2022-12-14T16:38:07.826-05:00 DEBUG 92726 --- [nio-9000-exec-1] org.hibernate.SQL                        : select u1_0.id,u1_0.display_name,u1_0.email,u1_0.enabled,u1_0.password,u1_0.registration_time,u1_0.username from app_user u1_0 where u1_0.username=?\n2022-12-14T16:38:07.832-05:00 DEBUG 92726 --- [nio-9000-exec-1] org.hibernate.SQL                        : select r1_0.user_id,r1_0.role_id from user_role r1_0 where r1_0.user_id=?\n2022-12-14T16:38:07.836-05:00 DEBUG 92726 --- [nio-9000-exec-1] org.hibernate.SQL                        : select a1_0.user_id,a1_0.id,a1_0.city,a1_0.line1,a1_0.state,a1_0.zip from address a1_0 where a1_0.user_id=?\n2022-12-14T16:38:07.840-05:00 DEBUG 92726 --- [nio-9000-exec-1] org.hibernate.SQL                        : select s1_0.principal_name,s1_0.primary_id,s1_0.session_id from spring_session s1_0 where s1_0.principal_name=?\n2022-12-14T16:38:07.871-05:00 DEBUG 92726 --- [nio-9000-exec-1] o.s.w.f.CommonsRequestLoggingFilter      : REQUEST DATA : GET /login, headers=[host:\"localhost:9000\", authorization:\"Basic YWRtaW46YWRtaW4=\", user-agent:\"curl/7.84.0\", accept:\"*/*\"]]\n2022-12-14T16:38:07.873-05:00  WARN 92726 --- [nio-9000-exec-1] w.c.HttpSessionSecurityContextRepository : Failed to create a session, as response has been committed. Unable to store SecurityContext.\n2022-12-14T16:38:07.873-05:00 DEBUG 92726 --- [nio-9000-exec-1] s.s.w.c.SecurityContextPersistenceFilter : Cleared SecurityContextHolder to complete request\n\nHttpClient\n2022-12-14T06:31:28.390-05:00 DEBUG 85610 --- [o-auto-1-exec-1] o.s.security.web.FilterChainProxy        : Securing GET /login\n2022-12-14T06:31:28.420-05:00 DEBUG 85610 --- [o-auto-1-exec-1] s.s.w.c.SecurityContextPersistenceFilter : Set SecurityContextHolder to empty SecurityContext\n2022-12-14T06:31:28.913-05:00 DEBUG 85610 --- [o-auto-1-exec-1] org.hibernate.SQL                        : select u1_0.id,u1_0.display_name,u1_0.email,u1_0.enabled,u1_0.password,u1_0.registration_time,r1_0.user_id,r1_0.role_id,u1_0.username from app_user u1_0 join user_role r1_0 on u1_0.id=r1_0.user_id where u1_0.username=?\n2022-12-14T06:31:29.102-05:00 DEBUG 85610 --- [o-auto-1-exec-1] o.s.s.a.dao.DaoAuthenticationProvider    : Authenticated user\n2022-12-14T06:31:29.103-05:00 DEBUG 85610 --- [o-auto-1-exec-1] o.s.s.w.a.www.BasicAuthenticationFilter  : Set SecurityContextHolder to UsernamePasswordAuthenticationToken [Principal=org.springframework.security.core.userdetails.User [Username=admin, Password=[PROTECTED], Enabled=true, AccountNonExpired=true, credentialsNonExpired=true, AccountNonLocked=true, Granted Authorities=[ROLE_ADMIN, ROLE_USER]], Credentials=[PROTECTED], Authenticated=true, Details=WebAuthenticationDetails [RemoteIpAddress=127.0.0.1, SessionId=19ab0971-5fb3-47fd-a4f9-cdde1ad24883], Granted Authorities=[ROLE_ADMIN, ROLE_USER]]\n2022-12-14T06:31:29.108-05:00 DEBUG 85610 --- [o-auto-1-exec-1] o.s.security.web.FilterChainProxy        : Secured GET /login\n2022-12-14T06:31:29.136-05:00 DEBUG 85610 --- [o-auto-1-exec-1] o.s.w.f.CommonsRequestLoggingFilter      : Before request [GET /login, headers=[authorization:\"Basic YWRtaW46YWRtaW4=\", content-length:\"0\", host:\"localhost:64723\", user-agent:\"Java-http-client/17.0.2\", cookie:\"SESSION=MTlhYjA5NzEtNWZiMy00N2ZkLWE0ZjktY2RkZTFhZDI0ODgz\", Content-Type:\"application/json;charset=UTF-8\"]]\n2022-12-14T06:31:29.274-05:00 DEBUG 85610 --- [o-auto-1-exec-1] horizationManagerBeforeMethodInterceptor : Authorizing method invocation ReflectiveMethodInvocation: public com.seebie.dto.User com.seebie.server.controller.UserController.login(java.security.Principal); target is of class [com.seebie.server.controller.UserController]\n2022-12-14T06:31:29.332-05:00 DEBUG 85610 --- [o-auto-1-exec-1] horizationManagerBeforeMethodInterceptor : Authorized method invocation ReflectiveMethodInvocation: public com.seebie.dto.User com.seebie.server.controller.UserController.login(java.security.Principal); target is of class [com.seebie.server.controller.UserController]\n2022-12-14T06:31:29.373-05:00 DEBUG 85610 --- [o-auto-1-exec-1] org.hibernate.SQL                        : select u1_0.id,u1_0.display_name,u1_0.email,u1_0.enabled,u1_0.password,u1_0.registration_time,u1_0.username from app_user u1_0 where u1_0.username=?\n2022-12-14T06:31:29.392-05:00 DEBUG 85610 --- [o-auto-1-exec-1] org.hibernate.SQL                        : select r1_0.user_id,r1_0.role_id from user_role r1_0 where r1_0.user_id=?\n2022-12-14T06:31:29.409-05:00 DEBUG 85610 --- [o-auto-1-exec-1] org.hibernate.SQL                        : select a1_0.user_id,a1_0.id,a1_0.city,a1_0.line1,a1_0.state,a1_0.zip from address a1_0 where a1_0.user_id=?\n2022-12-14T06:31:29.413-05:00 DEBUG 85610 --- [o-auto-1-exec-1] org.hibernate.SQL                        : select s1_0.principal_name,s1_0.primary_id,s1_0.session_id from spring_session s1_0 where s1_0.principal_name=?\n2022-12-14T06:31:29.678-05:00 DEBUG 85610 --- [o-auto-1-exec-1] o.s.w.f.CommonsRequestLoggingFilter      : REQUEST DATA : GET /login, headers=[authorization:\"Basic YWRtaW46YWRtaW4=\", content-length:\"0\", host:\"localhost:64723\", user-agent:\"Java-http-client/17.0.2\", cookie:\"SESSION=MTlhYjA5NzEtNWZiMy00N2ZkLWE0ZjktY2RkZTFhZDI0ODgz\", Content-Type:\"application/json;charset=UTF-8\"]]\n2022-12-14T06:31:29.680-05:00 DEBUG 85610 --- [o-auto-1-exec-1] w.c.HttpSessionSecurityContextRepository : Stored SecurityContextImpl [Authentication=UsernamePasswordAuthenticationToken [Principal=org.springframework.security.core.userdetails.User [Username=admin, Password=[PROTECTED], Enabled=true, AccountNonExpired=true, credentialsNonExpired=true, AccountNonLocked=true, Granted Authorities=[ROLE_ADMIN, ROLE_USER]], Credentials=[PROTECTED], Authenticated=true, Details=WebAuthenticationDetails [RemoteIpAddress=127.0.0.1, SessionId=19ab0971-5fb3-47fd-a4f9-cdde1ad24883], Granted Authorities=[ROLE_ADMIN, ROLE_USER]]] to HttpSession [org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper$HttpSessionWrapper@7ba784f2]\n2022-12-14T06:31:29.680-05:00 DEBUG 85610 --- [o-auto-1-exec-1] s.s.w.c.SecurityContextPersistenceFilter : Cleared SecurityContextHolder to complete request\n\nNote the session in headers for the HttpClient call... I think HttpClient makes a preflight auth call that gets a 401 and then makes the \"real\" call with the credentials, at least that's how it was in Java 11.\nI think if I understood the difference in how these calls are being made/handled that causes one technique to work but not the other, I would be able to solve the problem. So that really is the question: What is the difference in spring security 6 (along with spring session) handling session creation when using Java 17's HttpClient vs curl?\n[UPDATE] to anyone who read this far: the behavior is actually expected behavior for Spring Security. A full discussion and explanation are in the spring security issue that I had opened here\n",
    "AcceptedAnswerId": 74838578,
    "AcceptedAnswer": "Well, if we are not going to investigate why preflight requests make sense (IMO, that seems to be a bug), the explanation of what has been changed in spring 6 is following:\nas was mentioned in Session Management Migrations now Spring does not enable SecurityContextPersistenceFilter by default, however in Spring 5 SecurityContextPersistenceFilter was responsible for saving SecurityContext in http session (and hence creating it) unless that was explicitly disabled. Now in order to return previous behaviour you desire you need to setup SecurityContextRepository via:\nhttp.securityContext(securityContext -> securityContext.\n      securityContextRepository(new HttpSessionSecurityContextRepository())\n)\n\n"
}
{
    "Id": 74639116,
    "PostTypeId": 1,
    "Title": "What is the difference between green threads and virtual threads?",
    "Body": "Green Threads have been implemented with Java 1.1 and dropped in subsequent Java versions, according to https://en.wikipedia.org/wiki/Green_thread.\nJava 19 introduced Virtual Threads as a preview feature.\nhttps://openjdk.org/jeps/425\nBoth threads seem to work in User Space and not in Kernel Space as Javas Native Threads do.\nWhat's the difference between them, and are the previous limitations of Green Threads omitted with the new Virtual Threads?\n",
    "AcceptedAnswerId": 74639215,
    "AcceptedAnswer": "Short Answer:\nGreen Threads had an N:1 mapping with OS Threads. All the Green Threads ran on a single OS Thread. With Virtual Threads, multiple virtual threads can run on multiple native threads (n:m mapping)\nA bit more details from the JEP 425\n\nJava's green threads all shared one OS thread (M:1 scheduling) and were eventually outperformed by platform threads (Java's Native Threads) implemented as wrappers for OS threads (1:1 scheduling)\n\nVirtual threads employ M:N scheduling, where a large number (M) of virtual threads is scheduled to run on a smaller number (N) of OS threads.\n\n\nJust a small overview\n\n\n\n\nThread Type\nDescription\nJava Thread Type (M) : Native Threads(N)\n\n\n\n\nPlatform Threads\nA wrapper for OS Threads.\n1:1\n\n\nGreen Threads\nRuns multiple \"Green Threads\" on a single OS Thread.\nM:1\n\n\nVirtual Threads\nRuns multiple Virtual Threads on Multiple OS threads\nM:N (M > N)\n\n\n\nFull Quote from JEP\n\nVirtual threads are a lightweight implementation of threads that is\nprovided by the JDK rather than the OS. They are a form of user-mode\nthreads, which have been successful in other multithreaded languages\n(e.g., goroutines in Go and processes in Erlang). User-mode threads\neven featured as so-called \"green threads\" in early versions of Java,\nwhen OS threads were not yet mature and widespread. However, Java's\ngreen threads all shared one OS thread (M:1 scheduling) and were\neventually outperformed by platform threads, implemented as wrappers\nfor OS threads (1:1 scheduling). Virtual threads employ M:N\nscheduling, where a large number (M) of virtual threads is scheduled\nto run on a smaller number (N) of OS threads.\n\n"
}
{
    "Id": 74695402,
    "PostTypeId": 1,
    "Title": "BUG! exception in phase 'semantic analysis' in source unit '_BuildScript_' Unsupported class file major version 63",
    "Body": "Bug when first trying to run a brand new React Native application.\nBUG! exception in phase 'semantic analysis' in source unit 'BuildScript' Unsupported class file major version 63\nI encountered this error when I first installed the latest version of Java\n\njava 19.0.1\n\nand creating a React Native application that auto generated with\n\nreact-native dependency v0.70.6\n\n",
    "AcceptedAnswerId": 74695403,
    "AcceptedAnswer": "SOLUTION:\nThis is a dependency issue and we need the latest version of Gradle to support Java 19.\nIn your React Native application folder, nav to android/gradle/wrapper/gradle-wrapper.properties\nFind the distributionUrl variable and change the end path to gradle-7.6-all.zip\n"
}
{
    "Id": 72761919,
    "PostTypeId": 1,
    "Title": "Class SpringHibernateJpaPersistenceProvider does not implement the requested interface PersistenceProvider",
    "Body": "I'm stumped - I haven't used Hibernate in several years and then, never with Spring Boot.  Spring Boot but never with Hibernate or JPA.  So i'm trying to figure out how to get this to work for my job - I'm supposed to demo something Monday and if I can get 'this' to work, I'll copy it over to my work laptop and change the details of course.  Btw - here's the message I get - I had to shorten it in the title:\n\"Class org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider does not implement the requested interface javax.persistence.spi.PersistenceProvider\"\nI have the \"main\" class - TestWebApplication:\npackage net.draconia.testWeb;\n\nimport java.util.Properties;\n\nimport javax.sql.DataSource;\n\nimport org.apache.commons.dbcp2.BasicDataSource;\n\nimport org.springframework.boot.SpringApplication;\n\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\n\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.orm.hibernate5.HibernateTransactionManager;\nimport org.springframework.orm.hibernate5.LocalSessionFactoryBean;\nimport org.springframework.orm.jpa.JpaTransactionManager;\nimport org.springframework.orm.jpa.JpaVendorAdapter;\nimport org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean;\nimport org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter;\nimport org.springframework.transaction.PlatformTransactionManager;\n\n@SpringBootApplication(scanBasePackages = {\"com.draconia.testWeb.controller\"})\npublic class TestWebApplication\n{\n    \n    @Bean\n    public DataSource getDatasource()\n    {\n        BasicDataSource objDatasource = new BasicDataSource();\n        \n        objDatasource.setDriverClassName(\"com.mysql.jdbc.Driver\");\n        objDatasource.setUrl(\"jdbc:mysql://localhost:3306/Test\");\n        objDatasource.setUsername(\"root\");\n        objDatasource.setPassword(\"R3g1n@ M1lL$ 1$ My Qu3eN!\");\n        \n        return(objDatasource);\n    }\n    \n    @Bean\n    public LocalContainerEntityManagerFactoryBean getEntityManagerFactory()\n    {\n          LocalContainerEntityManagerFactoryBean objEntityManager = new LocalContainerEntityManagerFactoryBean();\n          \n          objEntityManager.setDataSource(getDatasource());\n          objEntityManager.setPackagesToScan(new String[] { \"net.draconia.testWeb.beans\" });\n\n          JpaVendorAdapter objVendorAdapter = new HibernateJpaVendorAdapter();\n          objEntityManager.setJpaVendorAdapter(objVendorAdapter);\n          objEntityManager.setJpaProperties(getHibernateProperties());\n\n          return(objEntityManager);\n   }\n    \n    protected Properties getHibernateProperties()\n    {\n        Properties objHibernateProperties = new Properties();\n        \n        objHibernateProperties.setProperty(\"hibernate.hbm2ddl.auto\", \"create-drop\");\n        objHibernateProperties.setProperty(\"hibernate.dialect\", \"org.hibernate.dialect.MySQLDialect\");\n        \n        return(objHibernateProperties);\n    }\n    \n    @Bean\n    public JpaTransactionManager getHibernateTransactionManager()\n    {\n        JpaTransactionManager objTransactionManager = new JpaTransactionManager();\n        \n        objTransactionManager.setEntityManagerFactory(getEntityManagerFactory().getObject());\n        \n        return(objTransactionManager);\n    }\n    \n    public static void main(String[] args)\n    {\n        SpringApplication.run(TestWebApplication.class, args);\n    }\n}\n\n, the entity bean:\npackage net.draconia.testWeb.beans;\n\nimport javax.persistence.Column;\nimport javax.persistence.Entity;\nimport javax.persistence.GeneratedValue;\nimport javax.persistence.GenerationType;\nimport javax.persistence.Id;\n\n@Entity(name = \"Books\")\npublic class Book\n{\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Integer miId;\n    \n    @Column(columnDefinition = \"varchar(200) not null\", insertable = true, length = 200, name = \"BookName\", nullable = false, table = \"Books\", unique = false, updatable = true)\n    private String msBookName;\n    \n    @Column(columnDefinition = \"varchar(100) not null\", insertable = true, length = 100, name=\"Author\", nullable = false, table = \"Books\", unique = false, updatable = true)\n    private String msAuthor;\n    \n    public String getAuthor()\n    {\n        if(msAuthor == null)\n            msAuthor = \"\";\n        \n        return(msAuthor);\n    }\n    \n    public String getBookName()\n    {\n        if(msBookName == null)\n            msBookName = \"\";\n        \n        return(msBookName);\n    }\n    \n    public int getId()\n    {\n        if(miId == null)\n            miId = 0;\n        \n        return(miId);\n    }\n    \n    public void setAuthor(final String sAuthor)\n    {\n        if(sAuthor == null)\n            msAuthor = \"\";\n        else\n            msAuthor = sAuthor;\n    }\n    \n    public void setBookName(final String sBookName)\n    {\n        if(sBookName == null)\n            msBookName = \"\";\n        else\n            msBookName = sBookName;\n    }\n    \n    public void setId(final Integer iId)\n    {\n        if(iId == null)\n            miId = 0;\n        else\n            miId = iId;\n    }\n}\n\n, the DAOConcrete class (the interface is just one method which is logical but if you want I'll post that too):\npackage net.draconia.testWeb.dao;\n\nimport java.util.List;\n\nimport javax.persistence.EntityManager;\nimport javax.persistence.EntityManagerFactory;\n\nimport org.springframework.beans.factory.annotation.Autowired;\n\nimport org.springframework.stereotype.Repository;\n\nimport net.draconia.testWeb.beans.Book;\n\n@Repository(\"bookDAO\")\npublic class BookDAOImpl implements BookDAO\n{\n    @Autowired\n    private EntityManagerFactory mObjEntityManagerFactory;\n    \n    public List getAllBooks()\n    {\n        EntityManager objEntityManager = getEntityManagerFactory().createEntityManager();\n        List lstBooks = objEntityManager.createQuery(\"from Books\", Book.class).getResultList();\n        \n        return(lstBooks);\n    }\n    \n    protected EntityManagerFactory getEntityManagerFactory()\n    {\n        return(mObjEntityManagerFactory);\n    }\n}\n\n, and the Controller class for the REST endpoints/MVC Controller:\npackage net.draconia.testWeb.controllers;\n\nimport java.util.List;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.GetMapping;\n\nimport net.draconia.testWeb.beans.Book;\nimport net.draconia.testWeb.dao.BookDAO;\n\n@Controller\npublic class TestController\n{\n    @Autowired\n    private BookDAO mObjDAO;\n    \n    @GetMapping(\"/Books\")\n    public List getBooks()\n    {\n        return(getDAO().getAllBooks());\n    }\n    \n    protected BookDAO getDAO()\n    {\n        return(mObjDAO);\n    }\n}\n\nThe POM file is here just for completeness but I don't think it's necessarily a problem unless I'm missing a dependency:\n\n\n    4.0.0\n    \n        org.springframework.boot\n        spring-boot-starter-parent\n        2.7.1\n         \n    \n    \n    net.draconia\n    testWeb\n    0.0.1-SNAPSHOT\n    testWeb\n    Demo project for Spring Boot\n    \n    \n        6.1.0.Final\n        11\n        8.0.29\n        5.3.2\n    \n    \n    \n        \n            com.fasterxml.jackson.core\n            jackson-core\n            2.13.3\n        \n        \n            jakarta.persistence\n            jakarta.persistence-api\n            3.0.0\n        \n        \n            javax.persistence\n            javax.persistence-api\n            2.2\n        \n        \n            mysql\n            mysql-connector-java\n            ${mysql.version}\n        \n        \n            org.apache.commons\n            commons-dbcp2\n            2.9.0\n        \n        \n            org.hibernate.orm\n            hibernate-core\n            ${hibernate.version}\n        \n        \n            org.springframework.boot\n            spring-boot-starter-test\n            test\n        \n        \n            org.springframework.boot\n            spring-boot-starter-web\n        \n        \n            org.springframework\n            spring-orm\n            ${spring.version}\n        \n    \n\n    \n        \n            \n                org.springframework.boot\n                spring-boot-maven-plugin\n            \n        \n    \n\n\nIf you'll note, i'm including a dependency for the Jackson library because the list of books should return as a JSON object.  I don't think that's a poblem but just saying - and I could probably have remoed that for this but then when it runs, the list of books would be unintelligible to me getting a response when/if it worked.  What am I doing wrong???\n",
    "AcceptedAnswerId": 72763415,
    "AcceptedAnswer": "Change hibernate to version 5.6.9.Final (or any higher 5.6.x):\n5.6.9.Final\n\n"
}
{
    "Id": 74701738,
    "PostTypeId": 1,
    "Title": "Spring Boot 3 springdoc-openapi-ui doesn't work",
    "Body": "I'm trying to add swagger-ui (OpenAPI 3.0) to a Spring Boot v3 application.\nI've added the openapi-ui maven dependency, and it should work as per the documentation.\n\n    org.springdoc\n    springdoc-openapi-ui\n    1.6.11\n\n\nBut apparently, it still doesn't work and localhost:8080/swagger-ui.html returns an 404 error.\nWhat am I missing?\n\n",
    "AcceptedAnswerId": 74701779,
    "AcceptedAnswer": "According to the documentation:\n\nFor spring-boot 3 support, make sure you use springdoc-openapi v2\n\nhttps://springdoc.org/v2/\n\nFor the integration between spring-boot and swagger-ui, add the\nlibrary to the list of your project dependencies (No additional\nconfiguration is needed)\n\n\n    org.springdoc\n    springdoc-openapi-starter-webmvc-ui\n    2.0.0\n\n\n\nThis will automatically deploy swagger-ui to a spring-boot\napplication:\nDocumentation will be available in HTML format, using the official\nswagger-ui jars\nThe Swagger UI page will then be available at\nhttp://server:port/context-path/swagger-ui.html and the OpenAPI\ndescription will be available at the following url for json format:\nhttp://server:port/context-path/v3/api-docs\n\nserver: The server name or IP\n\nport: The server port\n\ncontext-path: The context path of the application\n\nDocumentation can be available in yaml format as well, on the following path : /v3/api-docs.yaml\n\n\nPlease note that modules have been renamed:\nhttps://springdoc.org/v2/#migrating-from-springdoc-v1\n\n"
}
{
    "Id": 72738837,
    "PostTypeId": 1,
    "Title": "In Java, what does the / (i.e., forward slash) mean in object references like $Lambda$15/0x00000008000a9440@32e6e9c3)?",
    "Body": "In JShell, if I do this:\ninterface Foo { String foo(); }\n(Foo) () -> \"hi\"\n\nI get\n|  created interface Foo\n$2 ==> $Lambda$15/0x00000008000a9440@32e6e9c3\n\nFrom the research below, I know the following:\n$Lambda = an in-memory reference, as opposed to one persisted to disk by an anonymous inner class (AIC), to the generated bytecode\n$15 = an object reference to the AIC\n@32e6e9c3 = the sequential number of the object created--at least, in IntelliJ\nBut what does the / (slash) indicate, as in /0x00000008000a9440?\n",
    "AcceptedAnswerId": 72887915,
    "AcceptedAnswer": "Summary\n$Lambda$15/0x00000008000a9440 is the name of the created hidden class.\nAs it will be shown below, 0x00000008000a9440 is called a suffix.\nThe name of the class can be retrieved by calling the java.lang.Class.getName() method.\nTherefore:\n\nFor example, the same class names can be retrieved by a Java program (not through JShell).\nThe question does not seem to be about JShell, but about the Java language and the Java Virtual Machine.\n\nExample program to show name of hidden class\nProgram class\npackage info.brunov.stackoverflow.question72804142;\n\nimport java.util.function.Supplier;\n\npublic final class Program {\n    public static void main(final String args[]) {\n        printRuntimeInformation();\n\n        final Supplier supplier1 = () -> \"\";\n        final Supplier supplier2 = () -> \"\";\n        final Supplier supplier3 = () -> \"\";\n        System.out.println(\n            String.format(\"Supplier 1: %s\", supplier1.getClass().getName())\n        );\n        System.out.println(\n            String.format(\"Supplier 2: %s\", supplier2.getClass().getName())\n        );\n        System.out.println(\n            String.format(\"Supplier 3: %s\", supplier3.getClass().getName())\n        );\n    }\n\n    private static void printRuntimeInformation() {\n        System.out.println(\n            String.format(\n                \"Java Virtual Machine specification name: %s\",\n                System.getProperty(\"java.vm.specification.name\")\n            )\n        );\n        System.out.println(\n            String.format(\n                \"Java Virtual Machine specification version: %s\",\n                System.getProperty(\"java.vm.specification.version\")\n            )\n        );\n        System.out.println(\n            String.format(\n                \"Java Virtual Machine specification vendor: %s\",\n                System.getProperty(\"java.vm.specification.vendor\")\n            )\n        );\n        System.out.println(\n            String.format(\n                \"Java Virtual Machine implementation name: %s\",\n                System.getProperty(\"java.vm.name\")\n            )\n        );\n        System.out.println(\n            String.format(\n                \"Java Virtual Machine implementation version: %s\",\n                System.getProperty(\"java.vm.version\")\n            )\n        );\n        System.out.println(\n            String.format(\n                \"Java Virtual Machine implementation vendor: %s\",\n                System.getProperty(\"java.vm.vendor\")\n            )\n        );\n    }\n}\n\nProgram output\nJava Virtual Machine specification name: Java Virtual Machine Specification\nJava Virtual Machine specification version: 18\nJava Virtual Machine specification vendor: Oracle Corporation\nJava Virtual Machine implementation name: OpenJDK 64-Bit Server VM\nJava Virtual Machine implementation version: 18.0.1-ea+10-Debian-1\nJava Virtual Machine implementation vendor: Debian\nSupplier 1: info.brunov.stackoverflow.question72804142.Program$$Lambda$18/0x0000000800c031f0\nSupplier 2: info.brunov.stackoverflow.question72804142.Program$$Lambda$19/0x0000000800c033f8\nSupplier 3: info.brunov.stackoverflow.question72804142.Program$$Lambda$20/0x0000000800c03600\n\nDocumentation references\nJEP 371: Hidden Classes\nThe hidden classes have been introduced since JDK 15.\nFor additional details, please, refer to the JEP: JEP 371: Hidden Classes.\nHere is an excerpt from the JEP on the hidden class names:\n\nThe major difference in how a hidden class is created lies in the name it is given. A hidden class is not anonymous. It has a name that is available via Class::getName and may be shown in diagnostics (such as the output of java -verbose:class), in JVM TI class loading events, in JFR events, and in stack traces. However, the name has a sufficiently unusual form that it effectively makes the class invisible to all other classes. The name is the concatenation of:\n\nThe binary name in internal form (JVMS 4.2.1) specified by this_class in the ClassFile structure, say A/B/C;\nThe '.' character; and\nAn unqualified name (JVMS 4.2.2) that is chosen by the JVM implementation.\n\nFor example, if this_class specifies com/example/Foo (the internal form of the binary name com.example.Foo), then a hidden class derived from the ClassFile structure may be named com/example/Foo.1234. This string is neither a binary name nor the internal form of a binary name.\nGiven a hidden class whose name is A/B/C.x, the result of Class::getName is the concatenation of:\n\nThe binary name A.B.C (obtained by taking A/B/C and replacing each '/' with '.');\nThe '/' character; and\nThe unqualified name x.\n\nFor example, if a hidden class is named com/example/Foo.1234, then the result of Class::getName is com.example.Foo/1234. Again, this string is neither a binary name nor the internal form of a binary name.\nThe namespace of hidden classes is disjoint from the namespace of normal classes. Given a ClassFile structure where this_class specifies com/example/Foo/1234, invoking cl.defineClass(\"com.example.Foo.1234\", bytes, ...) merely results in a normal class named com.example.Foo.1234, distinct from the hidden class named com.example.Foo/1234. It is impossible to create a normal class named com.example.Foo/1234 because cl.defineClass(\"com.example.Foo/1234\", bytes, ...) will reject the string argument as being not a binary name.\n\nJavadoc: java.lang.Class#getName() method\nLet's refer to the method documentation: Class (Java SE 15 & JDK 15).\nAn excerpt from the documentation:\n\npublic\u00a0String\u00a0getName()\nReturns the name of the entity (class, interface, array class, primitive type, or void) represented by this Class object.\nIf this Class object represents a class or interface, not an array class, then:\n\nIf the class or interface is not hidden, then the binary name of the class or interface is returned.\nIf the class or interface is hidden, then the result is a string of the form: N + '/' +  where N is the binary name indicated by the class file passed to Lookup::defineHiddenClass, and  is an unqualified name.\n\n\nImplementation details: OpenJDK Java Virtual Machine: Hidden class name\nIntroduction\nLet's consider the source code of OpenJDK 18.\nLet's refer to the tag: openjdk/jdk18 at jdk-18+37.\nPlease, note that:\n\nThe below execution paths are theoretical: I am using the mentioned source code tag.\nThe below call stacks are real: I am using OpenJDK 18.0.1-ea+10-Debian-1.\n\nHidden class name mangling\nHidden class creation (the java.lang.invoke.MethodHandles.Lookup.defineHiddenClass() method) includes the mangling of its name.\nLet's consider the following call stack:\n\"main@1\" prio=5 tid=0x1 nid=NA runnable\n  java.lang.Thread.State: RUNNABLE\n      at java.lang.System$2.defineClass(System.java:2346)\n      at java.lang.invoke.MethodHandles$Lookup$ClassDefiner.defineClass(MethodHandles.java:2432)\n      at java.lang.invoke.MethodHandles$Lookup$ClassDefiner.defineClassAsLookup(MethodHandles.java:2413)\n      at java.lang.invoke.MethodHandles$Lookup.defineHiddenClass(MethodHandles.java:2119)\n      at java.lang.invoke.InnerClassLambdaMetafactory.generateInnerClass(InnerClassLambdaMetafactory.java:385)\n      at java.lang.invoke.InnerClassLambdaMetafactory.spinInnerClass(InnerClassLambdaMetafactory.java:293)\n      at java.lang.invoke.InnerClassLambdaMetafactory.buildCallSite(InnerClassLambdaMetafactory.java:228)\n      at java.lang.invoke.LambdaMetafactory.metafactory(LambdaMetafactory.java:341)\n      at java.lang.invoke.DirectMethodHandle$Holder.invokeStatic(DirectMethodHandle$Holder:-1)\n      at java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder:-1)\n      at java.lang.invoke.BootstrapMethodInvoker.invoke(BootstrapMethodInvoker.java:134)\n      at java.lang.invoke.CallSite.makeSite(CallSite.java:315)\n      at java.lang.invoke.MethodHandleNatives.linkCallSiteImpl(MethodHandleNatives.java:279)\n      at java.lang.invoke.MethodHandleNatives.linkCallSite(MethodHandleNatives.java:269)\n      at info.brunov.stackoverflow.question72804142.Program.main(Program.java:9)\n\nThen let's consider the following execution path as the continuation of the call stack:\nClass java.lang.ClassLoader#defineClass0(ClassLoader loader, Class lookup, String name, byte[] b, int off, int len, ProtectionDomain pd, boolean initialize, int flags, Object classData)\n\n// Native calls below.\njclass Unsafe_DefineClass0(JNIEnv *env, jobject unsafe, jstring name, jbyteArray data, int offset, int length, jobject loader, jobject pd)\njclass Unsafe_DefineClass_impl(JNIEnv *env, jstring name, jbyteArray data, int offset, int length, jobject loader, jobject pd)\nJNIEXPORT jclass JNICALL\njclass JVM_DefineClass(JNIEnv *env, const char *name, jobject loader, const jbyte *buf, jsize len, jobject pd)\njclass jvm_define_class_common(const char *name, jobject loader, const jbyte *buf, jsize len, jobject pd, const char *source, TRAPS)\nInstanceKlass* SystemDictionary::resolve_from_stream(ClassFileStream* st, Symbol* class_name, Handle class_loader, const ClassLoadInfo& cl_info, TRAPS)\nInstanceKlass* SystemDictionary::resolve_hidden_class_from_stream(ClassFileStream* st, Symbol* class_name, Handle class_loader, const ClassLoadInfo& cl_info, TRAPS)\nInstanceKlass* KlassFactory::create_from_stream(ClassFileStream* stream, Symbol* name, ClassLoaderData* loader_data, const ClassLoadInfo& cl_info, TRAPS)\nInstanceKlass* ClassFileParser::create_instance_klass(bool changed_by_loadhook, const ClassInstanceInfo& cl_inst_info, TRAPS)\nvoid ClassFileParser::mangle_hidden_class_name(InstanceKlass* const ik)\n\nLet's refer to the piece of source code: jdk18/classFileParser.cpp at jdk-18+37 \u00b7 openjdk/jdk18:\nvoid ClassFileParser::mangle_hidden_class_name(InstanceKlass* const ik) {\n  ResourceMark rm;\n  // Construct hidden name from _class_name, \"+\", and &ik. Note that we can't\n  // use a '/' because that confuses finding the class's package.  Also, can't\n  // use an illegal char such as ';' because that causes serialization issues\n  // and issues with hidden classes that create their own hidden classes.\n  char addr_buf[20];\n  if (DumpSharedSpaces) {\n    // We want stable names for the archived hidden classes (only for static\n    // archive for now). Spaces under default_SharedBaseAddress() will be\n    // occupied by the archive at run time, so we know that no dynamically\n    // loaded InstanceKlass will be placed under there.\n    static volatile size_t counter = 0;\n    Atomic::cmpxchg(&counter, (size_t)0, Arguments::default_SharedBaseAddress()); // initialize it\n    size_t new_id = Atomic::add(&counter, (size_t)1);\n    jio_snprintf(addr_buf, 20, SIZE_FORMAT_HEX, new_id);\n  } else {\n    jio_snprintf(addr_buf, 20, INTPTR_FORMAT, p2i(ik));\n  }\n\nPlease, note that the + character is used as the separator.\nGet hidden class name\nThe java.lang.Class#getName() method includes the character replacement: + is replaced with /.\nLet's consider the following execution path:\nString java.lang.Class.getName()\nString java.lang.Class.initClassName()\n\n// Native calls below.\nJNIEXPORT jstring JNICALL JVM_InitClassName(JNIEnv *env, jclass cls)\noop java_lang_Class::name(Handle java_class, TRAPS)\nconst char* java_lang_Class::as_external_name(oop java_class)\nconst char* Klass::external_name() const\nstatic char* convert_hidden_name_to_java(Symbol* name)\n\nLet's refer to the piece of source code: jdk18/klass.cpp at jdk-18+37 \u00b7 openjdk/jdk18:\n// Replace the last '+' char with '/'.\nstatic char* convert_hidden_name_to_java(Symbol* name) {\n\n"
}
{
    "Id": 72897155,
    "PostTypeId": 1,
    "Title": "Alternate for EC2MetadataUtils",
    "Body": "In our code, to get the ec2 instance's region we are using EC2MetadataUtils.getEC2InstanceRegion(), and we just realized we must not use EC2MetadataUtils because it is an internal API that is subject to change.\n\nNote: this is an internal API subject to change. Users of the SDK should not depend on this.\n\nDid some google searches but was unable to find an alternate solution, Is there any alternative solution available to get the ec2 instance's region?\nThanks for any help!\n",
    "AcceptedAnswerId": 72928313,
    "AcceptedAnswer": "This is the implementation of the class: https://github.com/aws/aws-sdk-java/blob/master/aws-java-sdk-core/src/main/java/com/amazonaws/util/EC2MetadataUtils.java\nI have found no Java alternative for this, despite searching on google, so, I have realized that a deeper research is needed. I describe the possibilities that you have as follows:\n1. You can leave this as it is\nThe warning clearly suggests that it's a good idea to use an alternative, but the nonexistence of a ready-made alternative and possible goodies of future versions of the class are good counter-arguments, so you can ignore this note for now.\n2. You can download the open-source library and search for calls of this method\nIf you find the calls for this method somewhere else in the library and you are able to somehow use it instead, then that may be an alternative. For instance, after cloning with\ngit clone git@github.com:aws/aws-sdk-java.git\n\nand searching for occurrences of this method with:\ngrep -rn 'yourpath' -e \"getEC2InstanceRegion\"\n\nI have got these results:\n/aws-sdk-java/aws-java-sdk-core/src/main/java/com/amazonaws/util/EC2MetadataUtils.java:286:    public static String getEC2InstanceRegion() {\n/aws-sdk-java/aws-java-sdk-core/src/main/java/com/amazonaws/regions/InstanceMetadataRegionProvider.java:59:            return EC2MetadataUtils.getEC2InstanceRegion();\n/aws-sdk-java/aws-java-sdk-core/src/main/java/com/amazonaws/regions/Regions.java:110:            final String region = EC2MetadataUtils.getEC2InstanceRegion();\n\nThe first match is the definition of the method.\nThe second match looks like this:\n/*\n * Copyright 2011-2022 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\").\n * You may not use this file except in compliance with the License.\n * A copy of the License is located at\n *\n *  http://aws.amazon.com/apache2.0\n *\n * or in the \"license\" file accompanying this file. This file is distributed\n * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n * express or implied. See the License for the specific language governing\n * permissions and limitations under the License.\n */\npackage com.amazonaws.regions;\n\nimport com.amazonaws.AmazonClientException;\nimport com.amazonaws.SDKGlobalConfiguration;\nimport com.amazonaws.util.EC2MetadataUtils;\nimport org.apache.commons.logging.Log;\nimport org.apache.commons.logging.LogFactory;\n\n/**\n * Attempts to load region information from the EC2 Metadata service. If the application is not\n * running on EC2 or {@link SDKGlobalConfiguration#isEc2MetadataDisabled()} returns true,\n * this provider will return null.\n */\npublic class InstanceMetadataRegionProvider extends AwsRegionProvider {\n\n    private static final Log LOG = LogFactory.getLog(InstanceMetadataRegionProvider.class);\n\n    /**\n     * Cache region as it will not change during the lifetime of the JVM.\n     */\n    private volatile String region;\n\n    /**\n     * @throws AmazonClientException if {@link SDKGlobalConfiguration#isEc2MetadataDisabled()} is true\n     */\n    @Override\n    public String getRegion() {\n        if (SDKGlobalConfiguration.isEc2MetadataDisabled()) {\n            throw new AmazonClientException(\"AWS_EC2_METADATA_DISABLED is set to true, not loading region from EC2 Instance \"\n                                         + \"Metadata service\");\n        }\n\n        if (region == null) {\n            synchronized (this) {\n                if (region == null) {\n                    this.region = tryDetectRegion();\n                }\n            }\n        }\n        return region;\n    }\n\n    private String tryDetectRegion() {\n        try {\n            return EC2MetadataUtils.getEC2InstanceRegion();\n        } catch (AmazonClientException sce) {\n            LOG.debug(\"Ignoring failure to retrieve the region: \" + sce.getMessage());\n            return null;\n        }\n    }\n}\n\nSo, it seems that the getRegion method of InstanceMetadataRegionProvider looks like the alternative that you were looking for.\nThe third match looks like this:\n/*\n * Copyright 2013-2022 Amazon Technologies, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at:\n *\n *    http://aws.amazon.com/apache2.0\n *\n * This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES\n * OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.amazonaws.regions;\n\nimport com.amazonaws.AmazonClientException;\nimport org.apache.commons.logging.LogFactory;\n\nimport com.amazonaws.util.EC2MetadataUtils;\n\n/**\n * Enumeration of region names\n */\npublic enum Regions {\n\n    GovCloud(\"us-gov-west-1\", \"AWS GovCloud (US)\"),\n    US_GOV_EAST_1(\"us-gov-east-1\", \"AWS GovCloud (US-East)\"),\n    US_EAST_1(\"us-east-1\", \"US East (N. Virginia)\"),\n    US_EAST_2(\"us-east-2\", \"US East (Ohio)\"),\n    US_WEST_1(\"us-west-1\", \"US West (N. California)\"),\n    US_WEST_2(\"us-west-2\", \"US West (Oregon)\"),\n    EU_WEST_1(\"eu-west-1\", \"EU (Ireland)\"),\n    EU_WEST_2(\"eu-west-2\", \"EU (London)\"),\n    EU_WEST_3(\"eu-west-3\", \"EU (Paris)\"),\n    EU_CENTRAL_1(\"eu-central-1\", \"EU (Frankfurt)\"),\n    EU_NORTH_1(\"eu-north-1\", \"EU (Stockholm)\"),\n    EU_SOUTH_1(\"eu-south-1\", \"EU (Milan)\"),\n    AP_EAST_1(\"ap-east-1\", \"Asia Pacific (Hong Kong)\"),\n    AP_SOUTH_1(\"ap-south-1\", \"Asia Pacific (Mumbai)\"),\n    AP_SOUTHEAST_1(\"ap-southeast-1\", \"Asia Pacific (Singapore)\"),\n    AP_SOUTHEAST_2(\"ap-southeast-2\", \"Asia Pacific (Sydney)\"),\n    AP_SOUTHEAST_3(\"ap-southeast-3\", \"Asia Pacific (Jakarta)\"),\n    AP_NORTHEAST_1(\"ap-northeast-1\", \"Asia Pacific (Tokyo)\"),\n    AP_NORTHEAST_2(\"ap-northeast-2\", \"Asia Pacific (Seoul)\"),\n    AP_NORTHEAST_3(\"ap-northeast-3\", \"Asia Pacific (Osaka)\"),\n\n    SA_EAST_1(\"sa-east-1\", \"South America (Sao Paulo)\"),\n    CN_NORTH_1(\"cn-north-1\", \"China (Beijing)\"),\n    CN_NORTHWEST_1(\"cn-northwest-1\", \"China (Ningxia)\"),\n    CA_CENTRAL_1(\"ca-central-1\", \"Canada (Central)\"),\n    ME_SOUTH_1(\"me-south-1\", \"Middle East (Bahrain)\"),\n    AF_SOUTH_1(\"af-south-1\", \"Africa (Cape Town)\"),\n    US_ISO_EAST_1(\"us-iso-east-1\", \"US ISO East\"),\n    US_ISOB_EAST_1(\"us-isob-east-1\", \"US ISOB East (Ohio)\"),\n    US_ISO_WEST_1(\"us-iso-west-1\", \"US ISO West\")\n    ;\n\n    /**\n     * The default region that new customers in the US are encouraged to use\n     * when using AWS services for the first time.\n     */\n    public static final Regions DEFAULT_REGION = US_WEST_2;\n\n    private final String name;\n    private final String description;\n\n    private Regions(String name, String description) {\n        this.name = name;\n        this.description = description;\n    }\n\n    /**\n     * The name of this region, used in the regions.xml file to identify it.\n     */\n    public String getName() {\n        return name;\n    }\n\n    /**\n     * Descriptive readable name for this region.\n     */\n    public String getDescription() {\n        return description;\n    }\n\n    /**\n     * Returns a region enum corresponding to the given region name.\n     *\n     * @param regionName\n     *            The name of the region. Ex.: eu-west-1\n     * @return Region enum representing the given region name.\n     */\n    public static Regions fromName(String regionName) {\n        for (Regions region : Regions.values()) {\n            if (region.getName().equals(regionName)) {\n                return region;\n            }\n        }\n        throw new IllegalArgumentException(\"Cannot create enum from \" + regionName + \" value!\");\n    }\n\n    /**\n     * Returns a Region object representing the region the application is\n     * running in, when running in EC2. If this method is called from a non-EC2\n     * environment, it will return null.\n     */\n    public static Region getCurrentRegion() {\n        try {\n            final String region = EC2MetadataUtils.getEC2InstanceRegion();\n            if (region != null)\n                return RegionUtils.getRegion(region);\n        } catch (AmazonClientException e) {\n            LogFactory.getLog(Regions.class).debug(\n                \"Ignoring failure to retrieve the region: \" + e.getMessage());\n        }\n        return null;\n    }\n}\n\nSo, getCurrentRegion at Regions looks like another alternative. If you manage to use one of these for your purpose successfully, then it will be easy to refactor and it also makes sense to refactor accordingly.\n3. Copy and rename the class\nIf the first two options are unfeasible for you, then you can copy and rename the class, so you will be able to make sure that this method will remain unchanged even if the internal API is changed. This is not a very elegant approach and it is not easy to implement either, as the class has dependencies, so, as a result, you will have some difficulties to resolve, but we know in advance that this is a possible solution.\n4. Finally the do-it-yourself approach\nThis is an article about retrieving instance metadata: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instancedata-data-retrieval.html\nAs we can see, among the metadata information of the instance, you can find the region: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instancedata-data-categories.html\n\nA command example that uses curl and jq that looks like\ncurl -s http://169.254.169.254/latest/dynamic/instance-identity/document | jq -r .region\n\ncan be found here: https://www.howtouselinux.com/post/find-ec2-instance-region-info-in-aws\n"
}
{
    "Id": 74781733,
    "PostTypeId": 1,
    "Title": "vulnerable dependency maven:org.yaml:snakeyaml",
    "Body": "I am periodically checking vulnerabilities on my pom.xml and generally fix these problems by updating the dependency versions. However, I get the following error:\n\nProvides transitive vulnerable dependency maven:org.yaml:snakeyaml:1.30 CVE-2022-25857 7.5 Uncontrolled Resource Consumption vulnerability pending CVSS allocation CVE-2022-38752 6.5\nOut-of-bounds Write vulnerability with medium severity found CVE-2022-38749 6.5 Out-of-bounds Write vulnerability pending CVSS allocation CVE-2022-38750 5.5\nOut-of-bounds Write vulnerability pending CVSS allocation CVE-2022-38751 6.5 Out-of-bounds Write vulnerability pending CVSS allocation CVE-2022-41854 6.5\nStack-based Buffer Overflow vulnerability with medium severity found CVE-2022-1471 9.8\nDeserialization of Untrusted Data vulnerability with high severity found\nResults powered by Checkmarx(c)\n\nI I try to add  to the spring-boot-starter-web in my pom.xml, but it does not make any sense.\nSo, how can I fix this problem properly? I use IntelliJ default features to fix this kind of problems, but should I do any an extra useful plugins etc.?\n",
    "AcceptedAnswerId": 74781869,
    "AcceptedAnswer": "Unfortunately, Spring Boot 2.7.x still uses an older, vulnerable version of SnakeYAML (1.30). They still have not upgraded it to the last version (1.33). Spring Boot 3.0.0 does depend on version 1.33.\nAssuming you cannot upgrade to Spring Boot 3.0.0 yet, the only thing that should work is to add a dependency to SnakeYAML 1.33 in your project. That version should then take precedence over Spring Boot's transitive dependency.\nHowever, SnakeYAML 1.33 still has a vulnerability. Since that is the last version (SnakeYAML 2.x is not compatible with 1.x), that's something you can't get rid off until the SnakeYAML team fixes that.\nEdit: with SnakeYAML 2.x, I meant this one. SnakeYAML 1.33 recently had a follow-up 2.0 version which is a different one. Compatibility between 1.33 and 2.0 is still not 100%, but Spring Boot 2.7.10+ and Spring Boot 3.x should support both.\n"
}
{
    "Id": 72692978,
    "PostTypeId": 1,
    "Title": "Eclipse: Project 'PROJECT_NAME' has no explicit encoding set",
    "Body": "I downgraded from Windows 11 to Windows 10 today and had to reinstall the Eclipse-IDE.\nAfter successfully importing my workspaces and fixing the projects, a warning appeared for every project saying \"Project XXX has no explicit encoding set\". I've already searched for a solution and only got some fixes for VSCode.\nI had Eclipse 2021-6 and installed Eclipse 2022-6\n",
    "AcceptedAnswerId": 72947638,
    "AcceptedAnswer": "Yes, the warning for projects with no explicit default encoding is a new thing in Eclipse 2022-06 (4.24).\nTo set an explicit default encoding do one of the following:\n\nIn the Problems view, select the warning, hit Ctrl+1 and apply the provided Quick Fix (sets the project encoding explicitly to the workspace encoding)\nChange the project manually in Project > Properties: Resource\n\nSee also my video showing and explaining this.\n"
}
{
    "Id": 73077902,
    "PostTypeId": 1,
    "Title": "Accessing protected method of anonymous object vs by a named reference",
    "Body": "Say I have this abstract class:\npackage test.one;\n\npublic abstract class One {\n  \n  protected abstract void whatever();\n\n  public void run() {\n    whatever();\n  }\n  \n}\n\nAnd use it like this:\npackage test.two;\n\nimport test.one.One;\n\npublic class Three {\n\n  public static void main(String[] args) {\n    One one = new One() {\n      @Override\n      protected void whatever() {\n        System.out.println(\"Do whatever..\");\n      }\n    };\n    one.whatever();\n  }\n}\n\nThis code fails on compilation which is pretty much expected.\ntest/two/Three.java:14: error: whatever() has protected access in One\n    one.whatever();\n       ^\n1 error\n\nBut the below code compiles successfully which seems surprisingly:\npackage test.two;\n\nimport test.one.One;\n\npublic class Two {\n\n  public static void main(String[] args) {\n    new One() {\n      @Override\n      protected void whatever() {\n        System.out.println(\"Do whatever..\");\n      }\n    }.whatever();\n  }\n}\n\nThe difference is that in the latter case I'm accessing the method without a named reference. Why does the compiler allow such access?\n",
    "AcceptedAnswerId": 73078028,
    "AcceptedAnswer": "\nThe difference is that in the latter case I'm accessing the method without a named reference. Why does the compiler allow such access?\n\nNo, the difference is that in the latter case you're accessing the method on the anonymous class rather than on a reference of type One.\nLeaving aside the oddities around protected access, you can see the difference very easily by just creating an anonymous class with a public method:\nclass Test {\n    public static void main(String[] args) {\n        // This is fine...\n        new Object() {\n            public void method() {\n                System.out.println(\"Called\");\n            }\n        }.method();\n        \n        // This is not, because Object doesn't contain a method called \"method\".\n        Object o = new Object() {\n            public void method() {\n                System.out.println(\"Called\");\n            }\n        };\n        o.method();        \n    }\n}\n\nAs noted in comments, another way to see the same effect is to use var, so that the compile-time type of the variable is the anonymous class.\nEven private members within anonymous classes can be accessed within the containing scope, just as if they were normal nested classes.\n"
}
{
    "Id": 72635074,
    "PostTypeId": 1,
    "Title": "Java Record with @Builder.Default",
    "Body": "I'm wondering is there any way to combine java record with lombok's @Builder.Default?\nLet's consider an example with properties object for new file creation.\nBefore java 14\n@Value\n@Builder\npublic class FileProperties {\n    @Builder.Default\n    String directory = System.getProperty(\"user.home\");\n    @Builder.Default\n    String name = \"New file\";\n    @Builder.Default\n    String extension = \".txt\";\n}\n\nJava 14\n@Builder\npublic record FileProperties (\n        String directory,\n        String name,\n        String extension\n) {}\n\nBut in case if I try to use something like\n@Builder\npublic record FileProperties (\n        @Builder.Default\n        String directory = System.getProperty(\"user.home\")\n) {}\n\nCompiler will fail with an error, revealing that such syntax is not allowed. Do we have any solution to this problem?\n",
    "AcceptedAnswerId": 75812314,
    "AcceptedAnswer": "This functionality is not available at the moment. Please check the first comment under the question\n\nNot right now, I hadn't considered that when extending support of @Builder to records.\n\n"
}
{
    "Id": 73162834,
    "PostTypeId": 1,
    "Title": "Why writing map entries to a HashSet is slower than to a CopyOnWriteArraySet in Java",
    "Body": "I think writing to a HashSet will be faster than to a CopyOnWriteArraySet; I'm not doing multi threading here. However I surpisingly got benchmark results indicate writing map entries to a CopyOnWriteArraySet is faster.\nI did benchmarking on writing 1000 of Map.Entry into a HashSet vs CopyOnWriteArraySet.\nBenchmark          (n)   Mode  Cnt     Score    Error  Units\nA.writeToCOWAS    1000  thrpt    4  1269.214 \u00b1 40.635  ops/s\nA.writeToHashSet  1000  thrpt    4   223.118 \u00b1 34.955  ops/s\n\nIn addition to that, I got benchmark results of equals() and hashCode() of Map.Entry reveal that the former is more expensive.\nBenchmark           Mode  Cnt          Score          Error  Units\nMapEntry.equals    thrpt    4  177773394.054 \u00b1 75436098.388  ops/s\nMapEntry.hashCode  thrpt    4  272240403.923 \u00b1 38794396.671  ops/s\n\nI believe writing to a HashSet calls to hashCode() while CopyOnWriteArraySet calls to equals().\nIn the case of writing Integer or String,HashSet is way faster. Then I'm wondering what happens with Map.Entry type and why CopyOnWriteArraySet is faster according to my analysis?\nMy perf test:\n@State(Scope.Benchmark)\n@Fork(value = 2)\n@Warmup(iterations = 2, time = 3)\n@Measurement(iterations = 2, time = 3)\npublic class A {\n    public Set> set;\n\n    @Param({\"1000\"})\n    public int n;\n\n    @Setup\n    public void setup() {\n        set = new HashSet((int) (n / 0.75f + 1f), 0.75f);\n        for (int i = 0; i < n; i++)\n            set.add(Map.entry(i, i));\n    }\n\n    private void eliminateDeadCode(Set> out, Blackhole hole) {\n        int hash = 0;\n        for (Map.Entry o : out)\n            hash += o.hashCode();\n        hole.consume(hash);\n        if (out.size() != set.size())\n            throw new RuntimeException(out.size() + \" != \" + set.size());\n    }\n\n    @Benchmark\n    public void writeToCOWAS(Blackhole hole) {\n        Set> out = new CopyOnWriteArraySet(set);\n        eliminateDeadCode(out, hole);\n    }\n\n    @Benchmark\n    public void writeToHashSet(Blackhole hole) {\n        Set> out = new HashSet(set);\n        eliminateDeadCode(out, hole);\n    }\n\n    public static void main(String[] args) throws RunnerException {\n        Options opt = new OptionsBuilder()\n                .include(A.class.getSimpleName())\n                .build();\n        new Runner(opt).run();\n    }\n}\n\n",
    "AcceptedAnswerId": 73188382,
    "AcceptedAnswer": "Hulk's answer is very instructive. However the problem is not necessarily the Map.entry() hashCode implementation, which is this, at least in Java 11:\npublic int hashCode() {\n    return key.hashCode() ^ value.hashCode();\n}\n\nThe problem is that the hash codes of key and value are always the same, both in the OP's test, and in Hulk's test, hence the hash codes combined via XOR will always end up as 0. Change it so that key and value are different, and performance will change.\n"
}
{
    "Id": 73226675,
    "PostTypeId": 1,
    "Title": "Why does this test take longer without garbage collection overhead?",
    "Body": "I ran into this scenario in the process of developing a lightweight library for asynchronous messaging. Trying to get an idea of the cost of creating lots of medium sized objects with short lifetimes, I wrote the following test:\nimport java.nio.ByteBuffer;\nimport java.util.Random;\n\n\npublic class MemPressureTest {\n    static final int SIZE = 4096;\n    static final class Bigish {\n        final ByteBuffer b;\n\n\n        public Bigish() {\n            this(ByteBuffer.allocate(SIZE));\n        }\n\n        public Bigish(ByteBuffer b) {\n            this.b = b;\n        }\n\n        public void fill(byte bt) {\n            b.clear();\n            for (int i = 0; i < SIZE; ++i) {\n                b.put(bt);\n            }\n        }\n    }\n\n\n    public static void main(String[] args) {\n        Random random = new Random(1);\n        Bigish tmp = new Bigish();\n        for (int i = 0; i < 3e7; ++i) {\n            tmp.fill((byte)random.nextInt(255));\n        }\n    }\n}\n\nOn my laptop, with default GC settings, it runs in about 95 seconds:\n/tmp$ time java -Xlog:gc MemPressureTest\n[0.006s][info][gc] Using G1\n\nreal    1m35.552s\nuser    1m33.658s\nsys 0m0.428s\n\nThis is where things get strange. I tweaked the program to allocate a new object for each iteration:\n...\n        Random random = new Random(1);\n        for (int i = 0; i < 3e7; ++i) {\n            Bigish tmp = new Bigish();\n            tmp.fill((byte)random.nextInt(255));\n        }\n...\n\nIn theory, this should add some small overhead, but none of the objects should ever be promoted out of Eden. At best, I'd expect the runtimes to be close to identical. However, this test completes in ~17 seconds:\n/tmp$ time java -Xlog:gc MemPressureTest\n[0.007s][info][gc] Using G1\n[0.090s][info][gc] GC(0) Pause Young (Normal) (G1 Evacuation Pause) 23M->1M(130M) 1.304ms\n[0.181s][info][gc] GC(1) Pause Young (Normal) (G1 Evacuation Pause) 76M->1M(130M) 0.870ms\n[0.247s][info][gc] GC(2) Pause Young (Normal) (G1 Evacuation Pause) 76M->0M(130M) 0.844ms\n[0.317s][info][gc] GC(3) Pause Young (Normal) (G1 Evacuation Pause) 75M->0M(130M) 0.793ms\n[0.381s][info][gc] GC(4) Pause Young (Normal) (G1 Evacuation Pause) 75M->0M(130M) 0.859ms\n[lots of similar GC pauses, snipped for brevity]\n[16.608s][info][gc] GC(482) Pause Young (Normal) (G1 Evacuation Pause) 254M->0M(425M) 0.765ms\n[16.643s][info][gc] GC(483) Pause Young (Normal) (G1 Evacuation Pause) 254M->0M(425M) 0.580ms\n[16.676s][info][gc] GC(484) Pause Young (Normal) (G1 Evacuation Pause) 254M->0M(425M) 0.841ms\n\nreal    0m16.766s\nuser    0m16.578s\nsys 0m0.576s\n\nI ran both versions several times, with near identical results to the above. I feel like I must be missing something very obvious. Am I going insane? What could explain this difference in performance?\n=== EDIT ===\nI rewrote the test using JMH as per apangin and dan1st's suggestions:\nimport org.openjdk.jmh.annotations.*;\nimport org.openjdk.jmh.infra.Blackhole;\n\nimport java.nio.ByteBuffer;\nimport java.util.Random;\n\n\npublic class MemPressureTest {\n    static final int SIZE = 4096;\n\n    @State(Scope.Benchmark)\n    public static class Bigish {\n        final ByteBuffer b;\n        private Blackhole blackhole;\n\n\n        @Setup(Level.Trial)\n        public void setup(Blackhole blackhole) {\n            this.blackhole = blackhole;\n        }\n\n        public Bigish() {\n            this.b = ByteBuffer.allocate(SIZE);\n        }\n\n        public void fill(byte bt) {\n            b.clear();\n            for (int i = 0; i < SIZE; ++i) {\n                b.put(bt);\n            }\n            blackhole.consume(b);\n        }\n    }\n\n    static Random random = new Random(1);\n\n\n    @Benchmark\n    public static void test1(Blackhole blackhole) {\n        Bigish tmp = new Bigish();\n        tmp.setup(blackhole);\n        tmp.fill((byte)random.nextInt(255));\n        blackhole.consume(tmp);\n    }\n\n    @Benchmark\n    public static void test2(Bigish perm) {\n        perm.fill((byte) random.nextInt(255));\n    }\n}\n\nStill, the second test much slower:\n> Task :jmh\n# JMH version: 1.35\n# VM version: JDK 18.0.1.1, OpenJDK 64-Bit Server VM, 18.0.1.1+2-6\n# VM invoker: /Users/xxx/Library/Java/JavaVirtualMachines/openjdk-18.0.1.1/Contents/Home/bin/java\n# VM options: -Dfile.encoding=UTF-8 -Djava.io.tmpdir=/Users/xxx/Dev/MemTests/build/tmp/jmh -Duser.country=US -Duser.language=en -Duser.variant\n# Blackhole mode: compiler (auto-detected, use -Djmh.blackhole.autoDetect=false to disable)\n# Warmup: 5 iterations, 10 s each\n# Measurement: 5 iterations, 10 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Throughput, ops/time\n# Benchmark: com.xxx.MemPressureTest.test1\n\n# Run progress: 0.00% complete, ETA 00:16:40\n# Fork: 1 of 5\n# Warmup Iteration   1: 2183998.556 ops/s\n# Warmup Iteration   2: 2281885.941 ops/s\n# Warmup Iteration   3: 2239644.018 ops/s\n# Warmup Iteration   4: 1608047.994 ops/s\n# Warmup Iteration   5: 1992314.001 ops/s\nIteration   1: 2053657.571 ops/s3s]\nIteration   2: 2054957.773 ops/sm 3s]\nIteration   3: 2051595.233 ops/sm 13s]\nIteration   4: 2054878.239 ops/sm 23s]\nIteration   5: 2031111.214 ops/sm 33s]\n\n# Run progress: 10.00% complete, ETA 00:15:04\n# Fork: 2 of 5\n# Warmup Iteration   1: 2228594.345 ops/s\n# Warmup Iteration   2: 2257983.355 ops/s\n# Warmup Iteration   3: 2063130.244 ops/s\n# Warmup Iteration   4: 1629084.669 ops/s\n# Warmup Iteration   5: 2063018.496 ops/s\nIteration   1: 1939260.937 ops/sm 33s]\nIteration   2: 1791414.018 ops/sm 43s]\nIteration   3: 1914987.221 ops/sm 53s]\nIteration   4: 1969484.898 ops/sm 3s]\nIteration   5: 1891440.624 ops/sm 13s]\n\n# Run progress: 20.00% complete, ETA 00:13:23\n# Fork: 3 of 5\n# Warmup Iteration   1: 2228664.719 ops/s\n# Warmup Iteration   2: 2263677.403 ops/s\n# Warmup Iteration   3: 2237032.464 ops/s\n# Warmup Iteration   4: 2040040.243 ops/s\n# Warmup Iteration   5: 2038848.530 ops/s\nIteration   1: 2023934.952 ops/sm 14s]\nIteration   2: 2041874.437 ops/sm 24s]\nIteration   3: 2002858.770 ops/sm 34s]\nIteration   4: 2039727.607 ops/sm 44s]\nIteration   5: 2045827.670 ops/sm 54s]\n\n# Run progress: 30.00% complete, ETA 00:11:43\n# Fork: 4 of 5\n# Warmup Iteration   1: 2105430.688 ops/s\n# Warmup Iteration   2: 2279387.762 ops/s\n# Warmup Iteration   3: 2228346.691 ops/s\n# Warmup Iteration   4: 1438607.183 ops/s\n# Warmup Iteration   5: 2059319.745 ops/s\nIteration   1: 1112543.932 ops/sm 54s]\nIteration   2: 1977077.976 ops/sm 4s]\nIteration   3: 2040147.355 ops/sm 14s]\nIteration   4: 1975766.032 ops/sm 24s]\nIteration   5: 2003532.092 ops/sm 34s]\n\n# Run progress: 40.00% complete, ETA 00:10:02\n# Fork: 5 of 5\n# Warmup Iteration   1: 2240203.848 ops/s\n# Warmup Iteration   2: 2245673.994 ops/s\n# Warmup Iteration   3: 2096257.864 ops/s\n# Warmup Iteration   4: 2046527.740 ops/s\n# Warmup Iteration   5: 2050379.941 ops/s\nIteration   1: 2050691.989 ops/sm 35s]\nIteration   2: 2057803.100 ops/sm 45s]\nIteration   3: 2058634.766 ops/sm 55s]\nIteration   4: 2060596.595 ops/sm 5s]\nIteration   5: 2061282.107 ops/sm 15s]\n\n\nResult \"com.xxx.MemPressureTest.test1\":\n  1972203.484 \u00b1(99.9%) 142904.698 ops/s [Average]\n  (min, avg, max) = (1112543.932, 1972203.484, 2061282.107), stdev = 190773.683\n  CI (99.9%): [1829298.786, 2115108.182] (assumes normal distribution)\n\n\n# JMH version: 1.35\n# VM version: JDK 18.0.1.1, OpenJDK 64-Bit Server VM, 18.0.1.1+2-6\n# VM invoker: /Users/xxx/Library/Java/JavaVirtualMachines/openjdk-18.0.1.1/Contents/Home/bin/java\n# VM options: -Dfile.encoding=UTF-8 -Djava.io.tmpdir=/Users/xxx/Dev/MemTests/build/tmp/jmh -Duser.country=US -Duser.language=en -Duser.variant\n# Blackhole mode: compiler (auto-detected, use -Djmh.blackhole.autoDetect=false to disable)\n# Warmup: 5 iterations, 10 s each\n# Measurement: 5 iterations, 10 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Throughput, ops/time\n# Benchmark: com.xxx.MemPressureTest.test2\n\n# Run progress: 50.00% complete, ETA 00:08:22\n# Fork: 1 of 5\n# Warmup Iteration   1: 282751.407 ops/s\n# Warmup Iteration   2: 283333.984 ops/s\n# Warmup Iteration   3: 293785.079 ops/s\n# Warmup Iteration   4: 268403.105 ops/s\n# Warmup Iteration   5: 280054.277 ops/s\nIteration   1: 279093.118 ops/s9m 15s]\nIteration   2: 282782.996 ops/s9m 25s]\nIteration   3: 282688.921 ops/s9m 35s]\nIteration   4: 291578.963 ops/s9m 45s]\nIteration   5: 294835.777 ops/s9m 55s]\n\n# Run progress: 60.00% complete, ETA 00:06:41\n# Fork: 2 of 5\n# Warmup Iteration   1: 283735.550 ops/s\n# Warmup Iteration   2: 283536.547 ops/s\n# Warmup Iteration   3: 294403.173 ops/s\n# Warmup Iteration   4: 284161.042 ops/s\n# Warmup Iteration   5: 281719.077 ops/s\nIteration   1: 276838.416 ops/s10m 56s]\nIteration   2: 284063.117 ops/s11m 6s]\nIteration   3: 282361.985 ops/s11m 16s]\nIteration   4: 289125.092 ops/s11m 26s]\nIteration   5: 294236.625 ops/s11m 36s]\n\n# Run progress: 70.00% complete, ETA 00:05:01\n# Fork: 3 of 5\n# Warmup Iteration   1: 284567.336 ops/s\n# Warmup Iteration   2: 283548.713 ops/s\n# Warmup Iteration   3: 294317.511 ops/s\n# Warmup Iteration   4: 283501.873 ops/s\n# Warmup Iteration   5: 283691.306 ops/s\nIteration   1: 283462.749 ops/s12m 36s]\nIteration   2: 284120.587 ops/s12m 46s]\nIteration   3: 264878.952 ops/s12m 56s]\nIteration   4: 292681.168 ops/s13m 6s]\nIteration   5: 295279.759 ops/s13m 16s]\n\n# Run progress: 80.00% complete, ETA 00:03:20\n# Fork: 4 of 5\n# Warmup Iteration   1: 284823.519 ops/s\n# Warmup Iteration   2: 283913.207 ops/s\n# Warmup Iteration   3: 294401.483 ops/s\n# Warmup Iteration   4: 283998.027 ops/s\n# Warmup Iteration   5: 283987.408 ops/s\nIteration   1: 278014.618 ops/s14m 17s]\nIteration   2: 283431.491 ops/s14m 27s]\nIteration   3: 284465.945 ops/s14m 37s]\nIteration   4: 293202.934 ops/s14m 47s]\nIteration   5: 290059.807 ops/s14m 57s]\n\n# Run progress: 90.00% complete, ETA 00:01:40\n# Fork: 5 of 5\n# Warmup Iteration   1: 285598.809 ops/s\n# Warmup Iteration   2: 284434.916 ops/s\n# Warmup Iteration   3: 294355.547 ops/s\n# Warmup Iteration   4: 284307.860 ops/s\n# Warmup Iteration   5: 284297.362 ops/s\nIteration   1: 283676.043 ops/s15m 57s]\nIteration   2: 283609.750 ops/s16m 7s]\nIteration   3: 284575.124 ops/s16m 17s]\nIteration   4: 293564.269 ops/s16m 27s]\nIteration   5: 216267.883 ops/s16m 37s]\n\n\nResult \"com.xxx.MemPressureTest.test2\":\n  282755.844 \u00b1(99.9%) 11599.112 ops/s [Average]\n  (min, avg, max) = (216267.883, 282755.844, 295279.759), stdev = 15484.483\n  CI (99.9%): [271156.731, 294354.956] (assumes normal distribution)\n\nThe JMH Blackhole should prevent code removal and the fact that JMH is now in charge of running separate iterations should prevent parallelization, right? Shouldn't Blackhole also stop the object from being confined to the stack? Also, wouldn't there be more variation between warmup iterations if hotspot were still doing a significant amount of optimization?\n",
    "AcceptedAnswerId": 73268952,
    "AcceptedAnswer": "Creating a new ByteBuffer right before filling, indeed helps JIT compiler to produce better optimized code, when you use relative put methods, and here is why.\n\nJIT compilation unit is a method. HotSpot JVM does not perform a whole-program optimization, which is quite hard even in theory due to dynamic nature of Java and the open world runtime environment.\nWhen the JVM compiles test1 method, buffer instantiation appears in the same compilation scope as filling:\n\nBigish tmp = new Bigish();\ntmp.setup(blackhole);\ntmp.fill((byte)random.nextInt(255));\n\nThe JVM knows everything about the created buffer: its exact size and its backing array, it knows the buffer has not been published yet, no other thread sees it. So, the JVM can agressively optimize the fill loop: vectorize it using AVX instructions and unroll it to set 512 bytes at a time:\n  0x000001cdf60c9ae0:   mov    %r9d,%r8d\n  0x000001cdf60c9ae3:   movslq %r8d,%r9\n  0x000001cdf60c9ae6:   add    %r11,%r9\n  0x000001cdf60c9ae9:   vmovdqu %ymm0,0x10(%rcx,%r9,1)\n  0x000001cdf60c9af0:   vmovdqu %ymm0,0x30(%rcx,%r9,1)\n  0x000001cdf60c9af7:   vmovdqu %ymm0,0x50(%rcx,%r9,1)\n  0x000001cdf60c9afe:   vmovdqu %ymm0,0x70(%rcx,%r9,1)\n  0x000001cdf60c9b05:   vmovdqu %ymm0,0x90(%rcx,%r9,1)\n  0x000001cdf60c9b0f:   vmovdqu %ymm0,0xb0(%rcx,%r9,1)\n  0x000001cdf60c9b19:   vmovdqu %ymm0,0xd0(%rcx,%r9,1)\n  0x000001cdf60c9b23:   vmovdqu %ymm0,0xf0(%rcx,%r9,1)\n  0x000001cdf60c9b2d:   vmovdqu %ymm0,0x110(%rcx,%r9,1)\n  0x000001cdf60c9b37:   vmovdqu %ymm0,0x130(%rcx,%r9,1)\n  0x000001cdf60c9b41:   vmovdqu %ymm0,0x150(%rcx,%r9,1)\n  0x000001cdf60c9b4b:   vmovdqu %ymm0,0x170(%rcx,%r9,1)\n  0x000001cdf60c9b55:   vmovdqu %ymm0,0x190(%rcx,%r9,1)\n  0x000001cdf60c9b5f:   vmovdqu %ymm0,0x1b0(%rcx,%r9,1)\n  0x000001cdf60c9b69:   vmovdqu %ymm0,0x1d0(%rcx,%r9,1)\n  0x000001cdf60c9b73:   vmovdqu %ymm0,0x1f0(%rcx,%r9,1)\n  0x000001cdf60c9b7d:   mov    %r8d,%r9d\n  0x000001cdf60c9b80:   add    $0x200,%r9d\n  0x000001cdf60c9b87:   cmp    %r10d,%r9d\n  0x000001cdf60c9b8a:   jl     0x000001cdf60c9ae0\n\n\nYou use relative put method. It not only sets a byte in a ByteBuffer, but also updates the position field. Note that the above vectorized loop does not update the position in memory. JVM sets it just once after the loop - it is allowed to do so as long as nobody can observe an inconsistent state of the buffer.\nNow try to publish ByteBuffer before filling:\n\nBigish tmp = new Bigish();\nvolatileField = tmp;  // publish\ntmp.setup(blackhole);\ntmp.fill((byte)random.nextInt(255));\n\nThe loop optimization breaks; now the array bytes are filled one by one, and the position field is incremented accordingly.\n  0x000001829b18ca5c:   nopl   0x0(%rax)\n  0x000001829b18ca60:   cmp    %r11d,%esi\n  0x000001829b18ca63:   jge    0x000001829b18ce34           ;*if_icmplt {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - java.nio.Buffer::nextPutIndex@10 (line 721)\n                                                            ; - java.nio.HeapByteBuffer::put@6 (line 209)\n                                                            ; - bench.MemPressureTest$Bigish::fill@22 (line 33)\n                                                            ; - bench.MemPressureTest::test1@28 (line 47)\n  0x000001829b18ca69:   mov    %esi,%ecx\n  0x000001829b18ca6b:   add    %edx,%ecx                    ;*getfield position {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - java.nio.Buffer::nextPutIndex@1 (line 720)\n                                                            ; - java.nio.HeapByteBuffer::put@6 (line 209)\n                                                            ; - bench.MemPressureTest$Bigish::fill@22 (line 33)\n                                                            ; - bench.MemPressureTest::test1@28 (line 47)\n  0x000001829b18ca6d:   mov    %esi,%eax\n  0x000001829b18ca6f:   inc    %eax                         ;*iinc {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - bench.MemPressureTest$Bigish::fill@26 (line 32)\n                                                            ; - bench.MemPressureTest::test1@28 (line 47)\n  0x000001829b18ca71:   mov    %eax,0x18(%r10)              ;*putfield position {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - java.nio.Buffer::nextPutIndex@25 (line 723)\n                                                            ; - java.nio.HeapByteBuffer::put@6 (line 209)\n                                                            ; - bench.MemPressureTest$Bigish::fill@22 (line 33)\n                                                            ; - bench.MemPressureTest::test1@28 (line 47)\n  0x000001829b18ca75:   cmp    %r8d,%ecx\n  0x000001829b18ca78:   jae    0x000001829b18ce14\n  0x000001829b18ca7e:   movslq %esi,%r9\n  0x000001829b18ca81:   add    %r14,%r9\n  0x000001829b18ca84:   mov    %bl,0x10(%rdi,%r9,1)         ;*bastore {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - java.nio.HeapByteBuffer::put@13 (line 209)\n                                                            ; - bench.MemPressureTest$Bigish::fill@22 (line 33)\n                                                            ; - bench.MemPressureTest::test1@28 (line 47)\n  0x000001829b18ca89:   cmp    $0x1000,%eax\n  0x000001829b18ca8f:   jge    0x000001829b18ca95           ;*if_icmpge {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - bench.MemPressureTest$Bigish::fill@14 (line 32)\n                                                            ; - bench.MemPressureTest::test1@28 (line 47)\n  0x000001829b18ca91:   mov    %eax,%esi\n  0x000001829b18ca93:   jmp    0x000001829b18ca5c\n\nThat's exactly what happens in test2. Since the ByteBuffer object is external to the compilation scope, JIT can't optimize it as freely as a local not-yet-published object.\n\nIs it possible at all to optimize the fill loop in case of an external buffer?\n\nThe good news, it is possible. Just use the absolute put method instead of relative. In this case, position field remains unchanged, and JIT can easily vectorize the loop without a risk of breaking ByteBuffer invariants.\nfor (int i = 0; i < SIZE; ++i) {\n    b.put(i, bt);\n}\n\nWith this change, the loop will be vectorized in both cases. Even better, now test2 becomes a lot faster than test1, proving that an object creation indeed has a performance overhead.\nBenchmark               Mode  Cnt      Score     Error   Units\nMemPressureTest.test1  thrpt   10   2447,370 \u00b1 146,804  ops/ms\nMemPressureTest.test2  thrpt   10  15677,575 \u00b1 136,075  ops/ms\n\nConclusion\n\nThe counterintuitive performance difference was caused by the JVM inability to vectorize the fill loop when the ByteBuffer object creation is not in the compilation scope.\nPrefer absolute get/put methods to relative ones where possible. Absolute methods are usually much faster, since they do not update the internal state of ByteBuffer, and JIT can apply more agressive optimizations.\nObject creation indeed has an overhead, as the modified benchmark shows.\n\n"
}
{
    "Id": 73470158,
    "PostTypeId": 1,
    "Title": "Stream.peek() can be skipped for optimization",
    "Body": "I've come across a rule in Sonar which says:\n\nA key difference with other intermediate Stream operations is that the Stream implementation is free to skip calls to peek() for optimization purpose. This can lead to peek() being unexpectedly called only for some or none of the elements in the Stream.\n\nAlso, it's mentioned in the Javadoc which says:\n\nThis method exists mainly to support debugging, where you want to see the elements as they flow past a certain point in a pipeline\n\nIn which case can java.util.Stream.peek() be skipped? Is it related to debugging?\n",
    "AcceptedAnswerId": 73470740,
    "AcceptedAnswer": "Not only peek but also map can be skipped. It is for sake of optimization.\nFor example, when the terminal operation count() is called, it makes no sense to peek or map the individual items as such operations do not change the number/count of the present items.\nHere are two examples:\n\n1. Map and peek are not skipped because the filter can change the number of items beforehand.\nlong count = Stream.of(\"a\", \"aa\")\n    .peek(s -> System.out.println(\"#1\"))\n    .filter(s -> s.length() < 2)\n    .peek(s -> System.out.println(\"#2\"))\n    .map(s -> {\n        System.out.println(\"#3\");\n        return s.length();\n    })\n    .count();\n\n\n#1\n#2\n#3\n#1\n1\n\n\n\n2. Map and peek are skipped because the number of items is unchanged.\nlong count = Stream.of(\"a\", \"aa\")\n    .peek(s -> System.out.println(\"#1\"))\n  //.filter(s -> s.length() < 2)\n    .peek(s -> System.out.println(\"#2\"))\n    .map(s -> {\n        System.out.println(\"#3\");\n        return s.length();\n    })\n    .count();\n\n\n2\n\n\n\nImportant: The methods should have no side-effects (they do above, but only for the sake of example).\n\nSide-effects in behavioral parameters to stream operations are, in general, discouraged, as they can often lead to unwitting violations of the statelessness requirement, as well as other thread-safety hazards.\n\nThe following implementation is dangerous. Assuming callRestApi method performs a REST call, it won't be performed as the Stream violates the side-effect.\nlong count = Stream.of(\"url1\", \"url2\")\n    .map(string -> callRestApi(HttpMethod.POST, string))\n    .count();\n\n/**\n * Performs a REST call\n */\npublic String callRestApi(HttpMethod httpMethod, String url);\n\n"
}
{
    "Id": 73414289,
    "PostTypeId": 1,
    "Title": "Granular media permissions Android 13 API 33",
    "Body": "I've been upgrading my project to SDK 33.\nI changed the permissions where I needed to access media files, such as photos, with the new permission READ_MEDIA_IMAGES and it is working fine.\nBut I need to access documents such as PDF files in order to upload them to the server, but I cannot find any information concerning android 13 and documents.\nBefore the upgrade I had READ_EXTERNAL_STORAGE permission and I accessed all the files.\nIn the andorid documentation on the link below, only these three permissions are provided READ_MEDIA_IMAGES, READ_MEDIA_VIDEO, READ_MEDIA_AUDIO instead of using READ_EXTERNAL_STORAGE.\nhttps://developer.android.com/about/versions/13/behavior-changes-13#granular-media-permissions\nAny ideas on how to fix this and what steps to follow?\n",
    "AcceptedAnswerId": 73535271,
    "AcceptedAnswer": "According to Google storage documentation. It seems that for non-media files no permission is needed. https://developer.android.com/training/data-storage.\n"
}
{
    "Id": 73457793,
    "PostTypeId": 1,
    "Title": "ClassCastException when stopping Tomcat 10 inside Eclipse",
    "Body": "I am using Eclipse 2022-06 and Tomcat 10.0.10.\nOften, when shutting down Tomcat running inside Eclipse, I get\nWARNUNG: Failed to clear soft references from ObjectStreamClass$Caches for web application [ROOT]\njava.lang.ClassCastException: class java.io.ObjectStreamClass$Caches$1 cannot be cast to class java.util.Map (java.io.ObjectStreamClass$Caches$1 and java.util.Map are in module java.base of loader 'bootstrap')\n    at org.apache.catalina.loader.WebappClassLoaderBase.clearCache(WebappClassLoaderBase.java:2363)\n\n...\nI have found this question, but it does not really apply: It's a different class (Map instead of String) and I cannot find a file called \"SESSIONS.ser\". I also have already removed everything from the actual web service part (so the code is doing nothing). I just have not started to remove all the jar files linked that are probably loaded automatically.\nIs there any way to find out which class actually causes the problem?\nBy the way, if by deploying a WAR file to a Tomcat installation outside Eclipse, I was not able to reproduce the error in the log. I am unsure whether that means it does not appear.\n",
    "AcceptedAnswerId": 73551982,
    "AcceptedAnswer": "I got the same problem after upgrading my IDE.\nAfter comparing the both tomcat logs, I saw that there were using 2 different jvm's.\nIndeed I had upgraded the jdk and the ide!\nThe problem is appeared with jvm11.0.16, no exception with jvm11.0.11 even on the latest ide version.\nThis is the explanation, but the solution consisting to keep the old jvm may be not very good...\nSo I did upgrade Tomcat to the latest version (8.5.82 in my case) and it solved the problem. I guess it is due to this feature (see tomcat changelog):\n\nDisable the memory leak correction code enabled by the Context\nattribute clearReferencesObjectStreamClassCaches when running on a JRE\nthat includes a fix for the underlying memory leak. (markt)\n\n"
}
{
    "Id": 73573742,
    "PostTypeId": 1,
    "Title": "Large size of HashSet throwing StackOverflow Error",
    "Body": "I have 81K records of Long object and I am trying to store it in HashSet. My code snippet looks like this:\nprivate static HashSet hashSet = new HashSet(Arrays.asList(*81K records*));\n\nWhile compiling this is giving me StackOverflow Error. I am not understanding why only 81K records are being problem here? Solutions are appreciated.\nJava version. :\nopenjdk version \"1.8.0_322\"\nOpenJDK Runtime Environment Corretto-8.322.06.1 (build 1.8.0_322-b06)\nOpenJDK 64-Bit Server VM Corretto-8.322.06.1 (build 25.322-b06, mixed mode)\n\nStack Trace:\n[javac] \n    [javac] \n    [javac] The system is out of resources.\n    [javac] Consult the following stack trace for details.\n    [javac] java.lang.StackOverflowError\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n\n\nLine 220 of Type:\n 208     /**\n 209      * Return the least specific subtype of t that starts with symbol\n 210      * sym.  If none exists, return null.  The least specific subtype\n 211      * is determined as follows:\n 212      *\n 213      * If there is exactly one parameterized instance of sym that is a\n 214      * subtype of t, that parameterized instance is returned.\n 215      * Otherwise, if the plain type or raw type `sym' is a subtype of\n 216      * type t, the type `sym' itself is returned.  Otherwise, null is\n 217      * returned.\n 218      */\n 219     public Type asSub(Type t, Symbol sym) {\n 220         return asSub.visit(t, sym);\n 221     }\n 222     // where\n 223         private final SimpleVisitor asSub = new SimpleVisitor() {\n\n",
    "AcceptedAnswerId": 73574421,
    "AcceptedAnswer": "The HashSet is irrelevant here. The problematic part is the varargs invocation of Arrays.asList with 81,000 elements.\nTo reproduce the issue, we can use the following code\nclass Tmp {\n  static final String ARGUMENTS = \">\";\n\n  static final List TEMPLATE = Arrays.asList(\n      \"import java.util.Arrays;\",\n      \"import java.util.List;\",\n      \"\",\n      \"class Tmp {\",\n      \"  static final List L = Arrays.asList(\",\n           ARGUMENTS,\n      \"  );\",\n      \"}\");\n\n  public static void main(String[] args) throws IOException {\n    Path p = Files.createTempFile(\"Test\", \".java\");\n    Files.write(p, () -> TEMPLATE.stream()\n        .flatMap(line -> line.equals(ARGUMENTS)? varargsArgument(): Stream.of(line))\n        .iterator());\n    JavaCompiler c = ToolProvider.getSystemJavaCompiler();\n    c.run(System.in, System.out, System.err, p.toString());\n  }\n\n  static Stream varargsArgument() {\n    return IntStream.range(0, 8100).mapToObj(i -> IntStream.range(0, 10)\n            .mapToObj(j -> i * 10 + j + (i < 8099 || j < 9? \", \": \"\"))\n            .collect(Collectors.joining()));\n  }\n}\n\nWith OpenJDK 8, it produces the\njava.lang.StackOverflowError\n    at com.sun.tools.javac.code.Type.map(Type.java:220)\n   \u2026\n\nOn recent JDKs, e.g. JDK\u00a012, it produces\n/tmp/Test14992292170362927520.java:6: error: code too large\n  static final List L = Arrays.asList(\n                             ^\n\nshowing that even when the compiler bug has been fixed, such code can\u2019t get compiled.\nSuch amount of data should be included as embedded resource which you read in once at startup.\n"
}
{
    "Id": 73603358,
    "PostTypeId": 1,
    "Title": "Understanding javadoc for ZonedDateTime::plusDays",
    "Body": "I am not able to understand one specific part of doc provided for the plusDays() method in ZonedDateTimeClass. Doc states:\n\nReturns a copy of this ZonedDateTime with the specified number of days\nadded.\nThis operates on the local time-line, adding days to the local\ndate-time. This is then converted back to a ZonedDateTime, using the\nzone ID to obtain the offset.\nWhen converting back to ZonedDateTime, if the local date-time is in an\noverlap, then the offset will be retained if possible, otherwise the\nearlier offset will be used. If in a gap, the local date-time will be\nadjusted forward by the length of the gap.\nThis instance is immutable and unaffected by this method call.\nParams: days \u2013 the days to add, may be negative\nReturns: a ZonedDateTime based on this date-time with the days added,\nnot null\nThrows: DateTimeException \u2013 if the result exceeds the supported date\nrange\n\nHow I understand this: Assume we have ZonedDateTime object representing September 4, 2022 6 PM in America/New_York TimeZone. So this method will first convert it to LocalDateTime, that is, it will lose timezone information and just retain September 4, 2022 6 PM. It will add some number of days to it, let's say 7, so that the result is September 11, 2022 6 PM, and now it will convert it back to ZonedDateTime object by providing back the information related to timezone.\nHowever, I am not able to understand the latter part of documentation, that is,\n\nWhen converting back to ZonedDateTime, if the local date-time is in an\noverlap, then the offset will be retained if possible, otherwise the\nearlier offset will be used. If in a gap, the local date-time will be\nadjusted forward by the length of the gap.\n\nWhat do they mean by local date-time is in an overlap? ...then the offset will be retained if possible, otherwise the earlier offset will be used. - what are these two different offsets? If in a gap... - what is this gap?\n",
    "AcceptedAnswerId": 73604362,
    "AcceptedAnswer": "The \"gap\" and \"overlap\" terms are defined in the class-level Javadoc of the ZonedDateTime class:\n\nThis class handles conversion from the local time-line of LocalDateTime to the instant time-line of Instant. The difference between the two time-lines is the offset from UTC/Greenwich, represented by a ZoneOffset.\nConverting between the two time-lines involves calculating the offset using the rules accessed from the ZoneId. Obtaining the offset for an instant is simple, as there is exactly one valid offset for each instant. By contrast, obtaining the offset for a local date-time is not straightforward. There are three cases:\n\nNormal, with one valid offset. For the vast majority of the year, the normal case applies, where there is a single valid offset for the local date-time.\nGap, with zero valid offsets. This is when clocks jump forward typically due to the spring daylight savings change from \"winter\" to \"summer\". In a gap there are local date-time values with no valid offset.\nOverlap, with two valid offsets. This is when clocks are set back typically due to the autumn daylight savings change from \"summer\" to \"winter\". In an overlap there are local date-time values with two valid offsets.\n\n\nExample\nLet's use your specific example of the America/New_York time zone.  Per timeanddate.com, the daylight saving time changes in New York for 2022 are:\n\nMar 13, 2022 - Daylight Saving Time Started\nWhen local standard time was about to reach\nSunday, March 13, 2022, 2:00:00 am clocks were turned forward 1 hour to\nSunday, March 13, 2022, 3:00:00 am local daylight time instead.\nNov 6, 2022 - Daylight Saving Time Ends\nWhen local daylight time is about to reach\nSunday, November 6, 2022, 2:00:00 am clocks are turned backward 1 hour to\nSunday, November 6, 2022, 1:00:00 am local standard time instead.\n\nTherefore, there are no times between 2:00 and 2:59 on March 13 in the New York time zone.  1:59 occurs in standard time.  When that minute ends, no 2:00 hour occurs, and instead the local time jumps to 3:00 daylight time.\nAdditionally, the times between 1:00 and 1:59 occur twice on November 6: one in daylight time and then one in standard time.\nJava ZonedDateTime example\nZoneId zone = ZoneId.of(\"America/New_York\");\n\n// 2022-03-13T03:15:30-04:00[America/New_York] (no 2:15)\nSystem.out.println(\n        ZonedDateTime.of(LocalDateTime.parse(\"2022-03-12T02:15:30\"), zone)\n        .plusDays(1));\n\nSince 2:15 AM on March 12 doesn't exist and is within a 1-hour gap, the following logic you quoted applies, adding 1 hour to the local time:\n\nIf in a gap, the local date-time will be adjusted forward by the length of the gap.\n\nTherefore, 3:15 AM is used when adding 1 day to March 11 at 1:15 AM.\nZoneId zone = ZoneId.of(\"America/New_York\");\n\n// 2022-11-06T01:15:30-04:00[America/New_York] (First 1:15)\nSystem.out.println(\n        ZonedDateTime.of(LocalDateTime.parse(\"2022-11-05T01:15:30\"), zone)\n        .plusDays(1));\n\n// 2022-11-06T01:15:30-05:00[America/New_York] (Second 1:15)\nSystem.out.println(\n        ZonedDateTime.of(LocalDateTime.parse(\"2022-11-05T01:15:30\"), zone)\n        .plusDays(1).plusHours(1));\n\nSince 1:15 AM is during an overlap \u2014 1:15 AM occurs twice on November 6 \u2014 the following logic you quoted applies, using the same -04:00 zone offset as 1:15 AM on November 5:\n\nif the local date-time is in an overlap, then the offset will be retained if possible\n\nTherefore, adding 1 day to November 5 at 1:15 uses the first 1:15 on November 6.  This is made more evident by the second call, which shows that adding an hour to this timestamp returns the second 1:15 of November 6.  The fact that these are different points on the timeline despite both being 1:15 local time is evident by their differing zone offsets: -04:00 & -05:00.\n"
}
{
    "Id": 73630599,
    "PostTypeId": 1,
    "Title": "Java regex inside text blocks",
    "Body": "I surely hoped that this would be supported:\nprivate static void regex() {\n    String plain = \"\\\\w+\";\n    String withTextBlocks = \"\"\"\n        \\w+\n    \"\"\";\n}\n\nbut withTextBlocks does not compile under Java-17. Isn\u2019t it the point of text blocks that we should not escape? I have been through the JEP and maybe the explanation is there, but I can't grok through it. And a second question in case someone knows, is there a future JEP for this? Thank you.\n",
    "AcceptedAnswerId": 73639221,
    "AcceptedAnswer": "You are conflating text blocks with raw strings.  These are different features, though they were explored together and this may explain why you mentally folded them together.  There is no support yet for raw strings (which turn out to be somewhat more slippery than they might first appear.)\n\nIsn\u2019t it the point of text blocks that we should not escape?\n\nNo, that is not the point of text blocks.  The point of text blocks is to allow us to represent two dimensional blocks of text in code, preserving the block's relative indentation but not absolute indentation.  This allows us to freely indent the source representation of the text block itself to match surrounding code, without affecting the indentation of the string the text block describes.\nAn additional design goal is that text blocks should differ from ordinary string literals only in ways that pertain to their two-dimensional nature.  There should not be a different set of escape characters, or different escaping rules.  (If we ever do raw strings, it should apply equally to text blocks and traditional string literals.)  If text blocks worked the way you wanted, you'd probably be complaining that you can't do the same with single-line strings.  These aspects are orthogonal and the language should treat them orthogonally.\n"
}
{
    "Id": 73841877,
    "PostTypeId": 1,
    "Title": "Regex (?U)\\p{Punct} is missing some Unicode punctuation signs in Java",
    "Body": "First of all, I want to remove all punctuation signs in a String. I wrote the following code.\nPattern pattern = Pattern.compile(\"\\\\p{Punct}\");\nMatcher matcher = pattern.matcher(\"!\\\"#$%&'()*+,-./:;?@[\\\\]^_`{|}~\uff08hello\uff09\");\nif (matcher.find())\n    System.out.println(matcher.replaceAll(\"\"));\n\nAfter replacement I got this output: \uff08hello\uff09.\nSo the pattern matches the one of !\"#$%&'()*+,-./:;?@[\\]^_{|}~`, which matches the official docs.\nBut I want to remove \"\uff08\" Fullwidth Left Parenthesis U+FF08* and \"\uff09\" Fullwidth Right Parenthesis U+FF09 as well, so I changed my code to this:\nPattern pattern = Pattern.compile(\"(?U)\\\\p{Punct}\");\n        Matcher matcher = pattern.matcher(\"!\\\"#$%&'()*+,-./:;?@[\\\\]^_`{|}~\uff08\uff09\");\n        if (matcher.find())\n            System.out.println(matcher.replaceAll(\"\"));\n\nAfter replacement, I got this output: $+^|~`\nIt indeed matched \"\uff08\" Fullwidth Left Parenthesis U+FF08* and \"\uff09\" Fullwidth Right Parenthesis U+FF09, bit it missed $+^|~`.\nI am so confused. Why did that happen? Can anyone give some help?\n",
    "AcceptedAnswerId": 73841931,
    "AcceptedAnswer": "Unicode (that is when you use (?U)) and POSIX (when not using (?U)) disagrees on what counts as a punctuation.\nWhen you don't use (?U), \\p{Punct} matches the POSIX punctuation character class, which is just\n!\"#$%&'()*+,-./:;?@[\\]^_`{|}~\n\nWhen you use (?U), \\p{Punct} matches the Unicode Punctuation category, which does not include some of the characters in the above list, namely:\n$+^`|~\n\nFor example, the Unicode category for $ is \"Symbol, Currency\", or Sc. See here.\nIf you want to match $+^`|~, plus all the Unicode punctuations, you can put them both in a character class. You can also just directly use the Unicode category \"P\", rather than turning on Unicode mode with (?U).\nPattern pattern = Pattern.compile(\"[\\\\p{P}$+^`|~]\");\nMatcher matcher = pattern.matcher(\"!\\\"#$%&'()*+,-./:;?@[\\\\]^_`{|}~\uff08\uff09\");\n// you don't need \"find\" first\nSystem.out.println(matcher.replaceAll(\"\"));\n\n"
}
{
    "Id": 73911550,
    "PostTypeId": 1,
    "Title": "How can I reduce the time complexity from O(n^2) to O(n)",
    "Body": "I recently attended an interview and they asked me to solve the below problem by using O(n) time complexity. (Hackerranker)\nProblem:\nGiven an integer array and there will be l integer and r integer. Need to find the which are all the pair of elements sum will be equal and in between l and r value;\n\nExample:\nint[] array = {2,3,4,5}; int l=5, int r=7;\n\nOutput: 4\n\nInput properties:\n\nThe input is unsorted.\nThe input will have duplicate elements.\nThe input array is non-negative.\n\nThe below combination will return the sum which will be equal and in between l and r range value, where if the pair is less than l or greater than r it should be skipped. And pairs can't be duplicated:\narray[0] + array[1] = 5 -> counter++\narray[0] + array[2] = 6 -> counter++\narray[0] + array[3] = 7 -> counter++\narray[1] + array[2] = 7 -> counter++\narray[1] + array[3] = 8 -> greater than r, no counter increment\n\nI tried the below approach and it works fine but its time complexity is O(n^2):\n public static int sumPairs(int[] array,int l, int r)\n    {\n        int counter=0;\n        for(int i=0;i<array.length;i++)\n        {\n            for(int j=i+1;j<array.length;j++)\n            {\n                int sum = array[i]+array[j];\n                \n                if(sum=l)\n                {\n                    counter++;\n                }\n            }\n        }\n        \n        return counter;\n    }\n\nCan someone help me to find a way to optimize the above code to become O(n) time complexity?\n",
    "AcceptedAnswerId": 73922249,
    "AcceptedAnswer": "Here's my approach using a cumulative histogram instead of a sort. In c++, sorry.\nstatic int sumPairsLinear(int *pArray,int iArraySize, int l, int r)\n{\n    int iResult = 0;\n    // 1. Iterate the array and toss any entries larger than r\n    for (int i=0;i<iArraySize;)\n    {\n        if (pArray[i] > r)\n            pArray[i] = pArray[--iArraySize];\n        else\n            i++;\n    }\n    // 2. Allocate a zero initialised array of ints, of size `r+1`.\n    int *pHistogram = new int[r+1];\n    memset(pHistogram, 0, sizeof(int)*(r+1));\n    // 3. Fill the histogram\n    for (int i=0;i<iArraySize;i++)\n    {\n        pHistogram[pArray[i]]++;\n    }\n    // 4. Convert it to a cumulative histogram. \n    for (int i=1;i<=r;i++)\n    {\n        pHistogram[i] += pHistogram[i-1];\n    }\n    // 5. Iterate through the values again. Use the cumulative histogram to calculate the number of valid pairs.\n    for (int i=0;i<iArraySize;i++)\n    {\n        int iVal = pArray[i];\n        int iIndex = l-iVal-1;\n        iResult += pHistogram[r-iVal] - ((iIndex >= 0) ? pHistogram[iIndex] : 0);\n        // Don't pair with self\n        iVal *= 2;\n        if (iVal <= r &&\n            iVal >= l)\n        {\n            iResult--;\n        }\n    }\n    // 6. Half iResult because we counted each pair twice.\n    iResult /= 2;\n\n    delete[] pHistogram;\n    return iResult;\n}\n\nHorrible performance if r is large but otherwise reasonable and still O(N).\n"
}
{
    "Id": 74045604,
    "PostTypeId": 1,
    "Title": "can not create a maven archetype project, the progress bar get stuck in 33%",
    "Body": "I installed Eclipse IDE for Enterprise Java and Web Developers (includes Incubating components)\nVersion: 2022-09 (4.25.0)\nBuild id: 20220908-1902\nIt includes already maven, and I have tried to create some maven archetype projects, but without success, always get stuck in the progress bar.\nAnyone has some clues? Thank you!\n\n",
    "AcceptedAnswerId": 74086551,
    "AcceptedAnswer": "I had this too, it took me a long time to spot the very simple fix.  If you look in the console you'll see that the maven project generation is in interactive mode.  You just need to click Y (yes) in the console to confirm that you are happy with the configuration and it will finish.\n"
}
{
    "Id": 71142680,
    "PostTypeId": 1,
    "Title": "co.elastic.clients.transport.TransportException: [es/search] Missing [X-Elastic-Product] header",
    "Body": "I'm following the tutorial from elastic search java api client here: https://www.elastic.co/guide/en/elasticsearch/client/java-api-client/current/connecting.html\nMy code is as following.\n// Create the low-level client\nRestClient restClient = RestClient.builder(\n new HttpHost(\"localhost\", 9200)).build();\n\n// Create the transport with a Jackson mapper\nElasticsearchTransport transport = new RestClientTransport(\n restClient, new JacksonJsonpMapper());\n\n// And create the API client\nElasticsearchClient client = new ElasticsearchClient(transport);\n\ntry {\n SearchResponse search = client.search(s -> s\n   .index(\"*:*\"),\n   Object.class);\n} catch (IOException e) {\n System.out.println(e.getMessage());\n}\n\nThis code is throwing out the following exception:\nco.elastic.clients.transport.TransportException: [es/search] Missing [X-Elastic-Product] header. Please check that you are connecting to an Elasticsearch instance, and that any networking filters are preserving that header.\n\nI've tried manually putting this header via the setDefaultHeaders method like this:\nRestClientBuilder builder = RestClient.builder(\n new HttpHost(\"localhost\", 9200, \"http\"));\nHeader[] defaultHeaders = new Header[]{new BasicHeader(\"X-Elastic-Product\", \"Elasticsearch\")};\nbuilder.setDefaultHeaders(defaultHeaders);\nRestClient restClient = builder.build();\n\nBut the error is the same.\nI've tried both version 7.16 and 8.0.0, same result.\n",
    "AcceptedAnswerId": 74102828,
    "AcceptedAnswer": "The default headers the RestClientBuilder allows you to specify are the request headers, not the response headers. The error you are getting is because older Elasticsearch [server] versions do not include the X-Elastic-Product=Elasticsearch header in any of the API responses, but the recent distributions do (7.14+?), so the newer versions of elasticsearch-java (i.e. client) expects them.\nI am in the same boat \u2014 I use 8.4.2 of elasticsearch-java with an Elasticsearch server version of 7.2.0.\nI ran into two format-based compatibility issues:\n\nThe client passing a Content-Type not known to the server, and so its request getting rejected with a 406\nThe client validating if the response has X-Elastic-Product=Elasticsearch header\n\nFortunately, the RestClientBuilder allows you to customize the underlying http client through: setHttpClientConfigCallback. The callback looks like this, so basically you can intercept the request and responses, manipulate headers, and thereby get around these issues:\n    public interface HttpClientConfigCallback {\n        /**\n         * Allows to customize the {@link CloseableHttpAsyncClient} being created and used by the {@link RestClient}.\n         * Commonly used to customize the default {@link org.apache.http.client.CredentialsProvider} for authentication\n         * or the {@link SchemeIOSessionStrategy} for communication through ssl without losing any other useful default\n         * value that the {@link RestClientBuilder} internally sets, like connection pooling.\n         */\n        HttpAsyncClientBuilder customizeHttpClient(HttpAsyncClientBuilder httpClientBuilder);\n    }\n\nSpecifically, here's what worked for me:\nvar httpClientConfigCallback = httpClientBuilder ->\n        httpClientBuilder\n            .setDefaultCredentialsProvider(credentialsProvider)\n            // this request & response header manipulation helps get around newer (>=7.16) versions\n            // of elasticsearch-java client not working with older (<7.14) versions of Elasticsearch\n            // server\n            .setDefaultHeaders(\n                List.of(\n                    new BasicHeader(\n                        HttpHeaders.CONTENT_TYPE, ContentType.APPLICATION_JSON.toString())))\n            .addInterceptorLast(\n                (HttpResponseInterceptor)\n                    (response, context) ->\n                        response.addHeader(\"X-Elastic-Product\", \"Elasticsearch\"));\nvar restClient =\n        RestClient.builder(elasticsearchHosts)\n            .setHttpClientConfigCallback(httpClientConfigCallback)\n            .build();\n\n\nNote that there could still be behavioral differences between the aforementioned product and API versions as they are way too apart. The above only fixes format-based incompatibilities. For this reason, it's always best to use at least the same major versions of these components, if not the exact versions.\n"
}
{
    "Id": 74081398,
    "PostTypeId": 1,
    "Title": "Android Studio : Cause: dagger/hilt/android/plugin/HiltGradlePlugin has been compiled by a more recent version of the Java Runtime",
    "Body": "I am getting this error while opening a project\nCause: dagger/hilt/android/plugin/HiltGradlePlugin has been compiled by a more recent version of the Java Runtime (class file version 55.0), this version of the Java Runtime only recognizes class file versions up to 52.0\nWhat i tried are :\nPlugin [id: 'dagger.hilt.android.plugin'] was not found in any of the following sources\nhttps://github.com/google/dagger/issues/3495\nDagger-hilt error while compiling project\nClass has been compiled by a more recent version of the Java Environment\nHow to resovle Java Runtime (class file version 55.0), this version of the Java Runtime only recognizes class file versions up to 52.0 error?\njava.lang.UnsupportedClassVersionError while integrating firebase performance library in react native app\njava.lang.unsupportedclassversionerror in gradle build\nThe Hilt Android Gradle plugin is applied but no com.google.dagger:hilt-android-compiler dependency was found\n",
    "AcceptedAnswerId": 74247022,
    "AcceptedAnswer": "The youtube link solution reported fixed the issue in my case, however here the instructions for the very latest Android Studio version (Android Studio Dolphin | 2021.3.1 Patch 1) on MacOS\n\nSelect your project App main folder in the Android Studio Project panel\nRight click -> Open Module Settings\nSelect the Project entry below the Project Settings section\nIn the dropdown menu next to SDK, select the Java 11 version\nClick on Apply and OK\nRebuild the project\n\nIf this doesn't work could be something deeper messed up in your machine JDK configuration or IDE configuration, would be easier I think to uninstall completely the IDE, clean the configuration file and install from scratch.\nIt could be overkill but sometime this is the most reliable way especially when nothing works.\n"
}
{
    "Id": 74837939,
    "PostTypeId": 1,
    "Title": "How to delete an \"Island\" of numbers in a 2D array in Java",
    "Body": "I'm creating a method that takes a 2D array and scans throughout the array to find \"Chunks\" of numbers that are completely surrounded by zeros and convert those Chunks (I call them the islands) into zeros.\nI'm trying to delete all of the \"islands\" except for the largest one.\nFor example, for this 2D array\n1 2 3 2 2 1 \n3 2 2 1 2 3\n3 2 2 1 3 2\n2 3 2 3 2 2\n2 2 3 1 1 2\n3 2 1 2 3 2\n2 3 1 2 3 2\n2 2 0 0 0 0\n0 0 0 1 2 0\n0 0 0 0 0 0 \n\nAfter the method the 2D array should now be:\n1 2 3 2 2 1 \n3 2 2 1 2 3\n3 2 2 1 3 2\n2 3 2 3 2 2\n2 2 3 1 1 2\n3 2 1 2 3 2\n2 3 1 2 3 2\n2 2 0 0 0 0\n0 0 0 0 0 0\n0 0 0 0 0 0 \n\nthe small chunk of 1 2  is \"deleted\"\nHere is a second example, as the method should also take chunks of numbers that are not part of the \"main\" chunk as Islands and that are on the edges as well.\nThe original array would be:\n1 2 3 2 2 1 \n3 2 2 1 2 3\n3 2 2 1 3 2\n2 3 2 3 2 2\n2 2 3 1 1 2\n3 2 1 2 3 2\n2 3 1 2 3 2\n2 2 0 0 0 0\n0 0 0 1 2 3\n0 0 0 0 3 2 \n\nAfter the method execution, it should be:\n1 2 3 2 2 1 \n3 2 2 1 2 3\n3 2 2 1 3 2\n2 3 2 3 2 2\n2 2 3 1 1 2\n3 2 1 2 3 2\n2 3 1 2 3 2\n2 2 0 0 0 0\n0 0 0 0 0 0\n0 0 0 0 0 0 \n\nIn this case, the island\n1 2 3 \n  3 2\n\nis deleted because it is separate from the big chunk and is surrounded by zeros.\nThe following code is the one I have so far, and it does not work as intended. It's wrong because I believe that it's taking the main chunk as an Island, and what happens is that it converts the entire array into zeros instead of deleting only the small Islands. It includes an example, and you should see what It does when you run it.\npublic class destroyIslands {\n    public static void main(String[] args) {\n        int[][] example = { {1, 2, 3, 1, 2},\n                            {2, 3, 2, 1, 2},\n                            {3, 2, 1, 2, 2},\n                            {0, 2, 0, 0, 0},\n                            {0, 0, 0, 2, 1} };\n        \n        example = deleteIslandBoard(example);\n        printGrid(example);\n    }\n    \n    public static int[][] deleteIslandBoard(int[][] array) {\n      // Create a boolean array to track which cells have been visited\n      boolean[][] visited = new boolean[array.length][array[0].length];\n    \n      // Iterate \n      for (int i = 0; i < array.length; i++) {\n        for (int j = 0; j < array[0].length; j++) {\n            // If the cell is not visited and is part of an island\n            if (!visited[i][j] && array[i][j] != 0) {\n                // Delete the island by setting all cells to 0\n                deleteIsland(array, i, j, visited);\n            }\n        }\n      }\n      // Return the modified array\n      return array;\n    }\n\n    public static void deleteIsland(int[][] array, int i, int j, boolean[][] visited) {\n      // Check if the current cell is out of board or if it has already been visited\n      if (i = array.length || j = array[0].length || visited[i][j]) {\n        return;\n      }\n      // Mark the current cell as visited\n      visited[i][j] = true; // If the current cell is part of the island, set it to 0\n      if (array[i][j] != 0) {\n        array[i][j] = 0;\n        // Recursively delete the neighboring cells that are part of the island\n        deleteIsland(array, i - 1, j, visited);\n        deleteIsland(array, i + 1, j, visited);\n        deleteIsland(array, i, j - 1, visited);\n        deleteIsland(array, i, j + 1, visited);\n      }\n    }\n    \n    public static void printGrid(int[][] grid) {\n        for(int i = 0; i < grid.length; i++) {\n            for(int j = 0; j < grid[i].length; j++) {\n                System.out.print(grid[i][j] + \" \");\n            }\n            System.out.println();\n        }\n    }\n}\n\nAny idea of what should I change?\n",
    "AcceptedAnswerId": 74839246,
    "AcceptedAnswer": "This problem can be solved in linear time O(n) by treating the cells of the given Matrix as the Vertexes of an undirected disjointed Graph.\nThe task boils down to exploring all Connected components (islands) in a Graph, and comparing them with each other.\nAnd for that we would need to implement of the Graph-traversal algorithms. I've chosen the Depth first search algorithm for that purpose.\nTo keep things simple, a Vertex of a graph would be represented as an array int[] of two elements containing coordinates of a cell (feel free to reimplement it by defining a separate class for a Vertex to make each vertex aware of it neighbors by holding a reference to a collection of Vertices)\nFor convenience, I've made several changes to your DestroyIslands class:\n\nIntroduced an inner class Island, which wraps a list of cells that constitute an Island (Connected component of the Graph). This class implements Comparable in based on size of the cells to make it easier to find the largest Island. And defines the method destroy() to nullify the rest Islands.\nIntroduced a static array NEIGHBOURS of type int[][] representing all possible adjacent cells, which should be considered while iterating through the matrix from left to right and from top to bottom.\nReference to the Matrix is stored in the instance field grid, and all methods of DestroyIslands are defined as instance methods (if you want to keep them static, fill free to change them as you see fit, it would be easy if you grasp the algorithm itself).\n\nThat's how implementation might look like:\npublic class DestroyIslands {\n    public static final int[][] NEIGHBOURS = // adjacent cells\n        {{0, 1},   // horizontal -\n         {1, 0},   // vertical   |\n         {1, 1},   // diagonal   \\\n         {1, -1}}; // diagonal   /\n\n    private List islands = new ArrayList(); // collection of Islands\n    private int[][] grid; // matrix\n    \n    public DestroyIslands(int[][] grid) {\n        this.grid = grid;\n    }\n    \n    public class Island implements Comparable {\n        private List cells = new ArrayList();\n        \n        public void addCell(int[] cell) {\n            cells.add(cell);\n        }\n        \n        public void destroy() {\n            cells.forEach(cell -> grid[cell[0]][cell[1]] = 0);\n        }\n        \n        @Override\n        public int compareTo(Island other) {\n            return Integer.compare(cells.size(), other.cells.size());\n        }\n    }\n    \n    public void deleteIslandBoard() {\n        exploreIslands();\n        deleteSmallerIslands();\n    }\n    \n    public void exploreIslands() {\n        boolean[][] visited = new boolean[grid.length][grid[0].length];\n        \n        for (int i = 0; i < grid.length; i++) {\n            for (int j = 0; j < grid[0].length; j++) {\n                \n                if (!visited[i][j] && grid[i][j] != 0) { // if a New Island was found\n                    exploreIsland(new int[]{i, j}, visited); // explore the Island, i.e. index all its cell and mark them as visited\n                }\n            }\n        }\n    }\n    \n    /**\n     * Depth first search implementation\n     */\n    public void exploreIsland(int[] cell, boolean[][] visited) {\n        Island island = new Island();\n        islands.add(island); // updating the list of Islands\n        \n        Deque stack = new ArrayDeque();\n        stack.push(cell);\n        \n        while (!stack.isEmpty()) {\n            int[] next = stack.poll();\n            island.addCell(next);\n            \n            for (int[] shift : NEIGHBOURS) {\n                int row = next[0] + shift[0];\n                int col = next[1] + shift[1];\n                \n                if (isValid(row, col) && !visited[row][col]) { // if cell exist, non-zero and not visited yet\n                    stack.push(new int[]{row, col});\n                    visited[row][col] = true;\n                }\n            }\n        }\n    }\n    \n    public boolean isValid(int row, int col) {\n        return row >= 0 && row < grid.length\n            && col >= 0 && col < grid[0].length\n            && grid[row][col] != 0;\n    }\n    \n    public void deleteSmallerIslands() {\n        if (islands.isEmpty()) return; // otherwise Collections.max() would throw NoSuchElementException\n\n        Island largest = Collections.max(islands);\n        for (Island next : islands) {\n            if (next != largest) next.destroy();\n        }\n    }\n    \n    public void printGrid() {\n        for (int i = 0; i < grid.length; i++) {\n            for (int j = 0; j < grid[i].length; j++) {\n                System.out.print(grid[i][j] + \" \");\n            }\n            System.out.println();\n        }\n    }\n}\n\nmain()\npublic static void main(String[] args) {\n        int[][] example = {\n            {1, 2, 3, 1, 2},\n            {2, 3, 2, 1, 2},\n            {3, 2, 1, 2, 2},\n            {0, 2, 0, 0, 0},\n            {0, 0, 0, 2, 1}};\n        \n        DestroyIslands destroyIslands = new DestroyIslands(example);\n        destroyIslands.deleteIslandBoard();\n        destroyIslands.printGrid();\n    }\n\nOutput:\n1 2 3 1 2 \n2 3 2 1 2 \n3 2 1 2 2 \n0 2 0 0 0 \n0 0 0 0 0\n\nA link to Online Demo\n"
}
{
    "Id": 74847682,
    "PostTypeId": 1,
    "Title": "Why have nothing to override, but still can put @Override without syntax error?",
    "Body": "I am using Java language level 17 on JDK 19. I have\npackage ocp17.ch07;\n\npublic record BeardedDragon(boolean fun) {\n    \n    @Override\n    public boolean fun() {\n        return false;\n    }\n    \n}\n\n\nWhy have nothing to override, but still can put @Override without syntax error?\n",
    "AcceptedAnswerId": 74847710,
    "AcceptedAnswer": "You are indeed overriding the fun method (which is bad in this case1). With Java records, the accessor name (which it automatically gives for you) doesn't have the get prefix - it is fun() and not getFun() or isFun().\nThe Record Members section of JLS states\n\nFurthermore, for each record component, a record class has a method with the same name as the record component and an empty formal parameter list. This method, which is declared explicitly or implicitly, is known as an accessor method.\n\nThe Records JEP also says,\n\nThe meaning of the @Override annotation was extended to include the case where the annotated method is an explicitly declared accessor method for a record component.\n\n@Sweeper's answer points to the appropriate section of JLS for this\nSo whatever you've done now counts as overriding.\n\n1 Why is it bad?\nLet's say you have an instance of BeardedDragon like,\nBeardedDragon dragon = new BeardedDragon(true);\nif (dragon.fun()) {\n     System.out.println(\"Yay!!\");\n} else {\n    System.out.println(\"Dang it.. It was supposed to be fun\");\n}\n\nIt will return false when you call fun(). I'm not sure if that is what you want.\nAlso, it violates the below requirement from the JLS.\n\nConsider a record class R that has components c1, ..., cn, and an\nimplicitly declared accessor method for every component, and an\nimplicitly declared equals method. If an instance r1 of R is copied in\nthe following way:\nR r2 = new R(r1.c1(), r1.c2(), ..., r1.cn());\nthen, assuming r1 is not the null reference, it is always the case\nthat the expression r1.equals(r2) will evaluate to true. Explicitly\ndeclared accessor methods and equals methods should respect this\ninvariant. It is not generally possible for a compiler to check\nwhether explicitly declared methods respect the invariant.\n\nUsing the example from @Johannes Kuhn (from the comments).\nvar b1 = new BeardedDragon(true); \nvar b2 = new BeardedDragon(b1.fun()); \nassert b1.equals(b2); // This will fail \n\n"
}
{
    "Id": 74752707,
    "PostTypeId": 1,
    "Title": "GitHub Actions : How to resolve : \"The process '/usr/bin/gpg' failed with exit code 2\" problem on actions/setup-java@v3",
    "Body": "Introduction\nCurrently, I'm trying to contribute on a GitHub Action that automatically publishes a java library.\nThe branch where I'm developing: https://github.com/MathieuSoysal/Java-maven-library-publisher/tree/2-add-automated-tests\nThe yaml code of the Action :\nname: Java maven library publisher\nauthor: \"Mathieu Soysal (@MathieuSoysal)\"\ndescription: \"Build automatically Java Maven library and publish it to GitHub Packages and Maven Central.\"\nbranding:\n  icon: \"package\"\n  color: \"gray-dark\"\n\ninputs:\n  nexus-username:\n    description: \"Nexus username\"\n    required: true\n  nexus-password:\n    description: \"Nexus password\"\n    required: true\n  gpg-private-key:\n    description: \"GPG private key\"\n    required: true\n  gpg-passphrase:\n    description: \"GPG passphrase\"\n    required: true\n  github-token:\n    description: \"GitHub token\"\n    required: true\n  # Java version to use\n  java-version:\n    description: \"Java version to use\"\n    required: true\n    default: \"17\"\n  # Library version\n  library-version:\n    description: \"Library version\"\n    required: false\n    default: \"\"\n\nruns:\n  using: \"composite\"\n\n  steps:\n    - name: Checkout\n      uses: actions/checkout@v3\n\n    - name: Set up JDK 17 for deploy to OSSRH\n      uses: actions/setup-java@v3\n      with:\n        distribution: \"adopt\"\n        java-version: ${{ inputs.java-version }}\n        server-id: ossrh\n        server-username: ${{ inputs.nexus-username }}\n        server-password: ${{ inputs.nexus-password }}\n        gpg-private-key: ${{ inputs.gpg-private-key }}\n        gpg-passphrase: ${{ inputs.gpg-passphrase }}\n\n    - name: Build with Maven\n      run: mvn -B package --file pom.xml\n      shell: bash\n\n    - name: Update package version\n      if: ${{ inputs.library-version != '' }}\n      run: mvn versions:set -DnewVersion=${{ inputs.library-version }}\n      shell: bash\n\n    - name: Prepare Maven environnement with Java 17 for deployment to OSSRH\n      run: export MAVEN_OPTS=\"--add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.desktop/java.awt.font=ALL-UNNAMED\"\n      shell: bash\n\n    - name: Publish to Apache Maven Central\n      run: mvn deploy -PossrhDeploy\n      shell: bash\n      env:\n        MAVEN_USERNAME: ${{ inputs.nexus-username }}\n        MAVEN_CENTRAL_TOKEN: ${{ inputs.nexus-password }}\n        MAVEN_GPG_PASSPHRASE: ${{ inputs.gpg-passphrase }}\n\n    - name: Set up JDK 17 for deploy to github packages\n      uses: actions/setup-java@v3\n      with:\n        distribution: \"adopt\"\n        java-version: ${{ inputs.java-version }}\n        server-id: github\n\n    - name: Publish to GitHub Packages Apache Maven\n      run: mvn deploy -PgithubDeploy\n      shell: bash\n      env:\n        GITHUB_TOKEN: ${{ inputs.github-token }}\n\nlink to the code: https://github.com/MathieuSoysal/Java-maven-library-publisher/blob/2-add-automated-tests/action.yaml\nThe workflow that execute the Action:\nname: Test Actions\n\non: [push]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Maven Library build and publish\n        uses: ./\n        with:\n          nexus-username: ${{ secrets.NEXUS_USERNAME }}\n          nexus-password: ${{ secrets.NEXUS_PASSWORD }}\n          gpg-private-key: ${{ secrets.GPG_PRIVATE_KEY }}\n          gpg-passphrase: ${{ secrets.GPG_PASSPHRASE }}\n          library-version: $GITHUB_RUN_NUMBER\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          java-version: 17\n\nLink to the code: https://github.com/MathieuSoysal/Java-maven-library-publisher/blob/2-add-automated-tests/.github/workflows/test-action.yml\nProblem\nWhen i'm trying to execute the action I obtain this error:\nGetting action download info\nDownload action repository 'actions/setup-java@v3' (SHA:c3ac5dd0ed8db40fedb61c32fbe677e6b355e94c)\nRun ./\nRun actions/checkout@v3\nSyncing repository: ***/Java-maven-library-publisher\nGetting Git version info\nTemporarily overriding HOME='/home/runner/work/_temp/45376e45-02aa-4aa5-b536-5f744f7e10d3' before making global git config changes\nAdding repository directory to the temporary git global config as a safe directory\n/usr/bin/git config --global --add safe.directory /home/runner/work/Java-maven-library-publisher/Java-maven-library-publisher\n/usr/bin/git config --local --get remote.origin.url\nhttps://github.com/***/Java-maven-library-publisher\nRemoving previously created refs, to avoid conflicts\nCleaning the repository\nDisabling automatic garbage collection\nSetting up auth\nFetching the repository\nDetermining the checkout info\nChecking out the ref\n/usr/bin/git log -1 --format='%H'\n'0e8da131bf626b218ddccbd08a661c7921dfb8da'\nRun actions/setup-java@v3\nInstalled distributions\nCreating settings.xml with server-id: ossrh\nWriting to /home/runner/.m2/settings.xml\nImporting private gpg key\nError: The process '/usr/bin/gpg' failed with exit code 2\n\nQuestion\nSomeone know how we can fix this The process '/usr/bin/gpg' failed with exit code 2 for actions/setup-java@v3 ?\n",
    "AcceptedAnswerId": 74848449,
    "AcceptedAnswer": "Can you make sure GPG private key is in the correct format. The key should be in the ASCII Armored format, which can be done by running the following command:\ngpg --armor --export-secret-keys  > gpg_key.asc\n\nOnce the key is in the correct format, add it as an input variable in the Action and pass it to the action in the workflow.\n"
}
{
    "Id": 74875058,
    "PostTypeId": 1,
    "Title": "How to get jwt token value in spring webflux? (to exchange it with Minio STS token)",
    "Body": "I have sping-boot application with rest services written using Spring web flux.\nFor now I access minio using login/password authorizaton and it works fine.\nFor now I want to exchange application JWT token with STS minio token and I implemented method to test:\n@PostMapping\npublic boolean test(JwtAuthenticationToken token) throws ServerException, InsufficientDataException, ErrorResponseException, IOException, NoSuchAlgorithmException, InvalidKeyException, InvalidResponseException, XmlParserException, InternalException {\n    MinioClient minioClient =\n            MinioClient.builder()\n                    .region(...)\n                    .endpoint(...)              \n                    .credentialsProvider(new WebIdentityProvider(\n                           \n                            () -> new Jwt(token.getToken().getTokenValue(), 1000),\n                            String.valueOf(...),\n                            null,\n                            null,\n                            null,\n                            null,\n                            null))\n                    .build();\n    return minioClient.bucketExists(\"mybucket\").build());\n}\n\nThis code successfully works and returns true because mybucket actually exists.\nBut it is only test and I need to move minioClient to the configuration. The issue here that I have to have credentials provider there.\nSo I've created folowing configuration:\n@Bean\npublic MinioClient minioClient() {\n    return MinioClient.builder()\n            .region(...)\n            .endpoint(...)\n            .credentialsProvider(new WebIdentityProvider(\n                   \n                    () -> {\n                        String block = null;\n                        try {\n                            block = ReactiveSecurityContextHolder\n                                .getContext()\n                                .map(context -> {\n                                            return context\n                                                    .getAuthentication()\n                                                    .getPrincipal();\n\n                                        }\n                                )\n                                .cast(Jwt.class)\n                                .map(Jwt::token)\n                                .block();\n                        } catch (Exception e) {\n                            // it fails here     <=======\n                            System.out.println(e);\n                        }\n\n                        Jwt jwt = new Jwt(String.valueOf(block),\n                                1000);\n                        return jwt; },\n                    String.valueOf(...),\n                    null,\n                    null,\n                    null,\n                    null,\n                    null))\n            .build();\n}\n\nBut unfortunately method block() fails with exception:\njava.lang.IllegalStateException: block()/blockFirst()/blockLast() are blocking, which is not supported in thread reactor-http-nio-6 \n\nAny ideas how to fix it?\nP.S.\n_\nI tried\n.toFuture()\n.get();\n\ninstead of .block();\nbut it returns null\n",
    "AcceptedAnswerId": 74883975,
    "AcceptedAnswer": "As Numichi stated in the comment you have to stay in the reactor context.\nOne option is to create a bean of type Mono.\n    @Bean\n    @Scope(BeanDefinition.SCOPE_PROTOTYPE)\n    public Mono reactiveMinio() {\n        return ReactiveSecurityContextHolder.getContext()\n                .map(securityContext ->\n                        (Jwt)securityContext.getAuthentication().getPrincipal())\n                .map(jwt -> MinioClient.builder()\n                        .region(\"someRegion\")\n                        .endpoint(\"someEndpoint\")\n                        .credentialsProvider(webIdentityProvider(jwt.token()))\n                        .build());\n    }\n\n    private WebIdentityProvider webIdentityProvider(String token) {\n        return new WebIdentityProvider(() -> new Jwt(token, 1000),\n                \"stsEndpoint\",\n                null,\n                null,\n                null,\n                null,\n                null);\n    }\n\nI think bean scope should be prototype since MinioClient is bound to security context.\nHere is the sample usage of reactive MinioClient:\n\n@RestController\npublic class MinioTest {\n\n    private Mono minioClient;\n\n    public MinioTest(Mono minioClient) {\n        this.minioClient = minioClient;\n    }\n\n    @GetMapping(\"/minio\")\n    public Mono client() {\n        return minioClient\n                .map(minio -> {\n                    try {\n                        return minio.bucketExists(BucketExistsArgs\n                                .builder()\n                                .bucket(\"my-bucketname\")\n                                .build());\n                    } catch (Exception e) {\n                        return new Exception(e);\n                    }\n                });\n    }\n}\n\n\n\n"
}
{
    "Id": 73095898,
    "PostTypeId": 1,
    "Title": "RCTModernEventEmitter fires twice for android fabric component",
    "Body": "I am trying to create a fabric component for android, specifically I want to use the onClickHandler of the button component and pass a callback to react-native side via RCTModernEventEmitter. It works fine for iOS but for android the RCTModernEventEmitter emits twice every time I click the button\nThis is my spec\nimport type {HostComponent, ViewProps} from 'react-native';\nimport type {\n  DirectEventHandler\n} from 'react-native/Libraries/Types/CodegenTypes';\nimport codegenNativeComponent from 'react-native/Libraries/Utilities/codegenNativeComponent';\n\ntype Event = Readonly<{\n  text?: string;\n}>;\n\ninterface NativeProps extends ViewProps {\n  text: string;\n  onClickHandler?: DirectEventHandler; ////Event name should start with on\n}\n\nexport default codegenNativeComponent(\n  'MyButtonView',\n) as HostComponent;\n\nOn native side I have created following files\npublic class MyButtonViewManager extends SimpleViewManager {\n\n    public static final String NAME = \"MyButtonView\";\n    ReactApplicationContext mCallerContext;\n\n    public MyButtonViewManager(ReactApplicationContext reactContext) {\n        mCallerContext = reactContext;\n    }\n \n    @NonNull\n    @Override\n    public String getName() {\n        return NAME;\n    }\n\n    @NonNull\n    @Override\n    protected MyButtonView createViewInstance(@NonNull ThemedReactContext reactContext) {\n        return new MyButtonView(reactContext);\n    }\n\n    @ReactProp(name = \"text\")\n    public void setQrCodeText(MyButtonView view, String text) {\n        view.setText(text);\n    }\n\n\n    @Nullable\n    @Override\n    public Map getExportedCustomDirectEventTypeConstants() {\n        return MapBuilder.of(\"topOnClickHandler\",\n                MapBuilder.of(\"registrationName\", \"onClickHandler\")\n        );\n    }\n\n}\n\npublic class MyButtonClickEvent extends Event {\n\n    public MyButtonClickEvent(int viewId) {\n        super(viewId);\n    }\n \n    @Override\n    public String getEventName() {\n        return \"topOnClickHandler\";\n    }\n\n//    @Override\n//    public void dispatch(RCTEventEmitter rctEventEmitter) {\n//        super.dispatch(rctEventEmitter);\n//        rctEventEmitter.receiveEvent(getViewTag(), getEventName(), Arguments.createMap());\n//    }\n\n    @Override\n    public void dispatchModern(RCTModernEventEmitter rctEventEmitter) {\n        super.dispatchModern(rctEventEmitter);\n        rctEventEmitter.receiveEvent(-1,\n                getViewTag(),getEventName(),\n                Arguments.createMap()\n        );\n    }\n\n    @Nullable\n    @Override\n    protected WritableMap getEventData() {\n        WritableMap event = Arguments.createMap();\n        event.putString(\"message\", \"MyMessage\");\n        return event;\n    }\n}\n\npublic class MyButtonView extends androidx.appcompat.widget.AppCompatButton {\n\n    public MyButtonView(Context context) {\n        super(context);\n        configureViews();\n    }\n\n    private void configureViews(){\n        setBackgroundColor(Color.YELLOW);\n        setOnClickListener(view -> {\n            ReactContext reactContext = (ReactContext)getContext();\n            EventDispatcher eventDispatcher = UIManagerHelper.getEventDispatcherForReactTag(\n                    reactContext ,getId()\n            );\n            eventDispatcher.dispatchEvent(new MyButtonClickEvent(getId()));\n        });\n    }\n}\n\nOn JS side\n<MyButtonView\n  style={{height: 100, width: 100, margin: 20}}\n  onClickHandler={(value: any) => {\n    console.log('Hello ok bye', value.nativeEvent);\n  }}\n  text=\"Hello\"\n/>\n\nI get value in onClickHandler of MyButtonView twice even though I press the button once\nFullrepo is here https://github.com/PritishSawant/ReactNativeFabricEventListenerExample\nEdit:\nI have updated my code to 0.71.1 and you can find it here\n",
    "AcceptedAnswerId": 75318050,
    "AcceptedAnswer": "Commenting  super.dispatchModern(rctEventEmitter); from dispatchModern resolved the issue\n"
}
{
    "Id": 70552008,
    "PostTypeId": 1,
    "Title": "Java hidden properties without Spring",
    "Body": "I am currently creating a Java program that uses a MongoDB database and I am storing the connection information in a properties file.\nBut my project is opensource on GitHub and I cannot store the connection information in the properties file.\nAnd so I wanted to ask you if it is possible to give the login information from docker run.\nexample : docker run registry/image -args db.password=psw db.username=user\nI have seen solutions in stackoverflow but all solutions use Spring features, but my project does not use Spring framework.\n",
    "AcceptedAnswerId": 70556743,
    "AcceptedAnswer": "We have multiple solutions for this:\nSecret Docker\nCreate a file with the properties syntax:\n//secret-file.txt\ndb.password=psw\ndb.username=user\n\nWith this file create a docker secret in your docker :\n$ docker secret create test-secret secret-file.txt\n\nAnd use this with the java library docker-secrets in your java program :\nMap secrets = DockerSecrets.loadFromFile(\"test-secret\");\nSystem.out.println(secrets.get(\"db.password\")) // readonly\n\nFor more example, look here.\n\nEnvironment variables\nSet the environment variables in the docker with -e argument :\n$ docker run -e DB_PASSWORD=pwd -e DB_USERNAME=user registry/image:tag\n\nAnd use these variables with System::getenv in your java program :\nSystem.out.println(System.getenv(\"DB_PASSWORD\"))\n\n\nVM Arguments\nThis solution depends on your base image that was used to create your Docker container.\nGive VM Arguments to the docker run command :\n$ docker run -e JAVA_OPTS=\"-Ddb.password=pwd -Ddb.username=user\" registry/image:tag\n\nAnd use these variables with System::getProperty in your java program :\nSystem.out.println(System.getProperty(\"db.password\"))\n\n\nProgram arguments\nGive arguments to docker run command :\nIt is important to give the arguments after declaring the image.\n$ docker run registry/image:tag pwd user\n\nAnd use these arguments with main method in your java program :\npublic static void main(String[] args) {\n    System.out.println(\"The password: \" + args[0]);\n    System.out.println(\"The username: \" + args[1]);\n}\n\nFor better handling of arguments, you can use the Apache's commons-cli java library or use a another library.\n"
}
{
    "Id": 70601508,
    "PostTypeId": 1,
    "Title": "Can I use Java 16 record with JPA entity?",
    "Body": "I am trying to do something similar like below.\n@Entity\n@Table(name=\"Sample\")\npublic record Sample(Integer id, String name) {\n\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    @Column(name=\"user_id\")\n    private Integer id;\n\n    @Column(name=\"username\")\n    private String name;\n\n}\n\nHowever, it gives me error \"User declared non-static fields id are not permitted in a record\"\nand same for name field as well.\nIs there a way to use new java feature \"record\" with JPA annotation?\n",
    "AcceptedAnswerId": 70601646,
    "AcceptedAnswer": "See the article, Using Records as Projections in JPA by Billy Korando. The following is a brief summary.\nRecords cannot be Entities\nJakarta Persistence  (JPA; formerly Java Persistence API) implementations such as Hibernate depend on features either forbidden or not recommended by the JEP 395: Records spec: no-arg constructors, non-final fields, setters, etc.\n\u27a5 So, no, records cannot be used as JPA Entity.\nOther uses of records\nYou can use records with:\n\nCriteriaBuilder\nTypedQuery\nNativeQuery\nMapping definition\n\nSpring data has some support as well.\nSee that article linked above for details, and for links to two other articles.\n"
}
{
    "Id": 70575180,
    "PostTypeId": 1,
    "Title": "Log4j2 vulnerability and Lombok annotation @log4j2",
    "Body": "We are using spring boot 2.1.5 and starter parent as pom dependency.\nSpring boot is using default logback for logging and we haven't explicitly switched to Log4j2 or changes any configurations. Below is our project dependency tree.\n\nWe have lot of lombok @log4j2 annotations in our project. But, we find in dependency tree we do not have any log4j2-core jar dependency (that has been found vulnerable to recent issues with log4j).\n@Log4j2\n@Service\n@DependsOn(\"applicationDependencyCheck\")\n\nIs lombok @log4j2 not dependent on log4j2-core.jar. Is it correct to assume this would show up in maven dependency tree or are we missing something.\nThis is our lombok entry -\n\n    org.projectlombok\n    lombok\n    true\n\n\nPlease share some insights.\nthanks\n",
    "AcceptedAnswerId": 70576095,
    "AcceptedAnswer": "In lombok documentation you can find it here https://projectlombok.org/api/lombok/extern/log4j/Log4j2.html\n\n@Log4j2  public class LogExample {  }\nwill generate:\npublic class LogExample {\nprivate static final org.apache.logging.log4j.Logger log = org.apache.logging.log4j.LogManager.getLogger(LogExample.class);  }\n\nBoth classes are present in log4j API jar\n\nhttps://logging.apache.org/log4j/2.x/log4j-api/apidocs/org/apache/logging/log4j/LogManager.html\nhttps://logging.apache.org/log4j/2.x/log4j-api/apidocs/org/apache/logging/log4j/Logger.html\n\nThere are no known vulnerabilities listed here https://mvnrepository.com/artifact/org.apache.logging.log4j/log4j-api\nAs described here https://logging.apache.org/log4j/2.x/log4j-api/index.html log4j api is just an interface.\nI think in such case your code does not depend on log4j core. You can double check the output of build (e.g. maven /target folder, war file etc)\n"
}
{
    "Id": 70593561,
    "PostTypeId": 1,
    "Title": "Cannot be resolved to absolute file path because it does not reside in the file system",
    "Body": "My Code:\nXWPFDocument doc = new XWPFDocument(OPCPackage.open(ResourceUtils.getFile(\"classpath:assets/OPTIONS_\" + jubilar1.getJubiLanguage().toUpperCase() + \".docx\")));\n\nI have already tried instead of .getFile(), extractJarFileFromURL or resource.getInputStream() but all this does not work. When I package my project and run it as a jar file and it tries to open the following file it always returns the following message.\nError:\n\njava.io.FileNotFoundException: class path resource [assets/OPTIONS_DE.\ndocx] cannot be resolved to absolute file path because it does not\nreside in the file system:\njar:file:/home/tkf6y/IdeaProjects/hrapps/backend/target/backend-3.0.0.jar!/BOOT-INF/classes!/assets/OPTIONS_EN.docx\n\n",
    "AcceptedAnswerId": 70604475,
    "AcceptedAnswer": "So yes it was the problem, as you are now using an InputStream as I suggested. The problem was (and always has been) the getFile stuff. What I suggest to do is don't use what you have now but rather do a new ClassPathResource(your location).getInputStream()) instead, it is easier, or even use a ResourceLoader (a Spring interface you can inject) and then use the path you had an again use getInputStream(). \u2013\n"
}
{
    "Id": 70576798,
    "PostTypeId": 1,
    "Title": "Boolean recursive static method that gets an array of integers",
    "Body": "I'm trying to write a method that would Return true if it is possible to divide all the members of an array into two different groups of equal size so that the sum of the members of the two groups is equal. If this is not possible, the method Return false.\nThe conditions are:\n\nThe method should be recursive with no use of loops at all, So are all the auxiliary methods\nCan not contain loops.\nThe array is neither null nor empty.\nDo not modify the contents of the array (not even temporarily), and do not use an auxiliary array.\n\npublic static boolean equalSplit (int[] arr){\n    if(arr.length % 2 != 0) // if array length is not equal both sides\n        return false;\n    return equalSplit (arr, arr[0],(0 + arr.length-1) / 2 , arr.length-1);\n} \n\npublic static boolean equalSplit (int[] arr, int start, int mid, int end){\n       \n}\n\nI got stuck here and i have no clue what to do next.\n",
    "AcceptedAnswerId": 70583488,
    "AcceptedAnswer": "something like this should solve your problem and handle all cases.\n    public static boolean canBeDividedEqually(int[] arr) {\n        if (arr.length % 2 != 0) {\n            return false;\n        }\n        int sum = getSum(arr);\n        if (sum % 2 != 0) {\n            return false;\n        }\n        return canBeDividedEqually(arr, sum);\n\n    }\n\n    public static int getSum(int[] arr) {\n        return getSum(arr, 0, 0);\n    }\n\n    private static int getSum(int[] arr, int sum, int index) {\n        if (index >= arr.length) {\n            return sum;\n        }\n        return getSum(arr, sum + arr[index], index + 1);\n    }\n\n    private static boolean canBeDividedEqually(int[] arr, int sum) {\n        // this can be optimized by canBeDividedEqually(arr, sum/2, arr[0], arr.length/2, 1, 1) because first element should always belong to first group, so we can start search from second element\n        return canBeDividedEqually(arr, sum/2, 0, arr.length/2, 0, 0);\n//        return canBeDividedEqually(arr, sum/2, arr[0], arr.length/2, 1, 1);\n    }\n\n    private static boolean canBeDividedEqually (int[] arr, int searchSum, int currentSum, int searchQuantity, int currentQuantity, int nextIndex) {\n        if(searchSum == currentSum && searchQuantity == currentQuantity) {\n            return true;\n        }\n        if(searchSum <= currentSum || searchQuantity <= currentQuantity) {\n            // we have too big sum or we take to much elements\n            return false;\n        }\n        if(nextIndex + (searchQuantity - currentQuantity) > arr.length) {\n            // we need to take more elements than we have still available\n            return false;\n        }\n        // add current element into account and search further\n        if(canBeDividedEqually(arr, searchSum, currentSum + arr[nextIndex], searchQuantity, currentQuantity + 1, nextIndex + 1)) {\n            System.out.println(\"true\");\n            return true;\n        }\n        // if above \"if\" statement is not true, then skip current element and try to search further\n        return canBeDividedEqually(arr, searchSum, currentSum, searchQuantity, currentQuantity, nextIndex + 1);\n    }\n\n"
}
{
    "Id": 70595267,
    "PostTypeId": 1,
    "Title": "Why does this code use an oversized array instead of a Map?",
    "Body": "Here's JBoss JSTL implementation for the EscapeXML tag\npublic class EscapeXML {\n\n    private static final String[] ESCAPES;\n\n    static {\n        int size = '>' + 1; // '>' is the largest escaped value\n        ESCAPES = new String[size];\n        ESCAPES['<'] = \"&lt;\";\n        ESCAPES['>'] = \"&gt;\";\n        ESCAPES['&'] = \"&amp;\";\n        ESCAPES['\\''] = \"&#039;\";\n        ESCAPES['\"'] = \"&#034;\";\n    }\n  //omitted\n}\n\nWhy is ESCAPES a 61 elements array? What are the implication of using a Map instead?\n",
    "AcceptedAnswerId": 70638166,
    "AcceptedAnswer": "I think the main reason is performance. Each map query needs to get the hashcode, and then calculate the position of the array in the map, and the array can be obtained directly. The following is a simple test, querying 10,000 times separately, the array is about 10 times faster than the map.\narray query result: cost time= 184041\nmap query result: cost time= 1677042\n\nimport org.junit.Before;\nimport org.junit.Test;\n\nimport java.util.Arrays;\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.Random;\n\n/**\n * @author jahe\n * @date 2022/1/9\n * @note\n */\npublic class ArrayMapTest {\n    private char[] chars = {'', '&', '\\'', '\"'};\n    private char[] charsForQuery = new char[10000];\n    @Before\n    public void init(){\n        Random random = new Random(5);\n        random.nextInt(5);\n        for (int i = 0; i < charsForQuery.length; i++) {\n            charsForQuery[i] = chars[random.nextInt(5)];\n        }\n        System.out.println(Arrays.toString(charsForQuery));\n    }\n    @Test\n    public void test() {\n        int size = '>' + 1;\n        String[] ESCAPES = new String[size];\n        ESCAPES['<'] = \"&lt;\";\n        ESCAPES['>'] = \"&gt;\";\n        ESCAPES['&'] = \"&amp;\";\n        ESCAPES['\\''] = \"&#039;\";\n        ESCAPES['\"'] = \"&#034;\";\n        long start = System.nanoTime();\n        doTestForArray(ESCAPES);\n        long end = System.nanoTime();\n        System.out.println(\"array query result: cost time= \" + (end - start));\n\n        Map map = new HashMap();\n        map.put('<', \"&lt;\");\n        map.put('>', \"&gt;\");\n        map.put('&', \"&amp;\");\n        map.put('\\'', \"&#039;\");\n        map.put('\"', \"&#034;\");\n        start = System.nanoTime();\n        doTestForMap(map);\n        end = System.nanoTime();\n        System.out.println(\"map query result: cost time= \" + (end - start));\n\n    }\n    private void doTestForArray(String[] ESCAPES){\n        for (char c : charsForQuery) {\n            String str = ESCAPES[c];\n        }\n    }\n    private void doTestForMap(Map map){\n        for (char c : charsForQuery) {\n            String s = map.get(c);\n        }\n    }\n}\n\n"
}
{
    "Id": 70601178,
    "PostTypeId": 1,
    "Title": "Java Generics: What is the benefit of using wildcards here?",
    "Body": "The Collections.fill method has the following header:\npublic static  void fill(List list, T obj)\n\nWhy is the wildcard necessary? The following header seems to work just as well:\npublic static  void fill(List list, T obj)\n\nI cannot see a reason why the wildcard is needed; code such as the following works with the second header as well as the first:\nList nums = new ArrayList();\nInteger i = 43;\nfill(nums, i); //fill method written using second header\n\nMy question is: For what specific call of fill would the first header work but not the second? And if there is no such call, why include the wildcard? In this case, the wildcard does not make the method more concise nor add to readability (in my opinion).\n",
    "AcceptedAnswerId": 70627059,
    "AcceptedAnswer": "This is a really good question and the simple answer was guessed already:\n\nFor the current version of the fill(List list, T obj) there is no\nsuch input that would be rejected given the signature is changed to fill(List list, T obj), so there is no benefit and the devs are likely followed the PECS principle\n\nThe above statement derives from the principle that: if there is a such type X so that\nX is a supertype of T then List is a supertype of List because of type contravariance.\nSince we can always find such X (at the worst case it's the Object class) - the compiler can infer a suitable List argument type given either form of fill.\nSo, knowing that fact we can interfere with the compiler and infer the type ourselves using \"type witness\" so the code breaks:\nList target = new ArrayList();\n//Compiles OK as we can represent List as List and it fits\nCollections.fill(target, 1);\n\n//Compilation error as List is invariant to List and not a valid substitute\nCollections.fillNew(target, 1);\n\nThis is all of course purely theoretical and nobody in their right mind would use the type argument there.\nHOWEVER\nWhile answering the question \"What is the benefit of using wildcards here?\" we yet considered only one side of the equation - us, consumers of the method and our experience but not library developers.\nHence this question is somewhat similar to why Collections.enumeration(final Collection c) is declared the way it is and not enumeration(Collection c) as final seems superfluous for the end-user.\nWe can speculate here about the real intention, but I can give a few subjective reasons:\n\nFirst: using List (as well as final for enumeration) immediately disambiguates the code that tiny bit more and for the  specifically - it useful to show that only partial knowledge about the\ntype parameter is required and the list cannot be used to produce values of T, but only to consume them.\nQuote:\n\n\nWildcards are useful in situations where only partial knowledge about the type parameter is required.\nJLS 4.5.1. Type Arguments of Parameterized Types\n\n\nSecond: it gives some freedom to the library owners to improve/update the method without breaking backward compatibility while conforming to the existing constraints.\n\n\nNow let's try make up some hypothetical \"improvements\" to see what I mean (I'll call the form of fill that uses List as fillNew):\n#1 The decision is to make method to return the obj value (used to fill up the list) back:\npublic static  void fill(List list, T obj)\n//becomes \u2193\u2193\u2193\npublic static  T fill(List list, T obj)\n\nThe updated method would work just fine for fill signature, but for fillNew - the inferred return type now isn't that obvious:\nList target = new ArrayList();\nLong val = fill(target, 1L); //<<Here Long is the most specific type that fits both arguments\n//Compilation error\nLong val = fillNew(target, 1L); //<<Here Number is, so it cannot be assigned back\n\n//More exotic case:\nInteger val = fill(asList(true), 0); //val is Integer as expected\nComparable val = fillNew(asList(true), 0); //val is now Comparable as the most specific type \n\n#2 The decision to add an overloaded version of fill that is 10x more performant in cases when T is Comparable:\n/* Extremely performant 10x version */\npublic static > void fill(List list, T value)\n/* Normal version */\npublic static void fill(List list, T value)\n\nList target = new ArrayList();\nfill(target, 1);  //\nfillNew(target, 1); //<< Still uses the slow version just because T is inferred to Number which is not Comparable\n    \n\nTo sum up - the current signature of fill is more flexible/descriptive in my opinion for all parties (developers and library designers)\n"
}
{
    "Id": 70581530,
    "PostTypeId": 1,
    "Title": "Error creating bean with name 'securityConfig': Requested bean is currently in creation:",
    "Body": "package ro.contabilitateexpert.AccountExpert.config;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.security.authentication.AuthenticationManager;\nimport org.springframework.security.config.BeanIds;\nimport org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;\nimport org.springframework.security.config.annotation.web.builders.HttpSecurity;\nimport org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;\nimport org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;\nimport org.springframework.security.core.userdetails.UserDetailsService;\nimport org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;\nimport org.springframework.security.crypto.password.PasswordEncoder;\n\n@EnableWebSecurity\npublic class SecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Autowired\n    private UserDetailsService userDetailsService;\n\n    @Bean(BeanIds.AUTHENTICATION_MANAGER)\n    @Override\n    public AuthenticationManager authenticationManagerBean() throws Exception {\n        return super.authenticationManagerBean();\n    }\n\n    @Override\n    public void configure(HttpSecurity httpSecurity) throws Exception {\n        httpSecurity.csrf().disable().authorizeRequests()\n                .antMatchers(\"/api/auth/**\")\n                .permitAll()\n                .anyRequest()\n                .authenticated();\n    }\n\n    @Autowired\n    public void configureGlobal(AuthenticationManagerBuilder authenticationManagerBuilder) throws Exception {\n        authenticationManagerBuilder.userDetailsService(userDetailsService).passwordEncoder(passwordEncoder());\n    }\n\n    @Bean\n    PasswordEncoder passwordEncoder() {\n        return new BCryptPasswordEncoder();\n    }\n}\n\nI have the following error :\nError creating bean with name 'securityConfig': Requested bean is currently in creation: Is there an unresolvable circular reference?\nHow can i solve it?\n",
    "AcceptedAnswerId": 70595758,
    "AcceptedAnswer": "After i changed to configure instead of configureGlobal with @Overrides and deleted @Autowired\nAdded @Configuration\nNow the code is working,\nThanks to  Alexey Veleshko\n"
}
{
    "Id": 70681453,
    "PostTypeId": 1,
    "Title": "How to implement fixed points of functors in Java",
    "Body": "I recently discovered how to simulate higher order types in Java  in a somewhat roundabout way like so\ninterface H { }\n\nHere H encodes a higher order type that takes a type parameter F which itself takes parameter T.\nNow this leaves me to wonder, can we use this to implement some more advanced constructs? E.g. fixed point of functors\nlike Fix in Haskell and its corresponding catamorphisms?\n",
    "AcceptedAnswerId": 70681454,
    "AcceptedAnswer": "Indeed this can be done by carefully translating the corresponding Haskell counterparts. Although this introduces a lot of line noise,\nthe implementation is quite close to the original:\n\n// Encoding of higher kinded type F of T\npublic interface H { }\n\npublic interface Functor {\n     H map(Function f);\n}\n\n// newtype Fix f = Fix {unfix::f (Fix f)}\npublic static record Fix & Functor, T>(F f) {\n    public Functor> unfix() {\n        return (Functor>) f;\n    }\n}\n\n// type Algebra f a = f a -> a\npublic interface Algebra extends Function, T> {}\n\n // cata :: Functor f => Algebra f a -> Fix f -> a\n // cata alg = alg . fmap (cata alg) . unfix\npublic static  & Functor, T> Function, T> cata(Algebra alg) {\n    return fix -> alg.apply(fix.unfix().map(cata(alg)));\n}\n\nAmazingly this works and can be used to implement e.g. interpreters for expression algebras\n// evalExprF :: Algebra ExprF Int\n// evalExprF (Const n) = n\n// evalExprF (Add m n) = m + n\n// evalExprF (Mul m n) = m * n\npublic static class ExprAlg implements Algebra {\n    @Override\n    public Integer apply(H hExpr) {\n        return Expr.expr(hExpr).match(\n            conzt -> conzt.n,\n            add   -> add.t1 + add.t2,\n            mul   -> mul.t1 * mul.t2);\n    }\n}\n\nFull working example in my GitHub repository.\n"
}
{
    "Id": 70604058,
    "PostTypeId": 1,
    "Title": "ObjectMapper enable method is deprecated",
    "Body": "I'm upgrading the version of my project and I am currently using jackson-databind-2.13.0\n.But I noticed that ObjectMapper's enable method is deprecated.\nThey said to use it like this instead.\n@deprecated Since 2.13 use {@code JsonMapper.builder().enable(...)}\n\nBut I couldn't use it.\nBelow is my ObjectMapper instance creation code. how can I change?\n      @Bean(name = {\"objectMapper\"})\n      @Primary\n      ObjectMapper objectMapper() {\n        return newObjectMapper();\n      }\n\n  public static ObjectMapper newObjectMapper() {\n    ObjectMapper objectMapper =\n        new ObjectMapper()\n            .disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS)\n            .configure(SerializationFeature.FAIL_ON_EMPTY_BEANS, false)\n            .configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false)\n            .configure(DeserializationFeature.ACCEPT_SINGLE_VALUE_AS_ARRAY, true)\n            .setSerializationInclusion(JsonInclude.Include.NON_NULL)\n            .enable(MapperFeature.ACCEPT_CASE_INSENSITIVE_PROPERTIES);\nJavaTimeModule javaTimeModule = new JavaTimeModule();\njavaTimeModule.addSerializer(OffsetDateTime.class, new OffsetDateTimeSerializer());\njavaTimeModule.addDeserializer(OffsetDateTime.class, new OffsetDateTimeDeserializer());\njavaTimeModule.addSerializer(LocalDate.class, new LocalDateSerializer());\njavaTimeModule.addDeserializer(LocalDate.class, new LocalDateDeserializer());\nobjectMapper\n    .registerModule(javaTimeModule)\n    .configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false);\n\nreturn objectMapper;\n\n}\nSolution:\n    ObjectMapper objectMapper = JsonMapper\n    .builder()\n    .enable(MapperFeature.ACCEPT_CASE_INSENSITIVE_PROPERTIES)\n    .disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS)\n    .configure(SerializationFeature.FAIL_ON_EMPTY_BEANS, false)\n    .configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false)\n    .configure(DeserializationFeature.ACCEPT_SINGLE_VALUE_AS_ARRAY, true)\n    .serializationInclusion(Include.NON_NULL).build();\n\n",
    "AcceptedAnswerId": 70605226,
    "AcceptedAnswer": "I would suggest to rewrite your code to either\n\nRemove this bean and use a fully Spring Boot configured ObjectMapper (which has the name jacksonObjectMapper)\nUse the Jackson2ObjectMapperBuilder to create an instance of the ObjectMapper.\n\nAll of these solutions hide the intricate parts of constructing the ObjectMapper and will also put the burden of constructing it (properly) on the Spring Boot team, instead of you.\nNow for option 1 you would need to remove your @Bean and place the following in your application.properties.\nspring.jackson.serialization.FAIL_ON_EMPTY_BEANS=false\nspring.jackson.serialization.WRITE_DATES_AS_TIMESTAMPS=false\n\nspring.jackson.deserialization.FAIL_ON_UNKNOWN_PROPERTIES=false\nspring.jackson.deserialization.ACCEPT_SINGLE_VALUE_AS_ARRAY=true\n\nspring.jackson.mapper.ACCEPT_CASE_INSENSITIVE_PROPERTIES=true\n\nspring.jackson.defaultPropertyInclusion=NON_NULL\n\nWhen Spring (Boot) detects the JavaTime module on the classpath it will automatically be registered with the ObjectMapper, so no need to additionally add that (or the serializers for that matter).\nThese lines of configuration should you give the same configured ObjectMapper as your explicitly configured one. H\nFor the second option you can inject the Jackson2ObjectMapperBuilder into the method by using an argument, configure the things you want on there and call the build method in the end.\n@Bean(name = {\"objectMapper\"})\n@Primary\nObjectMapper objectMapper(Jackson2ObjectMapperBuilder builder) {\n    return newObjectMapper(builder);\n}\n\npublic static ObjectMapper newObjectMapper(Jackson2ObjectMapperBuilder builder) {\n   return builder\n            .serializationInclusion(NON_NULL)\n            .failOnEmptyBeans(false)\n            .failOnUnknownProperties(false)\n           .featuresToEnable(MapperFeature.ACCEPT_CASE_INSENSITIVE_PROPERTIES, DeserializationFeature.ACCEPT_SINGLE_VALUE_AS_ARRAY)\n           .featuresToDisable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS)\n.build();\n\nYou still don't need to register the JavaTime module as that is still being auto-detected for you.\nIn theory you could combine 1 and 2 but in your case that wouldn't add much, only some code to construct the ObjectMapper.\n@Bean(name = {\"objectMapper\"})\n@Primary\nObjectMapper objectMapper(Jackson2ObjectMapperBuilder builder) {\n    return newObjectMapper(builder);\n}\n\npublic static ObjectMapper newObjectMapper(Jackson2ObjectMapperBuilder builder) {\n   return builder.build();\n}\n\n"
}
{
    "Id": 70692260,
    "PostTypeId": 1,
    "Title": "cvc-elt.1.a: Cannot find the declaration of element 'project'",
    "Body": "error: cvc-elt.1.a: Cannot find the declaration of element 'project'\nI am getting this error constantly. Whenever I create a project using maven it starts displaying this error. I have even mentioned the 'maven-war-plugin' under plugin tag and then updated and refreshed the project as well.\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n  4.0.0\n  com.myfirstmvcapp\n  helloworldabc\n  war\n  0.0.1-SNAPSHOT\n  helloworldabc Maven Webapp\n  http://maven.apache.org\n  \n    \n      junit\n      junit\n      3.8.1\n      test\n    \n  \n  \n  \n  \n  org.apache.maven.plugins\n  maven-war-plugin\n  3.3.1\n  \n  \n    helloworldabc\n  \n\n\n",
    "AcceptedAnswerId": 70693979,
    "AcceptedAnswer": "I have Found the Solution to this problem, Thanks to @M.Deinum who commented the solution below the question.\nAll I did was add https to the link in the tag, instead of http.\nhere is the previous code:\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n  4.0.0\n  com.myfirstmvcapp\n  helloworldabc\n  war\n  0.0.1-SNAPSHOT\n  helloworldabc Maven Webapp\n  http://maven.apache.org\n  \n    \n      junit\n      junit\n      3.8.1\n      test\n    \n  \n  \n  \n  \n  org.apache.maven.plugins\n  maven-war-plugin\n  3.3.1\n  \n  \n    helloworldabc\n  \n\n\nHere is the lastest code, all that is needed is to add https instead of http to the xsd link in the last link of project tag.\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/maven-v4_0_0.xsd\">\n  4.0.0\n  com.myfirstmvcapp\n  helloworldabc\n  war\n  0.0.1-SNAPSHOT\n  helloworldabc Maven Webapp\n  http://maven.apache.org\n  \n    \n      junit\n      junit\n      3.8.1\n      test\n    \n  \n  \n  \n  \n  org.apache.maven.plugins\n  maven-war-plugin\n  3.3.1\n  \n  \n    helloworldabc\n  \n\n\n"
}
{
    "Id": 70568676,
    "PostTypeId": 1,
    "Title": "Arrange array so adjacent has less space that gives minimum sum",
    "Body": "I have an array of numbers with even size, here is my task:\na) Discard any 2 elements from the array.\nb) Then pair the elements and calculate the sum of differences between the elements in the pair such that the sum is minimum.\nExample:\narray size even say 8.\narray elements : 1,3,4,6,3,4,100,200\n\nAns:\n5\n\nExplanation:\n\nHere I will remove 100 and 200, as pairing them gives me a difference of (200 - 100) = 100.\nSo remaining elements are [1,3,4,6,3,4]\nPairs with minimum sum are : (1 3) , (4 3), (6 4).\n= |3-1| = 2, |4-3|=1,|6-4| = 2. So Sum = 2 + 1 + 2 = 5\n\nExample:\narray size even say 4.\narray elements : 1,50,51,60\n\nAns:\n1\n\nExplanation: Here I will remove 1 and 60 so I will get the minimum sum.\nSo the remaining elements are [50, 51], same as the adjacent   [50 51] = 1. My code will fail for this case and returns 49.\nHow to achieve this in java?\nI tried sorting the elements like this but this is not the correct approach for all kinds of inputs.\npublic static int process(int[] a) {\n   int n = a.length;\n   int n1 = n/2-1;\n   Arrays.sort(arr);\n   int sum = 0;\n   for(int i=0; i<n1*2; i+=2) {\n     sum += a[i+1] - a[i];\n   }\n   return sum;\n}\n\n",
    "AcceptedAnswerId": 70622902,
    "AcceptedAnswer": "In this kind of problem, the real issue is to find a good algorithm.\nthis post will insists on this aspect. A C++ code is provided at the end just to illustrate it.\nIt is clear we must begin by sorting the array.\nA solution consists in iteratively calculate three sums, where\nsum0 is the minimum sum assuming no element has been removed\nsum1 is the minimum sum assuming one element has been removed\nsum2 is the minimum sum assuming two elements has been removed\n\nDuring this process, the code must keep trace of the last element available to calculate a difference,\none for each sum (i_dispo0, i_dispo1, i_dispo2).\nPrinciples:\n- if sum1 > sum0: sum1 is replaced by sum0\n- if sum2 > sum1: sum2 is replaced by sum1\n\nComplexity: O(n logn)for sorting, O(n) for the optimization phase.\nCode:\nThe algorithm is illustrated by the following simple code in C++.\nIt should be easy to understand.\nOutput:\n5\n1\n2\n0\n2\n#include \n#include \n#include \n\nint min_sum_diff (std::vector& arr) {\n    int n = arr.size();\n    if (n%2) exit (1);\n    std::sort (arr.begin(), arr.end());\n    int sum0 = 0, sum1 = arr[n-1] - arr[0] + 1, sum2 = arr[n-1] - arr[0] + 1;\n    int i_dispo0 = -1, i_dispo1 = -1, i_dispo2 = -1;\n    for (int i = 0; i < n; ++i) {\n        int sum0_old = sum0;\n        int sum1_old = sum1;\n        if (i_dispo0 == -1) {\n            i_dispo0 = i;\n        } else {\n            sum0 += arr[i] - arr[i_dispo0];\n            i_dispo0 = -1;\n        }\n        if (i_dispo1 == -1) {\n            i_dispo1 = i;\n        } else {\n            int add = arr[i] - arr[i_dispo1];\n            if (sum0_old < sum1 + add) {\n                sum1 = sum0_old;\n                i_dispo1 = i;\n            } else {\n                sum1 += add;\n                i_dispo1 = -1;\n            }\n        }\n        if (i_dispo2 == -1) {\n            i_dispo2 = i;\n        } else {\n            sum2 += arr[i] - arr[i_dispo2];\n            i_dispo2 = -1;\n        }\n        \n        if (sum2 > sum1_old) {\n            sum2 = sum1_old;\n            i_dispo2 = i;\n        }\n        //std::cout << i << \" : \" << sum0 << \"  \" << sum1 << \"  \" << sum2 << '\\n';\n    }\n    return sum2;\n}\n\nint main() {\n    std::vector> examples = {\n        {1, 3, 4, 6, 3, 4, 100, 200},   // -> 5\n        {1, 50, 51, 60},                // -> 1\n        {1,2,100,200,400,401},          // -> 2\n        {1, 10, 10, 20, 30, 30},        // -> 0\n        {1, 10, 11, 20, 30, 31}         // -> 2\n    };\n    for (std::vector& arr: examples) {\n        int sum = min_sum_diff (arr);\n        std::cout << sum << '\\n';\n    }\n    return 0;\n}\n\n"
}
{
    "Id": 70654559,
    "PostTypeId": 1,
    "Title": "How to give certificate to Java Websocket?",
    "Body": "Forgive me for the newb question, but I am confused and obviously not understanding the fundamentals or explanations of how to use a Websocket server hosted over HTTPS. Everything I find online leads me to have more questions than answers.\nI have a Websocket server hosted on my HTTPS website using Java code.\nThis is my WebsocketServer.java file:\nimport org.java_websocket.WebSocket;\nimport org.java_websocket.handshake.ClientHandshake;\nimport org.java_websocket.server.WebSocketServer;\n\nimport java.net.InetSocketAddress;\nimport java.util.HashSet;\nimport java.util.Set;\n\nimport org.apache.logging.log4j.LogManager;\nimport org.apache.logging.log4j.Logger;\n\npublic class WebsocketServer extends WebSocketServer {\n\n    private static final Logger logger = LogManager.getLogger(WebsocketServer.class);\n\n    private static int TCP_PORT = 6868;\n\n    private static Set conns;\n\n    public WebsocketServer() {\n        super(new InetSocketAddress(TCP_PORT));\n        conns = new HashSet();\n    }\n\n    @Override\n    public void onOpen(WebSocket conn, ClientHandshake handshake) {\n        conns.add(conn);\n        logger.info(\"New connection from \" + conn.getRemoteSocketAddress().getAddress().getHostAddress());\n        logger.info(\"Size of connection list: \" + conns.size());\n    }\n\n    @Override\n    public void onClose(WebSocket conn, int code, String reason, boolean remote) {\n        conns.remove(conn);\n        logger.info(\"Closed connection to \" + conn.getRemoteSocketAddress().getAddress().getHostAddress());\n    }\n\n    @Override\n    public void onMessage(WebSocket conn, String message) {\n        logger.info(\"Message from client: {}\", message);\n        // for (WebSocket sock : conns) {\n        // sock.send(\"SENDING BACK\" + message);\n        // }\n    }\n\n    @Override\n    public void onError(WebSocket conn, Exception ex) {\n\n        // ex.printStackTrace();\n        try {\n            if (conn != null) {\n                conns.remove(conn);\n                // do some thing if required\n            }\n            logger.info(\"ERROR from {}\", conn.getRemoteSocketAddress().getAddress().getHostAddress());\n        } catch (Exception e) {\n            logger.info(\"onError: WebSocketServer may already be running\");\n\n        }\n\n    }\n\n    public Set getConns() {\n        return conns;\n    }\n\n}\n\n\nThen I started the WebsocketServer like this:\nWebsocketServer websocketServer;\n// Start socket server\nwebsocketServer = new WebsocketServer();\nwebsocketServer.start();\n\nAnd on the client side, I connect to it like this:\n    // APP_WEB_SOCKET is the url to my site: api.my_custom_domain.com\n    var connection = new WebSocket(\"wss://\" + APP_WEB_SOCKET + \":6868\");\n\nQUESTIONS:\nI keep reading that I need a certificate if I want to use wss over HTTPS, but cannot find any documents that explain what this means in a way that I can understand.\nMy app is hosted in AWS Elastic Beanstalk environment. Do I need to somehow add a certificate to the setup of the WebsocketServer in my Java code?\nExample:\nWebsocketServer websocketServer;\n// Start socket server\nwebsocketServer = new WebsocketServer();\n\n// example guessing\nwebsocketServer.cert = \"SOMETHING\";??\nwebsocketServer.start();\n\nDoes the client code need to be changed at all?\nWho needs the certificate?\nIf someone could please explain what I am missing or point me in the correct direction, I would really appreciate it.\n",
    "AcceptedAnswerId": 70698577,
    "AcceptedAnswer": "Keep it easy.\nCerts inside your application are complex - they are hard to manage and you will get problems to run your application in a modern cloud environment (start new environments, renew certs, scale your application, ...).\nSimple conclusion: Dont implement any certs.\nHow-to get encrypted connections?\nAs Mike already pointed out in the comments: WebSockets are just upgraded HTTP(S) connections. A normal webserver (nginx, apache) takes care about the certs. It can be done in kubernetes (as ingress-controller) or with a \"bare-metal\" webserver.\nBoth of them should act as a reverse-proxy. This means: Your java-application doesn't know anything about certs. It has just unencrypted connections - like in your code on port 6868.\nBut the client will not use this port. 6868 is only internally reachable.\nThe client will call your reverse-proxy at the normal HTTPS port (=443). The reverse-proxy will forward the connection to your java-application.\nHere some links for further information:\n\nnginx reverse-proxy\nnginx reverse-proxy for websocket\ntutorial for java behind reverse-proxy\nLetsEncrypt for automatic and free certs\n\n"
}
{
    "Id": 70695039,
    "PostTypeId": 1,
    "Title": "org.h2.jdbc.JdbcSQLSyntaxErrorException after H2 version upgrade",
    "Body": "I recently upgraded h2 version from 1.4.200 to 2.0.206. Some of the queries that used to work in the older version are not working properly after the upgrade.\nCREATE TABLE SOMETABLE (\n  ID INT(11) NOT NULL AUTO_INCREMENT,\n  SOURCE_ID VARCHAR(255) NOT NULL,\n  MESSAGE VARCHAR(255) NOT NULL,\n  PRIMARY KEY (`ID`)\n);\n\nCREATE TABLE IF NOT EXISTS SOMEOTHERTABLE (\n    ID VARCHAR(255) NOT NULL,\n    NAME VARCHAR(255) NOT NULL,\n    CREATED_TIME TIMESTAMP NOT NULL,\n    LAST_MODIFIED TIMESTAMP NOT NULL,\n    HAS_FILE BOOLEAN(1) NOT NULL,\n    PRIMARY KEY (ID)\n);\n\nFor both these, I get similar errors\norg.h2.jdbc.JdbcSQLSyntaxErrorException: Syntax error in SQL statement \"  CREATE TABLE SOMETABLE ( ID INT([*]11) NOT NULL AUTO_INCREMENT, SOURCE_ID VARCHAR(255) NOT NULL, MESSAGE VARCHAR(255) NOT NULL, PRIMARY KEY (`ID`) )\"; expected \"ARRAY, INVISIBLE, VISIBLE, NOT, NULL, AS, DEFAULT, GENERATED, ON, NOT, NULL, AUTO_INCREMENT, DEFAULT, NULL_TO_DEFAULT, SEQUENCE, SELECTIVITY, COMMENT, CONSTRAINT, COMMENT, PRIMARY, UNIQUE, NOT, NULL, CHECK, REFERENCES, AUTO_INCREMENT, ., )\";\n\norg.h2.jdbc.JdbcSQLSyntaxErrorException: Syntax error in SQL statement \"  CREATE TABLE IF NOT EXISTS SOMEOTHERTABLE ( ID VARCHAR(255) NOT NULL, NAME VARCHAR(255) NOT NULL, CREATED_TIME TIMESTAMP NOT NULL, LAST_MODIFIED TIMESTAMP NOT NULL, HAS_FILE BOOLEAN([*]1) NOT NULL, PRIMARY KEY (ID) )\"; expected \"ARRAY, INVISIBLE, VISIBLE, NOT, NULL, AS, DEFAULT, GENERATED, ON, NOT, NULL, AUTO_INCREMENT, DEFAULT, NULL_TO_DEFAULT, SEQUENCE, SELECTIVITY, COMMENT, CONSTRAINT, COMMENT, PRIMARY, UNIQUE, NOT, NULL, CHECK, REFERENCES, AUTO_INCREMENT, ., )\";\n\nIt seems that in both these cases, having INT(11) and BOOLEAN(1) is the issue. Are those not allowed anymore in the new version? If so, how should I change those? Any help regarding this is appreciated.\n",
    "AcceptedAnswerId": 70696184,
    "AcceptedAnswer": "Why do you have such definitions? Documentation of H2 1.4.200 doesn't allow any parameters for these data types.\nINT(11) is allowed only in MySQL and MariaDB compatibility modes, but the specified precision is ignored by H2. This definition is rejected in all other compatibility modes in H2 2.0, you need to use INT or INTEGER.\nBOOLEAN(1) is not allowed at all, if it worked in 1.4.200, it was a bug in the parser. You need to use BOOLEAN.\nAUTO_INCREMENT clause also should normally be used only in MySQL and MariaDB compatibility modes, but it works in Regular mode too. The proper clause is GENERATED BY DEFAULT AS IDENTITY and explicit NOT NULL constraint isn't required for primary key and identity columns, you can remove it. Constraints also should normally be specified after all other clauses, NOT NULL before identity options is actually accepted by H2, but this wrong order of clauses isn't documented and isn't supported.\n"
}
{
    "Id": 70570084,
    "PostTypeId": 1,
    "Title": "Code reuse: returning lists of enum fields with common getter methods",
    "Body": "I have two enums:\nMain Menu Options\npublic enum MainMenuOptions {\n    \n    EXIT(\"Exit\"),\n    VIEW_RESERVATIONS(\"View Reservations By Host\"),\n    CREATE_RESERVATION(\"Create A Reservation\"),\n    EDIT_RESERVATION(\"Edit A Reservation\"),\n    CANCEL_RESERVATION(\"Cancel A Reservation\");\n    \n    private final String message;\n    \n    MainMenuOptions(String message) {\n        this.message = message;\n    }\n    \n    public String getMessage() {\n        return message;\n    }\n    \n    public static List asListString() {\n        return Arrays.stream(MainMenuOptions.values())\n                .map(MainMenuOptions::getMessage)\n                .collect(Collectors.toList());\n    }\n}\n\nHost Selection Method Options\npublic enum HostSelectionMethodOptions {\n    \n    FIND_ALL(\"Find all\"),\n    FIND_BY_LASTNAME_PREFIX(\"Find by last name prefix\"),\n    FIND_BY_CITY_STATE(\"Find by city & state\");\n    \n    String message;\n    \n    HostSelectionMethod(String message) {\n        this.message = message;\n    }\n    \n    public String getMessage() {\n        return message;\n    }\n    \n    public static List asListString() {\n        return Arrays.stream(HostSelectionMethod.values())\n                .map(HostSelectionMethod::getMessage)\n                .collect(Collectors.toList());\n    }\n}\n\nBoth enums share the same field\nprivate final String message;\n\nThe same getter\npublic String getMessage() {\n    return message;\n}\n\nAnd the same asListString() method\npublic static List asListString() {\n    return Arrays.stream(MainMenuOptions.values())\n            .map(MainMenuOptions::getMessage)\n            .collect(Collectors.toList());\n}\n\nHow can I DRY out these enums?\nI expect to have more enums with the same fields and methods, and it seems silly to write out the same thing over and over again for each one.\n\nI tried making both of the enums extend a superclass, but enums cannot have extends clauses\nI can create an interface that specifies the contract for the asListString() method, but that doesn't allow me to actually reuse any code.\n\nThe flavor I was hoping the code could have is something like this:\npublic class Utils {\n    \n    public static List enumAsListString(Enum e) {\n        return e.values().stream.map(e::getMessage).collect(Collectors.toList());\n    }\n}\n\n",
    "AcceptedAnswerId": 70570794,
    "AcceptedAnswer": "This is probably one of the cases where you need to pick one between being DRY and using enums.\nEnums don't go very far as far as code reuse is concerned, in Java at least; and the main reason for this is that primary benefits of using enums are reaped in static code - I mean static as in \"not dynamic\"/\"runtime\", rather than static :). Although you can \"reduce\" code duplication, you can hardly do much of that without introducing dependency (yes, that applies to adding a common API/interface, extracting the implementation of asListString to a utility class). And that's still an undesirable trade-off.\nFurthermore, if you must use an enum (for such reasons as built-in support for serialization, database mapping, JSON binding, or, well, because it's data enumeration, etc.), you have no choice but to duplicate method declarations to an extent, even if you can share the implementation: static methods just can't be inherited, and interface methods (of which getMessage would be one) shall need an implementation everywhere. I mean this way of being \"DRY\" will have many ways of being inelegant.\nIf I were you, I would simply make this data completely dynamic\nfinal class MenuOption {\n    private final String category; //MAIN_MENU, HOT_SELECTION\n    private final String message; //Exit, View Reservation By Host, etc.\n    public static MenuOption of(String key, String message) {\n        return new MenuOption(key, message);\n    }\n}\n\nThis is very scalable, although it introduces the need to validate data where enums would statically prevent bad options, and possibly custom code where an enum would offer built-in support.\nIt can be improved with a \"category\" enum, which gives static access to menu lists, and a single place for asListString():\nenum MenuCategory {\n    MAIN_MENU(\n        MenuOption.of(\"Exit\"), \n        MenuOption.of(\"View Reservations By Host\")\n    ),\n    HOT_SELECTION(\n        MenuOption.of(\"Find All\")\n    );\n    \n    private final List menuOptions;\n    \n    MenuCategory(MenuOption... options) {\n        this.menuOptions = List.of(options); //unmodifiable\n    }\n    \n    public ListasListString() {\n        return this.menuOptions.stream()\n                   .map(MenuOption::getMessage)\n                   .collect(Collectors.toList());\n    }\n}\n\nIt should be clear that you can replace class MenuOption with a bunch of enums implementing a common interface, which should change little to nothing in MenuCategory. I wouldn't do that, but it's an option.\n"
}
{
    "Id": 70686277,
    "PostTypeId": 1,
    "Title": "ERROR No qualifying bean of type 'org.springframework.security.oauth2.jwt.JwtDecoder' available",
    "Body": "I am trying to write a test for my controller but the test environment fails to load with the given stackTrace.\n    @PreAuthorize(\"hasAuthority('my.scope')\")\n    @GetMapping(value = \"/path\", produces = APPLICATION_JSON_VALUE)\n    public ResponseEntity>> getPath() {\n        return myService.pathFunction()\n            .map(ResponseEntity::ok);\n    }\n\nand following is how I've configured my security config\n@Configuration\n@EnableWebSecurity\n@EnableGlobalMethodSecurity(securedEnabled = true, prePostEnabled = true)\npublic class WebConfig extends WebSecurityConfigurerAdapter {\n\n    private static final String PRINCIPAL = \"sub\";\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n\n        JwtAuthenticationConverter authenticationConverter =\n            new JwtAuthenticationConverter();\n        authenticationConverter.setJwtGrantedAuthoritiesConverter(...);\n        authenticationConverter.setPrincipalClaimName(PRINCIPAL);\n\n        http.csrf().disable()\n            .cors()\n            .and()\n            .authorizeRequests().antMatchers(\"/actuator/**\").permitAll()\n            .anyRequest().authenticated()\n            .and()\n            .oauth2ResourceServer()\n            .jwt()\n            .jwtAuthenticationConverter(authenticationConverter);\n    }\n}\n\nThe controller is working as needed but my test fails with this error. I am not using any customer JwtDecoder\n@WebMvcTest(controllers = Controller.class)\nclass ControllerTest {\n\n    @MockBean\n    private MyService myService;\n\n    @Autowired\n    private MockMvc mockMvc;\n\n    @Test\n    @WithMockUser(authorities = {\"my.scope\"})\n    void controllerTest() throws Exception{\n        Map> mapResponse = Map.of(\"key\", Set.of(\"foo1\", \"foo2\"));\n        Mockito.when(myService.pathFunction()).thenReturn(Optional.of(mapResponse));\n\n        MockHttpServletResponse result = mockMvc.perform(get(\"/configuration/api-registry\")\n                .contentType(MediaType.APPLICATION_JSON))\n            .andExpect(status().isOk())\n            .andReturn()\n            .getResponse();\n\n        String response = result.getContentAsString();\n        assertTrue(response.contains(\"foo1\"));\n    }\n\n}\n\nHow do I run this test ?\njava.lang.IllegalStateException: Failed to load ApplicationContext\n\nCaused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'springSecurityFilterChain' defined in class path resource [org/springframework/security/config/annotation/web/configuration/WebSecurityConfiguration.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [javax.servlet.Filter]: Factory method 'springSecurityFilterChain' threw exception; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'org.springframework.security.oauth2.jwt.JwtDecoder' available\n    ...\nCaused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [javax.servlet.Filter]: Factory method 'springSecurityFilterChain' threw exception; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'org.springframework.security.oauth2.jwt.JwtDecoder' available\n    at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:185)\n    at org.springframework.beans.factory.support.ConstructorResolver.instantiate(ConstructorResolver.java:653)\n    ... 90 more\nCaused by: org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'org.springframework.security.oauth2.jwt.JwtDecoder' available\n    at ...\n\n",
    "AcceptedAnswerId": 70694659,
    "AcceptedAnswer": "I added mocking the decoder in the test as\n@MockBean\nprivate JwtDecoder jwtDecoder;\n\nand the test ran !\n"
}
{
    "Id": 70702544,
    "PostTypeId": 1,
    "Title": "Why do I get an ambiguity error in this code?",
    "Body": "Let's say we have these 3 classes:\nclass A { }\nclass B extends A { }\n\npublic class App {\n    static void f(int i, A a) { }\n    static void f(float j, B b) { }\n   \n    static public void main() {\n        int i = 0;\n        B b = new B();\n        App.f(i, b);\n    }\n}\n\nThis produces the error:\nApp.java:11: error: reference to f is ambiguous\n        App.f(i, b);\n           ^\n  both method f(int,A) in App and method f(float,B) in App match\n1 error\n\nWhy does it not choose the type f(int, A) since i is an integer?\n",
    "AcceptedAnswerId": 70702914,
    "AcceptedAnswer": "It is ambiguous because of two reasons:\n\nboth overloads are applicable, and;\nneither overload is more specific than the other\n\nNotice that both the f(int, A) overload and the f(float, B) overload can be called with the parameters (i, b), since there is an implicit conversion from int to float, and an implicit conversion from B to A.\nWhat happens when there are more than one applicable method? Java is supposed to choose the most specific method. This is described in \u00a715.12.2.5 of the language spec. It turns out that it is not the case that one of these overloads are more specific than the other.\n\nOne applicable method m1 is more specific than another applicable\nmethod m2, for an invocation with argument expressions e1, ..., ek, if\nany of the following are true:\n\nm2 is generic [...]\n\nm2 is not generic, and m1 and m2 are applicable by strict or loose invocation, and where m1 has formal parameter types S1, ..., Sn and m2\nhas formal parameter types T1, ..., Tn, the type Si is more specific\nthan Ti for argument ei for all i (1 \u2264 i \u2264 n, n = k).\n\nm2 is not generic, and m1 and m2 are applicable by variable arity invocation [...]\n\n\n\nOnly the second point applies to the two overloads of f. For one of the overloads to be more specific than the other, every parameter type of one overload has to be more specific than the corresponding parameter type in the other overload.\n\nA type S is more specific than a type T for any expression if S \u00a74.10).\n\nNote that\"B is clearly a subtype of A. float is actually a supertype (not subtype!) of int. This can be derived from the direct subtyping relations listed in \u00a74.10.1. Therefore, neither of the overloads is more specific than the other.\nThe language spec goes on to talk about maximally specific methods, which doesn't really apply to f here. Finally, it says:\n\nOtherwise, the method invocation is ambiguous, and a compile-time error occurs.\n\nMore Examples\nstatic void f(int x) {}\nstatic void f(float x) {}\n\nwhen called with an int are not ambiguous because the int overload is more specific.\nstatic void f(int x, B a) {}\nstatic void f(float x, A a) {}\n\nwhen called with argument types (int, A) are not ambiguous because the (int, B) overload is more specific.\nstatic void f(int x, A a) {}\nstatic void f(float x, A a) {}\n\nwhen called with argument types(int, A) are not ambiguous because the (int, A) overload is more specific. Note that the subtyping relationship is reflexive (i.e. A is a subtype of A).\n"
}
{
    "Id": 70860253,
    "PostTypeId": 1,
    "Title": "Java map function throws non-static method compiler error",
    "Body": "I have an odd problem, where I am struggling to understand the nature of \"static context\" in Java, despite the numerous SO questions regarding the topic.\nTL;DR:\nI have a design flaw, where ...\nThis works:\nList list = orderType.getOrderExtnTransList();\nthis.dtoOrderExtnTransList = list.stream().map(OrderExtnTrans::toDto).collect(Collectors.toList());\n\nBut this does not:\nthis.dtoOrderExtnTransList = orderType.getOrderExtnTransList().stream().map(OrderExtnTrans::toDto).collect(Collectors.toList());\n\n\nThe error shown in the second version is \"Non-static method cannot be referenced from a static context\".\nThe long version:\nObject Model:\nThe model consists of Business Type specific orders (eg. Stock exchange, payments), which inherit from a an order entity via an \"InheritanceType.JOINED\" inheritance strategy.\nThe parent order can be parameterized with the business type specific DTO object of that order, so for example DtoStockExchangeOrder. This is to enable, that JPA objects can be mapped to their DTO equivalent within the Entity, rather than in a service (which I did previously. It worked, but its \"less clean\").\nJPA Order:\n@Entity\n@Table(name = \"ORDER_BASE\")\n@Inheritance(strategy = InheritanceType.JOINED)\npublic class Order implements Serializable {\n\n    @OneToMany(fetch = FetchType.LAZY, mappedBy = \"order\", orphanRemoval = true)\n    private List orderExtnTransList = new ArrayList();\n\n}\n\nJPA Order - Business Type specific example:\n@Entity\n@Table(name = \"ORDER_STEX\")\n@Inheritance(strategy = InheritanceType.JOINED)\npublic class OrderStex extends Order implements Serializable {\n\nLikewise, DTO orders follow the same pattern, where they can be parameterized with the business type specific JPA entity, to enable the relevant mapping:\nDTO Order:\npublic class DtoOrder extends DtoEntity {\n\nDTO Order - Business Type Specific Example\npublic class DtoOrderStex extends DtoOrder {\n\nThe DTOEntity class it inherits from is just a \"wrapper\" class, consisting of an ID and a name.\nNow the tricky part:\nThe DTOOrder class has a constructor which populates the fields that are common to all business types, like the list of process status transitions, an order goes through in its life cycle (placed, cancelled, executed, etc..). Staying with the example of the process status transitions, these are also modelled as JPA entities in the database, with their corresponding DTO counterparts (likewise parameterized, that part works fine).\nHere the constructor:\npublic DtoOrder(OrderType orderType) {\n    super(orderType);\n    // this is the part from above, which works (but it shows a warning: Unchecked assignment: 'java.util.List' to 'java.util.List' )\n    List list = orderType.getOrderExtnTransList();\n    this.dtoOrderExtnTransList = list.stream().map(OrderExtnTrans::toDto).collect(Collectors.toList());\n    // this is how I would have expected it to work, but it does not, with the error shown above: \"Non-static method cannot be referenced from a static context\"\n    this.dtoOrderExtnTransList = orderType.getOrderExtnTransList().stream().map(OrderExtnTrans::toDto).collect(Collectors.toList());\n}\n\nIf I comment out the non-working version, the application behaves as expected and throws no error, so \"logically\", this works. But JAVA does not allow it as developed in the second version.\nIf instead of OrderType I use \"Order\", it works as well, but obviously throws errors elsewhere, because the signature of the constructor changed. I assume another approach would be to parameterise the method based on the the caller of the constructor or to parameterise the parent class DtoOrder to know the type of the child class, but there should be a better way?\nWhat am I doing wrong, and why does the upper version work as expected?\n",
    "AcceptedAnswerId": 70873247,
    "AcceptedAnswer": "Thanks for an interesting question, that shows some unexpected behaviour, that is behaving according to spec.\nTL;DR (ie, the correct way of quickly and easily fixing this) is to add the  generic wildcard to Order in the DtoOrder class declaration, so :\npublic class DtoOrder> extends DtoEntity {\n\nThis will make the all-in-one-line way in the constructor work \u200b:\n\u200bthis.dtoOrderExtnTransList = orderType.getOrderExtnTransList().stream().map(OrderExtnTrans::toDto).collect(Collectors.toList());\n\nAs for why this is the fix, this is because you have defined Order as a Generic type :\npublic class Order \n\nBy NOT specifying the generic type, you are declaring it (and therefore making OrderType as well) as a raw-type.\nGenerally we are used to List being generic, that at run-time undergoes type-erasure.  Further, that if we have old code like :\nList myRawTypeVariable = new ArrayList();\n\nthat myRawType is a raw type, in that we can add any Object and only get Objects out.\nHowever, it turns out that (as you have discovered) raw types go further than that, and type-erasure has compile-time implications as well.\nThe Java Language Specification (JLS) says this (source : https://docs.oracle.com/javase/specs/jls/se8/html/jls-4.html#jls-4.8 )\n\nThe type of a constructor (\u00a78.8), instance method (\u00a78.4, \u00a79.4), or\nnon-static field (\u00a78.3) of a raw type C that is not inherited from its\nsuperclasses or superinterfaces is the raw type that corresponds to\nthe erasure of its type in the generic declaration corresponding to C.\n\nNote that this is NOT limiting type erasure to ONLY those of the generic type;  The types of ALL instance methods get taken to their raw types !\nIn other words, by not specifying the generic type of Order, you are making Order a raw type - and therefore turning off all Generic type-checking for that class (except for methods, etc otherwise specified, from inheritance or interfaces).\nSo even though getOrderExtnTransList() is declared as returning a List, because you are using Order as a raw-type, it's dropping the  generic and treating that method as simply returning a List (effectively a List ).\nYou can confirm this by trying to insert a peek, so :\n   \u200bthis.dtoOrderExtnTransList = orderType.getOrderExtnTransList().stream().peek(s -> s.\n\nthen try to do an auto-complete.   You'll find that the options are only the members for Object, not the endsWith, etc members for String.\nThis, in turn, means that when it hits .map(OrderExtnTrans::toDto), instead of interpreting this for a OrderExtnTrans coming down the stream :\n `.map(o -> o.toDto())`, \n\nit thinks you mean\n  `.map(o -> OrderExtnTrans.toDto(o))` \n\nwhich is what is appropriate for an Object coming down the stream - and that is why it complains about toDto being a non-static method.\nAs stated, the solution is to simply not treat Order as a raw-type, instead to make it generic by adding the  as above.\n"
}
{
    "Id": 70667172,
    "PostTypeId": 1,
    "Title": "PortUnreachableExceptions spamming log after updating Spring Boot Parent",
    "Body": "After upgrading from spring-boot-parent version 2.5.5 to 2.6.0, I started seeing these error messages spamming the logs:\n[INFO] [stdout] 2022-01-11 13:40:01.157  WARN 76859 --- [    udp-epoll-2] i.m.s.reactor.netty.channel.FluxReceive  : [6d1243de, L:/127.0.0.1:58160 - R:localhost/127.0.0.1:8125] An exception has been observed post termination, use DEBUG level to see the full stack: java.net.PortUnreachableException: readAddress(..) failed: Connection refused\nUsing DEBUG level:\n[INFO] [stdout] 2022-01-11 13:38:29.733  WARN 76479 --- [    udp-epoll-2] i.m.s.reactor.netty.channel.FluxReceive  : [43aad7ce, L:/127.0.0.1:38108 - R:localhost/127.0.0.1:8125] An exception has been observed post termination\n[INFO] [stdout] \n[INFO] [stdout] java.net.PortUnreachableException: readAddress(..) failed: Connection refused\n[INFO] [stdout]     at io.micrometer.shaded.io.netty.channel.epoll.EpollDatagramChannel.translateForConnected(EpollDatagramChannel.java:575)\n[INFO] [stdout]     at io.micrometer.shaded.io.netty.channel.epoll.EpollDatagramChannel.access$400(EpollDatagramChannel.java:56)\n[INFO] [stdout]     at io.micrometer.shaded.io.netty.channel.epoll.EpollDatagramChannel$EpollDatagramChannelUnsafe.epollInReady(EpollDatagramChannel.java:503)\n[INFO] [stdout]     at io.micrometer.shaded.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:480)\n[INFO] [stdout]     at io.micrometer.shaded.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:378)\n[INFO] [stdout]     at io.micrometer.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n[INFO] [stdout]     at io.micrometer.shaded.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n[INFO] [stdout]     at io.micrometer.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n[INFO] [stdout]     at java.base/java.lang.Thread.run(Thread.java:833)\n[INFO] [stdout] Caused by: io.micrometer.shaded.io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection refused\n\nI can't find much about it in the release notes, except for a dependency upgrade that seems relevant:\n\nUpgrade to Micrometer 1.8.0 #28516\n\nBut the linked issue is not informative. Neither were Micronaut's own release notes for version 1.8.0 (except for the JVM crash notice, which we did run into - a surprising and rather unfortunate side-effect of upgrading Spring Boot, but I digress)\nWe don't (consciously) use Micrometer, so I tried disabling it in the application.yml file (micrometer.enabled: false and instrumentation.micrometer.enabled: false), but to no avail.\nDespite lots of googling (for various permutations of elements of the error message and digging through code on GitHub), I haven't been able to find how to fix this message, let alone figure out what causes it.\nNow I could of course suppress this message in the logging configuration, but I'd like to know what it's actually trying to achieve here, and whether it is useful for our application. And if not, disable it completely.\n",
    "AcceptedAnswerId": 70700918,
    "AcceptedAnswer": "assuming statsd is not used and configured on your side, since it's pointed to localhost, you may disable it by setting\nmanagement.metrics.export.statsd.enabled\n\nto false\n"
}
{
    "Id": 70709971,
    "PostTypeId": 1,
    "Title": "What is 'serviceability memory category' of Native Memory Tracking?",
    "Body": "I have an java app (JDK13) running in a docker container. Recently I moved the app to JDK17 (OpenJDK17) and found a gradual increase of memory usage by docker container.\nDuring investigation I found that the 'serviceability memory category' NMT grows constantly (15mb per an hour). I checked the page https://docs.oracle.com/en/java/javase/17/troubleshoot/diagnostic-tools.html#GUID-5EF7BB07-C903-4EBD-A9C2-EC0E44048D37 but this category is not mentioned there.\nCould anyone explain what this serviceability category means and what can cause such gradual increase?\nAlso there are some additional new memory categories comparing to JDK13. Maybe someone knows where I can read details about them.\nHere is the result of command jcmd 1 VM.native_memory summary\nNative Memory Tracking:\n\n(Omitting categories weighting less than 1KB)\n\nTotal: reserved=4431401KB, committed=1191617KB\n-                 Java Heap (reserved=2097152KB, committed=479232KB)\n                            (mmap: reserved=2097152KB, committed=479232KB) \n \n-                     Class (reserved=1052227KB, committed=22403KB)\n                            (classes #29547)\n                            (  instance classes #27790, array classes #1757)\n                            (malloc=3651KB #79345) \n                            (mmap: reserved=1048576KB, committed=18752KB) \n                            (  Metadata:   )\n                            (    reserved=139264KB, committed=130816KB)\n                            (    used=130309KB)\n                            (    waste=507KB =0.39%)\n                            (  Class space:)\n                            (    reserved=1048576KB, committed=18752KB)\n                            (    used=18149KB)\n                            (    waste=603KB =3.21%)\n \n-                    Thread (reserved=387638KB, committed=40694KB)\n                            (thread #378)\n                            (stack: reserved=386548KB, committed=39604KB)\n                            (malloc=650KB #2271) \n                            (arena=440KB #752)\n \n-                      Code (reserved=253202KB, committed=76734KB)\n                            (malloc=5518KB #23715) \n                            (mmap: reserved=247684KB, committed=71216KB) \n \n-                        GC (reserved=152419KB, committed=92391KB)\n                            (malloc=40783KB #34817) \n                            (mmap: reserved=111636KB, committed=51608KB) \n \n-                  Compiler (reserved=1506KB, committed=1506KB)\n                            (malloc=1342KB #2557) \n                            (arena=165KB #5)\n \n-                  Internal (reserved=5579KB, committed=5579KB)\n                            (malloc=5543KB #33822) \n                            (mmap: reserved=36KB, committed=36KB) \n \n-                     Other (reserved=231161KB, committed=231161KB)\n                            (malloc=231161KB #347) \n \n-                    Symbol (reserved=30558KB, committed=30558KB)\n                            (malloc=28887KB #769230) \n                            (arena=1670KB #1)\n \n-    Native Memory Tracking (reserved=16412KB, committed=16412KB)\n                            (malloc=575KB #8281) \n                            (tracking overhead=15837KB)\n \n-        Shared class space (reserved=12288KB, committed=12136KB)\n                            (mmap: reserved=12288KB, committed=12136KB) \n \n-               Arena Chunk (reserved=18743KB, committed=18743KB)\n                            (malloc=18743KB) \n \n-                   Tracing (reserved=32KB, committed=32KB)\n                            (arena=32KB #1)\n \n-                   Logging (reserved=7KB, committed=7KB)\n                            (malloc=7KB #289) \n \n-                 Arguments (reserved=1KB, committed=1KB)\n                            (malloc=1KB #53) \n \n-                    Module (reserved=1045KB, committed=1045KB)\n                            (malloc=1045KB #5026) \n \n-                 Safepoint (reserved=8KB, committed=8KB)\n                            (mmap: reserved=8KB, committed=8KB) \n \n-           Synchronization (reserved=204KB, committed=204KB)\n                            (malloc=204KB #2026) \n \n-            Serviceability (reserved=31187KB, committed=31187KB)\n                            (malloc=31187KB #49714) \n \n-                 Metaspace (reserved=140032KB, committed=131584KB)\n                            (malloc=768KB #622) \n                            (mmap: reserved=139264KB, committed=130816KB) \n \n-      String Deduplication (reserved=1KB, committed=1KB)\n                            (malloc=1KB #8) \n\nThe detailed information about increasing part of memory is:\n[0x00007f6ccb970cbe] OopStorage::try_add_block()+0x2e\n[0x00007f6ccb97132d] OopStorage::allocate()+0x3d\n[0x00007f6ccbb34ee8] StackFrameInfo::StackFrameInfo(javaVFrame*, bool)+0x68\n[0x00007f6ccbb35a64] ThreadStackTrace::dump_stack_at_safepoint(int)+0xe4\n                             (malloc=6755KB type=Serviceability #10944)\n\nUpdate#1 from 2022-01-17:\nThanks to @Aleksey Shipilev for help! We were able to find a place which causes the issue, is related to many ThreadMXBean#.dumpAllThreads calls. Here is MCVE, Test.java:\nRun with:\njava -Xmx512M -XX:NativeMemoryTracking=detail Test.java \n\nand check periodically serviceability category in result of\njcmd YOUR_PID VM.native_memory summary \n\nTest java:\nimport java.lang.management.ManagementFactory;\nimport java.lang.management.ThreadInfo;\nimport java.lang.management.ThreadMXBean;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.TimeUnit;\n\npublic class Test {\n\n    private static final int RUNNING = 40;\n    private static final int WAITING = 460;\n\n    private final Object monitor = new Object();\n    private final ThreadMXBean threadMxBean = ManagementFactory.getThreadMXBean();\n    private final ExecutorService executorService = Executors.newFixedThreadPool(RUNNING + WAITING);\n\n    void startRunningThread() {\n        executorService.submit(() -> {\n            while (true) {\n            }\n        });\n    }\n\n    void startWaitingThread() {\n        executorService.submit(() -> {\n            try {\n                monitor.wait();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        });\n    }\n\n    void startThreads() {\n        for (int i = 0; i < RUNNING; i++) {\n            startRunningThread();\n        }\n\n        for (int i = 0; i < WAITING; i++) {\n            startWaitingThread();\n        }\n    }\n\n    void shutdown() {\n        executorService.shutdown();\n        try {\n            executorService.awaitTermination(5, TimeUnit.SECONDS);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n\n    \n    public static void main(String[] args) throws InterruptedException {\n        Test test = new Test();\n\n        Runtime.getRuntime().addShutdownHook(new Thread(test::shutdown));\n\n        test.startThreads();\n\n        for (int i = 0; i < 12000; i++) {\n            ThreadInfo[] threadInfos = test.threadMxBean.dumpAllThreads(false, false);\n            System.out.println(\"ThreadInfos: \" + threadInfos.length);\n\n            Thread.sleep(100);\n        }\n\n        test.shutdown();\n    }\n}\n\n",
    "AcceptedAnswerId": 70713288,
    "AcceptedAnswer": "Unfortunately (?), the easiest way to know for sure what those categories map to is to look at OpenJDK source code. The NMT tag you are looking for is mtServiceability. This would show that \"serviceability\" are basically diagnostic interfaces in JDK/JVM: JVMTI, heap dumps, etc.\nBut the same kind of thing is clear from observing that stack trace sample you are showing mentions ThreadStackTrace::dump_stack_at_safepoint -- that is something that dumps the thread information, for example for jstack, heap dump, etc. If you have a suspicion for the memory leak in that code, you might try to build a MCVE demonstrating it, and submitting the bug against OpenJDK, or showing it to a fellow OpenJDK developer. You probably know better what your application is doing to cause thread dumps, focus there.\nThat being said, I don't see any obvious memory leaks in StackFrameInfo, neither can I reproduce any leak with stress tests, so maybe what you are seeing is \"just\" thread dumping over the larger and larger thread stacks. Or you capture it when thread dump is happening. Or... It is hard to say without the MCVE.\nUpdate: After playing with MCVE, I realized that it reproduces with 17.0.1, but not with either mainline development JDK, or JDK 18 EA, or JDK 17.0.2 EA. I tested with 17.0.2 EA before, so was not seeing it, dang. Bisection between 17.0.1 and 17.0.2 EA shows it was fixed with JDK-8273902 backport. 17.0.2 releases this week, so the bug should disappear after you upgrade.\n"
}
{
    "Id": 70555241,
    "PostTypeId": 1,
    "Title": "Spring Boot, OAuth2 authentication is lost between requests",
    "Body": "EDIT:\nlog from org.springframework.security:\n2022-01-17 12:31:03.495 IST\n2022-01-17 10:31:03.495 DEBUG [080-exec-5] o.s.s.w.s.SessionManagementFilter - Request requested invalid session id D5F8BA31A3D7466AK3K3C8EA26A4F037\nDefault\n\n2022-01-17 12:31:03.495 IST\n2022-01-17 10:31:03.495 DEBUG [080-exec-5] o.s.s.w.a.AnonymousAuthenticationFilter - Set SecurityContextHolder to anonymous SecurityContext\nDebug\n\n2022-01-17 12:31:03.495 IST\n\"Request requested invalid session id D5F8BA31A3D7466AK3K3C8EA26A4F037\"\nDebug\n\n2022-01-17 12:31:03.495 IST\n\"Set SecurityContextHolder to anonymous SecurityContext\"\nDefault\n\n2022-01-17 12:31:03.494 IST\n2022-01-17 10:31:03.494 DEBUG [080-exec-5] o.s.s.w.c.SecurityContextPersistenceFilter - Set SecurityContextHolder to empty SecurityContext\nDebug\n\n2022-01-17 12:31:03.494 IST\n\"Set SecurityContextHolder to empty SecurityContext\"\nDefault\n\n2022-01-17 12:31:03.493 IST\n2022-01-17 10:31:03.493 DEBUG [080-exec-5] o.s.security.web.FilterChainProxy - Securing GET /logo192.png\nDebug\n\n2022-01-17 12:31:03.493 IST\n\"Securing GET /logo192.png\"\n\n***But if I look in the logs some requests after I can get the valid auth:\nDebug\n2022-01-17 12:31:03.945 IST\n\"Set SecurityContextHolder to SecurityContextImpl [Authentication=OAuth2AuthenticationToken [Principal=com..security.oauth.CustomOAuth2User@, Credentials=[PROTECTED], Authenticated=true, Details=WebAuthenticationDetails [RemoteIpAddress=***, SessionId=9438C880A19C93AADJI206B9B8B3386], Granted Authorities=[ROLE_USER, SCOPE_https://www.googleapis.com/auth/userinfo.email, SCOPE_https://www.googleapis.com/auth/userinfo.profile, SCOPE_openid]]]\"\nDebug\n2022-01-17 12:31:03.945 IST\n\"Retrieved SecurityContextImpl [Authentication=OAuth2AuthenticationToken [Principal=com..security.oauth.CustomOAuth2User@, Credentials=[PROTECTED], Authenticated=true, Details=WebAuthenticationDetails [RemoteIpAddress=***, SessionId=9438C880A19C93AADJI206B9B8B3386], Granted Authorities=[ROLE_USER, SCOPE_https://www.googleapis.com/auth/userinfo.email, SCOPE_https://www.googleapis.com/auth/userinfo.profile, SCOPE_openid]]]\"\nDebug\n2022-01-17 12:31:03.945 IST\n\"Retrieved SecurityContextImpl [Authentication=OAuth2AuthenticationToken [Principal=com..security.oauth.CustomOAuth2User@, Credentials=[PROTECTED], Authenticated=true, Details=WebAuthenticationDetails [RemoteIpAddress=***, SessionId=9438C880A19C93AADJI206B9B8B3386], Granted Authorities=[ROLE_USER, SCOPE_https://www.googleapis.com/auth/userinfo.email, SCOPE_https://www.googleapis.com/auth/userinfo.profile, SCOPE_openid]]]\"\nDefault\n2022-01-17 12:31:03.944 IST\n2022-01-17 10:31:03.944 DEBUG [080-exec-8] o.s.security.web.FilterChainProxy - Securing GET /auth/api/getBasicInfo\nit looks like the session id is inconsistent\n\nI use spring security builtin oauth2 social login option,\nI implemented an OAuth2LoginSuccess class with the onAuthenticationSuccess method and inside of it I fetch the user the corresponds to the social id I got from the oauth:\nCustomOAuth2User oAuth2User = (CustomOAuth2User) authentication.getPrincipal();\nint sociald = oAuth2User.getAttribute(\"id\");\nUser user = usersUtils.getUserBySocailId(socialId);\nenter code here\n// add the user details to the Auth\nSecurityContextHolder.clearContext();\n((OAuth2AuthenticationToken) authentication).setDetails(user);\nSecurityContextHolder.getContext().setAuthentication(authentication);\n\nIf I debug inside the onAuthenticationSuccess I can see a valid auth with all the user details.\nafter the login I redirect to the home page and i send a auth get request to the server to check if there is a user logged in.\nthe problem is that 50% of the times the request is completed successfuly and the user can make authenticated requets.\nbut the other 50% i get redirected automaticly to Login page and when i check the log is see that Spring boot says that the user is unauthenticated and the auth is lost.\nBut in the onAuthenticationSuccess i can always see the correct auth.\nMy ApplicationSecurityConfig looks like this:\n    http.csrf().disable().authorizeRequests()\n            .antMatchers(\"/login*\", \"/signin/**\", \"/signup/**\", \"/oauth2/**\").permitAll()\n            .antMatchers(Constants.ADMIN_PREFIX + \"/**\").hasRole(\"ADMIN\")\n            .antMatchers(Constants.AUTH_PREFIX + \"/**\").hasAnyRole(\"ADMIN\", \"USER\")\n            .antMatchers(Constants.PUBLIC_PREFIX + \"/**\").permitAll()\n            .anyRequest().permitAll()\n            .and()\n            .exceptionHandling().authenticationEntryPoint(new UnauthenticatedRequestHandler())\n            .and()\n            .formLogin()\n            .passwordParameter(\"password\")\n            .usernameParameter(\"email\")\n            .loginPage(\"/Login\")\n            .loginProcessingUrl(\"/loginSecure\").permitAll().successHandler(new LoginSuccess()).failureHandler(new FailureSuccess())\n            .and()\n            .oauth2Login()\n            .loginPage(\"/Login\")\n            .userInfoEndpoint()\n            .userService(oAuth2UserService)\n            .and()\n            .successHandler(new OAuth2LoginSuccess())\n            .and()\n            .rememberMe()\n            .rememberMeParameter(\"remember-me\")\n            .tokenValiditySeconds((int) TimeUnit.DAYS.toSeconds(21))\n.userDetailsService(this.applicationUserService)\n            .and()\n            .logout()\n         .clearAuthentication(true).invalidateHttpSession(true).logoutSuccessUrl(\"/login\")\n            .addLogoutHandler(new CustomLogOutHandler());\n\nAnd this is the function i check if the user is logged in:\n   @GetMapping(Constants.AUTH_PREFIX + \"/checkUserLogged\")\npublic Integer checkUserLogged(Authentication authentication,HttpServletRequest request) {\n    try{\n        if (authentication != null) {\n            User (User) authentication.getDetails();\n            if (user == null) {\n                return -1;\n            }\n            return user.getId();\n        }\n    }\n    catch (Exception e){\n        logger.warning(e.getLocalizedMessage());\n    }\n    return -1;\n}\n\nbut when the problem occur it dosen't get to run the controller because spring security return unauthrozed error before.\nThank you in advance for your help\n",
    "AcceptedAnswerId": 70755813,
    "AcceptedAnswer": "I found the solution, I hope this could help.\nThe thing that caused the problem for me was that GCP and GAE use multiple instances of the server, and if the user is logged in a certain instance\ndoes not mean the other instances are familiar with it too because the Spring HTTPSession is in-memory.\nI Switched the Session platform to use the spring-session jdbc using the following configuration in the application.properties :\nspring.session.store-type=jdbc\n\n-- you can use redis instead of jdbc, as long as the session is stored in a shared place among all instances.\nalso added the transaction manager to the SecurtityConfig:\n@Bean\npublic PlatformTransactionManager transactionManager(DataSource dataSource) {\n    return new DataSourceTransactionManager(dataSource);\n}\n\nand added the following configurations :\n    http.csrf().disable()\n            .sessionManagement()\n            .maximumSessions(1)\n            .and()\n            .sessionCreationPolicy(SessionCreationPolicy.ALWAYS)\n\nIn addition like @stringy05 mentioned the authrizenClient Repository needs ti be updated too:\n    /**\n * Use the servlet container session store for authorized OAuth2 Clients\n */\n@Bean\npublic OAuth2AuthorizedClientRepository authorizedClientRepository() {\n    return new HttpSessionOAuth2AuthorizedClientRepository();\n}\n\nand add the .authorizedClientRepository line to the httpconfig:\n....\n                .oauth2Login()\n            .loginPage(\"/Login\")\n            .authorizedClientRepository(authorizedClientRepository)\n            .authorizationEndpoint().and()\n            .userInfoEndpoint()\n            .userService(oAuth2UserService)\n            .and()\n            .successHandler(new OAuth2LoginSuccess())\n\n....\nRegarding the GAE, I added the following line to the app.yaml file:\n  network:\n    session_affinity: true\n\n"
}
{
    "Id": 70664036,
    "PostTypeId": 1,
    "Title": "Find the missing module",
    "Body": "My question: when building a minimal JRE, how can one make sure that no required module is missing?\n\nTo illustrate the question, here is an example where I want to build a minimal JRE for my project. Let's assume for this example that logback is my only dependency.\nI run the following command to see what modules are required:\n$ jar --file=logback-core-1.2.3.jar --describe-module\nNo module descriptor found. Derived automatic module.\n\nlogback.core@1.2.3 automatic\nrequires java.base mandated\ncontains ch.qos.logback.core\ncontains ch.qos.logback.core.boolex\netc. (there are more \"contains ch.qos.logback.XXX\" lines)\n\nIt looks like I only need the java.base module and I build my minimal JRE accordingly:\njlink --output jre-min --add-modules java.base\n\nHowever when running the project with the minimal JRE, I encounter issues using logback's email logger (malformed emails over TLS). Through trial and error, I find that jdk.crypto.cryptoki module is also required:\njlink --output jre-min --add-modules java.base,jdk.crypto.cryptoki\n\nNow my project works fine. How could I have avoided the trial & error step?\n",
    "AcceptedAnswerId": 70733470,
    "AcceptedAnswer": "The JAR you're using there has \"no module descriptor\" (see first line of output) and thus can't tell you what modules it depends on, so you have to find out yourself. The canonical tool for that is jdeps but it may not be enough.\nStatic Dependencies\nI wrote a jdeps tutorial that gets you started, but the interesting bit is this section. The gist is this command:\njdeps --class-path 'jars/*' -summary -recursive logback-core-1.2.3.jar\n\nWhere jars contains all Logback dependencies. (If you don't have those at hand, you can leave --class-path and -recursive out, but then you don't know which modules the dependencies.) Besides a few other things, the output will list the dependencies on JDK modules.\nDynamic Dependencies\njdeps works by analyzing the byte code, which means it will only find dependencies that are statically linked. Consequently, if a JAR uses reflection, the service loader, or other mechanisms to avoid explicitly mentioning the classes it wants to use, jdeps will not notice them.\nTo find those cases, you can run an app with the java command-line option -XX:DumpLoadedClassList=classes.lst - it will generate a file classes.lst that lists all loaded classes.\nMinimal Runtime\nNote that the base module java.base uses a lot of services that are provided by other modules, for example locale data by jdk.localedata. That means a minimal runtime (i.e. one where service provider modules are not included) may miss things that an app needs (in the example, maybe locales).\nYou can list services with java --describe-module java.base (see list of uses ... in output) and then find potentiual providers for each with jlink's --suggest-providers option.\nYou can include all of possible providers with jlink's --bind-services option, but that immediately abandons the idea of a \"minimal\" runtime as it will include a lot of modules. If you're going for \"minimal\", probably better to include them one by one as needed.\nWhatever you do, make sure to thoroughly test your app on the custom-made runtime.\n"
}
{
    "Id": 70890854,
    "PostTypeId": 1,
    "Title": "2 files found with path 'lib/arm64-v8a/libc++_shared.so' from inputs...-react native",
    "Body": "I am trying to enable package of ffmpeg-kit-react-native in react-native.\nThe sample commands given in the example executes successfully. But I want to use libwebp for converting gif files to webp which is under package named video. As instrcuted . I have to enable the package to use some libraries.\n\n2.2.1 Enabling a Package on Android\nEdit android/build.gradle file and add the package name in ext.ffmpegKitPackage variable.\next {\n   ffmpegKitPackage = \"\"\n}\n\n\nSo I added a line in the node_module/ffmpeg-kit-react-native/android/build.gradle\nandroid {\n  compileSdkVersion 30\n\n  defaultConfig {\n    minSdkVersion safeExtGet('ffmpegKitPackage', 'https').contains(\"-lts\") ? 16 : 24\n    targetSdkVersion 30\n    versionCode 451\n    versionName \"4.5.1\"\n  }\n\n  buildTypes {\n    release {\n      minifyEnabled false\n    }\n  }\n  lintOptions {\n    disable 'GradleCompatible'\n  }\n  compileOptions {\n    sourceCompatibility JavaVersion.VERSION_1_8\n    targetCompatibility JavaVersion.VERSION_1_8\n  }\n\n  rootProject.ext.ffmpegKitPackage = \"video\" // Added this line here \n\n}\n\nError:\n* What went wrong:\nExecution failed for task ':app:mergeDebugNativeLibs'.\n> A failure occurred while executing com.android.build.gradle.internal.tasks.MergeJavaResWorkAction\n   > 2 files found with path 'lib/arm64-v8a/libc++_shared.so' from inputs:\n      - C:\\Users\\ADMIN\\.gradle\\caches\\transforms-3\\7403ebe5571a2ce5a6a5fc9876af4814\\transformed\\jetified-react-native-0.66.4\\jni\n      - C:\\Users\\ADMIN\\.gradle\\caches\\transforms-3\\4be54e44fe38656741a8345504588323\\transformed\\jetified-ffmpeg-kit-video-4.5.1-1\\jni\n     If you are using jniLibs and CMake IMPORTED targets, see\n     https://developer.android.com/r/tools/jniLibs-vs-imported-targets\n\nI have tried ./gradlew clean but problem is still there.\nHow to fix this error? Thanks\n",
    "AcceptedAnswerId": 70893407,
    "AcceptedAnswer": "add this in your node_module/ffmpeg-kit-react-native/android/build.gradle\nandroid{\n  packagingOptions {\n      pickFirst 'lib/x86/libc++_shared.so'\n      pickFirst 'lib/x86_64/libc++_shared.so'\n      pickFirst 'lib/armeabi-v7a/libc++_shared.so'\n      pickFirst 'lib/arm64-v8a/libc++_shared.so'\n  }\n  rootProject.ext.ffmpegKitPackage = \"video\"\n}\n\nffmpeg-kit-react-native has already talked about this error here. https://github.com/tanersener/ffmpeg-kit/wiki/Tips#2-depending-another-android-library-containing-libc_sharedso\n"
}
{
    "Id": 71006506,
    "PostTypeId": 1,
    "Title": "Java collector teeing a list of inputs",
    "Body": "I am trying to implement a simple collector, which takes a list of collectors and simultaneously collects values in slightly different ways from a stream.\nIt is quite similar to Collectors.teeing, but differs in that it\n\nReceives a list of collectors instead of just two\nRequires all collectors to produce a value of the same type\n\nThe type signature I want to have is\npublic static  Collector> list(\n      final List> downstreamCollectors);\n\nOne way to create such a collector would be to recursively pair up teeing collectors, like so:\npublic static  Collector> list(\n    final List> downstreamCollectors) {\n  return listrec(\n      Collectors.collectingAndThen(downstreamCollectors.get(0), List::of),\n      downstreamCollectors.stream().skip(1).toList());\n}\n\nprivate static  Collector> listrec(\n    final Collector> teedCollectors,\n    final List> downstreamCollectors) {\n  if (downstreamCollectors.size() == 0) {\n    return teedCollectors;\n  } else {\n    return listrec(\n        teeing(\n            teedCollectors,\n            downstreamCollectors.get(0),\n            (l, s) -> Stream.concat(l.stream(), Stream.of(s)).toList()),\n        downstreamCollectors.stream().skip(1).toList());\n  }\n}\n\nSomething feels a little \"off\" with this solution, so I am trying to create the collector myself, something like:\npublic static  Collector> list2(\n    final List> downstreamCollectors) {\n  return Collector.of(\n      () -> downstreamCollectors.stream().map(c -> c.supplier().get()).toList(),\n      (accumulators, t) ->\n          IntStream.range(0, downstreamCollectors.size())\n              .forEach(\n                  i -> downstreamCollectors.get(i).accumulator().accept(accumulators.get(i), t)),\n      (accumulator1, accumulator2) ->\n          IntStream.range(0, downstreamCollectors.size())\n              .mapToObj(\n                  i ->\n                      downstreamCollectors\n                          .get(i)\n                          .combiner()\n                          .apply(accumulator1.get(i), accumulator2.get(i)))\n              .toList(),\n      accumulators ->\n          IntStream.range(0, downstreamCollectors.size())\n              .mapToObj(i -> downstreamCollectors.get(i).finisher().apply(accumulators.get(i)))\n              .toList());\n}\n\nBecause of the unbounded wildcard in the downstream collectors' accumulator type, this doesn't compile. Changing the type signature to\npublic static  Collector> list2(\n    final List> downstreamCollectors);\n\nsolves the problem, but unfortunately renders the method much less usable as the downstream collectors (like the built in collectors from java.util.stream.Collectors) typically would have a unbounded wildcard in the accumulator type.\nIs there another way to implement this, keeping the wildcard in the method signature?\nI am using OpenJDK 17.0.2.\n",
    "AcceptedAnswerId": 71019502,
    "AcceptedAnswer": "Handling a list of collectors with arbitrary accumulator types as a flat list can\u2019t be done in a type safe way, as it would require declaring n type variables to capture these types, where n is the actual list size.\nTherefore, you can only implement the processing as a composition of operations, each with a finite number of components know at compile time, like your recursive approach.\nThis still has potential for simplifications, like replacing downstreamCollectors.size() == 0 with downstreamCollectors.isEmpty() or downstreamCollectors.stream().skip(1).toList() with a copying free downstreamCollectors.subList(1, downstreamCollectors.size()).\nBut the biggest impact has replacing the recursive code with a Stream Reduction operation:\npublic static  Collector> list(List> collectors) {\n    return collectors.stream()\n            .>>map(c-> Collectors.collectingAndThen(c, List::of))\n            .reduce((c1, c2) -> teeing(c1, c2,\n                        (l1, l2) -> Stream.concat(l1.stream(), l2.stream()).toList()))\n            .orElseThrow(() -> new IllegalArgumentException(\"no collector specified\"));\n}\n\nThis may work fairly well if you don\u2019t have a really large number of collectors to compose. A disadvantage of this concise solution is that every result will be wrapped into a single element list before the actual merging of results and even the result merging may bear multiple list copying operations.\nThis result processing can be optimized using\npublic static  Collector> list(List> collectors) {\n    int num = collectors.size();\n    switch(num) {\n        case 0: throw new IllegalArgumentException(\"no collector specified\");\n        case 1: return collectingAndThen(collectors.get(0), List::of);\n        case 2: return teeing(collectors.get(0), collectors.get(1), List::of);\n        case 3: return teeing(teeing(collectors.get(0), collectors.get(1), List::of),\n                           collectors.get(2), (l,r) -> List.of(l.get(0), l.get(1), r));\n        default:\n    }\n    Collector> c = teeing(collectors.get(0), collectors.get(1), (r1, r2) -> {\n        var list = new ArrayList(num);\n        list.add(r1);\n        list.add(r2);\n        return list;\n    });\n    for(int ix = 2; ix < num; ix ++) {\n        c = teeing(c, collectors.get(ix), (list, r) -> { list.add(r); return list; });\n    }\n    return collectingAndThen(c, List::copyOf);\n}\n\nThis provides special cases for small numbers of collectors whose results can be used to construct an immutable result list directly. For the other cases, all results are added to an ArrayList first, preventing excessive list copying, before converting the list to the final immutable list. This last step could be omitted, if getting an immutable result list is not important, I just tried to be as close to the Stream.toList() behavior of the original approach as possible.\nThere\u2019s still an unbalanced recursive structure behind the scenes during the Stream processing which prohibits really large numbers of collectors. There are two approaches to solve this.\n\nImplement your own type safe variant of teeing which exposes the intermediate container type, to allow to build a balanced tree and collecting all results into a list by traversing this tree without additional intermediate storage.\n\nAbandon the type safety and implement the collector with a flat list and raw types. Try to limit the unsafe code as much as possible.\n\n\nBut this might not be needed when you have an estimate of the expected number of collectors to \u201ctee\u201d and find the first solution working good enough.\n"
}
{
    "Id": 70756414,
    "PostTypeId": 1,
    "Title": "java.lang.reflect.InaccessibleObjectException: Unable to make field private final java.util.Comparator java.util.TreeMap.comparator accessible:module",
    "Body": "This is my first cucumber project and i followed a tutorial when setting everything up. It all seems to be the same but for some reason i get this:\njava.lang.ExceptionInInitializerError.\nCaused by: java.lang.reflect.InaccessibleObjectException: Unable to make field private final java.util.Comparator java.util.TreeMap.comparator accessible: module java.base does not \"opens java.util\" to unnamed module @74ad1f1f\nAny idea how to solve this error ?\nBelow i have posted everything that comes out in my console as well as my pom file in case there is an issue with my dependencies eventhough the guy from the tutorial's pom file is identical.\nThis is everything that comes out in my Console.\n[31mFailed scenarios:[0m\n[31muni/login/Login.feature:3 [0m# Scenario: Enter the system.\n1 Scenarios ([31m1 failed[0m)\n5 Steps ([31m1 failed[0m, [36m4 skipped[0m)\n0m0.185s\n\njava.lang.ExceptionInInitializerError\n    at cucumber.deps.com.thoughtworks.xstream.XStream.setupConverters(XStream.java:820)\n    at cucumber.deps.com.thoughtworks.xstream.XStream.(XStream.java:574)\n    at cucumber.deps.com.thoughtworks.xstream.XStream.(XStream.java:530)\n    at cucumber.runtime.xstream.LocalizedXStreams$LocalizedXStream.(LocalizedXStreams.java:50)\n    at cucumber.runtime.xstream.LocalizedXStreams.newXStream(LocalizedXStreams.java:37)\n    at cucumber.runtime.xstream.LocalizedXStreams.get(LocalizedXStreams.java:29)\n    at cucumber.runtime.StepDefinitionMatch.runStep(StepDefinitionMatch.java:37)\n    at cucumber.runtime.Runtime.runStep(Runtime.java:300)\n    at cucumber.runtime.model.StepContainer.runStep(StepContainer.java:44)\n    at cucumber.runtime.model.StepContainer.runSteps(StepContainer.java:39)\n    at cucumber.runtime.model.CucumberScenario.run(CucumberScenario.java:44)\n    at cucumber.runtime.junit.ExecutionUnitRunner.run(ExecutionUnitRunner.java:102)\n    at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:63)\n    at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:18)\n    at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)\n    at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)\n    at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:413)\n    at cucumber.runtime.junit.FeatureRunner.run(FeatureRunner.java:70)\n    at cucumber.api.junit.Cucumber.runChild(Cucumber.java:95)\n    at cucumber.api.junit.Cucumber.runChild(Cucumber.java:38)\n    at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)\n    at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)\n    at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:413)\n    at cucumber.api.junit.Cucumber.run(Cucumber.java:100)\n    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:93)\n    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:40)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:529)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:756)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:452)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:210)\n    at \u273d.Given \u041f\u043e\u0442\u0440\u0435\u0431\u0438\u0442\u0435\u043b\u044f\u0442 \u043e\u0442\u0432\u0430\u0440\u044f \u0435\u043a\u0440\u0430\u043d\u0430 \u0437\u0430 \u0432\u0445\u043e\u0434 \u0432 \u0441\u0438\u0441\u0442\u0435\u043c\u0430\u0442\u0430(uni/login/Login.feature:4)\nCaused by: java.lang.reflect.InaccessibleObjectException: Unable to make field private final java.util.Comparator java.util.TreeMap.comparator accessible: module java.base does not \"opens java.util\" to unnamed module @74ad1f1f\n    at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:357)\n    at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:297)\n    at java.base/java.lang.reflect.Field.checkCanSetAccessible(Field.java:177)\n    at java.base/java.lang.reflect.Field.setAccessible(Field.java:171)\n    at cucumber.deps.com.thoughtworks.xstream.core.util.Fields.locate(Fields.java:39)\n    at cucumber.deps.com.thoughtworks.xstream.converters.collections.TreeMapConverter.(TreeMapConverter.java:50)\n    at cucumber.deps.com.thoughtworks.xstream.XStream.setupConverters(XStream.java:820)\n    at cucumber.deps.com.thoughtworks.xstream.XStream.(XStream.java:574)\n    at cucumber.deps.com.thoughtworks.xstream.XStream.(XStream.java:530)\n    at cucumber.runtime.xstream.LocalizedXStreams$LocalizedXStream.(LocalizedXStreams.java:50)\n    at cucumber.runtime.xstream.LocalizedXStreams.newXStream(LocalizedXStreams.java:37)\n    at cucumber.runtime.xstream.LocalizedXStreams.get(LocalizedXStreams.java:29)\n    at cucumber.runtime.StepDefinitionMatch.runStep(StepDefinitionMatch.java:37)\n    at cucumber.runtime.Runtime.runStep(Runtime.java:300)\n    at cucumber.runtime.model.StepContainer.runStep(StepContainer.java:44)\n    at cucumber.runtime.model.StepContainer.runSteps(StepContainer.java:39)\n    at cucumber.runtime.model.CucumberScenario.run(CucumberScenario.java:44)\n    at cucumber.runtime.junit.ExecutionUnitRunner.run(ExecutionUnitRunner.java:102)\n    at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:63)\n    at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:18)\n    at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)\n    at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)\n    at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:413)\n    at cucumber.runtime.junit.FeatureRunner.run(FeatureRunner.java:70)\n    at cucumber.api.junit.Cucumber.runChild(Cucumber.java:95)\n    at cucumber.api.junit.Cucumber.runChild(Cucumber.java:38)\n    at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)\n    at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)\n    at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:413)\n    at cucumber.api.junit.Cucumber.run(Cucumber.java:100)\n    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:93)\n    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:40)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:529)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:756)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:452)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:210)\n\nAnd this is my pom.xml\n\n  4.0.0\n  uni.ais\n  first-cucumber-project\n  1.1.0-SNAPSHOT\n  first-cucumber-project-gr\n  \n    1.8\n    1.8\n    UTF-8\n  \n  \n    \n        info.cukes\n        cucumber-java\n        1.2.5\n    \n    \n        info.cukes\n        cucumber-junit\n        1.2.5\n    \n  \n\n\n",
    "AcceptedAnswerId": 70776589,
    "AcceptedAnswer": "I solved my problem. Turns out the JRE that eclipse had automatically downloaded and was using wasn't compatible with this version of cucumber. I manually changed the path to a jre 1.8 that i had in my ProgramFilex(x86)/Java folder and now everything works fine.\n"
}
{
    "Id": 70786275,
    "PostTypeId": 1,
    "Title": "Reading encrypted private key in PKCS#8 format through bouncycastle, Java failing in docker container",
    "Body": "I am trying to read a PKCS#8 private key which looks like following:\nkey.k8 --> (Sample key. Passphrase - 123456):\n-----BEGIN ENCRYPTED PRIVATE KEY-----\nMIIFLTBXBgkqhkiG9w0BBQ0wSjApBgkqhkiG9w0BBQwwHAQILbKY9hPxYSoCAggA\nMAwGCCqGSIb3DQIJBQAwHQYJYIZIAWUDBAEqBBCvaGt2Hmm2NpHpxbLvHKyOBIIE\n0IQ7dVrAGXLZl0exYIvyxLAu6zO00jL6b3sb/agTcCFOz8JU6fBanxY0d5aYO4Dn\nmynQG7BoljU470s0zIwW/wk0MmdUFl4nXWBX/4qnG0sZqZ9KZ7I8R/WrBkmpX8C/\n4pjdVhu8Ht8dfOYbkbjMBTohDJz8vJ0QwDIXi9yFjjef+QjwrFOl6kAeDJFVMGqc\ns7K/wOnhsL1XxfW9uTulPiZh5YTZKcatMkeGDR7c+cg5I+Mutim92diWuCekhNoa\nuvhUy1M3cbs7Azp1Mhz+V0CDKklI95EvN4u23WhiJPCjAofC/e45/heOP3Dwm7WZ\nzHEY1C/X8PsTl6MEEIF3ZJP+4Vr0corAs1L2FqE6oOng8dFFYmF5eRyBx6bxFd05\niYbfOH24/b3qtFKPC689kGEd0gWp1dwES35SNNK+cJqVRTjgI0oKhOai3rhbGnmp\ntx4+JqploQgTorj4w9asbtZ/qZA2mYSSR/Q64SHv7LfoUCI9bgx73MqRQBgvI5yS\nb4BoFBnuEgOduZLaGKGjKVW3m5/q8oiDAaspcSLCJMIrdOTYWJB+7mfxX4Xy0vEe\n5m2jXpSLQmrfjgpSTpHDKi/3b6OzKOcHjSFBf8IoiHuLc5DVvLECzDUxxaMrTZ71\n0YXvEPwl2R9BzEANwwR9ghJvFg1Be/d5W/WA1Efe6cNQNBlmErxD6l+4KDUgGjTr\nAaksp9SZAv8uQAsg7C57NFHpTA5Hznr5JctL+WlO+Gk0cAV6i4Py3kA6EcfatsnS\nPqP2KbxT+rb2ATMUZqgWc20QvDt6j0CTA1BuVD1PNhnAUFvb2ocyEEXOra22DPPS\nUPu6jirSIyFcjqFjJ9A1FD9L4/UuX2UkDSLqblFlYB1+G55KZp+EKz8SZoN5qXy1\nLyMtnacEP5OtRDrOjopzVNiuV1Uv63M9QVi1hZlVLJEomgjWuvuyEuIwDaY2uryW\nvx+jJEZyySFkb1JwAbrm+p6sCTFnbQ/URKC2cit/FJyKqNim6VQvGL8Sez34qV3z\nD13QJgTZfsy+BaZoaQ6cJTXtJ8cN0IcQciOiDNBKMW66zO6ujS8G+KNviNQypDm6\nh4sOgjMqLaZ4ezPEdNj/gaxV7Y15nVRu0re8dVkaa5t9ft/sh6A+yeTD5tS5hHkf\nNI7uJPTaTXVoz7xq2PAJUTWujMLMZKtmNOzNqYvxWRy3tCOFobBQkMxqEBEwHd+x\nSA+gFcJKJ+aNfCGZJ5fFr8rNlhtOF6uMwOAlfiUlP/pCUDUCKPjZVj4K95yNc8Io\njSZSPb5tGPe0HqXgc6IAfQarlUZt90oVtzL0OfOfTxe1bEzS2ccNadbx/6vjLBc4\nq5UuUBppl3rXpbuZ7J1Rp3n2byF4APxFdT2LHKq+MYMfWUToau/TCMT4lFIM9tM8\n7TuuyUT2PKzf/xlsl4iScw96z9xxGPQrXn7IA2W5iL+0eCLztJdjNRX1FisdfIBL\nPraOVlmF8jHKbFdRZ8Yi8pApbQjvHi24g7dX7u/cq1FH/VE+nJ0O8YVCYVDw13CW\nh0p7yD7BuB0R+0WnR0yvkp30vK4/rtCB+Ob8bH/+HvAZrAU5X8jq/wsQbLkrLHZV\n6A6GGfX8+hy5AoaXsH1BHnMyXkaF6Mv29z8JcslDJxX/\n-----END ENCRYPTED PRIVATE KEY-----\n\nFollowing code is being used to parse the private key:\n InputStream privateKeyInputStream = getPrivateKeyInputStream(); // reads the key file from classpath and share as DataStream\n logger.info(\"InputStreamExists --> {} \", privateKeyInputStream.available());\n PEMParser pemParser = new PEMParser(new InputStreamReader(privateKeyInputStream));\n Object pemObject = pemParser.readObject();\n if (pemObject instanceof PKCS8EncryptedPrivateKeyInfo) {\n     // Handle the case where the private key is encrypted.\n     PKCS8EncryptedPrivateKeyInfo encryptedPrivateKeyInfo = (PKCS8EncryptedPrivateKeyInfo) pemObject;\n     InputDecryptorProvider pkcs8Prov =\n            new JceOpenSSLPKCS8DecryptorProviderBuilder().build(passphrase.toCharArray());\n     privateKeyInfo = encryptedPrivateKeyInfo.decryptPrivateKeyInfo(pkcs8Prov); // fails here\n}\n\n\nInputStream resourceAsStream = null;\n    if (\"local\".equals(privateKeyMode)) {\n      resourceAsStream = this.getClass().getResourceAsStream(privateKeyPath);\n    } else {\n      File keyFile = new File(privateKeyPath);\n      logger.info(\n          \"Key file found in {} mode. FileName : {}, Exists : {}\",\n          privateKeyMode,\n          keyFile.getName(),\n          keyFile.exists());\n      try {\n        resourceAsStream = new DataInputStream(new FileInputStream(keyFile));\n      } catch (FileNotFoundException e) {\n        e.printStackTrace();\n      }\n\nWhen I am running this code through intelliJ on windows, the code works fine but when I run it through docker container I am getting following exception:\norg.bouncycastle.pkcs.PKCSException: unable to read encrypted data: failed to construct sequence from byte[]: Extra data detected in stream\nsnowflake-report-sync    |      at org.bouncycastle.pkcs.PKCS8EncryptedPrivateKeyInfo.decryptPrivateKeyInfo(Unknown Source) ~[bcpkix-jdk15on-1.64.jar!/:1.64.00.0]\nsnowflake-report-sync    |      at com.optum.snowflakereportsync.configuration.SnowFlakeConfig.getPrivateKey(SnowFlakeConfig.java:103) ~[classes!/:na]\nsnowflake-report-sync    |      at com.optum.snowflakereportsync.configuration.SnowFlakeConfig.getConnectionProperties(SnowFlakeConfig.java:67) ~[classes!/:na]\n\nFollowing is Dockerfile used:\nFROM adoptopenjdk/openjdk11-openj9:latest\nCOPY build/libs/snowflake-report-sync-*.jar snowflake-report-sync.jar\nRUN mkdir /encryption-keys\nCOPY encryption-keys/ /encryption-keys/ #keys are picked from docker filesystem when running in container\nEXPOSE 8080\nCMD java -Dcom.sun.management.jmxremote -noverify ${JAVA_OPTS} -jar snowflake-report-sync.jar\n\nOptions tried:\n\nEnsured that key file is being read while running in container. Logger \"InputStreamExists --> {}\" gives number of bytes\nRan dos2unix on key.k8 just to make sure there are no Window's \"^M\" characters which be could be causing issue as container is linux one : FROM adoptopenjdk/openjdk11-openj9:latest\n\nNot sure what I am doing wrong but any help or pointers would be appreciated.\n",
    "AcceptedAnswerId": 70905140,
    "AcceptedAnswer": "Like @Bragolgirith suspected, BouncyCastle seems to have problems with OpenJ9. I guess it is not a Docker issue, because I can reproduce it on GitHub Actions, too. It is also not limited to BouncyCastle 1.64 or 1.70, it happens in both versions. It also happens on OpenJ9 JDK 11, 14, 17 on Windows, MacOS and Linux, but for the same matrix of Java and OS versions it works on Adopt-Hotspot and Zulu.\nHere is an example Maven project and a failed matrix build. So if you select another JVM type, you should be fine. I know that @Bragolgirith already suggested that, but I wanted to make the problem reproducible for everyone and also provide an MCVE, in case someone wants to open a BC or OpenJ9 issue.\nP.S.: It is also not a character set issue with the InputStreamReader. This build fails exactly the same as before after I changed the constructor call.\n\nUpdate: I have created BC-Java issue #1099. Let's see what the maintainers can say about this.\n\nUpdate 2: The solution to your problem is to explicitly set the security provider to BC for your input decryptor provider. Thanks to David Hook for his helpful comment in #1099.\nBouncyCastleProvider securityProvider = new BouncyCastleProvider();\nSecurity.addProvider(securityProvider);\n\n// (...)\n\nInputDecryptorProvider pkcs8Prov = new JceOpenSSLPKCS8DecryptorProviderBuilder()\n  // Explicitly setting security provider helps to avoid ambiguities\n  // which otherwise can cause problems, e.g. on OpenJ9 JVMs\n  .setProvider(securityProvider)\n  .build(passphrase.toCharArray());\n\nSee this commit and the corresponding build, now passing on all platforms, Java versions and JVM types (including OpenJ9).\nBecause @Bragolgirith mentioned it in his answer: If you want to avoid the explicit new JceOpenSSLPKCS8DecryptorProviderBuilder().setProvider(securityProvider), the call Security.insertProviderAt(securityProvider, 1) instead of simply Security.addProvider(securityProvider) would in this case also solve the problem. But this holds true only as long as no other part of your code or any third-party library sets another provider to position 1 afterwards, as explained in the Javadoc. So maybe it is not a good idea to rely on that.\n"
}
{
    "Id": 70995023,
    "PostTypeId": 1,
    "Title": "What's the difference between String.format() and str.formatted() in Java?",
    "Body": "I know that method String.format() is nearly the same as method System.out.printf() except it returns a String. But I could hardly find the introduction about method \"formatted\" which is defined as follows:\npublic String formatted(Object... args) {\n        return new Formatter().format(this, args).toString();\n}\n\nAnd I know the functions of two codes below are the same.\nString str1 = String.format(\"%s\", \"abab\");\nSystem.out.println(str1);\n\nString str2;\nstr2 = \"%s\".formatted(\"abab\");\nSystem.out.println(str2);\n\nTherefore I'm wandering what's the difference between them. Thank you!\n",
    "AcceptedAnswerId": 70997302,
    "AcceptedAnswer": "Make sure you use a good IDE so that you have easy access to browse into JDK source code. In Eclipse say, use F3 to open to any declaration. IntelliJ IDEA has similar feature.\nIf you view the source code for both methods, you can see these calls are identical except that variables this is interchanged with format when comparing the instance vs static method:\npublic String formatted(Object... args) {\n    return new Formatter().format(this, args).toString();\n}\npublic static String format(String format, Object... args) {\n    return new Formatter().format(format, args).toString();\n}\n\nSo as you've observed: String.format(str, args) is same as str.formatted(args)\n"
}
{
    "Id": 71041836,
    "PostTypeId": 1,
    "Title": "GitHub Actions: Required property is missing: shell",
    "Body": "Introduction\nI am currently to crate a composite GitHub Actions that build a JavaDoc from Java project and publish it automatically to a static page with GitHub Page.\nProblematic\nBut I got this error when I try to run it:\nCurrent runner version: '2.287.1'\nOperating System\nVirtual Environment\nVirtual Environment Provisioner\nGITHUB_TOKEN Permissions\nSecret source: Actions\nPrepare workflow directory\nPrepare all required actions\nGetting action download info\nDownload action repository 'MathieuSoysal/Javadoc-publisher.yml@v2.0.2' (SHA:878c07f835dd9bcbb8800090d109c91b0f0d4581)\nError: MathieuSoysal/Javadoc-publisher.yml/v2.0.2/action.yml (Line: 29, Col: 5): Required property is missing: shell\nError: MathieuSoysal/Javadoc-publisher.yml/v2.0.2/action.yml (Line: 29, Col: 5): Required property is missing: shell\nError: GitHub.DistributedTask.ObjectTemplating.TemplateValidationException: The template is not valid. MathieuSoysal/Javadoc-publisher.yml/v2.0.2/action.yml (Line: 29, Col: 5): Required property is missing: shell\n   at GitHub.DistributedTask.ObjectTemplating.TemplateValidationErrors.Check()\n   at GitHub.Runner.Worker.ActionManifestManager.ConvertRuns(IExecutionContext executionContext, TemplateContext templateContext, TemplateToken inputsToken, String fileRelativePath, MappingToken outputs)\n   at GitHub.Runner.Worker.ActionManifestManager.Load(IExecutionContext executionContext, String manifestFile)\nError: Fail to load MathieuSoysal/Javadoc-publisher.yml/v2.0.2/action.yml\n\nAffected code:\nname: Deploy Javadoc\ndescription: 'Automatically  generate your Javadoc from your maven project and deploy it with GitHub Page on javadoc branch.'\nbranding:\n  icon: 'book-open'\n  color: 'white'\ninputs:\n  java-version:  # version of java\n    description: 'Java version inside your project'\n    required: true\n    default: '17'\n  GITHUB_TOKEN: # GitHub Token\n    description: 'The GitHub token the GitHub repository'\n    required: true\n  javadoc-branch: # branch where the javadoc is hosted\n    description: 'Branch where the javadoc is hosted'\n    required: true\n    default: javadoc\n \nruns:\n  using: \"composite\"\n  steps:\n  - uses: actions/checkout@v2\n    with:\n      fetch-depth: 0\n  - uses: actions/setup-java@v2\n    with:\n      java-version: ${{ inputs.java-version }}\n      distribution: 'adopt'\n  - name: Generate Javadoc\n    run: mvn org.apache.maven.plugins:maven-javadoc-plugin:3.3.1:aggregate\n  - name: Deploy \ud83d\ude80\n    uses: JamesIves/github-pages-deploy-action@4.1.8\n    with:\n      GITHUB_TOKEN: ${{ inputs.GITHUB_TOKEN }}\n      BRANCH: ${{ inputs.javadoc-branch }}\n      CLEAN: true\n      FOLDER: target/site/apidocs\n      TARGET_FOLDER: javadoc\n\nCode that execute the GitHub Actions in question:\nname: Deploy Javadoc\n\non:\n  push:\n    branches:\n      - master\n\njobs:\n  publish:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Deploy JavaDoc \ud83d\ude80\n        uses: MathieuSoysal/Javadoc-publisher.yml@v2.0.3\n        with:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n          javadoc-branch: javadoc\n          java-version: 17\n\nQuestion\nAnyone have an idea to solve this problem?\n",
    "AcceptedAnswerId": 71042698,
    "AcceptedAnswer": "When using composite actions, you have to specify the shell.\nAs you don\u2019t specify a runner type in composite actions, you need to specify the shell instead for each action.\nIn your case, the problem is in this step, you need to add shell: bash here:\n- name: Generate Javadoc\n  shell: bash\n  run: mvn org.apache.maven.plugins:maven-javadoc-plugin:3.3.1:aggregate\n\nDocs: https://docs.github.com/en/actions/creating-actions/creating-a-composite-action#creating-an-action-metadata-file\n"
}
{
    "Id": 70791142,
    "PostTypeId": 1,
    "Title": "Could not set unknown property 'mainClassName' for extension 'springBoot' of type org.springframework.boot.gradle.dsl.SpringBootExtension",
    "Body": "I have build.gradle like this and it works :\nplugins {\n    id 'org.springframework.boot' version '2.5.8' apply false\n    ...\n}\n...\n    springBoot {\n        mainClassName = 'com.mir3.service.contactfileparser.Main'\n    }\n\nbut if I upgrade spring boot version to 2.6.2 it fails with error:\nplugins {\n    id 'org.springframework.boot' version '2.6.2' apply false\n    ...\n}\n...\n    springBoot {\n        mainClassName = 'com.mir3.service.contactfileparser.Main'\n    }\n\nError text is:\nA problem occurred evaluating root project 'myProject'.\n> Could not set unknown property 'mainClassName' for extension 'springBoot' of type org.springframework.boot.gradle.dsl.SpringBootExtension.\n\nHow can I fix it ? What is the proper way to migrate from 2.5.8 to 2.6.2 ?\n",
    "AcceptedAnswerId": 70792363,
    "AcceptedAnswer": "Use:\nspringBoot {\n    mainClass = 'com.mir3.service.contactfileparser.Main'\n}\n\nSpringBootExtension has:\n/**\n * Returns the fully-qualified name of the application's main class.\n * @return the fully-qualified name of the application's main class\n * @since 2.4.0\n */\npublic Property getMainClass() {\n    return this.mainClass;\n}\n\nmainClassName was deprecated in favour of mainClass in 2.4.0 and was scheduled for removal in 2.6.0. It was removed with this commit: Remove deprecated code flagged for removal\n"
}
{
    "Id": 70793779,
    "PostTypeId": 1,
    "Title": "Idiomatic way to remove country code from currency format?",
    "Body": "Somewhere between Java 11 and 17 currency formatting changed to where this:\nNumberFormat.getCurrencyInstance(Locale.CANADA_FRENCH).format(100.00)\n\nwould print 100,00\u00a0$\u00a0CA instead of 100,00\u00a0$.\nIs there a better way than this to remove the country code CA?\nvar currencyFormat = NumberFormat.getCurrencyInstance(Locale.CANADA_FRENCH);\nif (currencyFormat instanceof DecimalFormat decimalFormat) {\n    var symbols = DecimalFormatSymbols.getInstance(Locale.CANADA_FRENCH);\n    symbols.setCurrencySymbol(\"$\");\n    decimalFormat.setDecimalFormatSymbols(symbols);\n}\n\nSeems a bit much just to get back something that was the default behavior up until recently.\n",
    "AcceptedAnswerId": 70911567,
    "AcceptedAnswer": "I dug a bit into this, the JDK locale data comes from Unicode CLDR by default, and it seems they reverted from $ CA to $ back in August, see CLDR-14862 and this commit (expand common/main/fr_CA.xml and then go to lines 5914/5923).\nThis was part of v40, released in October, so too late for JDK 17 whose doc says it uses CLDR v35.1\n(which was introduced in Java 13)\nbut it seems it was updated to v39 in April 2021 and\nthey forgot the release note\n(JDK 16 appears to have been upgraded to v38 already).\nCLDR v40 is planned for JDK 19.\nYou may want to run your application using the COMPAT locales first, with\n-Djava.locale.providers=COMPAT,CLDR,SPI\n\n(found here but see also LocaleServiceProvider)\nThis will use the locales compatible with Java 8, where this issue is not present.\n"
}
{
    "Id": 71051529,
    "PostTypeId": 1,
    "Title": "How to replace deprecated SeekToCurrentErrorHandler with DefaultErrorHandler (spring-kafka)?",
    "Body": "I am trying to find a way to use the new DefaultErrorHandler instead of deprecated SeekToCurrentErrorHandler in spring-kafka 2.8.1, in order to override the retry default behavior in case of errors. I want to \"stop\" the retry process, so if an error occurs, no retry should be done.\nNow I have, in a config class, the following bean that works as expected:\n@Bean\npublic KafkaListenerContainerFactory> kafkaListenerContainerFactory() {\n    ConcurrentKafkaListenerContainerFactory factory = new ConcurrentKafkaListenerContainerFactory();\n    factory.setErrorHandler(new **SeekToCurrentErrorHandler(new FixedBackOff(0L, 1L)**));\n    factory.setConsumerFactory(requestConsumerFactory());\n    factory.setReplyTemplate(kafkaTemplate());\n    return factory;\n}\n\nSince in this spring kafka version, the STCEH is deprecated, I tried to do the following, in the same config class:\n@Bean\npublic DefaultErrorHandler eh() {\n    return new DefaultErrorHandler(new FixedBackOff(0, 1));\n}\n\nBut it seems that it is not working. In case of error, the retry number is the default one, as I can see in logs:\n[org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] ERROR DefaultErrorHandler              - Backoff FixedBackOff{interval=0, currentAttempts=10, maxAttempts=9} exhausted for topicX\nHow should this DefaultErrorHandler be used in order to achieve the desired behavior? Or should I use something else?\nThx in advance!\n",
    "AcceptedAnswerId": 71052157,
    "AcceptedAnswer": "factory.setCommonErrorHandler(new Default....)\nBoot auto configuration of a CommonErrorHandler bean requires Boot 2.6.\nhttps://github.com/spring-projects/spring-boot/commit/c3583a4b06cff3f53b3322cd79f2b64d17211d0e\n"
}
{
    "Id": 71059252,
    "PostTypeId": 1,
    "Title": "Mac The operation couldn\u2019t be completed. Unable to locate a Java Runtime that supports jarsigner",
    "Body": "My purpose is to use jarsigner to sign apk.\nI get the following prompt\uff1a\n% jarsigner     \nThe operation couldn\u2019t be completed. Unable to locate a Java Runtime that supports jarsigner.\nPlease visit http://www.java.com for information on installing Java.\n\nmy java version hint\uff1a\n% java -version\njava version \"1.8.0_321\"\nJava(TM) SE Runtime Environment (build 1.8.0_321-b07)\nJava HotSpot(TM) 64-Bit Server VM (build 25.321-b07, mixed mode)\n\nMac version is 11.6.3\nHow can I solve this problem please?\n",
    "AcceptedAnswerId": 71059860,
    "AcceptedAnswer": "I finally solved it by downloading the JDK\n"
}
{
    "Id": 70997077,
    "PostTypeId": 1,
    "Title": "Spring Web MVC vs Spring WebFlux. Blocking and Non-blocking",
    "Body": "I'm new at Spring and I'm reading one book \"Pro Spring boot 2\". It says here that Spring Web MVC has some blocking on each request, and Spring Webflux is a completely non-blocking stack.\n\nTell me, please, what is meant?\nThe request that came to Spring MVC activates one thread to execute this request. When and why is it blocked?\nAnd why doesn't Spring WebFlux block thread?\n\n",
    "AcceptedAnswerId": 71000069,
    "AcceptedAnswer": "\nSpring Web MVC takes a single thread to handle each request to your API. Spring Webflux does not block a thread to handle each request, because no thread is kept waiting for something to be done (e.g. waiting for an answer from a database).\nAs written in 1., it can be blocked while waiting for an answer from a database or from another service that is called via HTTP.\nSpring Webflux takes advantage of the reactive stack (take a look at https://projectreactor.io/) which is fully non-blocking. This means that no thread is blocked waiting for something to happen. Everything is based on reactive streams publishers (Mono and Flux) making your code reactive to data being available (from a database or from another service called via HTTP as examples).\n\n"
}
{
    "Id": 70857274,
    "PostTypeId": 1,
    "Title": "Android 12 Splash Screen API - Increasing SplashScreen Duration",
    "Body": "I am learning Android's new SplashScreen API introduced with Android 12. I have so far gotten it to work on my Emulator and Google Pixel 4A, but I want to increase its duration. In my Splash Screen I do not want a fancy animation, I just want a static drawable.\nI know, I know (sigh) some of you might be thinking, that I should not increase the duration and I know there are several good arguments in favor of not doing so. However, for me the duration of a splash screen with a non animated drawable is so brief (less than a second), I think it raises an accessibility concern, especially so since it cannot be disabled (ironically). Simply, the organization behind the product or its brand/product identity cannot be properly absorbed or recognized by a new user at that size and in that time, rendering  the new splash screen redundant.\nI see the property windowSplashScreenAnimationDuration in the theme for the splash screen (shown below), but this has no effect on the duration presumably because I am not animating.\n \n        \n        @color/gold\n    \n        <!-- Use windowSplashScreenAnimatedIcon to add either a drawable or an\n             animated drawable. One of these is required-->\n        @drawable/accessibility_today\n        300 \n                                                                    \n        \n        @style/Theme.MyActivity\n    \n        @drawable/wculogo\n    \n    \n\nIs there a straightforward way to extend the duration of a non animated splash screen?\n",
    "AcceptedAnswerId": 70857275,
    "AcceptedAnswer": "As I was writing this question and almost ready to post it, I stumbled on the method setKeepOnScreenCondition (below) that belongs to the splashScreen that we must install on the onCreate of our main activity. I thought it seemed wasteful not to post this, given there are no other posts on this topic and no such similar answers to other related questions (as of Jan 2022).\nSplashScreen splashScreen = SplashScreen.installSplashScreen(this);\nplashScreen.setKeepOnScreenCondition(....);\n\nUpon inspecting it I found this method receives an instance of the splashScreen.KeepOnScreenCondition() interface for which the implementation must supply the following method signature implementation:\n public boolean shouldKeepOnScreen() \n\nIt seems this method will be called by the splash screen and retain the splash screen visibly until it returns false.  This is where the light bulb moment I so love about programming occurred.\nWhat if I use a boolean initialized as true, and set it to false after a delay? That hunch turned out to work. Here is my solution. It seems to work and I thought it would be useful to others. Presumably instead of using a Handler for a delay, one could  also use this to set the boolean after some process had completed.\npackage com.example.mystuff.myactivity;\n\nimport androidx.appcompat.app.AppCompatActivity;\nimport androidx.core.splashscreen.SplashScreen;\nimport android.os.Bundle;\nimport android.os.Handler;\n\npublic class MainActivity extends AppCompatActivity {\n    \n    private boolean keep = true;\n    private final int DELAY = 1250;\n\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n        // Handle the splash screen transition.\n        SplashScreen splashScreen = SplashScreen.installSplashScreen(this);\n        super.onCreate(savedInstanceState);\n\n        //Keep returning false to Should Keep On Screen until ready to begin.\n        splashScreen.setKeepOnScreenCondition(new SplashScreen.KeepOnScreenCondition() {\n            @Override\n            public boolean shouldKeepOnScreen() {\n                return keep;\n            }\n        });\n        Handler handler = new Handler();\n        handler.postDelayed(runner, DELAY);\n    }\n\n    /**Will cause a second process to run on the main thread**/\n    private final Runnable runner = new Runnable() {\n        @Override\n        public void run() {\n            keep = false;\n        }\n    };\n    \n}\n\nIf you are into Java Lambdas an even nicer and more compact solution is as follows:\npackage com.example.mystuff.myactivity;\n\nimport androidx.appcompat.app.AppCompatActivity;\nimport androidx.core.splashscreen.SplashScreen;\nimport android.os.Bundle;\nimport android.os.Handler;\n\npublic class MainActivity extends AppCompatActivity {\n    \n    private boolean keep = true;\n    private final int DELAY = 1250;\n\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n        // Handle the splash screen transition.\n        SplashScreen splashScreen = SplashScreen.installSplashScreen(this);\n        super.onCreate(savedInstanceState);\n        setContentView(R.layout.activity_main);\n\n        //Keep returning false to Should Keep On Screen until ready to begin.\n    splashScreen.setKeepOnScreenCondition(() -> keep);\n    Handler handler = new Handler();\n    handler.postDelayed(() -> keep = false, DELAY);;\n    }\n\n\n    \n}\n\nIf you have comments or feedback (besides telling me I should not increase the duration of the splash screen), or a better way please do comment or respond with additional answers.\n"
}
{
    "Id": 70925555,
    "PostTypeId": 1,
    "Title": "How can we provide Jackson annotations for java 17 record class",
    "Body": "How can we create add field level annotations for java 17 record class?\nrecord Rectangle(double length, double width) { }\n\n",
    "AcceptedAnswerId": 70925601,
    "AcceptedAnswer": "yes we can use field level annotations (annotation with @Target(ElementType.FIELD) in the defination.\n@JsonInclude(Include.NON_NULL)\nrecord Rectangle(\n    @JsonProperty(\"lengthAlias\") double length,\n    double width) { }\n\n"
}
{
    "Id": 70819069,
    "PostTypeId": 1,
    "Title": "Springboot: Better handling of error messages",
    "Body": "I'm developing an API with Spring Boot and currently, I'm thinking about how to handle error messages in an easily internationalizable way. My goals are as follows:\n\nDefine error messages in resource files/bundles\nConnect constraint annotation with error messages (e.g., @Length) in a declarative fashion\nError messages contain placeholders, such as {min}, that are replaced by the corresponding value from the annotation, if available, e.g., @Length(min = 5, message = msg) would result in something like msg.replace(\"{min}\", annotation.min()).replace(\"{max}\", annotation.max()).\nThe JSON property path is also available as a placeholder and automatically inserted into the error message when a validation error occurs.\nA solution outside of an error handler is preferred, i.e., when the exceptions arrive in the error handler, they already contain the desired error messages.\nError messages from a resource bundle are automatically registered as constants in Java.\n\nCurrently, I customized the methodArgumentNotValidHandler of my error handler class to read ObjectErrors from e.getBindingResult().getAllErrors() and then try to extract their arguments and error codes to decide which error message to choose from my resource bundle and format it accordingly. A rough sketch of my code looks as follows:\nInput:\n@Data\n@RequiredArgsConstructor\npublic class RequestBody {\n  @NotNull\n  @NotBlank(message = ErrorConstants.NOT_BLANK)\n  @Length(min = 5, max = 255, message = ErrorConstants.LENGTH_MIN_MAX) // LENGTH_MIN_MAX = validation.length.min-max\n  private String greeting;\n}\n\nError handler:\n@ResponseBody\n@ExceptionHandler(MethodArgumentNotValidException.class)\n@ResponseStatus(HttpStatus.BAD_REQUEST)\nErrorMessage methodArgumentNotValidHandler(MethodArgumentNotValidException e) {\n  ObjectError objectError = e.getBindingResult().getAllErrors().get(0);\n  Object[] arguments = objectError.getArguments();\n  String messageCode = objectError.getDefaultMessage(); // e.g., \"validation.length.min-max\" (key in resource bundle)\n  ResourceBundle errMsgBundle = ResourceBundle.getBundle(\"errorMsg\");\n  String message;\n  if (objectError.getCode().equals(\"Length\")) {\n    String messageTemplate = errMsgBundle.getString(messageCode);\n    message = String.format(messageTemplate, arguments[2], arguments[1]);\n  } else {\n    message = \"Bad input, but I cannot tell you the problem because the programmer hasn't handled this yet. Sorry :'(\";\n  }\n  return new ErrorMessage(message);\n}\n\nUnfortunately, I suppose this approach is not maintainable. In the error handler, I will end up with a huge if-else block that has to probe several different situations (error codes, number of arguments, ...) and format error messages accordingly. Changing error messages will possibly result in having to change the code (e.g., the order of arguments). Each property key must be present as a constant in ErrorConstants, which I find undesirable. This code also doesn't query the name or path of the faulty property, e.g., \"name\".\nHence,\n\nis there a solution that can satisfy some or all of the above-mentioned requirements?\nAt which place would I implement this?\nIs there at least a better solution to the above one?\nAre there recipes or patterns in SpringBoot to handle validation errors (I'm definitely not the first one thinking about this)?\n\n",
    "AcceptedAnswerId": 70936114,
    "AcceptedAnswer": "After some digging around, I found the confirmation that what I was looking for was indeed built-in already as this is a question I expect every developer who want to acquit oneself well would ask. And indeed, this question has been asked already (I could have found it earlier if I would have verbalized my requirements correctly). I was just asking to customize my localized error messages via resource bundles.\nWhen I create the resource bundle in the resources folder containing my custom error messages and name it \"validation_errors.properties\", then I can make the validator using these messages by creating a corresponding bean:\n@Bean\npublic Validator validatorFactory (MessageSource messageSource) {\n    LocalValidatorFactoryBean validator =  new LocalValidatorFactoryBean();\n    validator.setValidationMessageSource(messageSource);\n    return validator;\n}\n\n@Bean\npublic MessageSource messageSource() {\n    ReloadableResourceBundleMessageSource bean = new ReloadableResourceBundleMessageSource();\n    bean.addBasenames(\"classpath:org.hibernate.validator.ValidationMessages\", \"classpath:validation_errors\"); // validation_errors.properties is my resource bundle\n    bean.setDefaultEncoding(\"UTF-8\");\n    return bean;\n}\n\nMy custom validator retrieves the validation messages from an instance of ReloadableResourceBundleMessageSource, which in turn retrieves them from a properties file.\nThe properties file contains the qualified path of the \"message\" parameter of a validation annotation as keys and values arbitrary strings, where strings in curly brackets are replaced by arguments from the validation annotation and SpEL expressions are evaluated.\njavax.validation.constraints.NotNull.message = Not null please!\njavax.validation.constraints.NotBlank.message = Not empty please!\norg.hibernate.validator.constraints.Length.message = String length between {min} and {max} please!\n\nNext, in my error handler, I need to detect and unpack if the ObjectError instance in MethodArgumentNotValidException contains a ConstraintViolation (to simplify this example, I ignore other error sources):\n@ResponseBody\n@ExceptionHandler(MethodArgumentNotValidException.class)\n@ResponseStatus(HttpStatus.BAD_REQUEST)\nList methodArgumentNotValidHandler(MethodArgumentNotValidException e) {\n    return e.getBindingResult().getAllErrors().stream()\n            .filter(objectError -> objectError.contains(ConstraintViolation.class))\n            .map(objectError -> objectError.unwrap(ConstraintViolation.class))\n            .map(ConstraintViolation::getMessage)\n            .map(message -> new ErrorMessage(\"VE-400\", message))\n            .collect(Collectors.toList());\n}\n\nThis solution meets requirements 1, 3, 5 and 6. Requirement 2 is considered invalid as it's tied to a specific solution that I had in mind when I asked this question. Requirement 4 remains open, SpEL might be a possibility to look further, otherwise I would continue exploring Tris answer.\n"
}
{
    "Id": 70957923,
    "PostTypeId": 1,
    "Title": "Save authenticated users to database coming from Azure AD",
    "Body": "I am working on a simple web app for learning purposes using Angular for the frontend and Java Spring for the backend. I don't have a particular problem that I want you guys to help me out with, instead I have a question about OAuth2 authentication.\nI have registered my Angular SPA in Azure AD (Authorization Code Flow + PKCE), I set up roles and everything is working okay. My question is what do I do when authenticated users ping my backend? My backend has no information about the users.\nI thought of a solution to make a web filter, and every time an authenticated user pings any endpoint requiring the user to be authenticated, to check the database if the user exists (through the username), and save him if he does not exist. I'm pretty sure this will work, but I don't think this is the best solution, considering my web filter will have to read from the databases for every single HTTP request that comes in, and write to the database occasionally (if the user logs in for the first time).\nI shouldn't be worried about performance issues because I'm building this strictly for learning purposes, but nevertheless I want to do this the right way. I tried googling this in multiple ways, but I guess I'm not using the right keywords to find what I'm looking for. Any opinion or advice would be much appreciated! Thanks!\nEDIT: I followed this article to achieve the OAuth2 + OIDC authentication and authorization, my security config in the backend is the same: https://ordina-jworks.github.io/security/2020/08/18/Securing-Applications-Azure-AD.html\n",
    "AcceptedAnswerId": 71068091,
    "AcceptedAnswer": "Post the discussion with clarity on the requirements. If you want to use have the following:\n\nAccept an Azure AD logged in user to consumer your web service\nYou would want to check if the user exists in your application database with minimal network latency.\n\nWith the requirement of not always hitting your Database, one option is to use a cache.\nThe ideal solution for this cache to work is:\n\nEnsure the cache is checked for every HTTP Request using Web Filter\nMake sure the cache is always updated with the latest users being logged in via Azure AD\n\nExample:\nImplement a CacheService.java\npackage com.example.springboot;\n\nimport java.util.Collections;\n\nimport org.apache.catalina.User;\nimport org.springframework.cache.CacheManager;\nimport org.springframework.cache.annotation.Cacheable;\nimport org.springframework.cache.concurrent.ConcurrentMapCache;\nimport org.springframework.cache.support.SimpleCacheManager;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.stereotype.Component;\n\n@Component\npublic class CacheService {\n\n  @Bean\n  public CacheManager cacheManager() {\n    SimpleCacheManager cacheManager = new SimpleCacheManager();\n    cacheManager.setCaches(Collections.singletonList(new ConcurrentMapCache(\"users\")));\n    return cacheManager;\n  }\n\n\n  @Cacheable(cacheNames = \"users\")\n  public User getUser(String username) {\n    // Code below will not execute after the first calling for the given username. \n    // So if one username is already cached, it would not invoke for the same user again from the DB.\n\n    // Get or Create a new user based on the Database call\n    return null;\n  }\n}\n\nThen implement a web filter like:\npackage com.example.springboot;\n\nimport java.io.IOException;\n\nimport javax.servlet.FilterChain;\nimport javax.servlet.ServletException;\nimport javax.servlet.ServletRequest;\nimport javax.servlet.ServletResponse;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Component;\nimport org.springframework.web.filter.GenericFilterBean;\n\n@Component\npublic class CredentialsInjectionFilter extends GenericFilterBean {\n\n  @Autowired\n  private CacheService cacheService;\n\n  @Override\n  public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse,\n      FilterChain filterChain) throws IOException, ServletException {\n\n    cacheService.getUser(\"my_username\");\n\n    filterChain.doFilter(servletRequest, servletResponse);\n  }\n}\n\nMore on Caching with Springboot: https://www.javadevjournal.com/spring/spring-caching/\n"
}
{
    "Id": 70914692,
    "PostTypeId": 1,
    "Title": "minio Unsupported OkHttp library found. Must use okhttp >= 4.8.1",
    "Body": "after using minio as instructions and fixing it with ways below, I failed.what can i do to solve this bug\n        \n        io.minio\n        minio\n        8.3.5\n        \n            \n                okhttp\n                com.squareup.okhttp3\n            \n        \n    \n    \n    \n        com.squareup.okhttp3\n        okhttp\n        4.9.3\n    \n\n\n",
    "AcceptedAnswerId": 71050627,
    "AcceptedAnswer": "I also experienced this issues with io.minio:minio:8.3.6, but was able to force a newer version of okhttp, which works with the MinIO client library. Here is the snippet of build.gradle (should work similar with Maven):\nimplementation(\"io.minio:minio:8.3.6\")    \nimplementation(\"com.squareup.okhttp3:okhttp:4.9.3\")\n\nIn my case it was probably caused by spring-boot-dependencies coming with the spring dependency plugin, which manages a lot of dependencies containing also okhttp and thus forces the downgrade.\nSee also:\n\nhttps://mvnrepository.com/artifact/org.springframework.boot/spring-boot-dependencies/2.6.3\nhttps://github.com/minio/minio-java/issues/1298\n\nUpdate\nWith Spring Boot 2.7.0, the fix is no longer required, since the version requirements for okhttp have been updated. The MinIO dependency should work now out of the box.\n"
}
{
    "Id": 71224833,
    "PostTypeId": 1,
    "Title": "Lambda expressions and anonymous classes don't work when loaded as hidden classes",
    "Body": "I am trying to compile and load dynamically generated Java code during runtime. Since both ClassLoader::defineClass and Unsafe::defineAnonymousClass have serious drawbacks in this scenario, I tried using hidden classes via Lookup::defineHiddenClass instead. This works fine for all classes that I tried to load, except for those that call lambda expressions or contain anonymous classes.\nCalling a lambda expression throws the following exception:\nException in thread \"main\" java.lang.NoClassDefFoundError: tests/HiddenClassLambdaTest$LambdaRunner/0x0000000800c04400\n    at tests.HiddenClassLambdaTest.main(HiddenClassLambdaTest.java:22)\nCaused by: java.lang.ClassNotFoundException: tests.HiddenClassLambdaTest$LambdaRunner.0x0000000800c04400\n    at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:636)\n    at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:182)\n    at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:519)\n    ... 1 more\n\nExecuting code that instantiates an anonymous class throws the following error:\nException in thread \"main\" java.lang.VerifyError: Bad type on operand stack\nException Details:\n  Location:\n    tests/HiddenClassLambdaTest$LambdaRunner+0x0000000800c00400.run()V @5: invokespecial\n  Reason:\n    Type 'tests/HiddenClassLambdaTest$LambdaRunner+0x0000000800c00400' (current frame, stack[2]) is not assignable to 'tests/HiddenClassLambdaTest$LambdaRunner'\n  Current Frame:\n    bci: @5\n    flags: { }\n    locals: { 'tests/HiddenClassLambdaTest$LambdaRunner+0x0000000800c00400' }\n    stack: { uninitialized 0, uninitialized 0, 'tests/HiddenClassLambdaTest$LambdaRunner+0x0000000800c00400' }\n  Bytecode:\n    0000000: bb00 1159 2ab7 0013 4cb1               \n\n    at java.base/java.lang.ClassLoader.defineClass0(Native Method)\n    at java.base/java.lang.System$2.defineClass(System.java:2193)\n    at java.base/java.lang.invoke.MethodHandles$Lookup$ClassDefiner.defineClass(MethodHandles.java:2446)\n    at java.base/java.lang.invoke.MethodHandles$Lookup$ClassDefiner.defineClassAsLookup(MethodHandles.java:2427)\n    at java.base/java.lang.invoke.MethodHandles$Lookup.defineHiddenClass(MethodHandles.java:2133)\n    at tests.HiddenClassLambdaTest.main(HiddenClassLambdaTest.java:25)\n\n\nThis is a short example that recreates the problem:\nimport java.lang.invoke.MethodHandles;\n\npublic class HiddenClassLambdaTest {\n    /** This class is to be loaded and executed as hidden class */\n    public static final class LambdaRunner implements Runnable {\n        @Override public void run() {\n            Runnable runnable = () -> System.out.println(\"Success\");\n            runnable.run();\n        }\n    }\n    \n    public static void main(String[] args) throws Throwable {\n        // Path to the class file of the nested class defined above\n        String nestedClassPath = HiddenClassLambdaTest.class.getTypeName().replace('.','/') + \"$LambdaRunner.class\";\n        // Class file content of the LambdaRunner class\n        byte[] classFileContents = HiddenClassLambdaTest.class.getClassLoader().getResourceAsStream(nestedClassPath).readAllBytes();\n        Class lambdaRunnerClass = MethodHandles.lookup().defineHiddenClass(classFileContents, true).lookupClass();\n        Runnable lambdaRunnerInstance = (Runnable) lambdaRunnerClass.getConstructor().newInstance();\n        lambdaRunnerInstance.run();\n    }\n}\n\nI've already tried compiling and running the code with different JDKs, using different ways to create new instances of the hidden class, searching for bugs at https://bugs.openjdk.java.net/, messing with the bytecode itself and several other things. I am not an expert on Java internals, so I am not sure whether I have not understood the JEP that introduced hidden classes correctly.\nAm I doing something wrong, is this just impossible or is this a bug?\nEdit: The JEP states\n\nMigration should take the following into account:\nTo invoke private nestmate instance methods from code in a hidden class, use invokevirtual or invokeinterface instead of invokespecial. Generated bytecode that uses invokespecial to invoke a private nestmate instance method will fail verification. invokespecial should only be used to invoke private nestmate constructors.\n\nThis might be the problem for the anonymous class. Is there a way to compile the code such that invokespecial is avoided in the bytecode?\n",
    "AcceptedAnswerId": 71242195,
    "AcceptedAnswer": "You can not turn arbitrary classes into hidden classes.\nThe documentation of defineHiddenClass contains the sentence\n\n\nOn any attempt to resolve the entry in the run-time constant pool indicated by this_class, the symbolic reference is considered to be resolved to C and resolution always succeeds immediately.\n\n\nWhat it doesn\u2019t spell out explicitly is that this is the only place where a type resolution ever ends up at the hidden class.\nBut it has been said unambiguously in bug report JDK-8222730:\n\nFor a hidden class, its specified hidden name should only be accessible through the hidden class's 'this_class' constant pool entry.\nThe class should not be accessible by specifying its original name in, for example, a method or field signature even within the hidden class.\n\nWhich we can check. Even a simple case like\npublic class HiddenClassLambdaTest {\n\n    public static void main(String[] args) throws Throwable {\n        byte[] classFileContents = HiddenClassLambdaTest.class\n            .getResourceAsStream(\"HiddenClassLambdaTest$LambdaRunner.class\")\n            .readAllBytes();\n        var hidden = MethodHandles.lookup()\n            .defineHiddenClass(classFileContents, true, ClassOption.NESTMATE);\n        Runnable lambdaRunnerInstance = (Runnable)hidden.findConstructor(\n            hidden.lookupClass(), MethodType.methodType(void.class)).invoke();\n        lambdaRunnerInstance.run();\n    }\n\n    static class LambdaRunner implements Runnable {\n        LambdaRunner field = this;\n\n        @Override\n        public void run() {\n        }\n    }\n}\n\nwill already fail. Note that it is a special case that the attempt to resolve the original class name LambdaRunner within the hidden class will not fail, as you used an existing class as template. So you get an IncompatibleClassChangeError or a VerifierError due to mismatches between the hidden class and the existing LambdaRunner class. When you don\u2019t use a class definition of an existing class, you\u2019d get a NoClassDefFoundError.\nThe same applies to\n    static class LambdaRunner implements Runnable {\n        static void method(LambdaRunner arg) {\n        }\n\n        @Override\n        public void run() {\n            method(this);\n        }\n    }\n\nAs the cited bug report said, neither field nor methods can refer to the hidden class in their signature.\nA less intuitive example is\n    static class LambdaRunner implements Runnable {\n        @Override\n        public void run() {\n            System.out.println(\"\" + this);\n        }\n    }\n\nwhich will fail depending on the compiler and options, as when the StringConcatFactory is used, the behavior is like an invocation of a method having all non-constant parts as parameters and returning a String. So this is another case of having the hidden class in a method signature.\n\nLambda expressions are special, as a class like\n    static class LambdaRunner implements Runnable {\n        @Override\n        public void run() {\n            Runnable runnable = () -> System.out.println(\"Success\");\n            runnable.run();\n        }\n    }\n\ngets compiled similar to\n    static class LambdaRunner implements Runnable {\n        @Override\n        public void run() {\n            Runnable runnable = LambdaRunner::lambdaBody;\n            runnable.run();\n        }\n        private static void lambdaBody() {\n            System.out.println(\"Success\");\n        }\n    }\n\nwhich doesn\u2019t have the hidden class in the method signature, but has to refer to the method holding the body of the lambda expression as a MethodReference. Within the constant pool, the description of this method refers to its declaring class using the this_class entry. So it gets redirected to the hidden class as described in the documentation.\nBut the construction of the MethodType as part of the MethodReference does not use this information to load a Class like a class literal would do. Instead, it tries to load the hidden class through the defining class loader, which fails with the NoClassDefFoundError you have posted.\nThis seems to be related to JDK-8130087 which suggests that ordinary method resolution differs from the way, MethodType works, which can make MethodType fail where just invoking the method would work.\nBut it\u2019s possible to demonstrate that even fixing this issue wouldn\u2019t solve the general problem:\n    static class LambdaRunner implements Runnable {\n        @Override\n        public void run() {\n            var lookup = MethodHandles.lookup();\n            var noArgVoid = MethodType.methodType(void.class);\n            try {\n                MethodHandle mh = LambdaMetafactory.metafactory(lookup, \"run\",\n                    MethodType.methodType(Runnable.class), noArgVoid,\n                    lookup.findStatic(LambdaRunner.class, \"lambdaBody\", noArgVoid),\n                    noArgVoid).getTarget();\n                System.out.println(\"got factory\");\n                Runnable runnable = (Runnable)mh.invokeExact();\n                System.out.println(\"got runnable\");\n                runnable.run();\n            }\n            catch(RuntimeException|Error e) {\n                throw e;\n            }\n            catch(Throwable e) {\n                throw new AssertionError(e);\n            }\n        }\n        private static void lambdaBody() {\n            System.out.println(\"Success\");\n        }\n    }\n\nThis bypasses the problem described above and calls the LambdaMetafactory manually. When being redefined as hidden class, it will print:\ngot factory\ngot runnable\nException in thread \"main\" java.lang.NoClassDefFoundError: test/HiddenClassLambdaTest$LambdaRunner/0x0000000800c01400\n    at test/test.HiddenClassLambdaTest.main(HiddenClassLambdaTest.java:15)\nCaused by: java.lang.ClassNotFoundException: test.HiddenClassLambdaTest$LambdaRunner.0x0000000800c01400\n    at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)\n    at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)\n    at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:521)\n    ... 1 more\n\nwhich shows that all obstacles have been circumvented, but when it comes to the actual invocation from the generated Runnable to the method holding the lambda body, it will fail due to the fact that the target class is hidden. A JVM with eager resolution of symbolic references might fail earlier, i.e. the example might not print got runnable then.\nUnlike the old JVM anonymous classes, there is no way to link to a hidden class, not even from another hidden class.\n\nThe bottom line is, as said at the beginning, you can not turn arbitrary classes into hidden classes. Lambda expressions are not the only feature not working with hidden classes. It\u2019s not a good idea to try and get surprised. Hidden classes should only be used in conjunction with bytecode generators carefully using only features known to work.\n"
}
{
    "Id": 71216665,
    "PostTypeId": 1,
    "Title": "build.gradle cannot resolve symbol 'groovy.json.JsonSlurper'",
    "Body": "I can't resolve the groovy.json.JsonSlurper in the build.gradle file with Intellij, does anyone know how to fix it?\n\nplugins {\n    id 'java'\n}\n\ngroup 'org.example'\nversion '1.0-SNAPSHOT'\n\nrepositories {\n    mavenCentral()\n}\n\ndependencies {\n    testImplementation 'org.junit.jupiter:junit-jupiter-api:5.8.1'\n    testRuntimeOnly 'org.junit.jupiter:junit-jupiter-engine:5.8.1'\n}\n\ntest {\n    useJUnitPlatform()\n}\n\n\n\ntask sample() {\n    doLast {\n        sample();\n    }\n}\n\nimport groovy.json.JsonSlurper\ndef sample(){\n    def json = new JsonSlurper().parseText('{\"a\":\"b\"}')\n    println(json);\n}\n\n\n\n",
    "AcceptedAnswerId": 71218832,
    "AcceptedAnswer": "You missing the needed dependency.\nAdd org.codehaus.groovy:groovy-json:3.0.9 in dependencies section so ti will look like\ndependencies {\n    testImplementation 'org.junit.jupiter:junit-jupiter-api:5.8.1'\n    testRuntimeOnly 'org.junit.jupiter:junit-jupiter-engine:5.8.1'\n    implementation 'org.codehaus.groovy:groovy-json:3.0.9'\n}\n\nAnd then you can test with CLI as gradle sample or ./gradlew sample and it will return {a=b}\n"
}
{
    "Id": 71020415,
    "PostTypeId": 1,
    "Title": "Manifest merger failed : android:exported needs to be explicitly specified for <receiver>",
    "Body": "\nMerging Errors: Error: android:exported needs to be explicitly specified for element\n.\nApps targeting Android 12 and higher are required to specify an\nexplicit value for android:exported when the corresponding component\nhas an intent filter defined. See\nhttps://developer.android.com/guide/topics/manifest/activity-element#exported\nfor details. test.app main manifest (this file), line 19\n\nI don't even know what to do. I struggled with this mistake for a whole week, but I couldn't.\nHere is my sdk version\ncompileSdkVersion 32\n    defaultConfig {\n        multiDexEnabled true\n        applicationId \"com.example.app\"\n        minSdkVersion 21\n        targetSdkVersion 32\n        versionCode 53\n        versionName \"2.0.4\"\n        ndk.abiFilters 'armeabi-v7a', 'arm64-v8a', 'x86', 'x86_64'\n        testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\"\n    }\n\nWrote android:exported on all intent-filter, service, and provider. Ah, I don't have the receiver mentioned in this error.\ndependencies {\n    implementation fileTree(dir: 'libs', include: ['*.jar'])\n\n    implementation 'androidx.appcompat:appcompat:1.4.1'\n    implementation 'com.google.android.material:material:1.5.0'\n    implementation 'androidx.constraintlayout:constraintlayout:2.1.3'\n\n    implementation \"com.android.billingclient:billing:4.0.0\"\n\n    implementation \"com.google.firebase:firebase-messaging:23.0.0\"\n    implementation \"com.google.firebase:firebase-crashlytics:18.2.7\"\n    implementation \"com.google.firebase:firebase-analytics:20.0.2\"\n    implementation \"com.google.firebase:firebase-perf:20.0.4\"\n    implementation \"com.google.firebase:firebase-dynamic-links:21.0.0\"\n\n    implementation 'com.google.firebase:firebase-core:20.0.2'\n    implementation 'com.google.firebase:firebase-database:20.0.3'\n    implementation 'com.google.firebase:firebase-auth:21.0.1'\n    implementation 'com.google.firebase:firebase-config:21.0.1'\n    implementation \"com.facebook.android:facebook-login:9.0.0\"\n    implementation \"com.facebook.android:facebook-share:[5,6)\"\n    implementation \"com.linecorp:linesdk:5.0.1\"\n\n    implementation 'org.jetbrains.kotlin:kotlin-stdlib:1.6.10'\n\n    implementation \"com.squareup.retrofit2:retrofit:2.8.1\"\n    implementation \"com.squareup.retrofit2:converter-gson:2.8.1\"\n    implementation 'com.squareup.retrofit2:adapter-rxjava:2.3.0'\n    implementation 'com.squareup.okhttp3:logging-interceptor:4.2.1'\n    implementation 'io.reactivex:rxandroid:1.2.1'\n\n    implementation 'com.google.code.gson:gson:2.8.6'\n\n    implementation 'com.sun.easysnackbar:easysnackbar:1.0.1'\n\n    implementation 'com.romandanylyk:pageindicatorview:1.0.3@aar'\n\n    implementation 'com.google.android.exoplayer:exoplayer:2.16.1'\n\n    //MULTI DEX\n    implementation \"androidx.multidex:multidex:2.0.1\"\n\n    implementation 'com.google.android:flexbox:2.0.1'\n\n    implementation 'com.github.florent37:diagonallayout:1.0.9'\n\n    implementation('io.socket:socket.io-client:1.0.0') {\n        exclude group: 'org.json', module: 'json'\n    }\n\n    implementation 'com.github.instacart.truetime-android:library:3.4'\n    implementation 'com.github.instacart.truetime-android:library-extension-rx:3.4'\n\n    implementation \"androidx.navigation:navigation-fragment-ktx:2.4.0\"\n    implementation \"androidx.navigation:navigation-ui-ktx:2.4.0\"\n\n    implementation \"com.github.bumptech.glide:glide:4.12.0\"\n    annotationProcessor \"com.github.bumptech.glide:compiler:4.12.0\"\n\n    implementation \"de.hdodenhof:circleimageview:3.1.0\"\n\n    implementation \"com.pixplicity.easyprefs:library:1.9.0\"\n\n    implementation \"com.jakewharton.timber:timber:4.7.1\"\n\n    implementation \"com.airbnb.android:lottie:3.4.0\"\n\n    implementation 'com.github.jinatonic.confetti:confetti:1.1.2'\n\n    implementation \"com.nabinbhandari.android:permissions:3.8\"\n\n    implementation 'androidx.legacy:legacy-support-v4:1.0.0'\n\n    implementation \"com.github.YarikSOffice:lingver:1.2.1\"\n\n    implementation 'com.github.mreram:showcaseview:1.2.0'\n    implementation 'com.github.shripal17:MaterialIntroView-v2:2.2.0'\n\n    implementation 'com.github.unsplash:unsplash-photopicker-android:1.0.0'\n\n    implementation 'com.giphy.sdk:ui:2.1.0'\n\n    testImplementation 'junit:junit:4.13.2'\n    testImplementation 'androidx.test:core:1.4.0'\n    androidTestImplementation 'androidx.test.espresso:espresso-core:3.4.0'\n    androidTestImplementation \"androidx.test.ext:junit:1.1.3\"\n}\n\n",
    "AcceptedAnswerId": 71020750,
    "AcceptedAnswer": "Found the issue with instacart.truetime library. You're using 3.4 version & they resolved this error in 3.5 as mentioned here: https://github.com/instacart/truetime-android/releases/tag/3.5\nSo you need to update these dependencies to the new version of 3.5\n    implementation 'com.github.instacart.truetime-android:library:3.5'\n    implementation 'com.github.instacart.truetime-android:library-extension-rx:3.5'\n\nBuild the app & it resolves the issue\n"
}
{
    "Id": 71296783,
    "PostTypeId": 1,
    "Title": "JUINT test giving error java.lang.reflect.InaccessibleObjectException: Unable to make protected void java.lang.Object.finalize()",
    "Body": "While running the test I am getting the error , I am not able to understand why am I getting this error , this code is working with fine in java 8 , while running it in java 17 it is giving error. googled this error but found nothing useful. Please help me to understand this error.\nThanks in advance:)\n@RunWith(PowerMockRunner.class)\n@PrepareForTest({PopulatedAuthorizedUser.class})\n@SpringBootTest(classes = MockServletContext.class)\n@PowerMockIgnore({\"javax.management.*\", \"javax.net.ssl.*\", \n\"jdk.internal.reflect.*\"})\npublic class ProjectUserControllerTest {\n\nprivate ProjectUserController controller;\n\nprivate UUID projectId = UUID.randomUUID();\nprivate UUID groupId = UUID.randomUUID();\nprivate String email = \"project.user@email.com\";\n\n@Mock\nprivate ProjectUserService projectUserService;\n\nprivate ObjectMapper objectMapper = new ObjectMapper();\n\n@Mock\nprotected AuthorizedUser au;\n\n@Before\npublic void setUp() throws Exception {\n    controller = new ProjectUserController();\n    FieldUtils.writeField(controller, \"projectUserService\", projectUserService, true);\n    FieldUtils.writeField(controller, \"objectMapper\", objectMapper, true);\n    PowerMockito.mockStatic(PopulatedAuthorizedUser.class);\n    Mockito.when(PopulatedAuthorizedUser.get()).thenReturn(mockAuthorizedUser());\n}\n\n@Test\npublic void testGetProjectUsers() {\n    Mockito.doReturn(Arrays.asList(mockProjectUser())).when(projectUserService)\n            .findProjectUsersByProjectId(projectId);\n    Mockito.doNothing().when(projectUserService).enrichUserDetails(any(ProjectUserDto.class));\n    ResponseEntity> response=controller.getProjectUsers(projectId);\n    assertNotNull(response);\n    ProjectUserDto projectUserDto = response.getBody().get(0);\n    assertEquals(groupId, projectUserDto.getGroupId());\n    assertEquals(email, projectUserDto.getUsername());\n    assertTrue(projectUserDto.getEmailNotification());\n    assertEquals(ProjectUserRole.OWNER.toString(), projectUserDto.getRole());\n   }\n\n }\n\nException:\n java.lang.reflect.InaccessibleObjectException: Unable to make protected void java.lang.Object.finalize() throws java.lang.Throwable accessible: module java.base does not \"opens java.lang\" to unnamed module @5ba23b66\n\nat java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:354)\nat java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:297)\nat java.base/java.lang.reflect.Method.checkCanSetAccessible(Method.java:199)\nat java.base/java.lang.reflect.Method.setAccessible(Method.java:193)\nat org.powermock.reflect.internal.WhiteboxImpl.doGetAllMethods(WhiteboxImpl.java:1492)\nat org.powermock.reflect.internal.WhiteboxImpl.getAllMethods(WhiteboxImpl.java:1467)\nat org.powermock.reflect.internal.WhiteboxImpl.findMethodOrThrowException(WhiteboxImpl.java:847)\nat org.powermock.reflect.internal.WhiteboxImpl.doInvokeMethod(WhiteboxImpl.java:807)\nat org.powermock.reflect.internal.WhiteboxImpl.invokeMethod(WhiteboxImpl.java:790)\nat org.powermock.reflect.Whitebox.invokeMethod(Whitebox.java:466)\nat org.powermock.modules.junit4.common.internal.impl.PowerMockJUnit4RunListener.testFinished(PowerMockJUnit4RunListener.java:55)\nat org.junit.runner.notification.SynchronizedRunListener.testFinished(SynchronizedRunListener.java:87)\nat org.junit.runner.notification.RunNotifier$9.notifyListener(RunNotifier.java:225)\nat org.junit.runner.notification.RunNotifier$SafeNotifier.run(RunNotifier.java:72)\nat org.junit.runner.notification.RunNotifier.fireTestFinished(RunNotifier.java:222)\nat org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.testAborted(PowerMockJUnit44RunnerDelegateImpl.java:229)\nat org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.invokeTestMethod(PowerMockJUnit44RunnerDelegateImpl.java:206)\nat org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.runMethods(PowerMockJUnit44RunnerDelegateImpl.java:160)\nat org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl$1.run(PowerMockJUnit44RunnerDelegateImpl.java:134)\nat org.junit.internal.runners.ClassRoadie.runUnprotected(ClassRoadie.java:34)\nat org.junit.internal.runners.ClassRoadie.runProtected(ClassRoadie.java:44)\nat org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.run(PowerMockJUnit44RunnerDelegateImpl.java:136)\nat org.powermock.modules.junit4.common.internal.impl.JUnit4TestSuiteChunkerImpl.run(JUnit4TestSuiteChunkerImpl.java:121)\nat org.powermock.modules.junit4.common.internal.impl.AbstractCommonPowerMockRunner.run(AbstractCommonPowerMockRunner.java:57)\nat org.powermock.modules.junit4.PowerMockRunner.run(PowerMockRunner.java:59)\nat org.junit.runner.JUnitCore.run(JUnitCore.java:137)\nat com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)\nat com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33)\nat com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:235)\nat com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:54)\n\n",
    "AcceptedAnswerId": 71296829,
    "AcceptedAnswer": "In Java 9 and above, the module system can cause these errors. I've had the same issues with JUnit 5 itself because I omit the public from my test classes and methods.\nHere's what I have in my POM to solve this:\n\n  org.apache.maven.plugins\n  maven-surefire-plugin\n  \n    \n    --add-opens /=ALL-UNNAMED\n  \n\n\nIn your case you probably need to use java.base/java.lang=ALL_UNNAMED.\n"
}
{
    "Id": 71044636,
    "PostTypeId": 1,
    "Title": "JMH using java 17, no dead code elimination",
    "Body": "I run sample JHM benchmark which suppose to show dead code elimination. Code is rewritten for conciseness from jhm github sample.\nimport org.openjdk.jmh.annotations.*;\nimport java.util.concurrent.TimeUnit;\n\n@State(Scope.Thread)\n@BenchmarkMode(Mode.AverageTime)\n@OutputTimeUnit(TimeUnit.NANOSECONDS)\n@Fork(1)\npublic class Sample08DeadCode {\n\n    private double x = Math.PI;\n\n    @Benchmark\n    public void benchmark() {}\n\n    @Benchmark\n    public void measureIncorrect() { Math.log(x); }\n\n    @Benchmark\n    public double measureCorrect() { return Math.log(x); }\n}\n\nRun using JDK 1.8.0_211, Java HotSpot(TM) 64-Bit Server VM, 25.211-b12 produces following results:\nBenchmark                          Mode  Cnt   Score   Error  Units\nSample08DeadCode.benchmark         avgt    5   0,229 \u00b1 0,018  ns/op\nSample08DeadCode.measureCorrect    avgt    5  12,013 \u00b1 0,047  ns/op\nSample08DeadCode.measureIncorrect  avgt    5   0,228 \u00b1 0,016  ns/op\n\nbut using java JDK 17.0.2, Java HotSpot(TM) 64-Bit Server VM, 17.0.2+8-LTS-86 the results have no sign of dead code elimination:\nBenchmark                          Mode  Cnt  Score   Error  Units\nSample08DeadCode.benchmark         avgt    5  0,341 \u00b1 0,004  ns/op\nSample08DeadCode.measureCorrect    avgt    5  6,244 \u00b1 0,072  ns/op\nSample08DeadCode.measureIncorrect  avgt    5  6,263 \u00b1 0,094  ns/op\n\nWhy does the measureIncorrect() method is not optimized using java 17?\n",
    "AcceptedAnswerId": 71053938,
    "AcceptedAnswer": "Those samples depend on JDK internals.\nLooks like since JDK 9 and JDK-8152907, Math.log is no longer intrinsified into C2 intermediate representation. Instead, a direct call to a quick LIBM-backed stub is made. This is usually faster for the code that actually uses the result. Notice how measureCorrect is faster in JDK 17 output in your case.\nBut for JMH samples, it limits the the compiler optimizations around the Math.log, and dead code / folding samples do not work properly. The fix it to make samples that do not rely on JDK internals without a good reason, and instead use a custom written payload.\nThis is being done in JMH here:\n\nhttps://bugs.openjdk.java.net/browse/CODETOOLS-7903094\nhttps://github.com/openjdk/jmh/pull/60\n\n"
}
{
    "Id": 71075781,
    "PostTypeId": 1,
    "Title": "How to add classpath dependencies in build.gradle project?",
    "Body": "After the Gradle update, every new project has this type of format in build.gradle (project:\"...\")\n// Top-level build file where you can add configuration options common to all sub-projects/modules.\nplugins {\n    id 'com.android.application' version '7.1.0' apply false\n    id 'com.android.library' version '7.1.0' apply false\n}\n\ntask clean(type: Delete) {\n    delete rootProject.buildDir\n}\n\nNow how can I add classpath dependencies here?\n",
    "AcceptedAnswerId": 71272079,
    "AcceptedAnswer": "If you are adding firebase to your Android App it needs to look something like below.\n\nbuildscript {\n    repositories {\n        // Check that you have the following line (if not, add it):\n        google()  // Google's Maven repository\n\n    }\n    dependencies {\n\n        // Add this line\n        classpath 'com.google.gms:google-services:4.3.10'\n\n    }\n}\n\n\n\nplugins {\n    id 'com.android.application' version '7.1.2' apply false\n    id 'com.android.library' version '7.1.2' apply false\n}\n\n\ntask clean(type: Delete) {\n    delete rootProject.buildDir\n}\n\n"
}
{
    "Id": 71494924,
    "PostTypeId": 1,
    "Title": "How does Java know which overloaded method to call with lambda expressions? (Supplier, Consumer, Callable, ...)",
    "Body": "First off, I have no idea how to decently phrase the question, so this is up for suggestions.\nLets say we have following overloaded methods:\nvoid execute(Callable callable) {\n    try {\n        callable.call();\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n}\n\n T execute(Supplier supplier) {\n    return supplier.get();\n}\n\nvoid execute(Runnable runnable) {\n    runnable.run();\n}\n\nGoing off from this table, I got from another SO question\nSupplier       ()    -> x\nConsumer       x     -> ()\nBiConsumer     x, y  -> ()\nCallable       ()    -> x throws ex\nRunnable       ()    -> ()\nFunction       x     -> y\nBiFunction     x,y   -> z\nPredicate      x     -> boolean\nUnaryOperator  x1    -> x2\nBinaryOperator x1,x2 -> x3\n\nThese are the results I get locally:\n// Runnable -> expected as this is a plain void  \nexecute(() -> System.out.println()); \n\n// Callable -> why is it not a Supplier? It does not throw any exceptions..\nexecute(() -> null);\n\n// Supplier -> this returns an Object, but how is that different from returning null?\nexecute(() -> new Object());\n\n// Callable -> because it can throw an exception, right?\nexecute(() -> {throw new Exception();});\n\nHow does the compiler know which method to call?\nHow does it for example make the distinction between what's a Callable and what's a Runnable?\n",
    "AcceptedAnswerId": 71496000,
    "AcceptedAnswer": "I believe I have found where this is described in official documentation, although a bit hard to read.\nHere is mentioned:\n\n15.27.3. Type of a Lambda Expression\nNote that while boxing is not allowed in a strict invocation context,\nboxing of lambda result expressions is always allowed - that is, the\nresult expression appears in an assignment context, regardless of the\ncontext enclosing the lambda expression. However, if an explicitly\ntyped lambda expression is an argument to an overloaded method, a\nmethod signature that avoids boxing or unboxing the lambda result is\npreferred by the most specific check (\u00a715.12.2.5).\n\nand then here (15.12.2.5) is described analytically how the most specific method is chosen.\nSo according to this for example as described\n\nOne applicable method m1 is more specific than another applicable\nmethod m2, for an invocation with argument expressions e1, ..., ek, if\nany of the following are true:\nm2 is generic, and m1 is inferred to be more specific than m2 for\nargument expressions e1, ..., ek\n\nSo\n// Callable -> why is it not a Supplier?\nexecute(() -> null);   <-- Callable shall be picked from 2 options as M2 is generic and M1 is inferred to be more specific\n\nvoid execute(Callable callable) {  // <------ M1 \n   try {\n    callable.call();\n  } catch (Exception e) {\n      e.printStackTrace();\n  }\n}\n\n\n  T execute(Supplier supplier) {  // <------ M2 is Generic\n    return supplier.get();\n }\n\nWhy M1 is inferred to be more specific can be traced down from this process described here (18.5.4 More Specific Method Inference)\n"
}
{
    "Id": 71500951,
    "PostTypeId": 1,
    "Title": "maven-checkstyle-plugin failed to parse Java 'record'",
    "Body": "I'm trying to setup checkstyle in our project - but seems like Maven (v3.8.3) or maven-checkstyle-plugin (v3.1.1) itself are not aware of Java 14's record (we use Java 17).\n\r\n\r\nCaused by: java.lang.IllegalStateException: /Users/dmitry.adonin/IdeaProjects/raap/src/main/java/com/xxx/web/dto/Request.java:3:8: unexpected token: record\n    at com.puppycrawl.tools.checkstyle.JavaParser$1.reportError (JavaParser.java:93)\n    at com.puppycrawl.tools.checkstyle.grammar.GeneratedJavaRecognizer.typeDefinition (GeneratedJavaRecognizer.java:411)\n    at com.puppycrawl.tools.checkstyle.grammar.GeneratedJavaRecognizer.compilationUnit (GeneratedJavaRecognizer.java:202)\n    at com.puppycrawl.tools.checkstyle.JavaParser.parse (JavaParser.java:99)\n    at com.puppycrawl.tools.checkstyle.TreeWalker.processFiltered (TreeWalker.java:159)\n    at com.puppycrawl.tools.checkstyle.api.AbstractFileSetCheck.process (AbstractFileSetCheck.java:85)\n    at com.puppycrawl.tools.checkstyle.Checker.processFile (Checker.java:329)\n    at com.puppycrawl.tools.checkstyle.Checker.processFiles (Checker.java:291)\n    at com.puppycrawl.tools.checkstyle.Checker.process (Checker.java:216)\n    at org.apache.maven.plugins.checkstyle.exec.DefaultCheckstyleExecutor.executeCheckstyle (DefaultCheckstyleExecutor.java:202)\n    at org.apache.maven.plugins.checkstyle.CheckstyleViolationCheckMojo.execute (CheckstyleViolationCheckMojo.java:545)\n    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:137)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:210)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:156)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:148)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:305)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:972)\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:293)\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:196)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:566)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:282)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:225)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:406)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:347)\nCaused by: antlr.NoViableAltException: unexpected token: record\n    at com.puppycrawl.tools.checkstyle.grammar.GeneratedJavaRecognizer.typeDefinitionInternal (GeneratedJavaRecognizer.java:584)\n    at com.puppycrawl.tools.checkstyle.grammar.GeneratedJavaRecognizer.typeDefinition (GeneratedJavaRecognizer.java:389)\n    at com.puppycrawl.tools.checkstyle.grammar.GeneratedJavaRecognizer.compilationUnit (GeneratedJavaRecognizer.java:202)\n    at com.puppycrawl.tools.checkstyle.JavaParser.parse (JavaParser.java:99)\n    at com.puppycrawl.tools.checkstyle.TreeWalker.processFiltered (TreeWalker.java:159)\n    at com.puppycrawl.tools.checkstyle.api.AbstractFileSetCheck.process (AbstractFileSetCheck.java:85)\n    at com.puppycrawl.tools.checkstyle.Checker.processFile (Checker.java:329)\n    at com.puppycrawl.tools.checkstyle.Checker.processFiles (Checker.java:291)\n    at com.puppycrawl.tools.checkstyle.Checker.process (Checker.java:216)\n    at org.apache.maven.plugins.checkstyle.exec.DefaultCheckstyleExecutor.executeCheckstyle (DefaultCheckstyleExecutor.java:202)\n    at org.apache.maven.plugins.checkstyle.CheckstyleViolationCheckMojo.execute (CheckstyleViolationCheckMojo.java:545)\n    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:137)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:210)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:156)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:148)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:305)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:972)\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:293)\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:196)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:566)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:282)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:225)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:406)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:347)\r\n\r\n\r\n\nThere are the following configs:\npom.xml:\n\r\n\r\n\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    4.0.0\n\n    \n        org.springframework.boot\n        spring-boot-starter-parent\n        2.6.2\n        \n    \n\n    ...\n    ...\n    0.0.1-SNAPSHOT\n    ...\n\n    \n        17\n    \n\n    \n    ...\n    \n\n    \n        \n            \n                org.springframework.boot\n                spring-boot-maven-plugin\n                \n                    \n                        \n                            org.projectlombok\n                            lombok\n                        \n                    \n                \n            \n            \n                org.apache.maven.plugins\n                maven-checkstyle-plugin\n                3.1.1\n                \n                    project-checks.xml\n                    UTF-8\n                    true\n                    true\n                    true\n                    false\n                \n                \n                    \n                        checkstyle-validation\n                        validate\n                        \n                            check\n                        \n                    \n                \n            \n        \n    \n\n\r\n\r\n\r\n\nproject-checks.xml:\n\r\n\r\n\n\n<!DOCTYPE module PUBLIC\n        \"-//Checkstyle//DTD Checkstyle Configuration 1.3//EN\"\n        \"https://checkstyle.org/dtds/configuration_1_3.dtd\">\n\n<!--\n    Checkstyle configuration that checks the Google coding conventions from Google Java Style\n    that can be found at https://google.github.io/styleguide/javaguide.html\n    Checkstyle is very configurable. Be sure to read the documentation at\n    https://checkstyle.org (or in your downloaded distribution).\n    To completely disable a check, just comment it out or delete it from the file.\n    To suppress certain violations please review suppression filters.\n    Authors: Max Vetrenko, Ruslan Diachenko, Roman Ivanov.\n -->\n\n\n    \n\n    \n\n    \n    \n    \n    \n        \n    \n    \n    \n    \n        \n        \n    \n\n    \n    \n    \n        \n    \n\n    \n        \n        \n        \n    \n\n    \n        \n        \n            \n            <property name=\"format\"\n                      value=\"\\\\u00(09|0(a|A)|0(c|C)|0(d|D)|22|27|5(C|c))|\\\\(0(10|11|12|14|15|42|47)|134)\"/>\n            <property name=\"message\"\n                      value=\"Consider using special escape sequence instead of octal value or Unicode escaped value.\"/>\n        \n        \n            \n            \n            \n        \n        \n        \n        \n        \n            \n        \n        \n            \n            <property name=\"tokens\"\n                      value=\"LITERAL_TRY, LITERAL_FINALLY, LITERAL_IF, LITERAL_ELSE, LITERAL_SWITCH\"/>\n        \n        \n            <property name=\"tokens\"\n                      value=\"LITERAL_DO, LITERAL_ELSE, LITERAL_FOR, LITERAL_IF, LITERAL_WHILE\"/>\n        \n        \n            <property name=\"tokens\"\n                      value=\"ANNOTATION_DEF, CLASS_DEF, CTOR_DEF, ENUM_CONSTANT_DEF, ENUM_DEF,\n                    INTERFACE_DEF, LAMBDA, LITERAL_CASE, LITERAL_CATCH, LITERAL_DEFAULT,\n                    LITERAL_DO, LITERAL_ELSE, LITERAL_FINALLY, LITERAL_FOR, LITERAL_IF,\n                    LITERAL_SWITCH, LITERAL_SYNCHRONIZED, LITERAL_TRY, LITERAL_WHILE, METHOD_DEF,\n                    OBJBLOCK, STATIC_INIT\"/>\n        \n        \n            \n            <property name=\"tokens\"\n                      value=\"LITERAL_TRY, LITERAL_CATCH, LITERAL_FINALLY, LITERAL_IF, LITERAL_ELSE,\n                    LITERAL_DO\"/>\n        \n        \n            \n            \n            <property name=\"tokens\"\n                      value=\"CLASS_DEF, METHOD_DEF, CTOR_DEF, LITERAL_FOR, LITERAL_WHILE, STATIC_INIT,\n                    INSTANCE_INIT, ANNOTATION_DEF, ENUM_DEF\"/>\n        \n        \n            \n            \n            <property name=\"query\" value=\"//RCURLY[parent::SLIST[count(./*)=1]\n                                                 or preceding-sibling::*[last()][self::LCURLY]]\"/>\n        \n        \n            \n            \n            \n            \n            \n            <property name=\"tokens\"\n                      value=\"ASSIGN, BAND, BAND_ASSIGN, BOR, BOR_ASSIGN, BSR, BSR_ASSIGN, BXOR,\n                    BXOR_ASSIGN, COLON, DIV, DIV_ASSIGN, DO_WHILE, EQUAL, GE, GT, LAMBDA, LAND,\n                    LCURLY, LE, LITERAL_CATCH, LITERAL_DO, LITERAL_ELSE, LITERAL_FINALLY,\n                    LITERAL_FOR, LITERAL_IF, LITERAL_RETURN, LITERAL_SWITCH, LITERAL_SYNCHRONIZED,\n                     LITERAL_TRY, LITERAL_WHILE, LOR, LT, MINUS, MINUS_ASSIGN, MOD, MOD_ASSIGN,\n                     NOT_EQUAL, PLUS, PLUS_ASSIGN, QUESTION, RCURLY, SL, SLIST, SL_ASSIGN, SR,\n                     SR_ASSIGN, STAR, STAR_ASSIGN, LITERAL_ASSERT, TYPE_EXTENSION_AND\"/>\n            <message key=\"ws.notFollowed\"\n                     value=\"WhitespaceAround: ''{0}'' is not followed by whitespace. Empty blocks may only be represented as '{}' when not part of a multi-block statement (4.1.3)\"/>\n            <message key=\"ws.notPreceded\"\n                     value=\"WhitespaceAround: ''{0}'' is not preceded with whitespace.\"/>\n        \n        \n        \n        \n        \n        \n        \n        \n        \n            <property name=\"tokens\"\n                      value=\"PACKAGE_DEF, IMPORT, STATIC_IMPORT, CLASS_DEF, INTERFACE_DEF, ENUM_DEF,\n                    STATIC_INIT, INSTANCE_INIT, METHOD_DEF, CTOR_DEF, VARIABLE_DEF\"/>\n            \n            \n            \n        \n        \n            \n            \n            \n        \n        \n            \n            \n            \n        \n        \n            \n            \n            \n            \n        \n        \n            \n            \n            \n            \n        \n        \n            \n            \n            \n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Package name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Type name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Member name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Parameter name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Lambda parameter name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Catch parameter name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Local variable name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Class type name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Method type name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Interface type name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Method name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n        \n            <message key=\"ws.followed\"\n                     value=\"GenericWhitespace ''{0}'' is followed by whitespace.\"/>\n            <message key=\"ws.preceded\"\n                     value=\"GenericWhitespace ''{0}'' is preceded with whitespace.\"/>\n            <message key=\"ws.illegalFollow\"\n                     value=\"GenericWhitespace ''{0}'' should followed by whitespace.\"/>\n            <message key=\"ws.notPreceded\"\n                     value=\"GenericWhitespace ''{0}'' is not preceded with whitespace.\"/>\n        \n        \n            \n            \n            \n            \n            \n            \n        \n        \n            \n            \n            <property name=\"tokens\"\n                      value=\"CLASS_DEF, INTERFACE_DEF, ENUM_DEF, ANNOTATION_DEF, ANNOTATION_FIELD_DEF,\n                    PARAMETER_DEF, VARIABLE_DEF, METHOD_DEF\"/>\n        \n        \n        \n        \n            \n            \n            \n            \n            \n            \n        \n        \n            <property name=\"tokens\"\n                      value=\"CTOR_DEF, LITERAL_NEW, METHOD_CALL, METHOD_DEF,\n                    SUPER_CTOR_CALL, ENUM_CONSTANT_DEF\"/>\n        \n        \n            <property name=\"tokens\"\n                      value=\"COMMA, SEMI, POST_INC, POST_DEC, DOT, ELLIPSIS, METHOD_REF\"/>\n            \n        \n        \n            <property name=\"tokens\"\n                      value=\"ANNOTATION, ANNOTATION_FIELD_DEF, CTOR_CALL, CTOR_DEF, DOT, ENUM_CONSTANT_DEF,\n                    EXPR, LITERAL_CATCH, LITERAL_DO, LITERAL_FOR, LITERAL_IF, LITERAL_NEW,\n                    LITERAL_SWITCH, LITERAL_SYNCHRONIZED, LITERAL_WHILE, METHOD_CALL,\n                    METHOD_DEF, QUESTION, RESOURCE_SPECIFICATION, SUPER_CTOR_CALL, LAMBDA\"/>\n        \n        \n            \n            <property name=\"tokens\"\n                      value=\"BAND, BOR, BSR, BXOR, DIV, EQUAL, GE, GT, LAND, LE, LITERAL_INSTANCEOF, LOR,\n                    LT, MINUS, MOD, NOT_EQUAL, PLUS, QUESTION, SL, SR, STAR, METHOD_REF \"/>\n        \n        \n            \n            <property name=\"tokens\"\n                      value=\"CLASS_DEF, INTERFACE_DEF, ENUM_DEF, METHOD_DEF, CTOR_DEF\"/>\n        \n        \n            \n            \n            \n        \n        \n        \n        \n        \n            <property name=\"forbiddenSummaryFragments\"\n                      value=\"^@return the *|^This method returns |^A [{]@code [a-zA-Z0-9]+[}]( is a )\"/>\n        \n        \n        \n            \n            <property name=\"target\"\n                      value=\"CLASS_DEF, INTERFACE_DEF, ENUM_DEF, METHOD_DEF, CTOR_DEF, VARIABLE_DEF\"/>\n        \n        \n            \n            \n            \n            \n            \n        \n        \n            \n        \n        \n            \n        \n        \n            \n        \n        \n        \n            \n            \n        \n    \n\r\n\r\n\r\n\nCould someone please suggest what should be adjusted to make it work?\nThank you!\n",
    "AcceptedAnswerId": 71501025,
    "AcceptedAnswer": "The plugin by default comes with Checkstyle version 8.29. Try explicitly defining the CheckStyle version (plus a small version bump to 3.1.2). For example, with version 9.2:\n\n    org.apache.maven.plugins\n    maven-checkstyle-plugin\n    3.1.2\n    \n       ...\n    \n    \n        \n            com.puppycrawl.tools\n            checkstyle\n            9.2\n        \n    \n    \n        ...\n    \n\n\n"
}
{
    "Id": 71361477,
    "PostTypeId": 1,
    "Title": "Targeting S+ (version 31 and above) requires that one of FLAG_IMMUTABLE or FLAG_MUTABLE",
    "Body": "when I launch my app in android 12, it crashed and it give me this error,\nmy project already have this dependency\nimplementation 'androidx.work:work-runtime-ktx:2.7.1'\n\nI updated\nimplementation 'com.google.firebase:firebase-messaging-ktx:23.0.0'\n\nfirebase messaging library too\nand I used pending intent in my project like this\n    val pendingIntent = PendingIntent.getActivity(\n        applicationContext,\n        0,\n        intent,\n        PendingIntent.FLAG_IMMUTABLE or PendingIntent.FLAG_UPDATE_CURRENT // setting the mutability flag\n    )\n\nerror :\nE/AndroidRuntime: FATAL EXCEPTION: OkHttp Dispatcher\nProcess: com.internal, PID: 11866\njava.lang.IllegalArgumentException: com.internal: Targeting S+ (version 31 and above) requires that one of FLAG_IMMUTABLE or FLAG_MUTABLE be specified when creating a PendingIntent.\nStrongly consider using FLAG_IMMUTABLE, only use FLAG_MUTABLE if some functionality depends on the PendingIntent being mutable, e.g. if it needs to be used with inline replies or bubbles.\n    at android.app.PendingIntent.checkFlags(PendingIntent.java:375)\n    at android.app.PendingIntent.getActivityAsUser(PendingIntent.java:458)\n    at android.app.PendingIntent.getActivity(PendingIntent.java:444)\n    at android.app.PendingIntent.getActivity(PendingIntent.java:408)\n    at com.chuckerteam.chucker.internal.support.NotificationHelper$transactionsScreenIntent$2.invoke(NotificationHelper.kt:47)\n    at com.chuckerteam.chucker.internal.support.NotificationHelper$transactionsScreenIntent$2.invoke(NotificationHelper.kt:19)\n    at kotlin.SynchronizedLazyImpl.getValue(LazyJVM.kt:74)\n    at com.chuckerteam.chucker.internal.support.NotificationHelper.getTransactionsScreenIntent(Unknown Source:2)\n    at com.chuckerteam.chucker.internal.support.NotificationHelper.show(NotificationHelper.kt:101)\n    at com.chuckerteam.chucker.api.ChuckerCollector.onRequestSent$com_github_ChuckerTeam_Chucker_library(ChuckerCollector.kt:65)\n    at com.chuckerteam.chucker.api.ChuckerInterceptor.intercept(ChuckerInterceptor.kt:111)\n    at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:109)\n    at com.android.core.helpers.interceptor.HeadersInterceptor.intercept(HeadersInterceptor.kt:41)\n    at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:109)\n    at com.android.core.helpers.AuthInterceptor.intercept(AuthInterceptor.kt:39)\n    at okhttp3.internal.http.RealInterceptorChain.proceed(RealInterceptorChain.kt:109)\n    at okhttp3.internal.connection.RealCall.getResponseWithInterceptorChain$okhttp(RealCall.kt:201)\n    at okhttp3.internal.connection.RealCall$AsyncCall.run(RealCall.kt:517)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)\n    at java.lang.Thread.run(Thread.java:920)\nE/WebEngage: App has crashed\n    java.lang.IllegalArgumentException: com.internal: Targeting S+ (version 31 and above) requires that one of FLAG_IMMUTABLE or FLAG_MUTABLE be specified when creating a PendingIntent.\n    Strongly consider using FLAG_IMMUTABLE, only use FLAG_MUTABLE if some functionality depends on the PendingIntent being mutable, e.g. if it needs to be used with inline replies or bubbles.\n\n",
    "AcceptedAnswerId": 71370528,
    "AcceptedAnswer": "I finally found the problem,\nI had chucker library and I updated it to the latest version and it fixed\n"
}
{
    "Id": 71063202,
    "PostTypeId": 1,
    "Title": "check valid date in java",
    "Body": "I tried to check a String input that is a valid date using the format dd/MM/yyyy like this:\nString input = Scanner.nextLine();\nDateTimeFormatter formater = DateTimeFormatter.ofPattern(\"dd/MM/yyyy\");\ntry{\n    LocaleDate.parse(input, formater);\n}\ncatch(Exception e)\n\nBut it can't check some rules below:\nLeap year, February 29 days.\n\nCommon year, February 28 days.\n\nMonth 1, 3, 5, 7, 8, 10, 12, max 31 days.\n\nMonth 4, 6, 9, 11, max 30 days.\n\nWhen I use input = \"30/02/2022\", it's legal.\nI use netbeans 8.2 and jdk 1.8. Do they support some methods for checking these rules?\n",
    "AcceptedAnswerId": 71063276,
    "AcceptedAnswer": "There are two things you need to change in your formatter:\n\nUse uuuu instead of yyyy. It's easy to try the latter, but y means \"year within ERA\". It doesn't know whether it's BC or AD. u means \"year\" including ERA information.\nThe default resolver style is SMART. Use .withResolverStyle(ResolverStyle.STRICT) to return a strict copy of the formatter.\n\n"
}
{
    "Id": 71250218,
    "PostTypeId": 1,
    "Title": "Java, project panama and how to deal with Hunspell 'suggest' result",
    "Body": "I'm experimenting with Hunspell and how to interact with it using Java Project Panama (Build 19-panama+1-13 (2022/1/18)). I was able to get some initial testing done, as in creating a handle to Hunspell and subsequently using that to perform a spell check. I'm now trying something more elaborate, letting Hunspell give me suggestions for a word not present in the dictionary. This is the code that I have for that now:\npublic class HelloHun {\n    public static void main(String[] args) {\n        MemoryAddress hunspellHandle = null;\n        try (ResourceScope scope = ResourceScope.newConfinedScope()) {\n            var allocator = SegmentAllocator.nativeAllocator(scope);\n\n            // Point it to US english dictionary and (so called) affix file\n            // Note #1: it is possible to add words to the dictionary if you like\n            // Note #2: it is possible to have separate/individual dictionaries and affix files (e.g. per user/doc type)\n            var en_US_aff = allocator.allocateUtf8String(\"/usr/share/hunspell/en_US.aff\");\n            var en_US_dic = allocator.allocateUtf8String(\"/usr/share/hunspell/en_US.dic\");\n\n            // Get a handle to the Hunspell shared library and load up the dictionary and affix\n            hunspellHandle = Hunspell_create(en_US_aff, en_US_dic);\n\n            // Feed it a wrong word\n            var javaWord = \"koing\";\n\n            // Do a simple spell check of the word\n            var word = allocator.allocateUtf8String(javaWord);\n            var spellingResult = Hunspell_spell(hunspellHandle, word);\n            System.out.println(String.format(\"%s is spelled %s\", javaWord, (spellingResult == 0 ? \"incorrect\" : \"correct\")));\n\n            // Hunspell also supports giving suggestions for a word - which is what we do next\n            // Note #3: by testing this `koing` word in isolation - we know that there are 4 alternatives for this word\n            // Note #4: I'm still investigating how to access individual suggestions\n\n            var suggestions = allocator.allocate(10);\n            var suggestionCount = Hunspell_suggest(hunspellHandle, suggestions, word);\n\n            System.out.println(String.format(\"There are %d suggestions for %s\", suggestionCount, javaWord));\n\n            // `suggestions` - according to the hunspell API - is a `pointer to an array of strings pointer`\n            // we know how many `strings` pointer there are, as that is the returned value from `suggest`\n            // Question: how to process `suggestions` to get individual suggestions\n\n\n        } finally {\n            if (hunspellHandle != null) {\n                Hunspell_destroy(hunspellHandle);\n            }\n        }\n    }\n}\n\nWhat I'm seeing is that a call to Hunspell_suggest (created from jextract) succeeds and gives me back (4) suggestions (which I verified using Hunspell from the commandline) - so no problem there.\nWhat is more challenging for me now is how do I unpack the suggestions element that comes back from this call? I've been looking at various examples, but none of them seem to go into this level of detail (and even if I find examples, they seem to be using outdated panama APIs).\nSo in essence, here is my question:\nHow do I unpack a structure that reportedly consists of a pointer to an array of strings pointer using panama JDK19 APIs to their respective collection of strings?\n",
    "AcceptedAnswerId": 71258371,
    "AcceptedAnswer": "Looking at the header here: https://github.com/hunspell/hunspell/blob/master/src/hunspell/hunspell.h#L80\n/* suggest(suggestions, word) - search suggestions\n * input: pointer to an array of strings pointer and the (bad) word\n *   array of strings pointer (here *slst) may not be initialized\n * output: number of suggestions in string array, and suggestions in\n *   a newly allocated array of strings (*slts will be NULL when number\n *   of suggestion equals 0.)\n */\nLIBHUNSPELL_DLL_EXPORTED int Hunspell_suggest(Hunhandle* pHunspell,\n                                              char*** slst,\n                                              const char* word);\n\nThe slst is a classic 'out' parameter. i.e. we pass a pointer to some value (in this case a char** i.e. an array of strings), and the function will set this pointer for us, as a way to return multiple results. (the first result being the number of suggestions)\nIn panama you use 'out' parameters by allocating a segment with the layout of the type the parameter is a pointer of. In this case char*** is a pointer to char**, so the layout is ADDRESS. We then pass the created segment to the function, and finally retrieve/use the value from that segment after the function call, which will have filled in the segment contents:\n// char***\nvar suggestionsRef = allocator.allocate(ValueLayout.ADDRESS); // allocate space for an address\nvar suggestionCount = Hunspell_suggest(hunspellHandle, suggestionsRef, word);\n// char** (the value set by the function)\nMemoryAddress suggestions = suggestionsRef.get(ValueLayout.ADDRESS, 0);\n\nAfter that, you can iterate over the array of strings:\nfor (int i = 0; i < suggestionCount; i++) {\n    // char* (an element in the array)\n    MemoryAddress suggestion = suggestions.getAtIndex(ValueLayout.ADDRESS, i);\n    // read the string\n    String javaSuggestion = suggestion.getUtf8String(suggestion, 0);\n}\n\n"
}
{
    "Id": 71587610,
    "PostTypeId": 1,
    "Title": "Micrometer @Timed annotation on simple public and private (service) methods",
    "Body": "I'm trying to apply Prometheus metrics using the micrometer @Timed annotations.\nI found out that they only work on controller endpoints and not \"simple\" public and private methods.\nGiven this example:\n@RestController\npublic class TestController {\n\n    @GetMapping(\"/test\")\n    @Timed(\"test-endpoint\") //does create prometheus metrics\n    public String test() {\n        privateMethod();\n        publicMethod();\n        return \"test\";\n    }\n\n    @Timed(\"test-private\") //does NOT create prometheus metrics\n    private void privateMethod() {System.out.println(\"private stuff\");}\n\n    @Timed(\"test-public\") //does NOT create prometheus metrics\n    public void publicMethod() {System.out.println(\"public stuff\");}\n}\n\ncreates the following metrics:\n...\n# HELP test_endpoint_seconds  \n# TYPE test_endpoint_seconds summary\ntest_endpoint_seconds_count{class=\"com.example.micrometerannotationexample.TestController\",exception=\"none\",method=\"test\",} 1.0\ntest_endpoint_seconds_sum{class=\"com.example.micrometerannotationexample.TestController\",exception=\"none\",method=\"test\",} 0.0076286\n# HELP test_endpoint_seconds_max  \n# TYPE test_endpoint_seconds_max gauge\ntest_endpoint_seconds_max{class=\"com.example.micrometerannotationexample.TestController\",exception=\"none\",method=\"test\",} 0.0076286\n...\n\nNo metrics found for @Timed(\"test-private\") and @Timed(\"test-public\"), why is that?\n\nNote: I've read on this github thread, that Spring Boot does not recognize @Timed annotations on arbitrary methods and that you need to manually configure a TimedAspect Bean in order for it to work. I've tried that but still it yields no results.\n@Configuration\n@EnableAspectJAutoProxy\npublic class MetricsConfig {\n    @Bean\n    public TimedAspect timedAspect(MeterRegistry registry) {\n        return new TimedAspect(registry);\n    }\n}\n\nTo try this locally see necessary gist here\n",
    "AcceptedAnswerId": 71602539,
    "AcceptedAnswer": "@Timed works only on public methods called by another class.\nSpring Boot annotations like @Timed / @Transactional need the so-called proxying which happens only between invocations of public methods.\nA good explanation is this one https://stackoverflow.com/a/3429757/2468241\n"
}
{
    "Id": 70938297,
    "PostTypeId": 1,
    "Title": "How to add classpath in new version of Android Studio",
    "Body": "I updated my android studio version to bumblebee version.\nNow I want add navigation component to my project.\nI want add classpath to gradle, but this file gradle has been changed and I don'y know how can I add this.\nI want add this        classpath(\"androidx.navigation:navigation-safe-args-gradle-plugin:$nav_version\") to gradle files!\nMy project gradle file is :\n    plugins {\n    id 'com.android.application' version '7.1.0' apply false\n    id 'com.android.library' version '7.1.0' apply false\n    id 'org.jetbrains.kotlin.android' version '1.6.10' apply false\n}\n\ntask clean(type: Delete) {\n    delete rootProject.buildDir\n}\n\nHow can I add this classpath to application gradle ?!\n",
    "AcceptedAnswerId": 71410793,
    "AcceptedAnswer": "In the latest version in February 2022 doesn't need to add buildscript anymore just add the id in build.gradle for project. It will be like this in build.gradle for project:\nplugins {\n    id 'com.android.application' version '7.1.2' apply false\n    id 'com.android.library' version '7.1.2' apply false\n    id 'org.jetbrains.kotlin.android' version '1.6.10' apply false\n\n    id 'androidx.navigation.safeargs' version '2.4.1' apply false\n    // classpath are changed, so no need to add classpath anymore just the id and the version\n}\n\nDon't forget add the id again in the build.gradle module,\nplugins {\n    id 'com.android.application'\n    id 'org.jetbrains.kotlin.android'\n    id 'androidx.navigation.safeargs'\n}\n\n"
}
{
    "Id": 71724227,
    "PostTypeId": 1,
    "Title": "When to use and not use @Mock annotation, @MockBean annotation, @InjectMock annotation & @Autowired annotation in a spring webflux reactive project",
    "Body": "Can you please explain when to use below annotations and when not to use those. I am pretty new to testing frameworks and confused with all the answers in the web.\n@Mock\nprivate Resource resource;\n@MockBean\nprivate Resource resource;\n@InjectMock\nprivate ProductService productService; \n@AutoWired\nPrivate ProductRepository productRepo;\n\n",
    "AcceptedAnswerId": 71724474,
    "AcceptedAnswer": "@Mock\nUsed to make Mockito create a mock object.\n@InjectMock\nWhen you want Mockito to create an instance of an object and use the mocks annotated with @Mock as its dependencies.\n@AutoWired\nUsed when you want to autowire a bean from the spring context, works exactly the same as in normal code but can only be used in tests that actually creates an application context, such as tests annotated with @WebMvcTest or @SpringBootTest.\n@MockBean\nCan be used to add mock objects to the Spring application context. The mock will replace any existing bean of the same type in the application context. If no bean of the same type is defined, a new one will be added. Often used together with @SpringBootTest\nSo normally you either:\n\nUse @Mock and @InjectMocks for running tests without a spring\ncontext, this is preferred as it's much faster.\nUse @SpringBootTest or @SpringMvcTest to start a spring context together with @MockBean to create mock objects and @Autowired to get an instance of class you want to test, the mockeans will be used for its autowired dependencies. You use this when writing integration tests for code that interact with a database or want to test your REST API.\n\n"
}
{
    "Id": 71029574,
    "PostTypeId": 1,
    "Title": "Firebase Push notification not receiving in Android12 in Samsung S10 Device After updating Patch Update",
    "Body": "I am using a Samsung Galaxy S10 mobile. On February 3rd Security patch was updated on my phone. After the update Push notification was not received in my App. Other App notifications are working fine. Anyone can answer my question, please? What was the reason for not receiving notification?\n",
    "AcceptedAnswerId": 71506283,
    "AcceptedAnswer": "The answer could be because the PendingIntent for that app's notifications hasn't had its mutability defined. Starting from Android 12, you have to define whether a PendingIntent is immutable or mutable for it to work properly:\nhttps://developer.android.com/about/versions/12/behavior-changes-12#pending-intent-mutability\nAnother thing to try to make notifications work again is to add the \"exported:false\" tag to the notifications service:\nhttps://developer.android.com/about/versions/12/behavior-changes-12#exported\nThat should help.\n"
}
{
    "Id": 71338792,
    "PostTypeId": 1,
    "Title": "java.lang.NoClassDefFoundError: Failed resolution of: Ljava/lang/Math8 when upgrading Gradle and Android Gradle Plugin",
    "Body": "I'm working on an Android app with a Gradle version of 7.1.1 and an Android Gradle Plugin version of 7.0.0. When I upgrade to Gradle version 7.2 and Android Gradle Plugin version 7.1.1, I get the following error.\n2022-03-02 17:15:47.072 25300-25300/... E/AndroidRuntime: FATAL EXCEPTION: main\n    Process: ..., PID: 25300\n    java.lang.NoClassDefFoundError: Failed resolution of: Ljava/lang/Math8;\n        at j$.time.Instant.ofEpochSecond(Instant.java:328)\n        at j$.time.Instant.(Instant.java:232)\n        at j$.time.Instant.ofEpochMilli(Instant.java:344)\n        ...\n        at kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)\n        at kotlinx.coroutines.DispatchedTask.run(DispatchedTask.kt:106)\n        at android.os.Handler.handleCallback(Handler.java:883)\n        at android.os.Handler.dispatchMessage(Handler.java:100)\n        at android.os.Looper.loop(Looper.java:214)\n        at android.app.ActivityThread.main(ActivityThread.java:7356)\n        at java.lang.reflect.Method.invoke(Native Method)\n        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:492)\n        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:930)\n     Caused by: java.lang.ClassNotFoundException: Didn't find class \"java.lang.Math8\" on path: DexPathList[[zip file \"/data/app/...-NbMXeOj8LumN03n4IMK5Cw==/base.apk\"],nativeLibraryDirectories=[/data/app/...-NbMXeOj8LumN03n4IMK5Cw==/lib/x86, /data/app/...-NbMXeOj8LumN03n4IMK5Cw==/base.apk!/lib/x86, /system/lib, /system/product/lib]]\n        at dalvik.system.BaseDexClassLoader.findClass(BaseDexClassLoader.java:196)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:379)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:312)\n        at j$.time.Instant.ofEpochSecond(Instant.java:328) \n        at j$.time.Instant.(Instant.java:232) \n        at j$.time.Instant.ofEpochMilli(Instant.java:344) \n        ...\n        at kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33) \n        at kotlinx.coroutines.DispatchedTask.run(DispatchedTask.kt:106) \n        at android.os.Handler.handleCallback(Handler.java:883) \n        at android.os.Handler.dispatchMessage(Handler.java:100) \n        at android.os.Looper.loop(Looper.java:214) \n        at android.app.ActivityThread.main(ActivityThread.java:7356) \n        at java.lang.reflect.Method.invoke(Native Method) \n        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:492) \n        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:930)\n\nThe error is coming from this code:\nfun toLocalStartOfDay(date: Long): Instant = Instant.ofEpochMilli(date)\n    .atZone(ZoneId.systemDefault())\n    .withHour(0)\n    .withMinute(0)\n    .withSecond(0)\n    .withNano(0)\n    .toInstant()\n\nThe build.gradle file is set to target JVM 1.8 with desugaring.\ncompileOptions {\n    coreLibraryDesugaringEnabled = true\n    sourceCompatibility JavaVersion.VERSION_1_8\n    targetCompatibility JavaVersion.VERSION_1_8\n}\n\nkotlinOptions {\n    jvmTarget = '1.8'\n}\n\nThe desugar_jdk_libs version is set to 1.0.9.\nversions.androidDesugaringVersion = '1.0.9'\nsupport.android_desugaring = \"com.android.tools:desugar_jdk_libs:$versions.androidDesugaringVersion\"\n\nWhy would upgrading cause this error?\n",
    "AcceptedAnswerId": 71340133,
    "AcceptedAnswer": "Desugaring effects \"a subset of java.time\" so upgrading to the latest version of desugar_jdk_libs should fix the issue. At the time of posting, the latest version is 1.1.5.\nReferences\n\nJava 8+ API desugaring support (Android Gradle Plugin 4.0.0+)\ndesugar_jdk_libs (Maven)\n\n"
}
{
    "Id": 71722390,
    "PostTypeId": 1,
    "Title": "Log4J2 AppenderLoggingException NoSuchMethodError StackLocatorUtil.getCurrentStackTrace()",
    "Body": "As soon as an exception/error occurs and is supposed to be logged, I get the following error/stack trace:\norg.apache.logging.log4j.core.appender.AppenderLoggingException: java.lang.NoSuchMethodError: 'java.util.Deque org.apache.logging.log4j.util.StackLocatorUtil.getCurrentStackTrace()'\n   at org.apache.logging.log4j.core.config.AppenderControl.tryCallAppender(AppenderControl.java:165)\n   at org.apache.logging.log4j.core.config.AppenderControl.callAppender0(AppenderControl.java:134)\n   at org.apache.logging.log4j.core.config.AppenderControl.callAppenderPreventRecursion(AppenderControl.java:125)\n   at org.apache.logging.log4j.core.config.AppenderControl.callAppender(AppenderControl.java:89)\n   at org.apache.logging.log4j.core.config.LoggerConfig.callAppenders(LoggerConfig.java:675)\n   at org.apache.logging.log4j.core.config.LoggerConfig.processLogEvent(LoggerConfig.java:633)\n   at org.apache.logging.log4j.core.config.LoggerConfig.log(LoggerConfig.java:616)\n   at org.apache.logging.log4j.core.config.LoggerConfig.log(LoggerConfig.java:552)\n   at org.apache.logging.log4j.core.config.AwaitCompletionReliabilityStrategy.log(AwaitCompletionReliabilityStrategy.java:82)\n   at org.apache.logging.log4j.core.Logger.log(Logger.java:161)\n   at org.apache.logging.log4j.spi.AbstractLogger.tryLogMessage(AbstractLogger.java:2205)\n   at org.apache.logging.log4j.spi.AbstractLogger.logMessageTrackRecursion(AbstractLogger.java:2159)\n   at org.apache.logging.log4j.spi.AbstractLogger.logMessageSafely(AbstractLogger.java:2142)\n   at org.apache.logging.log4j.spi.AbstractLogger.logMessage(AbstractLogger.java:2017)\n   at org.apache.logging.log4j.spi.AbstractLogger.logIfEnabled(AbstractLogger.java:1983)\n   at org.apache.logging.log4j.spi.AbstractLogger.fatal(AbstractLogger.java:1063)\n\nthe next at is whatever called Logger#fatal/error(String,Throwable)\nJava 11, Log4J 2.17.2 (-core and -api), project built using Gradle. removing Multi-Release: true from build.gradle doesn't seem to fix the issue (only adds the, to be expected, Reflection.getCallerClass() warning)\nWhat am I missing?\n",
    "AcceptedAnswerId": 71729253,
    "AcceptedAnswer": "Turns out a library had the dependency Log4J-api 2.17.1 (but not -core), my gradle file specified Log4J-core 2.17.2 so the older -api version overrid the latest one.\nApparently, from 2.17.1 to .2, StackLocatorUtil.getCurrentStackTrace()'s return was changed from Stack to Deque.\n"
}
{
    "Id": 71771423,
    "PostTypeId": 1,
    "Title": "React Native: 'compileJava' task (current target is 1.8) and 'compileKotlin' task (current target is 11) jvm target compat",
    "Body": "Hello everyone I am trying to create and run a react native app. I run\nnpx react-native init rn4 but when I run npm run android I have this error:\n> Task :react-native-gradle-plugin:compileKotlin\n'compileJava' task (current target is 1.8) and 'compileKotlin' task (current target is 11) jvm target compatibility should be set to the same Java version.\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\ReactExtension.kt: (10, 37): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\ReactExtension.kt: (119, 30): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\ReactExtension.kt: (135, 26): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\ReactExtension.kt: (155, 32): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\ReactExtension.kt: (161, 31): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\ReactExtension.kt: (169, 36): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\ReactPlugin.kt: (99, 48): 'reactRoot: DirectoryProperty' is deprecated. reactRoot was confusing and has been replace with rootto point to your root project and reactNativeDir to point to the folder of the react-native NPM package\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\TaskConfiguration.kt: (10, 37): 'ApplicationVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\TaskConfiguration.kt: (11, 37): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\TaskConfiguration.kt: (12, 37): 'LibraryVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\TaskConfiguration.kt: (28, 51): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\TaskConfiguration.kt: (131, 12): 'ApplicationVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\TaskConfiguration.kt: (132, 12): 'LibraryVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\TaskConfiguration.kt: (250, 14): 'BaseVariant' is deprecated. Deprecated in Java\n\n> Task :react-native-gradle-plugin:compileJava\n6 actionable tasks: 6 executed\nNote: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\java\\com\\facebook\\react\\codegen\\generator\\SchemaJsonParser.java uses or overrides a deprecated API.\nNote: Recompile with -Xlint:deprecation for details.\n\nFAILURE: Build failed with an exception.\n\n* Where:\nBuild file 'C:\\Users\\emanu\\App\\rn4\\android\\app\\build.gradle' line: 1\n\n* What went wrong:\nA problem occurred evaluating project ':app'.\n> Failed to apply plugin 'com.android.internal.application'.\n   > Android Gradle plugin requires Java 11 to run. You are currently using Java 1.8.\n     You can try some of the following options:\n       - changing the IDE settings.\n       - changing the JAVA_HOME environment variable.\n       - changing `org.gradle.java.home` in `gradle.properties`.\n\n* Try:\n> Run with --stacktrace option to get the stack trace.\n> Run with --info or --debug option to get more log output.\n> Run with --scan to get full insights.\n\n* Get more help at https://help.gradle.org\n\nBUILD FAILED in 59s\n\nerror Failed to install the app. Make sure you have the Android development environment set up: https://reactnative.dev/docs/environment-setup.\nError: Command failed: gradlew.bat app:installDebug -PreactNativeDevServerPort=8081\nNote: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\java\\com\\facebook\\react\\codegen\\generator\\SchemaJsonParser.java uses or overrides a deprecated API.\nNote: Recompile with -Xlint:deprecation for details.\n\nFAILURE: Build failed with an exception.\n\n* Where:\nBuild file 'C:\\Users\\emanu\\App\\rn4\\android\\app\\build.gradle' line: 1\n\n* What went wrong:\nA problem occurred evaluating project ':app'.\n> Failed to apply plugin 'com.android.internal.application'.\n   > Android Gradle plugin requires Java 11 to run. You are currently using Java 1.8.\n     You can try some of the following options:\n       - changing the IDE settings.\n       - changing the JAVA_HOME environment variable.\n       - changing `org.gradle.java.home` in `gradle.properties`.\n\n* Try:\n> Run with --stacktrace option to get the stack trace.\n> Run with --info or --debug option to get more log output.\n> Run with --scan to get full insights.\n\n* Get more help at https://help.gradle.org\n\nBUILD FAILED in 59s\n\n    at makeError (C:\\Users\\emanu\\App\\rn4\\node_modules\\execa\\index.js:174:9)\n    at C:\\Users\\emanu\\App\\rn4\\node_modules\\execa\\index.js:278:16\n    at processTicksAndRejections (node:internal/process/task_queues:96:5)\n    at async runOnAllDevices (C:\\Users\\emanu\\App\\rn4\\node_modules\\@react-native-community\\cli-platform-android\\build\\commands\\runAndroid\\runOnAllDevices.js:109:5)\n    at async Command.handleAction (C:\\Users\\emanu\\App\\rn4\\node_modules\\@react-native-community\\cli\\build\\index.js:192:9)\ninfo Run CLI with --verbose flag for more details.\n\nI also run cd android && ./gradlew clean and the output is:\nFAILURE: Build failed with an exception.\n\n* Where:\nBuild file 'C:\\Users\\emanu\\App\\rn4\\android\\app\\build.gradle' line: 1\n\n* What went wrong:\nA problem occurred evaluating project ':app'.\n> Failed to apply plugin 'com.android.internal.application'.\n   > Android Gradle plugin requires Java 11 to run. You are currently using Java 1.8.\n     You can try some of the following options:\n       - changing the IDE settings.\n       - changing the JAVA_HOME environment variable.\n       - changing `org.gradle.java.home` in `gradle.properties`.\n\nThis is the file in android/gradle/wrapper/gradle-wrapper.properties\ndistributionBase=GRADLE_USER_HOME\ndistributionPath=wrapper/dists\ndistributionUrl=https\\://services.gradle.org/distributions/gradle-7.3.3-all.zip\nzipStoreBase=GRADLE_USER_HOME\nzipStorePath=wrapper/dists\n\nand this is the output when I run ./gradlew --version\n------------------------------------------------------------\nGradle 7.3.3\n------------------------------------------------------------\n\nBuild time:   2021-12-22 12:37:54 UTC\nRevision:     6f556c80f945dc54b50e0be633da6c62dbe8dc71\n\nKotlin:       1.5.31\nGroovy:       3.0.9\nAnt:          Apache Ant(TM) version 1.10.11 compiled on July 10 2021\nJVM:          1.8.0_302 (Oracle Corporation 25.302-b08)\nOS:           Windows 10 10.0 amd64\n\nI read similar posts but I haven't been able to fix it. With folders that I created some days ago I have no problem when I run the app.\nSomeone can help me please?\nVery thanks!\n",
    "AcceptedAnswerId": 71800545,
    "AcceptedAnswer": "If you are using React Native witch Chocolatey, you must update JDK version to 11.\nIn order to do the update, execute this in PowerShell (with admin privileges):\nchoco install -y openjdk11\n\nAfter that, the first time (only the first time) you run npm android, you will get a lot of warnings, but the built of the project will work.\nIf you continue receiving an error, maybe you need to adjust the gradle version of your project to be compatible with the new JDK version.\nYou can achieve this by editing the file YOUR_PROJECT\\android\\gradle\\wrapper\\gradle-wrapper.properties\nUpdate the version of distributionUrl to 7.4.2\nI hope I have been helpful\n"
}
{
    "Id": 70725347,
    "PostTypeId": 1,
    "Title": "The application \u201cEclipse\u201d can\u2019t be opened. (macOS Monterey)",
    "Body": "I downloaded Eclipse on my Mac for school, following these instructions:\n\nIn your browser, go to Eclipse Downloads. Do not use the Eclipse Installer. Instead follow these steps to download and install Eclipse.\nFind the Eclipse IDE for Java Developers package (make sure you do not pick the wrong package) and click on the appropriate download link for your operating system (Windows, Mac, or Linux) and architecture (32-bit or 64-bit). There are many other packages but this is the one that you'll need in this class.\nOnce the download has completed, locate the downloaded file. This file will be a compressed (i.e., a \".zip\", or \".tar.gz\") file. Uncompress this file into the directory of your choice. It doesn't really matter where you put the Eclipse installation folder as long as you know how to retrieve it. You can optionally create a shortcut of the Eclipse IDE executable file (\"eclipse.exe\" on Windows, or \"eclipse\" on Linux, or \"Eclipse\" on Mac OS X) found in the directory that is created. To start Eclipse you just double-click on the executable file or the shortcut\n\nI downloaded the Eclipse macOS x86_64 version, and moved it into my applications folder. I was able to open Eclipse, and everything works perfectly, and I can work if it's open; but after I close Eclipse and a couple hours go by, I get the following messages once I try to reopen it. \"Eclipse quit unexpectedly\" and \"The application \u201cEclipse\u201d can\u2019t be opened.\"\nI had the .dmg file in my downloads folder, which might have been the problem. I moved it into my applications folder with Eclipse, and that still doesn't work.\nI have tried to delete and redownload Eclipse multiple times, and nothing works.\ndo you have any suggestions on how I can fix this?\n",
    "AcceptedAnswerId": 71740449,
    "AcceptedAnswer": "Faced the same issue each time I'm restarting the Macbook pro M1, and a random Reddit thread provided me with a way to fix it. Open a terminal and run,\nsudo codesign --force --deep --sign - /Applications/Eclipse.app\n\nNot sure why this codesigning fixes the problem. But seems to be a bug in the eclipse itself. Hope this helps someone.\n"
}
{
    "Id": 71377448,
    "PostTypeId": 1,
    "Title": "When I Update my Phone to Android 12, Installation did not succeed. The application could not be installed: INSTALL_PARSE_FAILED_MANIFEST_MALFORMED",
    "Body": "I was working on my project perfectly since I Update my phone to Android 12 unfortunately when I run the project to my phone this Error appears:\n\nInstallation did not succeed.\nThe application could not be installed: INSTALL_PARSE_FAILED_MANIFEST_MALFORMED\n\n\nList of apks:\n[0] 'C:\\Users\\Microsoft\\AndroidStudioProjects\\YmmyServer\\app\\build\\outputs\\apk\\debug\\app-debug.apk'\nInstallation failed due to: 'null'\nRetry\n\nThis is My build.gradle(Project) File:\n// Top-level build file where you can add configuration options common to all sub-projects/modules.\nbuildscript {\n    repositories {\n        google()\n        jcenter()\n    }\n    dependencies {\n        classpath 'com.google.gms:google-services:4.3.10'\n        classpath 'com.android.tools.build:gradle:4.0.0'\n        // NOTE: Do not place your application dependencies here; they belong\n        // in the individual module build.gradle files\n    }\n}\n\nallprojects {\n    repositories {\n        google()\n        jcenter()\n        maven { url \"https://jitpack.io\" }\n    }\n}\n\ntask clean(type: Delete) {\n    delete rootProject.buildDir\n}\n\nAnd this is My build.gradle(Module) File:\nplugins {\n    id 'com.android.application'\n}\n\nandroid {\n    compileSdkVersion 32\n    buildToolsVersion \"30.0.3\"\n\n    defaultConfig {\n        applicationId \"com.example.ymmyserver\"\n        minSdkVersion 30\n        targetSdkVersion 32\n        versionCode 1\n        versionName \"1.0\"\n\n        testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\"\n    }\n\n    buildTypes {\n        release {\n            minifyEnabled false\n            proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro'\n        }\n    }\n    compileOptions {\n        sourceCompatibility JavaVersion.VERSION_1_8\n        targetCompatibility JavaVersion.VERSION_1_8\n    }\n}\napply plugin: 'com.android.application'\napply plugin: 'com.google.gms.google-services'\ndependencies {\n\n    implementation 'com.github.jd-alexander:android-flat-button:v1.1'\n//    implementation 'info.hoang8f:fbutton:1.0.5'\n    implementation 'com.google.firebase:firebase-auth'\n    implementation 'com.google.firebase:firebase-storage'\n    implementation 'com.firebaseui:firebase-ui-database:8.0.0'\n    implementation 'com.squareup.picasso:picasso:2.71828'\n    implementation \"androidx.cardview:cardview:1.0.0\"\n    implementation \"androidx.recyclerview:recyclerview:1.2.1\"\n    implementation 'com.rengwuxian.materialedittext:library:2.1.4'\n    implementation 'com.google.firebase:firebase-core:10.2.0'\n    implementation 'com.google.firebase:firebase-database'\n    implementation 'com.google.firebase:firebase-analytics'\n    implementation platform('com.google.firebase:firebase-bom:29.1.0')\n    implementation 'androidx.appcompat:appcompat:1.4.1'\n    implementation 'com.google.android.material:material:1.5.0'\n    implementation 'androidx.constraintlayout:constraintlayout:2.1.3'\n    implementation 'androidx.navigation:navigation-fragment:2.4.1'\n    implementation 'androidx.navigation:navigation-ui:2.4.1'\n    implementation 'androidx.lifecycle:lifecycle-livedata-ktx:2.4.1'\n    implementation 'androidx.lifecycle:lifecycle-viewmodel-ktx:2.4.1'\n    testImplementation 'junit:junit:4.+'\n    androidTestImplementation 'androidx.test.ext:junit:1.1.3'\n    androidTestImplementation 'androidx.test.espresso:espresso-core:3.4.0'\n}\n\nAnd this is the Mainifest File:\n\n<manifest xmlns:android=\"http://schemas.android.com/apk/res/android\"\n    package=\"com.example.ymmyserver\">\n\n    <application\n        android:allowBackup=\"true\"\n        android:icon=\"@mipmap/ic_launcher\"\n        android:label=\"@string/app_name\"\n        android:roundIcon=\"@mipmap/ic_launcher_round\"\n        android:supportsRtl=\"true\"\n        android:theme=\"@style/Theme.Ymmy\">\n        \n        <activity\n            android:name=\".Home\"\n            android:label=\"@string/title_activity_home\"\n            android:theme=\"@style/Theme.Ymmy.NoActionBar\">\n        \n        \n            \n                \n\n                \n            \n        \n    \n\n\n\nWhat Should I do Please Help Me\n",
    "AcceptedAnswerId": 71381120,
    "AcceptedAnswer": "Try to use this tag in your AndroidManifest.xml file for the activity\n<activity \n   android:name=\".MainActivity\"\n   android:exported=\"true\">\n\n"
}
{
    "Id": 71966064,
    "PostTypeId": 1,
    "Title": "Java: FileOutputStream(\"NUL:\") not working after Java upgrade",
    "Body": "On Windows, NUL is the null output device similar to /dev/null on Linux.\nWith Oracle Java 8 Update 331, trying to get a new FileOutputStream(\"NUL:\") throws an exception. Previously (Java 8u321) it worked fine.\nThe problem seems to be the colon:\n\nnew FileOutputStream(\"NUL\") - OK\nnew FileOutputStream(\"NUL:\") - exception\n\nCan anyone point me to docs or JDK sources regarding this change? I can't change the code itself because it is in a 3rd party lib (xnio-api).\ntry\n{\n  new FileOutputStream(\"NUL:\");\n  System.out.println(\"OK\");\n}\ncatch (FileNotFoundException e)\n{\n  System.out.println(e);\n}\n\n",
    "AcceptedAnswerId": 71966125,
    "AcceptedAnswer": "I suspect this is the offending change.\nApparently it tries to avoid accessing ADS (alternate data streams), but seems to \"accidentally\" also prevent access to device-files like this.\nIf that's correct, then you can try setting the system property jdk.io.File.enableADS to true to re-enable the old behaviour.\n"
}
{
    "Id": 71429854,
    "PostTypeId": 1,
    "Title": "Could not find org.junit.jupiter:junit-jupiter:",
    "Body": "I was trying to learn how to use OkHTTP. I importetd the library to my project but when i compile the code it brings out this error.\nCould not find org.junit.jupiter:junit-jupiter:.\nRequired by:\nproject :app\nSearch in build.gradle files.\nplease what should i do. This is my build.gradle below\nplugins {\nid 'com.android.application'\n}\n\nandroid {\ncompileSdk 32\n\ndefaultConfig {\n    applicationId \"com.omolayoseun.saprktesterapp\"\n    minSdk 23\n    targetSdk 32\n    versionCode 1\n    versionName \"1.0\"\n\n    testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\"\n}\n\nbuildTypes {\n    release {\n        minifyEnabled false\n        proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard- \nrules.pro'\n    }\n}\ncompileOptions {\n    sourceCompatibility JavaVersion.VERSION_1_8\n    targetCompatibility JavaVersion.VERSION_1_8\n}\n}\n\ndependencies {\n\nimplementation 'androidx.appcompat:appcompat:1.4.1'\nimplementation 'com.google.android.material:material:1.5.0'\nimplementation 'androidx.constraintlayout:constraintlayout:2.1.3'\nimplementation 'org.junit.jupiter:junit-jupiter'\ntestImplementation 'junit:junit:4.13.2'\nandroidTestImplementation 'androidx.test.ext:junit:1.1.3'\nandroidTestImplementation 'androidx.test.espresso:espresso-core:3.4.0'\n\nimplementation 'com.squareup.okhttp3:okhttp:4.9.1'\n// https://mvnrepository.com/artifact/org.junit.jupiter/junit-jupiter-api\ntestImplementation 'org.junit.jupiter:junit-jupiter-api:5.8.2'\n\n}\n\n",
    "AcceptedAnswerId": 72124953,
    "AcceptedAnswer": "Seems that your problem is in the maven repository setting.\nPlace the code below to your build.gradle which is located in the project core folder.\nbuildscript {\nrepositories {\n    mavenCentral()\n    google()\n}}\n\nIf it not helps or this repositories already there - try to turn off offline mode.\nGo to Preferences > Gradle and uncheck \"Offline work\"\nIf Gradle is in offline mode, which means that it won't go to the network to resolve dependencies.\n"
}
{
    "Id": 72139334,
    "PostTypeId": 1,
    "Title": "Why onAdDismissedFullScreenContent is being called lately?",
    "Body": "I have created a function to show interstitial ad before showing another activity.\nIt's working but onAdDismissedFullScreenContent is being called 2-3 sec lately after closing the ad. It causes previous screen to stand-by.\nThere's a chance to re-click the button to show the wanted Activity.\nI really don't understand how to resolve this issue.\n\nHere is my code:\npublic class MainActivity extends AppCompatActivity {\n\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n        setContentView(R.layout.activity_main);\n        Button button = findViewById(R.id.button);\n        button.setOnClickListener(new View.OnClickListener() {\n            @Override\n            public void onClick(View view) {\n                AdManager.showInterstitial(MainActivity.this, () -> {\n                    Intent i = new Intent(MainActivity.this, MainActivity2.class);\n                    startActivity(i);\n                });\n            }\n        });\n        AdManager.loadInterstitial(this);\n    }\n}\n\n\nAnd this is Application Class:\n\npublic class App  extends Application {\n    private static Context mContext;\n\n\n    @Override\n    public void onCreate() {\n        super.onCreate();\n        mContext = getApplicationContext();\n        AdManager.Init(this);\n    }\n\n    public static Context getContext() {\n        return mContext;\n    }\n}\n\nAdManager Class:\npublic class AdManager {\n\n    private static InterstitialAd mInterstitialAd;\n    private static boolean loading, showing;\n\n\n    public static void Init(Context context) {\n\n        MobileAds.initialize(context, initializationStatus -> {\n            loadInterstitial(context);\n        });\n    }\n\n\n    public static void loadInterstitial(Context context) {\n\n        if (context == null)\n            context = App.getContext();\n\n        Context finalContext = context;\n        \n        if (mInterstitialAd != null) {\n            Toast.makeText(context,\"already loaded\",Toast.LENGTH_LONG).show();\n            return;\n        }\n        if (loading) {\n            Toast.makeText(context,\"already another request is processing\",Toast.LENGTH_LONG).show();\n            return;\n        }\n        Toast.makeText(context,\"requesting interstitial\",Toast.LENGTH_LONG).show();\n\n        loading = true;\n        AdRequest adRequest = new AdRequest.Builder().build();\n\n        InterstitialAd.load(context, \"Interstial Ad Unit ID\", adRequest, new InterstitialAdLoadCallback() {\n            @Override\n            public void onAdLoaded(@NonNull InterstitialAd interstitialAd) {\n                mInterstitialAd = interstitialAd;\n                Toast.makeText(finalContext,\"ad loaded\",Toast.LENGTH_LONG).show();\n                loading = false;\n            }\n\n            @Override\n            public void onAdFailedToLoad(@NonNull LoadAdError loadAdError) {\n                mInterstitialAd = null;\n                loading = false;\n                Toast.makeText(finalContext,\"ad failed to load\",Toast.LENGTH_LONG).show();\n            }\n\n        });\n    }\n\n    public static void showInterstitial(Activity activity, @NonNull AdListener listener) {\n        \n        if (showing) {\n            Toast.makeText(activity,\"already showing\",Toast.LENGTH_LONG).show();\n            listener.onCompleted();\n            return;\n        }\n\n        if (mInterstitialAd != null) {\n            showNow(activity, listener);\n\n        } else {\n            Toast.makeText(activity,\"mInterstitialAd is null\",Toast.LENGTH_LONG).show();\n            listener.onCompleted();\n            loadInterstitial(activity.getApplicationContext());\n        }\n\n    }\n\n    private static void showNow(Activity activity, AdListener listener) {\n\n        if (mInterstitialAd != null && !showing) {\n            showing = true;\n            mInterstitialAd.setFullScreenContentCallback(new FullScreenContentCallback() {\n                @Override\n                public void onAdDismissedFullScreenContent() {\n                    Toast.makeText(activity,\"Ad dismissed\",Toast.LENGTH_LONG).show();\n                    mInterstitialAd = null;\n                    listener.onCompleted();\n                    showing = false;\n                    // times to load an new interstitial ad content\n                    loadInterstitial(activity.getApplicationContext());\n                }\n\n                @Override\n                public void onAdFailedToShowFullScreenContent(@NonNull AdError adError) {\n                    Toast.makeText(activity,\"AdFailedToShowFullScreenContent\",Toast.LENGTH_LONG).show();\n                    mInterstitialAd = null;\n                    listener.onCompleted();\n                    showing = false;\n\n                    // times to load an new interstitial ad content\n                    loadInterstitial(activity.getApplicationContext());\n                }\n\n\n            });\n            //  Now show the ad\n            Toast.makeText(activity,\"call to show ad\",Toast.LENGTH_LONG).show();\n            mInterstitialAd.show(activity);\n        } else {\n            Toast.makeText(activity,\"either mInterstitialAd is null or ad already is showing\",Toast.LENGTH_LONG).show();\n            listener.onCompleted();\n        }\n    }\n\n        public interface AdListener {\n        void onCompleted();\n    }\n\n}\n\n\nPlease help.\n",
    "AcceptedAnswerId": 72150183,
    "AcceptedAnswer": "The delay problem\n\nYou can't really help it. The problem is from the admob. This will happen. But, to know more about it, we can post an issue abt that on the Google Issue Tracker.\nThe button problem\n\nI dont think this is any hard task. Just follow the steps:\n\nCreate a ProgressBar in your xml layout on top of the button and set its visibility to gone\n\nWhen the button is click and the ad is shown, you can set the button to invisible and the progress bar can be set to invisible.\n\nThen after a delay, the other activity opens without any harm to the activity from NullPointerException\n\n\n"
}
{
    "Id": 71956115,
    "PostTypeId": 1,
    "Title": "Why does jaxb2-maven-plugin xjc fail with Corretto jdk11.0.15_9 but not with Temurin jdk-11.0.14.1+1",
    "Body": "Since upgrading my jdk to Corretto jdk11.0.15_9 the xjc goal of jaxb2-maven-plugin fails.\nThe problem doesn't manifest when running with Temurin jdk-11.0.14.1+1. I'm running it on windows 10 with maven 3.8.5.\nCommand:\n> set JAVA_HOME=C:\\Corretto\\jdk11.0.15_9\n> mvn jaxb2:xjc\n\n[INFO] Scanning for projects...\n[INFO]\n[INFO] -----------------------------------\n[INFO] Building example 1.0.0-SNAPSHOT\n[INFO] --------------------------------[ jar ]---------------------------------\n[INFO]\n[INFO] --- jaxb2-maven-plugin:2.5.0:xjc (default-cli) @ example ---\n[INFO] Created EpisodePath [C:\\Workspace\\example\\target\\generated-sources\\jaxb\\META-INF\\JAXB]: true\n[INFO] Created EpisodePath [C:\\Workspace\\example\\target\\generated-sources\\jaxb\\META-INF\\JAXB]: true\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time:  0.764 s\n[INFO] Finished at: 2022-04-21T15:24:15+02:00\n[INFO] ------------------------------------------------------------------------\n[ERROR] Failed to execute goal org.codehaus.mojo:jaxb2-maven-plugin:2.5.0:xjc (default-cli) on project example: \"file:\\C:\\Users\\johndoe\\.m2\\repository\\org\\glassfish\\jaxb\\jaxb-xjc\\2.3.2\\jaxb-xjc-2.3.2.jar!\\META-INF\\versions\\9\" is not a valid file name: {1}: Invalid file path -> [Help 1]\n[ERROR]\n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR]\n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException\n\nI have a bindings file here: src/main/xjb/jaxb-bindings.xjb and multiple xsd files in src/main/xsd.\nThis is the relevant piece of my pom.xml:\n\n    org.glassfish.jaxb\n    jaxb-runtime\n    2.3.6\n\n\n    org.jvnet.jaxb2_commons\n    jaxb2-basics-runtime\n    0.12.0\n    \n        \n        \n            com.sun.istack\n            istack-commons-runtime\n        \n    \n\n...\n\n    org.codehaus.mojo\n    jaxb2-maven-plugin\n    2.5.0\n    \n        \n            xjc\n            \n                xjc\n            \n        \n    \n    \n        com.example\n        \n            -Xequals\n            -XhashCode\n            -XtoString\n        \n        true\n    \n    \n        \n            org.jvnet.jaxb2_commons\n            jaxb2-basics\n            0.12.0\n        \n    \n\n\nRunning it again with -X gives me the following stacktrace which makes me think something must have changed in the java.io.File.toURL behavior.\n[ERROR] Failed to execute goal org.codehaus.mojo:jaxb2-maven-plugin:2.5.0:xjc (default-cli) on project example: \"file:\\C:\\Users\\johndoe\\.m2\\repository\\org\\glassfish\\jaxb\\jaxb-xjc\\2.3.2\\jaxb-xjc-2.3.2.jar!\\META-INF\\versions\\9\" is not a valid file name: {1}: Invalid file path -> [Help 1]\norg.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.codehaus.mojo:jaxb2-maven-plugin:2.5.0:xjc (default-cli) on project example: \"file:\\C:\\Users\\johndoe\\.m2\\repository\\org\\glassfish\\jaxb\\jaxb-xjc\\2.3.2\\jaxb-xjc-2.3.2.jar!\\META-INF\\versions\\9\" is not a valid file name: {1}\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute (MojoExecutor.java:306)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:211)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:165)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:157)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:121)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:127)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:294)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:960)\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:293)\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:196)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:566)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:282)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:225)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:406)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:347)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:566)\n    at org.apache.maven.wrapper.BootstrapMainStarter.start (BootstrapMainStarter.java:47)\n    at org.apache.maven.wrapper.WrapperExecutor.execute (WrapperExecutor.java:156)\n    at org.apache.maven.wrapper.MavenWrapperMain.main (MavenWrapperMain.java:72)\nCaused by: org.apache.maven.plugin.MojoExecutionException: \"file:\\C:\\Users\\johndoe\\.m2\\repository\\org\\glassfish\\jaxb\\jaxb-xjc\\2.3.2\\jaxb-xjc-2.3.2.jar!\\META-INF\\versions\\9\" is not a valid file name: {1}\n    at org.codehaus.mojo.jaxb2.javageneration.AbstractJavaGeneratorMojo.performExecution (AbstractJavaGeneratorMojo.java:555)\n    at org.codehaus.mojo.jaxb2.AbstractJaxbMojo.execute (AbstractJaxbMojo.java:337)\n    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:137)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute (MojoExecutor.java:301)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:211)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:165)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:157)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:121)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:127)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:294)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:960)\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:293)\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:196)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:566)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:282)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:225)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:406)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:347)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:566)\n    at org.apache.maven.wrapper.BootstrapMainStarter.start (BootstrapMainStarter.java:47)\n    at org.apache.maven.wrapper.WrapperExecutor.execute (WrapperExecutor.java:156)\n    at org.apache.maven.wrapper.MavenWrapperMain.main (MavenWrapperMain.java:72)\nCaused by: com.sun.tools.xjc.BadCommandLineException: \"file:\\C:\\Users\\johndoe\\.m2\\repository\\org\\glassfish\\jaxb\\jaxb-xjc\\2.3.2\\jaxb-xjc-2.3.2.jar!\\META-INF\\versions\\9\" is not a valid file name: {1}\n    at com.sun.tools.xjc.Options.parseArgument (Options.java:515)\n    at com.sun.tools.xjc.Driver$OptionsEx.parseArgument (Driver.java:502)\n    at com.sun.tools.xjc.Options.parseArguments (Options.java:827)\n    at com.sun.tools.xjc.Driver.run (Driver.java:231)\n    at org.codehaus.mojo.jaxb2.javageneration.AbstractJavaGeneratorMojo.performExecution (AbstractJavaGeneratorMojo.java:475)\n    at org.codehaus.mojo.jaxb2.AbstractJaxbMojo.execute (AbstractJaxbMojo.java:337)\n    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:137)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute (MojoExecutor.java:301)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:211)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:165)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:157)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:121)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:127)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:294)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:960)\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:293)\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:196)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:566)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:282)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:225)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:406)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:347)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:566)\n    at org.apache.maven.wrapper.BootstrapMainStarter.start (BootstrapMainStarter.java:47)\n    at org.apache.maven.wrapper.WrapperExecutor.execute (WrapperExecutor.java:156)\n    at org.apache.maven.wrapper.MavenWrapperMain.main (MavenWrapperMain.java:72)\nCaused by: java.net.MalformedURLException: Invalid file path\n    at java.io.File.toURL (File.java:695)\n    at com.sun.tools.xjc.Options.parseArgument (Options.java:512)\n    at com.sun.tools.xjc.Driver$OptionsEx.parseArgument (Driver.java:502)\n    at com.sun.tools.xjc.Options.parseArguments (Options.java:827)\n    at com.sun.tools.xjc.Driver.run (Driver.java:231)\n    at org.codehaus.mojo.jaxb2.javageneration.AbstractJavaGeneratorMojo.performExecution (AbstractJavaGeneratorMojo.java:475)\n    at org.codehaus.mojo.jaxb2.AbstractJaxbMojo.execute (AbstractJaxbMojo.java:337)\n    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:137)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.doExecute (MojoExecutor.java:301)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:211)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:165)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:157)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:121)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:127)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:294)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:960)\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:293)\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:196)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:566)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:282)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:225)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:406)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:347)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:566)\n    at org.apache.maven.wrapper.BootstrapMainStarter.start (BootstrapMainStarter.java:47)\n    at org.apache.maven.wrapper.WrapperExecutor.execute (WrapperExecutor.java:156)\n    at org.apache.maven.wrapper.MavenWrapperMain.main (MavenWrapperMain.java:72)\n\nMinimal reproducable scenario:\nhttps://github.com/Crydust/so71956115\n",
    "AcceptedAnswerId": 71979169,
    "AcceptedAnswer": "Switching to a newer version of jaxb2-maven-plugin required a switch to jaxb3,\nbut replacing jaxb2-maven-plugin by maven-jaxb2-plugin worked.\n\n    org.jvnet.jaxb2.maven2\n    maven-jaxb2-plugin\n    0.14.0\n    \n        \n            \n                generate\n            \n        \n    \n    \n        \n            -Xequals\n            -XhashCode\n            -XtoString\n        \n        com.example\n        ${project.basedir}/src/main/xsd\n        \n            \n                org.jvnet.jaxb2_commons\n                jaxb2-basics\n                0.12.0\n            \n        \n    \n\n\n\nBarry's suggestion (with some tweaks) works too.\n\n    org.codehaus.mojo\n    jaxb2-maven-plugin\n    2.5.0\n    \n        \n            \n                xjc\n            \n        \n    \n    \n        com.example.generated\n        \n            -Xequals\n            -XhashCode\n            -XtoString\n        \n        true\n    \n    \n        \n            org.jvnet.jaxb2_commons\n            jaxb2-basics\n            0.12.0\n        \n        \n            org.glassfish.jaxb\n            jaxb-runtime\n            2.3.6\n        \n        \n            org.glassfish.jaxb\n            jaxb-xjc\n            2.3.6\n        \n    \n\n\n"
}
{
    "Id": 71434304,
    "PostTypeId": 1,
    "Title": "Does Java Evaluate a Variable Declared as Final only Once?",
    "Body": "I'm writing a Java program that requires thousands of System.out.println() statements that will be printed hundreds of millions (or billions) of times throughout the lifecycle of the program for debugging purposes:\nif (GVar.runInDebugMode) System.out.println(\"Print debug message\");\n\nIn the real world, these statements can be deactivated in order to speed up a computational heavy calculation.\nIf I set:\npublic final static boolean runInDebugMode = false;\n\nDoes the compiler re-evaluate runInDebugMode each time it comes across a statement like: if (GVar.runInDebugMode) or since it was declared as final it will be evaluated once at the beginning of the program and won't put additional strain on the CPU? In other words, would I be better off commenting out all debug statements entirely once I deploy the app or is setting runInDebugMode  to false sufficient?\n",
    "AcceptedAnswerId": 71470775,
    "AcceptedAnswer": "When you declare a variable like\npublic final static boolean runInDebugMode = false;\n\nit\u2019s a compile-time constant.\n\nA constant variable is a final variable of primitive type or type String that is initialized with a constant expression (\u00a715.29).\n\nwhich means that\n\nA reference to a field that is a constant variable (\u00a74.12.4) must be resolved at compile time to the value V denoted by the constant variable's initializer.\nIf such a field is static, then no reference to the field should be present in the code in a binary file, including the class or interface which declared the field.\n\nIn other words, when you write if(runInDebugMode) anywhere and runInDebugMode is false at compile time, the behavior is as if you\u2019ve written if(false), as the value must be resolved at compile time and no reference to the field appears in the compiled class file.\nYour use case has been discussed specifically in \u00a714.22\n\nHowever, in order to allow the if statement to be used conveniently for \"conditional compilation\" purposes, the actual rules differ.\nAs an example, the following statement results in a compile-time error:\nwhile (false) { x=3; }\n\nbecause the statement x=3; is not reachable; but the superficially similar case:\nif (false) { x=3; }\n\ndoes not result in a compile-time error. An optimizing compiler may realize that the statement x=3; will never be executed and may choose to omit the code for that statement from the generated class file, but the statement x=3; is not regarded as \"unreachable\" in the technical sense specified here.\nThe rationale for this differing treatment is to allow programmers to define \"flag\" variables such as:\nstatic final boolean DEBUG = false;\n\nand then write code such as:\nif (DEBUG) { x=3; }\n\nThe idea is that it should be possible to change the value of DEBUG from false to true or from true to false and then compile the code correctly with no other changes to the program text.\nConditional compilation comes with a caveat. If a set of classes that use a \"flag\" variable - or more precisely, any static constant variable (\u00a74.12.4) - are compiled and conditional code is omitted, it does not suffice later to distribute just a new version of the class or interface that contains the definition of the flag.\n\nSo, this statement makes clear that this form of conditional compilation matches the intent of the language designers and that compilers are entitled to omit the code in question (all relevant compilers do). In principle, a compiler is not required to omit the code, but since it must not generate a reference to the field GVar.runInDebugMode in the compiled code, the code can\u2019t contain a real conditional. If the code is not omitted, it must be skipped in a de-facto unconditional way. Either, by a goto instruction or, when compiling in the most na\u00efve way imaginable, by literally testing false, iconst_0; ifeq \u2026. Both approaches would be on the nanosecond scale in interpreted execution mode and no challenge to the JIT compiler/ optimizer at all.\n\nIt\u2019s worth mentioning that static final fields are trusted fields which are normally not even changeable by Reflection. This is used, e.g. by the Assertion feature, as under the hood, a class containing an assert statement will have a static final boolean field initialized at class initialization time (so it\u2019s not a compile-time constant) and each assert statement will skip its check conditionally, depending on the state of the static final variable. It was as early as at Java\u00a01.4 time, when it was concluded that the necessary dead code elimination is commonplace in JVMs, to rely on it in this way.\nSo even if you turn your debug flag from compile-time constant to an initialization-time constant, the impact on the performance would be hardly noticeable. But the way you\u2019re using it now, the code is removed at compile-time already and doesn\u2019t rely on the JVM anyway.\n"
}
{
    "Id": 71095913,
    "PostTypeId": 1,
    "Title": "What is the difference between jaxb-impl and jaxb-runtime?",
    "Body": "Clearly the com.sun.xml.bind:jaxb-impl artifact is labelled \"Old JAXB Runtime module\" in the maven repository (see link below), and yet both of these artifacts are still getting new releases:\nhttps://mvnrepository.com/artifact/org.glassfish.jaxb/jaxb-runtime\nhttps://mvnrepository.com/artifact/com.sun.xml.bind/jaxb-impl\nThis answer Which artifacts should I use for JAXB RI in my Maven project?\ndoes not clarify the difference.\nThe accepted answer to both the above question and this one How to resolve java.lang.NoClassDefFoundError: javax/xml/bind/JAXBException conclude that for Java 9+ you should use:  org.glassfish.jaxb:jaxb-runtime\nBut I have code using com.sun.xml.bind:jaxb-impl and it appears to be working fine.  So what do I lose or gain by moving to jaxb-runtime?\nEven the latest (3.0.2 at the time I write this) version is available for the \"OLD\" jaxb-impl module.  If Oracle isn't doing this anymore, who makes the com.sun.xml.bind:jaxb-impl artifact? What is it for? Why doesn't it share the Maven group coordinates with jaxb-runtime?\nIs there any central location that clearly documents what the current state of affairs is with JAXB?\nThere is just so much confusion with JAXB now.\nP.S. I need to remain compatible with Java 8 for the time being - so I can't go to 3.x yet, and 2.4.x appears to be an abandoned attempt at fixing the modularity that they foolishly broke when it was split out of the JDK.\n",
    "AcceptedAnswerId": 72151763,
    "AcceptedAnswer": "The only difference between jaxb-impl and jaxb-runtime is packaging: jaxb-impl bundles istack/txw2 inside the jar, whereas jaxb-runtime provides them via separate dependencies.\nVersion Compatibility and the JakartaEE Migration\nI've been trying to make sense of this for the last day, and it's incredibly confusing. Particularly when you're trying to avoid the java.xml.bind to jakarta.xml.bind migration. There's out of date information everywhere and some broken releases in the jaxb-impl 2.3.x release line.\nBest I can tell, GlassFish was providing the JAXB reference implementation. It's since moved to EE4J, but releases continue from that project against both sets of coordinates. Appears that com.sun.xml.bind:jaxb-ri is where the latest full bundles are released:\nhttps://github.com/eclipse-ee4j/jaxb-ri/\nHaving figured out that piece of history, the real mess is that none of the artifacts reflect the javax.xml.bind to jakarta.xml.bind move in their artifact coordinates, only in the versions. This means if you're in ecosystem where you need both to exist, you're going to have a bad time.\nFor instance, the 2.3.3 release changed from depending on javax.xml.bind:jaxb-api to jakarta.xml.bind:jakarta.xml.bind-api because at 2.x, the jakarta artifacts provide the javax.xml.bind packages. At version 3.0.0 it provides jakarta.xml.bind.\nThe implementations are the same at 3.0.0 which means while the earlier versions could happily exist at runtime, you have no way of resolving them both in build tools and conflict resolution is going to break legacy uses of javax.xml.bind APIs.\nAllow javax.xml.bind and jakarta.xml.bind to coexist\nFor projects that need both APIs to coexist without migrating the legacy code:\n\nFor javax.xml.bind use com.sun.xml.bind:jaxb-impl:2.3.6. Ignore the 3.0.0 and later releases. Add an explicit dependency on javax.xml.bind:jaxb-api:2.3.1 so that you have a package providing the javax.xml.bind API\nFor jakarta.xml.bind use the latest org.glassfish.jaxb:jaxb-runtime. Ignore the releases earlier than 3.0.0\n\nRuntime compatibility with jakarta.xml.bind\nUse the tomcat-jakartaee-migration tool to rewrite classes for deployment.\nFor Gradle projects, you can use the gradle-jakartaee-migration-plugin, and get the benefit of capabilities and transforms at development time too.\nMigrate to jakarta.xml.bind\nYou can use either of the coordinates for the runtime based on your preferences for packaging:\n\ncom.sun.xml.bind:jaxb-impl:4.0.0\norg.glassfish.jaxb:jaxb-runtime:4.0.0\n\nBoth depend on jakarta.xml.bind:jakarta.xml.bind-api with the jakarta.xml.bind package namespace.\n"
}
{
    "Id": 72335789,
    "PostTypeId": 1,
    "Title": "Can not extract resource from com.android.aaptcompiler",
    "Body": "Can not extract resource from com.android.aaptcompiler.ParsedResource@636e1e76.\nExecution failed for task ':app:mergeDebugResources'.\n> A failure occurred while executing com.android.build.gradle.internal.res.ResourceCompilerRunnable\n   > Resource compilation failed (Failed to compile values resource file E:\\My Client\\Henkako\\HenkakoPlus\\app\\build\\intermediates\\incremental\\debug\\mergeDebugResources\\merged.dir\\values\\values.xml. Cause: java.lang.IllegalStateException: Can not extract resource from com.android.aaptcompiler.ParsedResource@636e1e76.). Check logs for more details.\n\n* Exception is:\norg.gradle.api.tasks.TaskExecutionException: Execution failed for task ':app:mergeDebugResources'.\n    at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.lambda$executeIfValid$1(ExecuteActionsTaskExecuter.java:145)\n    at org.gradle.internal.Try$Failure.ifSuccessfulOrElse(Try.java:282)\n    at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeIfValid(ExecuteActionsTaskExecuter.java:143)\n    at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:131)\n    at org.gradle.api.internal.tasks.execution.CleanupStaleOutputsExecuter.execute(CleanupStaleOutputsExecuter.java:77)\n    at org.gradle.api.internal.tasks.execution.FinalizePropertiesTaskExecuter.execute(FinalizePropertiesTaskExecuter.java:46)\n    at org.gradle.api.internal.tasks.execution.ResolveTaskExecutionModeExecuter.execute(ResolveTaskExecutionModeExecuter.java:51)\n    at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:57)\n    at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:56)\n    at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:36)\n    at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.executeTask(EventFiringTaskExecuter.java:77)\n    at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.call(EventFiringTaskExecuter.java:55)\n    at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.call(EventFiringTaskExecuter.java:52)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:204)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:199)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:66)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:59)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:157)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:59)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.call(DefaultBuildOperationRunner.java:53)\n    at org.gradle.internal.operations.DefaultBuildOperationExecutor.call(DefaultBuildOperationExecutor.java:73)\n    at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter.execute(EventFiringTaskExecuter.java:52)\n    at org.gradle.execution.plan.LocalTaskNodeExecutor.execute(LocalTaskNodeExecutor.java:74)\n    at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$InvokeNodeExecutorsAction.execute(DefaultTaskExecutionGraph.java:402)\n    at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$InvokeNodeExecutorsAction.execute(DefaultTaskExecutionGraph.java:389)\n    at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:382)\n    at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:368)\n    at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.lambda$run$0(DefaultPlanExecutor.java:127)\n    at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.execute(DefaultPlanExecutor.java:191)\n    at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.executeNextNode(DefaultPlanExecutor.java:182)\n    at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.run(DefaultPlanExecutor.java:124)\n    at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64)\n    at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48)\n    at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:61)\nCaused by: org.gradle.workers.internal.DefaultWorkerExecutor$WorkExecutionException: A failure occurred while executing com.android.build.gradle.internal.res.ResourceCompilerRunnable\n    at org.gradle.workers.internal.DefaultWorkerExecutor$WorkItemExecution.waitForCompletion(DefaultWorkerExecutor.java:342)\n    at org.gradle.internal.work.DefaultAsyncWorkTracker.waitForItemsAndGatherFailures(DefaultAsyncWorkTracker.java:142)\n    at org.gradle.internal.work.DefaultAsyncWorkTracker.waitForItemsAndGatherFailures(DefaultAsyncWorkTracker.java:94)\n    at org.gradle.internal.work.DefaultAsyncWorkTracker.waitForAll(DefaultAsyncWorkTracker.java:80)\n    at org.gradle.internal.work.DefaultAsyncWorkTracker.waitForCompletion(DefaultAsyncWorkTracker.java:68)\n    at org.gradle.api.internal.tasks.execution.TaskExecution$2.run(TaskExecution.java:247)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$1.execute(DefaultBuildOperationRunner.java:29)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$1.execute(DefaultBuildOperationRunner.java:26)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:66)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:59)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:157)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:59)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.run(DefaultBuildOperationRunner.java:47)\n    at org.gradle.internal.operations.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:68)\n    at org.gradle.api.internal.tasks.execution.TaskExecution.executeAction(TaskExecution.java:224)\n    at org.gradle.api.internal.tasks.execution.TaskExecution.executeActions(TaskExecution.java:207)\n    at org.gradle.api.internal.tasks.execution.TaskExecution.executeWithPreviousOutputFiles(TaskExecution.java:190)\n    at org.gradle.api.internal.tasks.execution.TaskExecution.execute(TaskExecution.java:168)\n    at org.gradle.internal.execution.steps.ExecuteStep.executeInternal(ExecuteStep.java:89)\n    at org.gradle.internal.execution.steps.ExecuteStep.access$000(ExecuteStep.java:40)\n    at org.gradle.internal.execution.steps.ExecuteStep$1.call(ExecuteStep.java:53)\n    at org.gradle.internal.execution.steps.ExecuteStep$1.call(ExecuteStep.java:50)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:204)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:199)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:66)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:59)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:157)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:59)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.call(DefaultBuildOperationRunner.java:53)\n    at org.gradle.internal.operations.DefaultBuildOperationExecutor.call(DefaultBuildOperationExecutor.java:73)\n    at org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:50)\n    at org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:40)\n    at org.gradle.internal.execution.steps.RemovePreviousOutputsStep.execute(RemovePreviousOutputsStep.java:68)\n    at org.gradle.internal.execution.steps.RemovePreviousOutputsStep.execute(RemovePreviousOutputsStep.java:38)\n    at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:48)\n    at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:36)\n    at org.gradle.internal.execution.steps.CancelExecutionStep.execute(CancelExecutionStep.java:41)\n    at org.gradle.internal.execution.steps.TimeoutStep.executeWithoutTimeout(TimeoutStep.java:74)\n    at org.gradle.internal.execution.steps.TimeoutStep.execute(TimeoutStep.java:55)\n    at org.gradle.internal.execution.steps.CreateOutputsStep.execute(CreateOutputsStep.java:51)\n    at org.gradle.internal.execution.steps.CreateOutputsStep.execute(CreateOutputsStep.java:29)\n    at org.gradle.internal.execution.steps.CaptureStateAfterExecutionStep.execute(CaptureStateAfterExecutionStep.java:61)\n    at org.gradle.internal.execution.steps.CaptureStateAfterExecutionStep.execute(CaptureStateAfterExecutionStep.java:42)\n    at org.gradle.internal.execution.steps.BroadcastChangingOutputsStep.execute(BroadcastChangingOutputsStep.java:60)\n    at org.gradle.internal.execution.steps.BroadcastChangingOutputsStep.execute(BroadcastChangingOutputsStep.java:27)\n    at org.gradle.internal.execution.steps.BuildCacheStep.executeWithoutCache(BuildCacheStep.java:188)\n    at org.gradle.internal.execution.steps.BuildCacheStep.lambda$execute$1(BuildCacheStep.java:75)\n    at org.gradle.internal.Either$Right.fold(Either.java:175)\n    at org.gradle.internal.execution.caching.CachingState.fold(CachingState.java:59)\n    at org.gradle.internal.execution.steps.BuildCacheStep.execute(BuildCacheStep.java:73)\n    at org.gradle.internal.execution.steps.BuildCacheStep.execute(BuildCacheStep.java:48)\n    at org.gradle.internal.execution.steps.StoreExecutionStateStep.execute(StoreExecutionStateStep.java:38)\n    at org.gradle.internal.execution.steps.StoreExecutionStateStep.execute(StoreExecutionStateStep.java:27)\n    at org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:36)\n    at org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:22)\n    at org.gradle.internal.execution.steps.SkipUpToDateStep.executeBecause(SkipUpToDateStep.java:109)\n    at org.gradle.internal.execution.steps.SkipUpToDateStep.lambda$execute$2(SkipUpToDateStep.java:56)\n    at org.gradle.internal.execution.steps.SkipUpToDateStep.execute(SkipUpToDateStep.java:56)\n    at org.gradle.internal.execution.steps.SkipUpToDateStep.execute(SkipUpToDateStep.java:38)\n    at org.gradle.internal.execution.steps.ResolveChangesStep.execute(ResolveChangesStep.java:73)\n    at org.gradle.internal.execution.steps.ResolveChangesStep.execute(ResolveChangesStep.java:44)\n    at org.gradle.internal.execution.steps.legacy.MarkSnapshottingInputsFinishedStep.execute(MarkSnapshottingInputsFinishedStep.java:37)\n    at org.gradle.internal.execution.steps.legacy.MarkSnapshottingInputsFinishedStep.execute(MarkSnapshottingInputsFinishedStep.java:27)\n    at org.gradle.internal.execution.steps.ResolveCachingStateStep.execute(ResolveCachingStateStep.java:89)\n    at org.gradle.internal.execution.steps.ResolveCachingStateStep.execute(ResolveCachingStateStep.java:50)\n    at org.gradle.internal.execution.steps.ValidateStep.execute(ValidateStep.java:114)\n    at org.gradle.internal.execution.steps.ValidateStep.execute(ValidateStep.java:57)\n    at org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:76)\n    at org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:50)\n    at org.gradle.internal.execution.steps.SkipEmptyWorkStep.lambda$execute$2(SkipEmptyWorkStep.java:93)\n    at org.gradle.internal.execution.steps.SkipEmptyWorkStep.execute(SkipEmptyWorkStep.java:93)\n    at org.gradle.internal.execution.steps.SkipEmptyWorkStep.execute(SkipEmptyWorkStep.java:34)\n    at org.gradle.internal.execution.steps.legacy.MarkSnapshottingInputsStartedStep.execute(MarkSnapshottingInputsStartedStep.java:38)\n    at org.gradle.internal.execution.steps.LoadPreviousExecutionStateStep.execute(LoadPreviousExecutionStateStep.java:43)\n    at org.gradle.internal.execution.steps.LoadPreviousExecutionStateStep.execute(LoadPreviousExecutionStateStep.java:31)\n    at org.gradle.internal.execution.steps.AssignWorkspaceStep.lambda$execute$0(AssignWorkspaceStep.java:40)\n    at org.gradle.api.internal.tasks.execution.TaskExecution$3.withWorkspace(TaskExecution.java:284)\n    at org.gradle.internal.execution.steps.AssignWorkspaceStep.execute(AssignWorkspaceStep.java:40)\n    at org.gradle.internal.execution.steps.AssignWorkspaceStep.execute(AssignWorkspaceStep.java:30)\n    at org.gradle.internal.execution.steps.IdentityCacheStep.execute(IdentityCacheStep.java:37)\n    at org.gradle.internal.execution.steps.IdentityCacheStep.execute(IdentityCacheStep.java:27)\n    at org.gradle.internal.execution.steps.IdentifyStep.execute(IdentifyStep.java:44)\n    at org.gradle.internal.execution.steps.IdentifyStep.execute(IdentifyStep.java:33)\n    at org.gradle.internal.execution.impl.DefaultExecutionEngine$1.execute(DefaultExecutionEngine.java:76)\n    at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeIfValid(ExecuteActionsTaskExecuter.java:142)\n    at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:131)\n    at org.gradle.api.internal.tasks.execution.CleanupStaleOutputsExecuter.execute(CleanupStaleOutputsExecuter.java:77)\n    at org.gradle.api.internal.tasks.execution.FinalizePropertiesTaskExecuter.execute(FinalizePropertiesTaskExecuter.java:46)\n    at org.gradle.api.internal.tasks.execution.ResolveTaskExecutionModeExecuter.execute(ResolveTaskExecutionModeExecuter.java:51)\n    at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:57)\n    at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:56)\n    at org.gradle.api.internal.tasks.execution.CatchExceptionTaskExecuter.execute(CatchExceptionTaskExecuter.java:36)\n    at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.executeTask(EventFiringTaskExecuter.java:77)\n    at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.call(EventFiringTaskExecuter.java:55)\n    at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter$1.call(EventFiringTaskExecuter.java:52)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:204)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:199)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:66)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:59)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:157)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:59)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.call(DefaultBuildOperationRunner.java:53)\n    at org.gradle.internal.operations.DefaultBuildOperationExecutor.call(DefaultBuildOperationExecutor.java:73)\n    at org.gradle.api.internal.tasks.execution.EventFiringTaskExecuter.execute(EventFiringTaskExecuter.java:52)\n    at org.gradle.execution.plan.LocalTaskNodeExecutor.execute(LocalTaskNodeExecutor.java:74)\n    at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$InvokeNodeExecutorsAction.execute(DefaultTaskExecutionGraph.java:402)\n    at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$InvokeNodeExecutorsAction.execute(DefaultTaskExecutionGraph.java:389)\n    at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:382)\n    at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:368)\n    at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.lambda$run$0(DefaultPlanExecutor.java:127)\n    at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.execute(DefaultPlanExecutor.java:191)\n    at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.executeNextNode(DefaultPlanExecutor.java:182)\n    at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.run(DefaultPlanExecutor.java:124)\n    at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64)\n    at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48)\n    at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:61)\nCaused by: com.android.aaptcompiler.ResourceCompilationException: Resource compilation failed (Failed to compile values resource file E:\\My Client\\Henkako\\HenkakoPlus\\app\\build\\intermediates\\incremental\\debug\\mergeDebugResources\\merged.dir\\values\\values.xml. Cause: java.lang.IllegalStateException: Can not extract resource from com.android.aaptcompiler.ParsedResource@636e1e76.). Check logs for more details.\n    at com.android.aaptcompiler.ResourceCompiler.compileResource(ResourceCompiler.kt:129)\n    at com.android.build.gradle.internal.res.ResourceCompilerRunnable$Companion.compileSingleResource(ResourceCompilerRunnable.kt:34)\n    at com.android.build.gradle.internal.res.ResourceCompilerRunnable.run(ResourceCompilerRunnable.kt:15)\n    at com.android.build.gradle.internal.profile.ProfileAwareWorkAction.execute(ProfileAwareWorkAction.kt:74)\n    at org.gradle.workers.internal.DefaultWorkerServer.execute(DefaultWorkerServer.java:63)\n    at org.gradle.workers.internal.NoIsolationWorkerFactory$1$1.create(NoIsolationWorkerFactory.java:66)\n    at org.gradle.workers.internal.NoIsolationWorkerFactory$1$1.create(NoIsolationWorkerFactory.java:62)\n    at org.gradle.internal.classloader.ClassLoaderUtils.executeInClassloader(ClassLoaderUtils.java:97)\n    at org.gradle.workers.internal.NoIsolationWorkerFactory$1.lambda$execute$0(NoIsolationWorkerFactory.java:62)\n    at org.gradle.workers.internal.AbstractWorker$1.call(AbstractWorker.java:44)\n    at org.gradle.workers.internal.AbstractWorker$1.call(AbstractWorker.java:41)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:204)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$CallableBuildOperationWorker.execute(DefaultBuildOperationRunner.java:199)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:66)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner$2.execute(DefaultBuildOperationRunner.java:59)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:157)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.execute(DefaultBuildOperationRunner.java:59)\n    at org.gradle.internal.operations.DefaultBuildOperationRunner.call(DefaultBuildOperationRunner.java:53)\n    at org.gradle.internal.operations.DefaultBuildOperationExecutor.call(DefaultBuildOperationExecutor.java:73)\n    at org.gradle.workers.internal.AbstractWorker.executeWrappedInBuildOperation(AbstractWorker.java:41)\n    at org.gradle.workers.internal.NoIsolationWorkerFactory$1.execute(NoIsolationWorkerFactory.java:59)\n    at org.gradle.workers.internal.DefaultWorkerExecutor.lambda$submitWork$2(DefaultWorkerExecutor.java:206)\n    at org.gradle.internal.work.DefaultConditionalExecutionQueue$ExecutionRunner.runExecution(DefaultConditionalExecutionQueue.java:214)\n    at org.gradle.internal.work.DefaultConditionalExecutionQueue$ExecutionRunner.runBatch(DefaultConditionalExecutionQueue.java:164)\n    at org.gradle.internal.work.DefaultConditionalExecutionQueue$ExecutionRunner.run(DefaultConditionalExecutionQueue.java:131)\n    ... 3 more\nCaused by: com.android.aaptcompiler.ResourceCompilationException: Failed to compile values resource file E:\\My Client\\Henkako\\HenkakoPlus\\app\\build\\intermediates\\incremental\\debug\\mergeDebugResources\\merged.dir\\values\\values.xml\n    at com.android.aaptcompiler.ResourceCompiler.compileTable(ResourceCompiler.kt:192)\n    at com.android.aaptcompiler.ResourceCompiler.access$compileTable(ResourceCompiler.kt:1)\n    at com.android.aaptcompiler.ResourceCompiler$getCompileMethod$1.invoke(ResourceCompiler.kt:138)\n    at com.android.aaptcompiler.ResourceCompiler$getCompileMethod$1.invoke(ResourceCompiler.kt:138)\n    at com.android.aaptcompiler.ResourceCompiler.compileResource(ResourceCompiler.kt:123)\n    ... 27 more\nCaused by: java.lang.IllegalStateException: Can not extract resource from com.android.aaptcompiler.ParsedResource@636e1e76.\n    at com.android.aaptcompiler.TableExtractor.extractResourceValues(TableExtractor.kt:270)\n    at com.android.aaptcompiler.TableExtractor.extract(TableExtractor.kt:181)\n    at com.android.aaptcompiler.ResourceCompiler.compileTable(ResourceCompiler.kt:188)\n    ... 31 more\n\n",
    "AcceptedAnswerId": 72355635,
    "AcceptedAnswer": "Find and exchange all ' symbols in your strings.xml or somewhere else in your code with \\'\n"
}
{
    "Id": 71363302,
    "PostTypeId": 1,
    "Title": "Java sorting list of array vs sorting list of list",
    "Body": "I have a list of points where each point is a tiny list of size 2. I want to sort the list of points in increasing order of x and if x values are equal, I break tie by sorting in decreasing order of y.\nI wrote a custom comparator to sort the points like this:\nCollections.sort(points, (a, b) -> {\n    if (a.get(0) != b.get(0)) {\n        return a.get(0) - b.get(0);\n    } return b.get(1) - a.get(1); \n});\n\nHere's the input before sorting:\n(2, 1000)\n(9, -1000)\n(3, 15)\n(9, -15)\n(5, 12)\n(12, -12)\n(5, 10)\n(10001, -10)\n(19, 8)\n(10001, -8)\n\nHere's the result produced after sorting with the above comparator:\n(2, 1000)\n(3, 15)\n(5, 12)\n(5, 10)\n(9, -15)\n(9, -1000)\n(12, -12)\n(19, 8)\n(10001, -10)\n(10001, -8)\n\nObservations:\n\nThe input is sorted in ascending order on x.\n(5, 12) was correctly put before (5, 10).\n(9, -15) was correctly put before (9, -1000).\nHowever, (10001, -10) was put before (10001, -8). Even though -8 is larger than -10.\n\nFeel like I am missing something trivial. I experimented with a few other ways of writing the comparator like using Integer.compare(a, b) or just a.compareTo(t), but got the same result.\nFinally, I changed the representation of point from List to int[] and wrote the same comparator again. See results below:\nCollections.sort(points, (a, b) -> {\n    if (a[0] != b[0])\n        return a[0] - b[0];\n    return b[1] - a[1];\n});\n\nInput before sorting:\n(2, 1000)\n(9, -1000)\n(3, 15)\n(9, -150\n(5, 12)\n(12, -12)\n(5, 10)\n(10001, -10)\n(19, 8)\n(10001, -8)\n\nAfter sorting:\n(2, 1000)\n(3, 15)\n(5, 12)\n(5, 10)\n(9, -15)\n(9, -1000)\n(12, -12)\n(19, 8)\n(10001, -8)\n(10001, -10)\n\nSo list of arrays is getting sorted correctly as (10001, -8) was correctly put before (10001, -10).\nI am not able to understand why changing the representation of point resolved the issue and hence this question. I can give more details on how I am creating the List of points if required.\n",
    "AcceptedAnswerId": 71363726,
    "AcceptedAnswer": "\nI am missing something trivial\n\nMethod equals() should be used for object comparison. Double equals == checks whether two references point to the same object in memory.\nIf you change the condition inside the comparator to !a.get(0).equals(b.get(0)) it will work correctly.\n\nHowever, (10001, -10) was put before (10001, -8). Even though -8 is larger than -10.\n\nThe reason for such behavior is that JVM caches all the instances of Integer (as well as Byte, Short and Long) in the range [-128; 127]. I.e. these instances are reused, the result of autoboxing of let's say int with a value of 12 will be always the same object.\nBecause small values in your example like 3, 5, 12 will be represented by a single object, they were compared with == without issues. But the result of comparison with == for two Integer instances with a value of 10001 will be false because in this case there will be two distinct objects in the heap.\nThe approach of caching frequently used objects is called the Flyweight design pattern. It's very rarely used in Java because this pattern can bring benefits when tons of identical objects are being created and destroyed. Only in such a case caching these objects will pay off with a significant performance improvement. As far as I know, it's used in game development.\nUse the power of objects\nPoint must be an object, not a list, as Code-Apprentice has pointed out in his answer. Use the power of objects and don't overuse collections. It brings several advantages:\n\nclass provides you a structure, it's easier to organize your code when you are thinking in terms of objects;\nbehavior declared inside a class is reusable and easier to test;\nwith classes, you can use the power of polymorphism.\n\nCaution: objects could be also misused, one of the possible indicators of that is when a class doesn't declare any behavior apart from getters and its data is being processed somehow in the code outside this class.\nAlthough the notion of point (as a geometrical object) isn't complicated, there are some useful options with regard to methods. For example, you could make instances of the Point class to be able to check to whether they are aligned horizontally or vertically, or whether two points are within a particular radius. And Point class can implement Comparable interface so that points will be able to compare themselves without a Comparator.\nSorting\nWith Java 8 method sort()\nwas added to the List interface. It expects an instance of Comparator, and if element of the list implement comparable, and you want them to be sorted according to the natural order null can be passed as an argument.\n\nIf the specified comparator is null then all elements in this list must implement the Comparable interface and the elements' natural ordering should be used.\n\nSo instead of using utility class Collections you can invoke method sort() directly on a list of points (assuming that Point implements Comparable):\npoints.sort(null); // the same as   points.sort(Comparator.naturalOrder()); \n\nAlso, you can create multiple custom comparators by utilizing default and static methods from the Comparator interface like comparingInt() and thenComparing().\n(for more information on how to build comparators with Java 8 methods take a look at this tutorial)\n"
}
{
    "Id": 71463016,
    "PostTypeId": 1,
    "Title": "Find occurrence count of the longest common Prefix/Suffix in a List of Strings?",
    "Body": "Given a list of Strings:\nArrayList strList = new ArrayList();\nstrList.add(\"Mary had a little lamb named Willy\");\nstrList.add(\"Mary had a little ham\");\nstrList.add(\"Old McDonald had a farm named Willy\");\nstrList.add(\"Willy had a little dog named ham\");\nstrList.add(\"(abc)\");\nstrList.add(\"(xyz)\");\nstrList.add(\"Visit Target Store\");\nstrList.add(\"Visit Walmart Store\");\n\nThis should produce the output in the form of a HashMap prefixMap and suffixMap:\nPREFIX:\nMary had a -> 2\nMary had a little -> 2\n( -> 2\nVisit -> 2\n\nSUFFIX:\nnamed Willy -> 2\nham -> 2\n) -> 2\nStore -> 2\n\nSo far I'm able to generate a prefix that is present in all items in list using the following code:\npublic static final int INDEX_NOT_FOUND = -1;\n\npublic static String getAllCommonPrefixesInList(final String... strs) {\n    if (strs == null || strs.length == 0) {\n        return EMPTY_STRING;\n    }\n    \n    \n    final int smallestIndexOfDiff = getIndexOfDifference(strs);\n    if (smallestIndexOfDiff == INDEX_NOT_FOUND) {\n        \n        // All Strings are identical\n        if (strs[0] == null) {\n            return EMPTY_STRING;\n        }\n        return strs[0];\n    } else if (smallestIndexOfDiff == 0) {\n        \n        \n        // No common initial characters found, return empty String\n        return EMPTY_STRING;\n    } else {\n        \n        // Common initial character sequence found, return sequence\n        return strs[0].substring(0, smallestIndexOfDiff);\n    }\n}\n\n\n\n\n\n\npublic static int getIndexOfDifference(final CharSequence... charSequence) {\n    if (charSequence == null || charSequence.length <= 1) {\n        return INDEX_NOT_FOUND;\n    }\n    boolean isAnyStringNull = false;\n    boolean areAllStringsNull = true;\n    \n    \n    final int arrayLen = charSequence.length;\n    int shortestStrLen = Integer.MAX_VALUE;\n    int longestStrLen = 0;\n\n    // Find the min and max string lengths - avoids having to check that we are not exceeding the length of the string each time through the bottom loop.\n    for (int i = 0; i < arrayLen; i++) {\n        if (charSequence[i] == null) {\n            isAnyStringNull = true;\n            shortestStrLen = 0;\n        } else {\n            areAllStringsNull = false;\n            shortestStrLen = Math.min(charSequence[i].length(), shortestStrLen);\n            longestStrLen = Math.max(charSequence[i].length(), longestStrLen);\n        }\n    }\n\n    // Deals with lists containing all nulls or all empty strings\n    \n    if (areAllStringsNull || longestStrLen == 0 && !isAnyStringNull) {\n        return INDEX_NOT_FOUND;\n    }\n\n    // Handle lists containing some nulls or some empty strings\n    if (shortestStrLen == 0) {\n        return 0;\n    }\n\n    // Find the position with the first difference across all strings\n    int firstDiff = -1;\n    for (int stringPos = 0; stringPos < shortestStrLen; stringPos++) {\n        final char comparisonChar = charSequence[0].charAt(stringPos);\n        for (int arrayPos = 1; arrayPos < arrayLen; arrayPos++) {\n            if (charSequence[arrayPos].charAt(stringPos) != comparisonChar) {\n                firstDiff = stringPos;\n                break;\n            }\n        }\n        if (firstDiff != -1) {\n            break;\n        }\n    }\n\n    if (firstDiff == -1 && shortestStrLen != longestStrLen) {\n        \n        // We compared all of the characters up to the length of the\n        // shortest string and didn't find a match, but the string lengths\n        // vary, so return the length of the shortest string.\n        return shortestStrLen;\n    }\n    return firstDiff;\n}\n\nHowever, my goal is to include any prefix/suffix with at least 2+ occurrences into the resulting map.\nHow can this be achieved with Java?\n",
    "AcceptedAnswerId": 71507839,
    "AcceptedAnswer": "In my understanding of this problem the most suitable data structure for solving it is an acyclic disjointed Graph.\nIn general case, a graph will be comprised of several unconnected clusters. Each cluster will have a tree-like structure, in the edge case it'll form a linked list.\nBasically, the most simple naive approach on how to solve this problem is to create a bunch of linked list based on each line, and iterate over them. The drawbacks are: duplication of nodes (greater memory consumption), greater time-complexity (more operations required) and it's more error-prone because more manual actions are needed.\nThe description of the Graph\nSo I'll stick with the graph as the data structure for this problem and try to keep things as simple as possible.\nLet's consider the following input:\n\"Mary had a little lamb named Willy\"\n\"Mary had a little ham\"\n\"A B C\"\n\nThe graphical representation of the graph will look like this;\n\nThe two first lines will constitute a cluster formed from a linked list (the head part) and a tree (the tail part). The second cluster will be represented by a linked list, its vertices aren't connected with vertices formed from other strings.\nIt's not the only way the vertexes can be structured, the head could spawn an N-tree and a linked list could be observed somewhere in the middle.\nThe main takeaway is that in order to solve the problem, we need to track the chain of vertexes through all the branches until the vertexes overlap. In these parts of the graph, every prefix-strings and suffix-string that is common among two or more lines will be represented by a single vertex (node).\nTo maintain the number of strings that are mapped to a particular vertex, each vertex should have a variable (int groupCount in the code below), which is assigned with a default value of 1 when a vertex is being created and incremented each time a new string gets mapped to this vertex.\nEach vertex contains a map that holds references to its neighbours. When a new neighbour-vertex is being added, either new Vertex in being created based on the given string or the count of an existing vertex gets incremented.\nIn order to conform to this task, the graph should maintain references to all head-vertexes and tail-vertexes. For simplicity, instead of maintaining two groups of references to adjacent nodes, and two separate count variables (because suffix-count and prefix-count will differ) in each vertex, in this solution graph is actually comprised of two graph (suffix-graph and prefix-graph). And for that reason, the implementing class in named MultiGraph.\nIn order to populate both suffix-graph and prefix-graph with vertexes, method addCluster() iterates over the string of the given line by the means of Iterator in normal or reversed order, depending on which graph is being populated.\nDepth first search\nThe next step after the graphs are populated is to generate the maps of strings with the frequency of 2 and greater.\nFor that, the classical depth first search algorithm is being used.\nIn order to implement the DFS, a mutable container that will be used as a stack is required (ArrayDeque is being used for that purpose). The first element that is taken from the map of heads/tails will be placed on the top of the stack and an instance of StringBuilder holding the name of this element will be placed in the map.\nThen, to restore a string with a particular count, vertexes will be popped from the top of the stack and their neighbours with count > 1 in turn will be placed on top of the stack. A copy of the current prefix with the delimiter and the neighbour's name appended will get mapped to the neighbour-vertex.\nIf a count changes, that indicates that the current prefix represents the longest common string between at least two lines. In this case, prefix and count are being added to the resulting map.\nImplementation\nThe following implementation consists of two classes that are narrow-focused and self-contained. The MultiGraph class acts exclusively as data structure, maintaining two graphs. The pluming code, like splitting the lines of strings, is extracted into a separate class GraphManager.\nGraph\npublic class MultiGraph {\n    private final Map heads = new HashMap();\n    private final Map tails = new HashMap();\n\n    public void addCluster(Deque names) {\n        addCluster(heads, names.iterator());\n        addCluster(tails, names.descendingIterator());\n    }\n\n    private void addCluster(Map clusters, Iterator names) {\n        String rootName = names.next();\n        if (clusters.containsKey(rootName)) {\n            clusters.get(rootName).incrementGroupCount();\n        } else {\n            clusters.put(rootName, new Vertex(rootName));\n        }\n\n        Vertex current = clusters.get(rootName);\n        while (names.hasNext()) {\n            current = current.addNext(names.next());\n        }\n    }\n\n    public Map generatePrefixMap(String delimiter) {\n        Map countByPrefix = new HashMap();\n\n        for (Vertex next: heads.values()) {\n            if (next.getGroupCount() == 1) {\n                continue;\n            }\n            performDFS(heads, countByPrefix, delimiter, next);\n        }\n        return countByPrefix;\n    }\n\n    public Map generateSuffixMap(String delimiter) {\n        Map countBySuffix = new HashMap();\n\n        for (Vertex next: tails.values()) {\n            if (next.getGroupCount() == 1) {\n                continue;\n            }\n            performDFS(tails, countBySuffix, delimiter, next);\n        }\n        return countBySuffix;\n    }\n    // implementation of the Depth First Search algorithm\n    public void performDFS(Map clusters,\n                           Map countByPrefix,\n                           String delimiter, Vertex next) {\n\n        StringBuilder prefix = null;\n        Vertex current = next;\n        int count = next.getGroupCount();\n\n        Deque stack = new ArrayDeque(); // create as stack\n        Map prefixByVert = new HashMap();\n        stack.push(next); // place the first element on the stack\n        prefixByVert.put(current, new StringBuilder(current.getName()));\n\n        while (!stack.isEmpty()) {\n            current = stack.pop();\n            if (current.getGroupCount() < count) { // the number of strings mapped to the current Vertex has been changed\n                countByPrefix.put(prefix.toString(), count); // saving the result\n                count = current.getGroupCount();\n            }\n            prefix = prefixByVert.get(current);\n\n            for (Vertex neighbour: current.getNextVertByVal().values()) {\n                if (next.getGroupCount() == 1) {\n                    continue;\n                }\n                stack.push(neighbour);\n                prefixByVert.put(neighbour, new StringBuilder(prefix)\n                                    .append(delimiter)\n                                    .append(neighbour.getName()));\n            }\n        }\n\n        if (prefix != null && count > 1) {\n            countByPrefix.putIfAbsent(prefix.toString(), count);\n        }\n    }\n\n    private static class Vertex {\n        private final String name;\n        private int groupCount = 1;\n        private final Map nextVertByVal = new HashMap();\n\n        public Vertex(String name) {\n            this.name = name;\n        }\n\n        public Vertex addNext(String value) {\n            if (nextVertByVal.containsKey(value)) {\n                nextVertByVal.get(value).incrementGroupCount();\n            } else {\n                nextVertByVal.put(value, new Vertex(value));\n            }\n            return nextVertByVal.get(value);\n        }\n\n        public void incrementGroupCount() {\n            this.groupCount++;\n        }\n\n        public String getName() {\n            return name;\n        }\n\n        public int getGroupCount() {\n            return groupCount;\n        }\n\n        public Map getNextVertByVal() {\n            return nextVertByVal;\n        }\n    }\n}\n\nThe following class deals with the task of processing the input data: it splits the lines, takes care of discarding the empty string which might take place, and packs the input into a Deque to accommodate the iteration in both directions in a convenient way.\nIt also instantiates the graph and governs it's work. GraphManager takes care of providing the delimiter to the graph in order to restore the initial shape of strings while the resulting maps are being created. With that you can split the given lines on a white space, by empty string to process lines character by character or by punctuation marks without changing a single line in these two classes.\nGraphManager\npublic class GraphManager {\n    private MultiGraph graph = new MultiGraph();\n    private String delimiter;\n\n    private GraphManager(String delimiter) {\n        this.delimiter = delimiter;\n    }\n\n    public static GraphManager getInstance(Iterable lines, String delimiter) {\n        GraphManager gm = new GraphManager(delimiter);\n        gm.init(lines);\n        return gm;\n    }\n\n    private void init(Iterable lines) {\n        for (String line: lines) {\n            Deque names = new ArrayDeque();\n            for (String name: line.split(delimiter)) {\n                if (!name.isEmpty()) {\n                    names.add(name);\n                }\n            }\n            addCluster(names);\n        }\n    }\n\n    private void addCluster(Deque names) {\n        graph.addCluster(names);\n    }\n\n    public Map getPrefixMap() {\n        return graph.generatePrefixMap(delimiter);\n    }\n\n    public Map getSuffixMap() {\n        return graph.generateSuffixMap(delimiter);\n    }\n}\n\nmain()\npublic static void main(String[] args) {\n    List lines = List.of(\n            \"Mary had a little lamb named Willy\", \"Mary had a little ham\",\n            \"Old McDonald had a farm named Willy\", \"Willy had a little dog named ham\",\n            \"( abc )\", \"( xyz )\", \"Visit Target Store\", \"Visit Walmart Store\");\n\n    GraphManager gm = GraphManager.getInstance(lines, \" \");\n    \n    System.out.println(\"Prefixes:\");\n    for (Map.Entry entry: gm.getPrefixMap().entrySet()) {\n        System.out.println(entry.getValue() + \" \" + entry.getKey());\n    }\n\n    System.out.println(\"\\nSuffixes:\");\n    for (Map.Entry entry: gm.getSuffixMap().entrySet()) {\n        System.out.println(entry.getValue() + \" \" + entry.getKey());\n    }\n}\n\nOutput\nPrefixes:\n2 Mary had a little\n2 Visit\n2 (\n\nSuffixes:\n2 ham\n2 )\n2 Store\n2 Willy named\n\n"
}
{
    "Id": 72396628,
    "PostTypeId": 1,
    "Title": "Adding multiple products to productlist for queryProductDetailsAsync in android billing 5.0.0",
    "Body": "In the old android billing implementation you would build an sku list to query products:\nList skuList = new ArrayList();\n        skuList.add(SKU_POTION);\n        skuList.add(SKU_SWORD);\n        skuList.add(SKU_BOW);\n        SkuDetailsParams.Builder params = SkuDetailsParams.newBuilder();\n        params.setSkusList(skuList).setType(BillingClient.SkuType.INAPP);\n\nThe new billing implementation is more involved, and appears to limit you to adding just one product to a query list:\nImmutableList productList = ImmutableList.from(QueryProductDetailsParams.Product.newBuilder()\n                    .setProductId(SKU_POTION)\n                    .setProductType(BillingClient.ProductType.INAPP)\n                    .build());\n    \n            QueryProductDetailsParams params = QueryProductDetailsParams.newBuilder()\n                    .setProductList(productList)\n                    .build();\n    \n            billingClient.queryProductDetailsAsync(\n            params,\n            new ProductDetailsResponseListener() {\n                public void onProductDetailsResponse(BillingResult billingResult, List productDetailsList) {\n                    if (billingResult.getResponseCode() == BillingClient.BillingResponseCode.OK && productDetailsList != null) {\n                        for (ProductDetails skuDetails : productDetailsList) {                    \n                            mProductDetailsMap.put(skuDetails.getProductId(), skuDetails);                           \n                        }\n                    }\n                   \n                }\n            }\n    );\n\nIt makes you build the productList for the productDetailsList for the mProductDetailsMap that's needed to start the purchase flow:\npuchasestring=SKU_POTION;\ninitiatePurchaseFlow(mProductDetailsMap.get(puchasestring));\n\nHow would I add multiple products to the productList that begins the implementation? I don't want to have to repeat the entire code segment for each item to add to the mProductDetailsMap, which is the Primitive Pete method I'm using for now.\n",
    "AcceptedAnswerId": 72397831,
    "AcceptedAnswer": "For multiple products:\nImmutableList productList = ImmutableList.from(\nQueryProductDetailsParams.Product.newBuilder()\n                    .setProductId(SKU_POTION)\n                    .setProductType(BillingClient.ProductType.INAPP)\n                    .build(),\nQueryProductDetailsParams.Product.newBuilder()\n                    .setProductId(SKU_SWORD)\n                    .setProductType(BillingClient.ProductType.INAPP)\n                    .build(),\nQueryProductDetailsParams.Product.newBuilder()\n                    .setProductId(SKU_BOW)\n                    .setProductType(BillingClient.ProductType.INAPP)\n                    .build());\n\n"
}
{
    "Id": 71473553,
    "PostTypeId": 1,
    "Title": "Action requested: Declare your Ad ID permission",
    "Body": "Today i have got this email:\n\nLast July, we announced Advertising policy changes to help bolster\nsecurity and privacy. We added new restrictions on identifiers used by\napps that target children. When users choose to delete their\nadvertising ID in order to opt out of personalization advertising,\ndevelopers will receive a string of zeros instead of the identifier if\nthey attempt to access the identifier. This behavior will extend to\nphones, tablets, and Android TV starting April 1, 2022. We also\nannounced that you need to declare an AD_ID permission when you update\nyour app targeting API level to 31 (Android 12). Today, we are sharing\nthat we will give developers more time to ease the transition. We will\nrequire this permission declaration when your apps are able to target\nAndroid 13 instead of starting with Android 12.\nAction Items If you use an advertising ID, you must declare the AD_ID\nPermission when your app targets Android 13 or above. Apps that don\u2019t\ndeclare the permission will get a string of zeros. Note: You\u2019ll be\nable to target Android 13 later this year. If your app uses an SDK\nthat has declared the Ad ID permission, it will acquire the permission\ndeclaration through manifest merge. If your app\u2019s target audience\nincludes children, you must not transmit Android Advertising ID (AAID)\nfrom children or users of unknown age.\n\nMy app is not using the Advertising ID. Should i declare the AD_ID Permission in Manifest or not?\n",
    "AcceptedAnswerId": 71474159,
    "AcceptedAnswer": "If your app uses the Google Mobile Ads SDK(Admob) version\u00a020.4.0\u00a0or higher, you can skip setting up the permission manually since the SDK automatically declares it\nMore informations here:\nhttps://developers.google.com/admob/android/quick-start\n"
}
{
    "Id": 72227442,
    "PostTypeId": 1,
    "Title": "Unsupported class file major version 61",
    "Body": "I am trying to integrate Glowroot into my Java application. Unfortunately, I get the following error:\n2022-05-13 09:25:57.777 ERROR o.g.a.w.PointcutClassFileTransformer - Unsupported class file major version 61\njava.lang.IllegalArgumentException: Unsupported class file major version 61\n    at org.glowroot.agent.shaded.org.objectweb.asm.ClassReader.(ClassReader.java:196)\n\nNeither Glowroot nor my application seem to use gradle so I have no idea where this incompatibility is coming from.\nHave you got any idea on how I could find the source of the incompatibility and then how I could fix it?\nThank you!\nEDIT: I use Glowroot in the version 0.13.6 .\nSecond edit: Seems like the version of glowroot was the issue...\n",
    "AcceptedAnswerId": 72229157,
    "AcceptedAnswer": "(I incorrectly was zeroing in on the \"Unsupported class file major version 61\" message without looking at the stacktrace.)\nThe problem (as pointed out by @Mark Rotteveel) is that glowroot is failing while trying to do some code transformation using ASM.  Apparently the ClassReader in the version of ASM that is bundled in glowroot 0.13.6 doesn't understand version 61 (Java 17) class files.\nQ: How to solve this?\nA: Use glowroot 0.14.0-beta.2 or later; see https://github.com/glowroot/glowroot/issues/906.  Alternative, build your application and its dependencies (as required) for an earlier (target) version of Java, and (maybe1) run on an earlier version of Java.\n\n1 - It depends on whether the code transformations involve the ASM ClassReader reading Java SE classes.\n"
}
{
    "Id": 71548717,
    "PostTypeId": 1,
    "Title": "Differences in floating point between JDK 8 and JDK 13",
    "Body": "It seems that JDK 8 and JDK 13 have different floating points.\nI get on JDK 8, using Math:\ncos(2.3) = -0.666276021279824\n\nAnd on JDK 13:\ncos(2.3) = -0.6662760212798241\n\nHow does this happen? Difference shows on 11th Gen Intel and on AMD Ryzen using Windows 10.\nEdit 20.03.2022:\nUsing Long.toHexString(Double.doubleToRawLongBits()) I get different bit patterns:\nI get on JDK 8:\ncos(2.3) = 0xbfe5522217302fe0\n\nAnd I get on JDK 13:\ncos(2.3) = 0xbfe5522217302fe1\n\n",
    "AcceptedAnswerId": 71549434,
    "AcceptedAnswer": "This seems to be caused by a JVM intrinsic function for Math.cos, which is described in the related issue JDK-8242461. The behavior experienced there is not considered an issue:\n\nThe returned results reported in this bug are indeed adjacent floating-point values [this is the case here as well]\n[...]\nTherefore, while it is possible one or the other of the returned values is outside of the accuracy bounds, just have different return values for Math.cos is not in and of itself evidence of a problem.\nFor reproducible results, use the StrictMath.cos instead.\n\nAnd indeed, disabling the intrinsics using -XX:+UnlockDiagnosticVMOptions -XX:DisableIntrinsic=_dcos (as proposed in the linked issue), causes Math.cos to have the same (expected) result as StrictMath.cos.\nSo it appears the behavior you are seeing here is most likely compliant with the Math documentation as well.\n"
}
{
    "Id": 72478972,
    "PostTypeId": 1,
    "Title": "Stange behaviour since upgrade from 2.6.2 to 2.7.0",
    "Body": "I faced to a strange behaviour while upgrading my application from SpringBoot 2.6.2 to 2.7.0.\nI've a starter with autoconfiguration which is responsible of initializing JPA auditing :\n@Configuration\n@ConditionalOnBean(DataSource.class)\n@ConditionalOnClass({DataSource.class, AuditorAware.class, SecurityContextHolder.class})\n@AutoConfigureAfter({HibernateJpaAutoConfiguration.class, SecurityAutoConfiguration.class, ClockSpringConfiguration.class})\n@EnableJpaAuditing(auditorAwareRef = \"auditorProvider\", dateTimeProviderRef = \"dateTimeProvider\")\npublic class JpaAuditingSpringConfiguration {\n    @Bean\n    public AuditorAware auditorProvider() {\n        return () ->\n                Optional.ofNullable(SecurityContextHolder.getContext())\n                        .map(SecurityContext::getAuthentication)\n                        .map(Authentication::getName);\n    }\n\n    @Bean\n    public DateTimeProvider dateTimeProvider(Clock clock) {\n        return () ->\n                Optional.of(clock)\n                        .map(Clock::instant);\n    }\n}\n\nThis starter is fine in 2.6.2. But in 2.7.0 the @ConditionalOnBean(DataSource.class) avoid the starter to perform initialization.\nWhen i remove the statement all is fine again.\nI don't understand why it doesn't work since the update?\nMaybe i misused or forgot some statement. The behaviour i attempt to is the autoconfiguration apply only if a datasource bean is registred.\nIf someone can help me ?\nPS : sorry for my english :-)\n",
    "AcceptedAnswerId": 72531265,
    "AcceptedAnswer": "So i found the solution, it was a mistake from myself... I put the @AutoConfigureAfter on a @Configuration imported by the autoconfiguration entrypoint. So i move the statement on the autoconfiguration class and now all is fine.\nThe new annotation @AutoConfiguration will be very usefull to avoid this kinf of mistake.\n"
}
{
    "Id": 71473485,
    "PostTypeId": 1,
    "Title": "What is the difference between a final Class and a Record?",
    "Body": "In simple words what is the difference between a final class and a record in Java 17?\nIn which case should I use a record?\n",
    "AcceptedAnswerId": 71474203,
    "AcceptedAnswer": "Record is an immutable class, i.e. all its fields are final. Records are implicitly final, hence as well as regular final class record can't be extended.\nThere are a number of restrictions imposed on records (for more details, take a look at JEP 395).\nContrary to normal classes:\n\nit's forbidden to declare instance fields explicitly inside records (and reminder: all fields are final, which is a very impotent distinction);\nextends clause is not allowed with records, because every record implicitly extends abstract class Record;\nrecord can't be declared with any of these modifiers: abstract, sealed, or non-sealed (as a consequence of being implicitly final);\nrecords can't declare instance initializers and native methods.\n\nRecords are meant to be \"transparent carriers for immutable data\" as JEP 395 says.\nThey are designed to be concise, default constructor, getters, hashCode/equals and toString() will be generated by the compiler for you. So that inside a record you need to declare only your custom logic (if any) and record declaration can be literally a one-liner.\nRecords differ a lot from regular final classes.\nAlso, apart from the peculiarities mentioned above, the mechanism of serialization / deserialization was reimplemented for records, so that deserialization doesn't bypass the constructor.\n\nIn which case should I use a record?\n\nIn short, if your objects must be stateful, or you need to extend a particular class, then you can't utilize record in such a case.\nOn the other hand, if your objects are meant just carry the data, they are not intended to be modified or inherit from other classes, then it might be a good candidate to be implemented as a record.\n"
}
{
    "Id": 72259078,
    "PostTypeId": 1,
    "Title": "Invariant Generics don't seem working correctly",
    "Body": "I've read some articles about Covariance, Contravariance, and Invariance in Java, but I'm confused about them.\nI'm using Java 11, and I have a class hierarchy A => B => C (means that C is a subtype of B and A, and B is a subtype of A) and a class Container:\nclass Container {\n    public final T t;\n    public Container(T t) {\n        this.t = t;\n    }\n}\n\nfor example, if I define a function:\npublic Container method(Container param){\n  ...\n}\n\nhere is my confusion, why does the third line compile?\nmethod(new Container(new A())); // ERROR\nmethod(new Container(new B())); // OK\nmethod(new Container(new C())); // OK Why ?, I make a correction, this compiles OK\n\nif in Java Generics are invariant.\nWhen I define something like this:\nContainer conta =  new Container(new A()); // ERROR, Its OK!\nContainer contb =  new Container(new B()); // OK, Its OK!\nContainer contc =  new Container(new C()); // Ok, why ? It's not valid, because they are invariant\n\n",
    "AcceptedAnswerId": 72275673,
    "AcceptedAnswer": "One of the boons introduced with Java 7 is the so-called diamond operator .\nAnd it has been with us for so long, that it's easy to forget that every time when diamond is being used while instantiating a generic class the compiler should infer the generic type from the context.\nIf we define a variable which will hold a reference to a list of Person objects like this:\nList people = new ArrayList(); // effectively - ArrayList()\n\nthe compiler will infer the type of the ArrayList instance from the type of the variable people on the left.\nIn the Java language specification, the expression new ArrayList() is being described as a class instance creation expression and because it doesn't specify the generic type parameter and is used within a context, it should be classified as being a poly expression. A quote from the specification:\n\nA class instance creation expression is a poly expression (\u00a715.2) if\nit uses the diamond form for type arguments to the class, and it\nappears in an assignment context or an invocation context (\u00a75.2,\n\u00a75.3).\n\nI.e. when diamond  is used with a generic class instantiation, the actual type will depend on the context in which it appears.\nThe three statements below represent the case of so-called assignment context. And all three instances Container will be inferred as being of type B.\nContainer conta = new Container(new A()); // 1 - ERROR   because `B t = new A()` is incorrect\nContainer contb = new Container(new B()); // 2 - fine    because `B t = new B()` is correct\nContainer contc = new Container(new C()); // 3 - fine    because `B t = new C()` is also correct\n\nSince all instances of container are of type B and of parameter type expected by the contractor also will be B. I.e. can provide an instance of B or any of its subtypes. Therefore, in the case 1 we are getting a compilation error, meanwhile 2 and 3 (B and subtype of B) will compile correctly.\nAnd it in't a violation of invariant behavior. Think about it this way: we can store in a List instances of Integer, Byte, Double, etc., that would not lead to any problem since they all can represent their super type Number. But the compiler will not allow assigning this list to any list that is not of type List because otherwise it would be impossible to ensure that this assignment is safe. And that is what the invariance means - we can assign only List to a variable of type List (but we are free to store any subtype of Number in it, it's safe).\nAs an example, let's consider that there's a setter method in the Container class:\npublic class Container {\n    public T t;\n    public Container(T t) {\n        this.t = t;\n    }\n        \n    public void setT(T t) {\n        this.t = t;\n    }\n}\n\nNow let's use it:\nContainer contb =  new Container(null); // to avoid any confusion initialy `t` will be assigned to `null`\n\ncontb.setT(new A()); // compilation error - because expected type is `B` or it's subtype\ncontb.setT(new B()); // fine\ncontb.setT(new C()); // fine because C is a subtype of B\n\nWhen we deal with a class instance creation expression using diamond , which is passed to a method as an argument, the type will be inferred from the invocation context as the quote from the specification provided above states.\nBecause method() expects Container, all instances above will be inferred as being of type B.\nmethod(new Container(new A())); // Error\nmethod(new Container(new B())); // OK - because `B t = new B()` is correct\nmethod(new Container(new C())); // OK - because `B t = new C()` is also correct\n\nNote\nThe important thing to mention that prior to Java 8 (i.e. with Java 7, because we are using diamond) the expression new Container(new C()) will be interpreted by the compiler as a standalone expression (i.e. the context will be ignored) creating an instance of Container. It means your initial guess was somewhat correct: with Java 7 the below statement would not compile.\nContainer contc = new Container(new C()); // Container = Container - is an illegal assignment\n\nBut Java 8 has introduced a feature called target types and poly expressions (i.e. expressions that appear within a context) that insures that context will always be taken into account by the type inference mechanism.\n"
}
{
    "Id": 71642208,
    "PostTypeId": 1,
    "Title": "Parameter value [%Gabrek%] did not match expected type [java.lang.Character (n/a)];",
    "Body": "i've been writing wirting a program in Spring Boot Web with JPA and i'm using a query to access some data with a 'contains' and 'ignorecase' filter, i've done this before in other programs and it has worked fine, but now i'm getting this error, i'm completely lost at this point since i can't find anything in google, i went really far down the rabbit hole looking as to why it happens and so far i don't see anything out of place in my code, the type of variable declared seems to be okay but as i've said, i'm lost. It's important to mention that for some reason when I do the query on my website for the first time, everything works fine, i get the proper results and all, but when I go back to home and try with another query (or even the same) i get the error. Code below:\nModel\nimport javax.persistence.Column;\nimport javax.persistence.Entity;\nimport javax.persistence.GeneratedValue;\nimport javax.persistence.GenerationType;\nimport javax.persistence.Id;\n\n@Entity\npublic class Serie {\n    \n    @Id\n    @Column(columnDefinition = \"NUMERIC(19,0)\")\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Integer id;\n    private String title;\n    private String red;\n    @Column(columnDefinition = \"NUMERIC(19,0)\")\n    private double rating;\n\nRepository\nimport java.util.List;\n\nimport org.springframework.data.jpa.repository.JpaRepository;\n\nimport cl.desafiolatam.imdb.modelo.Serie;\n\npublic interface SerieRepository extends JpaRepository {\n\n    public List findByTitleContainingIgnoreCase(String title);\n    \n}\n\nService\nimport cl.desafiolatam.imdb.vo.SerieVO;\n\npublic interface SerieService {\n    \n    public SerieVO findByTitleContainingIgnoreCase(String title);\n\n}\n\nService implementation\nimport java.util.ArrayList;\nimport java.util.List;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Service;\nimport org.springframework.transaction.annotation.Transactional;\n\nimport cl.desafiolatam.imdb.dao.SerieRepository;\nimport cl.desafiolatam.imdb.modelo.Serie;\nimport cl.desafiolatam.imdb.service.SerieService;\nimport cl.desafiolatam.imdb.vo.SerieVO;\n\n@Service\npublic class SerieServiceImpl implements SerieService {\n    \n    private static final Logger logger = LoggerFactory.getLogger(SerieServiceImpl.class);\n    \n    @Autowired\n    SerieRepository dao;\n    SerieVO respuesta;\n\n    @Override\n    @Transactional(readOnly = true)\n    public SerieVO findByTitleContainingIgnoreCase(String title) {\n        \n        respuesta = new SerieVO(\"Ha ocurrido un error!\", \"104\", new ArrayList());\n\n        try {\n            List serie = dao.findByTitleContainingIgnoreCase(title);\n            System.out.println(serie);\n            if(serie.size() > 0) {\n                respuesta.setSeries(serie);\n                respuesta.setMensaje(\"Se ha encontrado el registro\");\n                respuesta.setCodigo(\"0\");\n            } else {\n                respuesta.setMensaje(\"No se ha encontrado el registro\");\n                respuesta.setCodigo(\"104\");\n            }\n        } catch (Exception e) {\n            logger.error(\"Error al buscar la serie\", e);\n        }\n        \n        return respuesta;\n    }\n\n}\n\nVisual object\nimport java.util.List;\n\nimport cl.desafiolatam.imdb.modelo.Serie;\n\npublic class SerieVO extends GenericVO {\n    \n    List series;\n\n    public SerieVO(String mensaje, String codigo, List series) {\n        super(mensaje, codigo);\n        this.series = series;\n    }\n\n    public SerieVO() {\n        super();\n    }\n\nController\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Controller;\nimport org.springframework.ui.Model;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.ModelAttribute;\nimport org.springframework.web.bind.annotation.PostMapping;\nimport org.springframework.web.bind.annotation.RequestParam;\nimport org.springframework.web.servlet.ModelAndView;\nimport org.springframework.web.servlet.mvc.support.RedirectAttributes;\n\nimport cl.desafiolatam.imdb.modelo.Serie;\nimport cl.desafiolatam.imdb.service.SerieService;\nimport cl.desafiolatam.imdb.vo.SerieVO;\n\n@Controller\npublic class SerieController {\n\n    private final static Logger logger = LoggerFactory.getLogger(SerieController.class);\n\n    @Autowired\n    private SerieService svc;\n\n@GetMapping(\"/buscarSerie\")\n    public ModelAndView buscarSerie(Model model, @RequestParam String nombreSerie) {\n        \n        SerieVO respuestaServicio = new SerieVO();\n        respuestaServicio.setMensaje(\"No se ha encontrado la serie\");\n        \n        try {\n            respuestaServicio = svc.findByTitleContainingIgnoreCase(nombreSerie);\n            model.addAttribute(\"listaSeries\", respuestaServicio.getSeries());\n            return new ModelAndView(\"resultadoserie\");\n        } catch (Exception e) {\n            logger.error(\"Error al buscar la serie\", e);\n        }\n        \n        return new ModelAndView(\"redirect:/user\");\n        \n    }\n}\n\nSearch input\n\n        \n            \n                \n                    Buscar serie\n                \n            \n            \n                \n                    \n                        \n                            \n                                <input type=\"text\" class=\"form-control\" id=\"floatingInputGrid\"\n                                    value=\"\" name=\"nombreSerie\" required> <label\n                                    for=\"floatingInputGrid\">Serie\n                            \n                        \n                    \n                    \n                        \n                    \n                \n            \n        \n    \n\nAs i've said, im really lost, researched everywhere, and checked the code in my last projects, i just can't find out why this one does me this dirty. Won't even fail at the start, it gives me a glimpse of hope and when i want to retry it, it crushes that little hope. :)\nI tried deleting my code and copy&paste from projects where i know it works as intended, changed the variable and param. names to make it work with the new program but didn't work. Did a side by side comparison, tried a @Query writing the specific instruction. Looking for info. only with the 'contains' filter and yet, nothing worked.\n",
    "AcceptedAnswerId": 71649782,
    "AcceptedAnswer": "According to the Spring Data JPA issue #2472 this seems to be a problem in Hibernate 5.6.6 and 5.6.7.\nThe Hibernate bug is HHH-15142.\nThe solution is to either downgrade to Hibernate 5.6.5 or wait for a Hibernate patch to solve this issue.\nUpdate: According to the bug report above this is resolved in version 5.6.9.\n"
}
{
    "Id": 72510274,
    "PostTypeId": 1,
    "Title": "Terminate a Stream when there is no incoming Data after certain Timeout",
    "Body": "I have an InputStream and OutputStream (there is no socket).\nI have a stream-based code that does some mapping/filtering/grouping/processing.\nMy main goal to terminate the stream if the maxDuration was exceeded:\nvoid fillStreamMap(BufferedReader reader) {\n    final Instant end = Instant.now().plusNanos(TimeUnit.NANOSECONDS.convert(maxDuration));\n\n    this.map = reader.lines()\n        .takeWhile(e -> checkTimeout(end))\n        .map(this::jsonToBuyerEventInput)\n        .filter(Objects::nonNull)\n        .filter(getFilter()::apply)\n        .limit(super.maxEvent)\n        .collect(Collectors.groupingBy(BuyerEventInput::getBuyer));\n}\n\nboolean checkTimeout(Instant end){\n    return Instant.now().getEpochSecond() <= end.getEpochSecond();\n}\n\nI'm using takeWhile which is a very useful function, but it checks the termination condition if there is an upcoming event.\nSo if there is no data sent, it doesn't check the condition because this function is built to take a Predicate as an argument.\nIs there any way to accomplish this goal?\n",
    "AcceptedAnswerId": 72553605,
    "AcceptedAnswer": "Here is an approach that operates on Streams. The core function is timedTake(Stream stream, long timeout, TimeUnit unit). The idea is to traverse the original stream using its raw Spliterator, which makes it possible to set a timeout.\nimport java.io.BufferedReader;\nimport java.io.InputStreamReader;\nimport java.util.Optional;\nimport java.util.Spliterator;\nimport java.util.concurrent.ExecutionException;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.Future;\nimport java.util.concurrent.ThreadFactory;\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.TimeoutException;\nimport java.util.function.Supplier;\nimport java.util.stream.Stream;\n\nclass Main {\n    static  Stream generateOrderedStream(Supplier> s) {\n        // Returns an ordered stream with the values of the Optionals returned by s.get(). An empty Optional ends the stream.\n        // As pseudocode:\n        //     for (Optional o = s.get(); o.isPresent(); o = s.get())\n        //         emit o.get();\n        return Stream.iterate(s.get(), Optional::isPresent, prev -> s.get())\n            .map(Optional::get);\n    }\n\n    static  Optional advance(Spliterator iter) {\n        // Returns an Optional with the next element of the iterator, or an empty Optional if there are no more elements.\n        // (This method is much nicer than calling iter.tryAdvance() directly.)\n        final var r = new Object() { T elem; };\n        return iter.tryAdvance(elem -> r.elem = elem) ? Optional.of(r.elem) : Optional.empty();\n    }\n\n    static ThreadFactory daemonThreadFactory() {\n        return (r) -> {\n            Thread thread = new Thread(r);\n            thread.setDaemon(true);\n            return thread;\n        };\n    }\n\n    static  Stream timedTake(Stream stream, long timeout, TimeUnit unit) {\n        // Traverses the stream until the timeout elapses and returns the traversed elements.\n        final long deadlineNanos = System.nanoTime() + unit.toNanos(timeout);\n        final ExecutorService executor = Executors.newSingleThreadExecutor(daemonThreadFactory());\n        final Spliterator iter = stream.spliterator();\n        return generateOrderedStream(() -> {\n            try {\n                Future> future = executor.submit(() -> advance(iter));\n                long remainingNanos = deadlineNanos - System.nanoTime();\n                Optional optElem = future.get(remainingNanos, TimeUnit.NANOSECONDS);\n                if (!optElem.isPresent()) { // this is the end of the input stream, so clean up\n                    executor.shutdownNow();\n                }\n                return optElem;\n            } catch (TimeoutException e) {\n                executor.shutdownNow();\n                return Optional.empty(); // mark this as the end of the result stream\n            } catch (ExecutionException e) {\n                executor.shutdownNow();\n                throw new RuntimeException(e.getCause());\n            } catch (InterruptedException e) {\n                executor.shutdownNow();\n                throw new RuntimeException(e);\n            }\n        });\n    }\n\n    static void fillStreamMap(BufferedReader reader) {\n        // streaming demo\n        long maxDurationSecs = 5;\n        timedTake(reader.lines(), maxDurationSecs, TimeUnit.SECONDS)\n            .takeWhile(line -> !line.contains(\"[stop]\"))\n            .map(line -> \"[mapped] \" + line)\n            .forEachOrdered(System.out::println);\n    }\n\n    public static void main(String[] args) {\n        BufferedReader reader = new BufferedReader(new InputStreamReader(System.in));\n        fillStreamMap(reader);\n    }\n}\n\n\nAnother approach is to operate at the Reader level, and read with a timeout from the BufferedReader (which presumably wraps System.in). Unfortunately, it's very hard to do this properly (see e.g. Set timeout for user's input, and the article Timeout on Console Input).\nOne idea from those linked pages is to poll BufferedReader.ready() until it returns true, and then call readLine(). This is ugly (because it uses polling) and unreliable, because readLine() can block even if ready() returned true \u2013 for example because an incomplete line is available (on Unix-like systems the user can achieve this by typing some text then pressing Ctrl+D instead of Enter).\nAnother idea is to create a background thread that repeatedly calls BufferedReader.readLine() and inserts the results into a BlockingQueue (such as ArrayBlockingQueue). Then the main thread can call take() or poll(timeout, unit) on the queue to obtain lines.\nA limitation of this approach is that if you later want to read from the BufferedReader directly (as opposed to through the queue), it's pretty much impossible to avoid losing (at least) one line of input. This is because a thread can't be interrupted cleanly when it's blocked on readLine(), so if the main thread decides to stop early (e.g. because of a timeout) it can't prevent the background thread from reading the line it is currently waiting for.\nYou could try to \"unread\" the last line using mark(readAheadLimit) and reset(), but synchronization will be difficult \u2013 another thread could try to read from the BufferedReader before the background thread calls reset(). You'd probably have to synchronize using the the lock field, however its access level is protected so you'd only be able to access it using reflection or by subclassing BufferedReader. Also, reset() will fail if the line to be unread is longer than readAheadLimit.\nHere is an implementation that assumes you only read lines via the queue.\nDISCLAIMER: Beware of bugs in these code snippets \u2013 multi-threading is tricky. I might try improve the code another time.\nimport java.io.BufferedReader;\nimport java.io.IOException;\nimport java.io.InputStreamReader;\nimport java.util.Optional;\nimport java.util.concurrent.ArrayBlockingQueue;\nimport java.util.concurrent.TimeUnit;\nimport java.util.function.Supplier;\nimport java.util.stream.Stream;\n\nclass InterruptibleLineReader {\n    private static final String EOF = new String(\"\");\n    BufferedReader reader;\n    ArrayBlockingQueue lines = new ArrayBlockingQueue(/* capacity: */ 2);\n    Thread backgroundThread;\n    IOException exception;\n\n    public InterruptibleLineReader(BufferedReader reader) {\n        this.reader = reader;\n        // start a background thread to read lines\n        backgroundThread = new Thread(this::backgroundTask);\n        backgroundThread.setDaemon(true);\n        backgroundThread.start();\n    }\n\n    public void close() {\n        backgroundThread.interrupt();\n        lines.clear();\n        lines.add(EOF);\n    }\n\n    private void backgroundTask() {\n        try {\n            try {\n                while (true) {\n                    String line = reader.readLine();\n                    if (Thread.interrupted()) {\n                        // nothing to do (close() is responsible for lines.put(EOF) etc. in this case)\n                        break;\n                    } else if (line == null) {\n                        lines.put(EOF);\n                        break;\n                    }\n                    lines.put(line);\n                }\n            } catch (IOException e) {\n                exception = e;\n                lines.put(EOF);\n            }\n        } catch (InterruptedException e) {\n            // nothing to do (close() is responsible for lines.put(EOF) etc. in this case)\n        }\n    }\n\n    public String readLine(long timeout, TimeUnit unit) throws IOException, InterruptedException {\n        String line = lines.poll(timeout, unit);\n        if (line == EOF) { // EOF or IOException\n            lines.put(EOF); // restore the EOF so that any concurrent (and future) calls to this method won't block\n            if (exception != null) {\n                throw exception;\n            } else {\n                return null;\n            }\n        }\n        return line;\n    }\n}\n\nclass Main {\n    static  Stream generateOrderedStream(Supplier> s) {\n        // Returns an ordered stream with the values of the Optionals returned by s.get(). An empty Optional ends the stream.\n        // As pseudocode:\n        //     for (Optional o = s.get(); o.isPresent(); o = s.get())\n        //         emit o.get();\n        return Stream.iterate(s.get(), Optional::isPresent, prev -> s.get())\n            .map(Optional::get);\n    }\n\n    static Stream timedReadLines(InterruptibleLineReader lineReader, long timeout, TimeUnit unit) {\n        // Reads lines until the timeout elapses and returns them as a stream.\n        final long deadlineNanos = System.nanoTime() + unit.toNanos(timeout);\n        return generateOrderedStream(() -> {\n            try {\n                long remainingNanos = deadlineNanos - System.nanoTime();\n                return Optional.ofNullable(lineReader.readLine(remainingNanos, TimeUnit.NANOSECONDS));\n            } catch (IOException|InterruptedException e) {\n                throw new RuntimeException(e);\n            }\n        });\n    }\n\n    static void fillStreamMap(InterruptibleLineReader lineReader) {\n        // streaming demo\n        long maxDurationSecs = 5;\n        timedReadLines(lineReader, maxDurationSecs, TimeUnit.SECONDS)\n            .takeWhile(line -> !line.contains(\"[stop]\"))\n            .map(line -> \"[mapped] \" + line)\n            .forEachOrdered(System.out::println);\n    }\n\n    public static void main(String[] args) {\n        BufferedReader reader = new BufferedReader(new InputStreamReader(System.in));\n\n        // stream lines\n        InterruptibleLineReader lineReader = new InterruptibleLineReader(reader);\n        fillStreamMap(lineReader);\n        lineReader.close();\n\n        /*\n        // attempt to use the BufferedReader directly\n        // NOTE: several lines may be lost (depending on the capacity of the ArrayBlockingQueue and how quickly the lines are consumed)\n        System.out.println(\"--- reading directly from BufferedReader ---\");\n        while (true) {\n            try {\n                String line = reader.readLine();\n                if (line == null) { break; }\n                System.out.println(\"[raw] \" + line);\n            } catch (IOException e) {\n                throw new RuntimeException(e);\n            }\n        }\n        */\n    }\n}\n\nHere is a more sophisticated implementation that only loses one line of input if you close the queue and read directly from the BufferedReader. It uses a custom \"0-capacity\" queue to ensure that at most one line will be lost.\nimport java.io.BufferedReader;\nimport java.io.IOException;\nimport java.io.InputStreamReader;\nimport java.util.NoSuchElementException;\nimport java.util.Optional;\nimport java.util.concurrent.TimeUnit;\nimport java.util.function.Supplier;\nimport java.util.stream.Stream;\n\nclass InterruptibleLineReader {\n    BufferedReader reader;\n    ZeroCapacityBlockingQueue lines = new ZeroCapacityBlockingQueue(); // a null line indicates EOF or IOException\n    Thread backgroundThread;\n    IOException exception;\n    boolean eof;\n\n    public InterruptibleLineReader(BufferedReader reader) {\n        this.reader = reader;\n        // start a background thread to read lines\n        backgroundThread = new Thread(this::backgroundTask);\n        backgroundThread.setDaemon(true);\n        backgroundThread.start();\n    }\n\n    private void markAsEOF() {\n        eof = true;\n        if (lines.poll() != null) { // markAsEOF() should not be called when there are unconsumed lines\n            throw new IllegalStateException();\n        }\n        lines.offer(null); // unblock threads that are waiting on the queue\n    }\n\n    public void close() {\n        backgroundThread.interrupt();\n        // warn if there is an unconsumed line, and consume it so we can indicate EOF\n        String line = lines.poll();\n        if (line != null) {\n            System.err.println(\"InterruptibleLineReader: warning: discarding unconsumed line during close(): '\" + line + \"'\");\n        }\n        markAsEOF();\n    }\n\n    private void backgroundTask() {\n        try {\n            while (true) {\n                String line = reader.readLine();\n                if (Thread.interrupted()) {\n                    if (line != null) {\n                        System.err.println(\"InterruptibleLineReader: warning: discarding line that was read after close(): '\" + line + \"'\");\n                    }\n                    // nothing further to do (close() is responsible for calling markAsEOF() in this case)\n                    break;\n                } else if (line == null) { // EOF\n                    markAsEOF();\n                    break;\n                }\n                lines.put(line); // this blocks until the line has been consumed (\"0-capacity\" behaviour)\n                if (Thread.interrupted()) {\n                    // nothing to do (close() is responsible for calling markAsEOF() in this case)\n                    break;\n                }\n            }\n        } catch (IOException e) {\n            exception = e;\n            markAsEOF();\n        } catch (InterruptedException e) {\n            // nothing to do (close() is responsible for calling markAsEOF() in this case)\n        }\n    }\n\n    public String readLine() throws IOException, InterruptedException {\n        String line = lines.take();\n        if (line == null) { // EOF or IOException\n            markAsEOF(); // restore the null so that any concurrent (and future) calls to this method won't block\n            if (exception != null) {\n                throw exception;\n            } else {\n                return null; // EOF\n            }\n        } else {\n            return line;\n        }\n    }\n\n    public String readLine(long timeout, TimeUnit unit) throws IOException, InterruptedException {\n        String line = lines.poll(timeout, unit);\n        if (line == null && eof) { // EOF or IOException (not timeout)\n            markAsEOF(); // restore the null so that any concurrent (and future) calls to this method won't block\n            if (exception != null) {\n                throw exception;\n            } else {\n                return null; // EOF\n            }\n        } else {\n            return line;\n        }\n    }\n}\n\nclass ZeroCapacityBlockingQueue {\n    int count;\n    T item;\n\n    public synchronized boolean add(T x) {\n        // does not block (i.e. behaves as if the capacity is actually 1)\n        if (count == 1) {\n            throw new IllegalStateException(\"Queue full\");\n        }\n        item = x;\n        count++;\n        notifyAll();\n        return true;\n    }\n\n    public synchronized boolean offer(T x) {\n        // does not block (i.e. behaves as if the capacity is actually 1)\n        if (count == 1) {\n            return false;\n        }\n        return add(x);\n    }\n\n    public synchronized void put(T x) throws InterruptedException {\n        // blocks until the item has been removed (\"0-capacity\" behaviour)\n        while (count == 1) {\n            wait();\n        }\n        add(x);\n        while (count == 1 && item == x) {\n            wait();\n        }\n    }\n\n    public synchronized T remove() {\n        if (count == 0) {\n            throw new NoSuchElementException();\n        }\n        T x = item;\n        item = null;\n        count--;\n        notifyAll();\n        return x;\n    }\n\n    public synchronized T poll() {\n        if (count == 0) {\n            return null;\n        }\n        return remove();\n    }\n\n    public synchronized T take() throws InterruptedException {\n        while (count == 0) {\n            wait();\n        }\n        return remove();\n    }\n\n    public synchronized T poll(long timeout, TimeUnit unit) throws InterruptedException {\n        long deadlineNanos = System.nanoTime() + unit.toNanos(timeout);\n        while (count == 0) {\n            long remainingNanos = deadlineNanos - System.nanoTime();\n            if (remainingNanos <= 0) {\n                return null;\n            }\n            TimeUnit.NANOSECONDS.timedWait(this, remainingNanos);\n        }\n        return remove();\n    }\n}\n\nclass Main {\n    static  Stream generateOrderedStream(Supplier> s) {\n        // Returns an ordered stream with the values of the Optionals returned by s.get(). An empty Optional ends the stream.\n        // As pseudocode:\n        //     for (Optional o = s.get(); o.isPresent(); o = s.get())\n        //         emit o.get();\n        return Stream.iterate(s.get(), Optional::isPresent, prev -> s.get())\n            .map(Optional::get);\n    }\n\n    static Stream timedReadLines(InterruptibleLineReader lineReader, long timeout, TimeUnit unit) {\n        // Reads lines until the timeout elapses and returns them as a stream.\n        final long deadlineNanos = System.nanoTime() + unit.toNanos(timeout);\n        return generateOrderedStream(() -> {\n            try {\n                long remainingNanos = deadlineNanos - System.nanoTime();\n                return Optional.ofNullable(lineReader.readLine(remainingNanos, TimeUnit.NANOSECONDS));\n            } catch (IOException|InterruptedException e) {\n                throw new RuntimeException(e);\n            }\n        });\n    }\n\n    static void fillStreamMap(InterruptibleLineReader lineReader) {\n        // streaming demo\n        long maxDurationSecs = 5;\n        timedReadLines(lineReader, maxDurationSecs, TimeUnit.SECONDS)\n            .takeWhile(line -> !line.contains(\"[stop]\"))\n            .map(line -> \"[mapped] \" + line)\n            .forEachOrdered(System.out::println);\n    }\n\n    public static void main(String[] args) {\n        BufferedReader reader = new BufferedReader(new InputStreamReader(System.in));\n\n        // stream lines\n        InterruptibleLineReader lineReader = new InterruptibleLineReader(reader);\n        fillStreamMap(lineReader);\n        lineReader.close();\n\n        /*\n        // attempt to use the BufferedReader directly\n        // NOTE: a line will be lost\n        System.out.println(\"--- reading directly from BufferedReader ---\");\n        while (true) {\n            try {\n                String line = reader.readLine();\n                if (line == null) { break; }\n                System.out.println(\"[raw] \" + line);\n            } catch (IOException e) {\n                throw new RuntimeException(e);\n            }\n        }\n        */\n    }\n}\n\nHere is an example run of the second implementation (with the last part of main() uncommented). The timestamps are in seconds and \">\" denotes input.\n0.06 --- streaming lines using InterruptibleLineReader for 5.0 sec  ---\n0.82 > one\n0.83 [mapped] one\n1.76 > two\n1.76 [mapped] two\n2.73 > three\n2.73 [mapped] three\n5.06 --- reading directly from BufferedReader ---\n6.93 > four\n6.94 InterruptibleLineReader: warning: discarding line that was read after close(): 'four'\n7.76 > five\n7.76 [raw] five\n8.60 > six\n8.60 [raw] six\n\nNote how the line \"four\" was lost. To avoid losing lines, don't use the underlying BufferedReader after the InterruptibleLineReader instance is created.\n(If you really need a BufferedReader after that point, you could write a dummy subclass of BufferedReader that wraps InterruptibleLineReader and forwards readLine() calls to it. The other BufferedReader methods, such as read() and mark(), can't be implemented easily.)\n"
}
{
    "Id": 71525731,
    "PostTypeId": 1,
    "Title": "java.lang.IllegalAccessError: class org.jetbrains.kotlin.kapt3.base.KaptContext Android",
    "Body": "I've been getting an error like this for days, but I couldn't find a solution. Can you please help me?\nWhat could the problem be caused by?\nError :\njava.lang.IllegalAccessError: class org.jetbrains.kotlin.kapt3.base.KaptContext (in unnamed module @0x6acdb135) cannot access class com.sun.tools.javac.util.Context (in module jdk.compiler) because module jdk.compiler does not export com.sun.tools.javac.util to unnamed module @0x6acdb135\n    at org.jetbrains.kotlin.kapt3.base.KaptContext.(KaptContext.kt:28)\n    at org.jetbrains.kotlin.kapt3.KaptContextForStubGeneration.(KaptContextForStubGeneration.kt:40)\n    at org.jetbrains.kotlin.kapt3.AbstractKapt3Extension.contextForStubGeneration(Kapt3Extension.kt:287)\n    at org.jetbrains.kotlin.kapt3.AbstractKapt3Extension.analysisCompleted(Kapt3Extension.kt:171)\n    at org.jetbrains.kotlin.kapt3.ClasspathBasedKapt3Extension.analysisCompleted(Kapt3Extension.kt:102)\n    at org.jetbrains.kotlin.cli.jvm.compiler.TopDownAnalyzerFacadeForJVM.analyzeFilesWithJavaIntegration$invokeExtensionsOnAnalysisComplete(TopDownAnalyzerFacadeForJVM.kt:112)\n    at org.jetbrains.kotlin.cli.jvm.compiler.TopDownAnalyzerFacadeForJVM.analyzeFilesWithJavaIntegration(TopDownAnalyzerFacadeForJVM.kt:122)\n    at org.jetbrains.kotlin.cli.jvm.compiler.TopDownAnalyzerFacadeForJVM.analyzeFilesWithJavaIntegration$default(TopDownAnalyzerFacadeForJVM.kt:86)\n    at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler$analyze$1.invoke(KotlinToJVMBytecodeCompiler.kt:252)\n    at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler$analyze$1.invoke(KotlinToJVMBytecodeCompiler.kt:243)\n    at org.jetbrains.kotlin.cli.common.messages.AnalyzerWithCompilerReport.analyzeAndReport(AnalyzerWithCompilerReport.kt:113)\n    at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler.analyze(KotlinToJVMBytecodeCompiler.kt:243)\n    at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler.compileModules$cli(KotlinToJVMBytecodeCompiler.kt:90)\n    at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler.compileModules$cli$default(KotlinToJVMBytecodeCompiler.kt:56)\n    at org.jetbrains.kotlin.cli.jvm.K2JVMCompiler.doExecute(K2JVMCompiler.kt:169)\n    at org.jetbrains.kotlin.cli.jvm.K2JVMCompiler.doExecute(K2JVMCompiler.kt:52)\n    at org.jetbrains.kotlin.cli.common.CLICompiler.execImpl(CLICompiler.kt:92)\n    at org.jetbrains.kotlin.cli.common.CLICompiler.execImpl(CLICompiler.kt:44)\n    at org.jetbrains.kotlin.cli.common.CLITool.exec(CLITool.kt:98)\n    at org.jetbrains.kotlin.incremental.IncrementalJvmCompilerRunner.runCompiler(IncrementalJvmCompilerRunner.kt:412)\n    at org.jetbrains.kotlin.incremental.IncrementalJvmCompilerRunner.runCompiler(IncrementalJvmCompilerRunner.kt:112)\n    at org.jetbrains.kotlin.incremental.IncrementalCompilerRunner.compileIncrementally(IncrementalCompilerRunner.kt:358)\n    at org.jetbrains.kotlin.incremental.IncrementalCompilerRunner.compileIncrementally$default(IncrementalCompilerRunner.kt:300)\n    at org.jetbrains.kotlin.incremental.IncrementalCompilerRunner.compileImpl$rebuild(IncrementalCompilerRunner.kt:119)\n    at org.jetbrains.kotlin.incremental.IncrementalCompilerRunner.compileImpl(IncrementalCompilerRunner.kt:170)\n    at org.jetbrains.kotlin.incremental.IncrementalCompilerRunner.compile(IncrementalCompilerRunner.kt:81)\n    at org.jetbrains.kotlin.daemon.CompileServiceImplBase.execIncrementalCompiler(CompileServiceImpl.kt:607)\n    at org.jetbrains.kotlin.daemon.CompileServiceImplBase.access$execIncrementalCompiler(CompileServiceImpl.kt:96)\n    at org.jetbrains.kotlin.daemon.CompileServiceImpl.compile(CompileServiceImpl.kt:1658)\n    at jdk.internal.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)\n    at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.base/java.lang.reflect.Method.invoke(Method.java:568)\n    at java.rmi/sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:360)\n    at java.rmi/sun.rmi.transport.Transport$1.run(Transport.java:200)\n    at java.rmi/sun.rmi.transport.Transport$1.run(Transport.java:197)\n    at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)\n    at java.rmi/sun.rmi.transport.Transport.serviceCall(Transport.java:196)\n    at java.rmi/sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:587)\n    at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:828)\n    at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:705)\n    at java.base/java.security.AccessController.doPrivileged(AccessController.java:399)\n    at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:704)\n    at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n    at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n    at java.base/java.lang.Thread.run(Thread.java:833)\n\n\nExecution failed for task ':app:kaptGenerateStubsMacellanDebugKotlin'.\n> Internal compiler error. See log for more details\n\n",
    "AcceptedAnswerId": 71527580,
    "AcceptedAnswer": "I found a solution and fixed this damn problem :D\nI recommend using, adding it to the root build.gradle. This will force using the given dependency in the whole project:\nbuild.gradle (Project)\nallprojects {\n    configurations.all {\n        resolutionStrategy {\n            force 'org.xerial:sqlite-jdbc:3.34.0'\n        }\n    }\n}\n\n"
}
{
    "Id": 71818173,
    "PostTypeId": 1,
    "Title": "How to handle NumberFormatException with Java StreamAPI",
    "Body": "Is there a way to filter out all values that are bigger than the max value that can be stored in a Long using Stream API?\nThe current situation is that you can search in the frontend with a simple search bar after some customers by using their ID.\nFor example: 123456789, 10987654321. If you put a \"separator\" between these two IDs, everything works. But if you forget the \"separator\" my code is trying to parse 12345678910987654321 into a Long and I guess there is the problem.\nThat causes a NumberFormatException after trying to search. Is there a way to filter these numbers out that can't be parsed into a Long because they are too big?\nString hyphen = \"-\";\n\nString[] customerIds = bulkCustomerIdProperty.getValue()\n              .replaceAll(\"[^0-9]\", hyphen)\n              .split(hyphen);\n...\ncustomerFilter.setCustomerIds(Arrays.asList(customerIds).stream()\n              .filter(n -> !n.isEmpty()) \n              .map(n -> Long.valueOf(n)) // convert to Long\n              .collect(Collectors.toSet()));\n\n",
    "AcceptedAnswerId": 71818306,
    "AcceptedAnswer": "You can either extract parsing into a separate method and wrap it with a try/catch, or use BigInteger to eliminate values that exceed the range of long.\nExample with BigInteger:\nSet result =  Stream.of(\"\", \"12345\", \"9999999999999999999999999999\")\n        .filter(n -> !n.isEmpty())\n        .map(BigInteger::new)\n        .filter(n -> n.compareTo(BigInteger.valueOf(Long.MAX_VALUE)) <= 0 &&\n                     n.compareTo(BigInteger.valueOf(Long.MIN_VALUE)) >= 0)\n        .map(BigInteger::longValueExact) // convert to Long\n        .peek(System.out::println) // printing the output\n        .collect(Collectors.toSet());\n\nExample with handling NumberFormatException in a separate method:\nSet result =  Stream.of(\"\", \"12345\", \"9999999999999999999999999999\")\n        .filter(n -> !n.isEmpty())\n        .map(n -> safeParse(n))\n        .filter(OptionalLong::isPresent)\n        .map(OptionalLong::getAsLong) // extracting long primitive and boxing it into Long\n        .peek(System.out::println) // printing the output\n        .collect(Collectors.toSet());\n\npublic static OptionalLong safeParse(String candidate) {\n    try {\n        return OptionalLong.of(Long.parseLong(candidate));\n    } catch (NumberFormatException e) {\n        return OptionalLong.empty();\n    }\n}\n\nOutput (from peek())\n12345\n\n"
}
{
    "Id": 71643702,
    "PostTypeId": 1,
    "Title": "Making sense of error message related to type inference when using a method reference",
    "Body": "I wanted to create a list of non-alphabetic characters from a string, so I wrote:\nstr.chars()\n        .mapToObj(c -> (char) c)\n        .filter(Predicate.not(Character::isAlphabetic))\n        .toList();\n\nHowever this throws the following error message:\n\nno instance(s) of type variable(s) exist so that Character conforms to\nInteger inference variable T has incompatible bounds: equality\nconstraints: Integer lower bounds: Character\n\nI didn't fully understand the error message, but I figured that it is caused by Character#isAlphabetic taking in int codePoint as a parameter instead of a char because replacing Character::isAlphabetic with Character::isUpperCase (for example) which takes in a char works fine.\nNow, if I write:\nstr.chars()\n        .mapToObj(c -> (char) c)\n        .filter(c -> !Character.isAlphabetic(c))\n        .toList();\n\nit compiles just fine, and I'm not even that surprised/confused. However, if I write\nstr.chars()\n        .mapToObj(c -> (char) c)\n        .filter(Predicate.not(c -> Character.isAlphabetic(c)))\n        .toList();\n\nit also compiles just fine, which definitely confuses me because isn't Character::isAlphabetic basically equivalent to c -> Character.isAlphabetic(c)? Well, apparently it isn't in all cases (because AFAIK it is in most)\nSo my 2 questions are:\n\nWhat exactly is this error message saying? I do understand it to an extent but definitely not completely\nWhy does the first version not work but the third does?\n\n",
    "AcceptedAnswerId": 71648220,
    "AcceptedAnswer": "The difference between Character::isAlphabetic and c -> Character.isAlphabetic(c) is that since Character.isAlphabetic(int) is not an overloaded method, the former is an exact method reference whereas the latter is an implicitly typed lambda expression.\nWe can show that an inexact method reference is accepted the same way as an implicitly typed lambda expression:\nclass SO71643702 {\n    public static void main(String[] args) {\n        String str = \"123abc456def\";\n        List l = str.chars()\n            .mapToObj(c -> (char) c)\n            .filter(Predicate.not(SO71643702::isAlphabetic))\n            .toList();\n        System.out.println(l);\n    }\n\n    public static boolean isAlphabetic(int codePoint) {\n        return Character.isAlphabetic(codePoint);\n    }\n\n    public static boolean isAlphabetic(Thread t) {\n      throw new AssertionError(\"compiler should never choose this method\");\n    }\n}\n\nThis is accepted by the compiler.\nHowever, this doesn\u2019t imply that this behavior is correct. Exact method references may help in overload selection where inexact do not, as specified by \u00a715.12.2.:\n\nCertain argument expressions that contain implicitly typed lambda expressions (\u00a715.27.1) or inexact method references (\u00a715.13.1) are ignored by the applicability tests, because their meaning cannot be determined until the invocation's target type is selected.\n\nIn contrast, when it comes to the 15.13.2. Type of a Method Reference, there is no difference between exact and inexact method references mentioned. Only the target type determines the actual type of the method reference (assuming that the target type is a functional interface and the method reference is congruent).\nConsequently, the following works without problems:\nclass SO71643702 {\n    public static void main(String[] args) {\n        String str = \"123abc456def\";\n        List l = str.chars()\n            .mapToObj(c -> (char) c)\n            .filter(Character::isAlphabetic)\n            .toList();\n        System.out.println(l);\n    }\n}\n\nOf course, that\u2019s not the original program logic\nHere, Character::isAlphabetic still is an exact method reference, but it\u2019s congruent with the target type Predicate, so it works not different to\nPredicate p = Character::isAlphabetic;\n\nor\nPredicate p = (Character c) -> Character.isAlphabetic(c);\n\nIt\u2019s not as if the insertion of a generic method into nesting of method invocations will stop the type inference from working in general. As discussed in this answer to a similar fragile type inference issue, we can insert a generic method not contributing to the resulting type without problems:\nclass SO71643702 {\n    static  X dummy(X x) { return x; }\n\n    public static void main(String[] args) {\n        String str = \"123abc456def\";\n        List l = str.chars()\n            .mapToObj(c -> (char) c)\n            .filter(dummy(Character::isAlphabetic))\n            .toList();\n        System.out.println(l);\n    }\n}\n\nand even \u201cfix\u201d the problem of the original code by inserting the method\nclass SO71643702 {\n    static  X dummy(X x) { return x; }\n\n    public static void main(String[] args) {\n        String str = \"123abc456def\";\n        List l = str.chars()\n            .mapToObj(c -> (char) c)\n            .filter(Predicate.not(dummy(Character::isAlphabetic)))\n            .toList();\n        System.out.println(l);\n    }\n}\n\nIt\u2019s important that there is no subtype relationship between Predicate and Predicate, so the dummy method can not translate between them. It\u2019s just returning exactly the same type as the compiler inferred for its argument.\nI consider the compiler error a bug, but as I said at the other answer, even if the specification backs up this behavior, it should get corrected, in my opinion.\n\nAs a side note, for this specific example, I\u2019d use\nvar l = str.chars()\n    .filter(c -> !Character.isAlphabetic(c))\n    .mapToObj(c -> (char)c)\n    .toList();\n\nanyway, as this way, you\u2019re not boxing int values to Character objects, just to unbox them to int again in the predicate, but rather, only box values after passing the filter.\n"
}
{
    "Id": 72300024,
    "PostTypeId": 1,
    "Title": "Does the use of Spring Webflux's WebClient in a blocking application design cause a larger use of resources than RestTemplate",
    "Body": "I am working on several spring-boot applications which have the traditional pattern of thread-per-request. We are using Spring-boot-webflux to acquire WebClient to perform our RESTful integration between the applications. Hence our application design requires that we block the publisher right after receiving a response.\nRecently, we've been discussing whether we are unnecessarily spending resources using a reactive module in our otherwise blocking application design. As I've understood it, WebClient makes use of the event loop by assigning a worker thread to perform the reactive actions in the event loop. So using webclient with .block() would sleep the original thread while assigning another thread to perform the http-request. Compared to the alternative RestTemplate, it seems like WebClient would spend additional resources by using the event loop.\nIs it correct that partially introducing spring-webflux in this way leads to additional spent resources while not yielding any positive contribution to performance, neither single threaded and concurrent? We are not expecting to ever upgrade our current stack to be fully reactive, so the argument of gradually upgrading does not apply.\n",
    "AcceptedAnswerId": 72311944,
    "AcceptedAnswer": "In this presentation Rossen Stoyanchev from the Spring team explains some of these points.\nWebClient will use a limited number of threads - 2 per core for a total of 12 threads on my local machine - to handle all requests and their responses in the application. So if your application receives 100 requests and makes one request to an external server for each, WebClient will handle all of those using those threads in a non-blocking / asynchronous manner.\nOf course, as you mention, once you call block your original thread will block, so it would be 100 threads + 12 threads for a total of 112 threads to handle those requests. But keep in mind that these 12 threads do not grow in size as you make more requests, and that they don't do I/O heavy lifting, so it's not like WebClient is spawning threads to actually perform the requests or keeping them busy on a thread-per-request fashion.\nI'm not sure if when the thread is under block it behaves the same as when making a blocking call through RestTemplate - it seems to me that in the former the thread should be inactive waiting for the NIO call to complete, while in the later the thread should be handling I/O work, so maybe there's a difference there.\nIt gets interesting if you begin using the reactor goodies, for example handling requests that depend on one another, or many requests in parallel. Then WebClient definitely gets an edge as it'll perform all concurrent actions using the same 12 threads, instead of using a thread per request.\nAs an example, consider this application:\n@SpringBootApplication\npublic class SO72300024 {\n\n    private static final Logger logger = LoggerFactory.getLogger(SO72300024.class);\n\n    public static void main(String[] args) {\n        SpringApplication.run(SO72300024.class, args);\n    }\n\n    @RestController\n    @RequestMapping(\"/blocking\")\n    static class BlockingController {\n\n        @GetMapping(\"/{id}\")\n        String blockingEndpoint(@PathVariable String id) throws Exception {\n            logger.info(\"Got request for {}\", id);\n            Thread.sleep(1000);\n            return \"This is the response for \" + id;\n        }\n\n        @GetMapping(\"/{id}/nested\")\n        String nestedBlockingEndpoint(@PathVariable String id) throws Exception {\n            logger.info(\"Got nested request for {}\", id);\n            Thread.sleep(1000);\n            return \"This is the nested response for \" + id;\n        }\n\n    }\n\n    @Bean\n    ApplicationRunner run() {\n        return args -> {\n            Flux.just(callApi(), callApi(), callApi())\n                    .flatMap(responseMono -> responseMono)\n                    .collectList()\n                    .block()\n                    .stream()\n                    .flatMap(Collection::stream)\n                    .forEach(logger::info);\n            logger.info(\"Finished\");\n        };\n    }\n\n    private Mono> callApi() {\n        WebClient webClient = WebClient.create(\"http://localhost:8080\");\n        logger.info(\"Starting\");\n        return Flux.range(1, 10).flatMap(i ->\n                        webClient\n                                .get().uri(\"/blocking/{id}\", i)\n                                .retrieve()\n                                .bodyToMono(String.class)\n                                .doOnNext(resp -> logger.info(\"Received response {} - {}\", I, resp))\n                                .flatMap(resp -> webClient.get().uri(\"/blocking/{id}/nested\", i)\n                                        .retrieve()\n                                        .bodyToMono(String.class)\n                                        .doOnNext(nestedResp -> logger.info(\"Received nested response {} - {}\", I, nestedResp))))\n                .collectList();\n    }\n}\n\nIf you run this app, you can see that all 30 requests are handled immediately in parallel by the same 12 (in my computer) threads. Neat! If you think you can benefit from such kind of parallelism in your logic, it's probably worth it giving WebClient a shot.\nIf not, while I wouldn't actually worry about the \"extra resource spending\" given the reasons above, I don't think it would be worth it adding the whole reactor/webflux dependency for this - besides the extra baggage, in day to day operations it should be a lot simpler to reason about and debug RestTemplate and the thread-per-request model.\nOf course, as others have mentioned, you ought to run load tests to have proper metrics.\n"
}
{
    "Id": 71884469,
    "PostTypeId": 1,
    "Title": "Unable to find /oauth/device/code Auth0 Java API",
    "Body": "Is there an API to fetch the device code via Auth0 Java API, we use the following snippet in Go, the question is if there is a standard API or should we make a HTTP request call\nurl := \"https://dev-foo.us.auth0.com/oauth/device/code\"\n\npayload := strings.NewReader(\"client_id=RO6N7mr&scope=openid&audience=https://dev-foo.us.auth0.com/api/v2/\")\n\nreq, _ := http.NewRequest(\"POST\", url, payload)\n\n",
    "AcceptedAnswerId": 71909729,
    "AcceptedAnswer": "The documentation tells you that you need to send a POST request like the following:\n\nPOST https://YOUR_DOMAIN/oauth/device/code\n\n\nContent-Type:\n\n\napplication/x-www-form-urlencoded\nclient_id=YOUR_CLIENT_ID&scope=SCOPE&audience=API_IDENTIFIER\n\nand the response would look like\nHTTP/1.1 200 OK\nContent-Type: application/json\n{\n  \"device_code\":\"GmRh...k9eS\",\n  \"user_code\":\"WDJB-MJHT\",\n  \"verification_uri\":\"https://YOUR_DOMAIN/device\",\n  \"verification_uri_complete\":\"https://YOUR_DOMAIN/device?user_code=WDJB-MJHT\",\n  \"expires_in\":900, //in seconds\n  \"interval\":5\n}\n\n\n"
}
{
    "Id": 72401149,
    "PostTypeId": 1,
    "Title": "limit set by 'FEATURE_SECURE_PROCESSING'",
    "Body": "I used my own xlst transformator in java (XSLTTransformator) but transformation is very big and I have got error:\nCaused by: javax.xml.transform.TransformerConfigurationException: JAXP0801002: the compiler encountered an XPath expression containing '107' operators that exceeds the '100' limit set by 'FEATURE_SECURE_PROCESSING'.\n                at com.sun.org.apache.xalan.internal.xsltc.trax.TransformerFactoryImpl.newTemplates(TransformerFactoryImpl.java:990)\n                at com.aspp.dms.ruleengine.transformation.TemplatesCache.retrieveUncached(TemplatesCache.java:44)\n                at com.aspp.dms.ruleengine.transformation.TemplatesCache.retrieveUncached(TemplatesCache.java:21)\n                at com.gratex.java.util.SoftValueCache.get(SoftValueCache.java:41)\n                at com.aspp.dms.ruleengine.transformation.XSLTTransformator.transform(XSLTTransformator.java:73)\n\nCan you please help me find correct argument for java to solve my problem? Something like -DxpathOperatorsLimit=150\nthank you\n",
    "AcceptedAnswerId": 72833393,
    "AcceptedAnswer": "That behaviour seems to come from new FEATURE_SECURE_PROCESSING, which Oracle introduced in a recent \"update\" of their Java. See: https://www.oracle.com/java/technologies/javase/11-0-15-relnotes.html\nIt is 3 parameters they introduced:\n\njdk.xml.xpathExprGrpLimit Description: Limits the number of groups\nan XPath expression can contain. Default 10.\njdk.xml.xpathExprOpLimit Description: Limits the number of operators\nan XPath expression can contain. Default 100.\njdk.xml.xpathTotalOpLimit Description: Limits the total number of\nXPath operators in an XSL Stylesheet. Default 10000.\n\nYour problem is on #2 (JAXP0801002, default 100).\nWe got a very similar issue on #3 (JAXP0801003, default 10.000), with this message (quoted, so google will find it):\nERROR:  'JAXP0801003: the compiler encountered XPath expressions with an accumulated '10.002' operators that exceeds the '10.000' limit set by 'FEATURE_SECURE_PROCESSING'.'\nFATAL ERROR:  'JAXP0801003: the compiler encountered XPath expressions with an accumulated '10.002' operators that exceeds the '10.000' limit set by 'FEATURE_SECURE_PROCESSING'.'\n\nWe wasted 2 days in getting away of that sh*t.\nWe added some parameters to the java call:\n    java -Djdk.xml.xpathExprGrpLimit=0 -Djdk.xml.xpathExprOpLimit=0 -Djdk.xml.xpathTotalOpLimit=0 -Xmx2g -Xms512m -XX:-UseGCOverheadLimit ....\n\n\nParameters 1,2,3 to to solve the issue. Values \"0\" set the limits to \"off\". As XPath can now get huge, it might be advisable to set the heap and stack size and change behaviour of the garbage collection (parameters 4-6).\nI hope it will help you too. Have fun!\n"
}
{
    "Id": 72388741,
    "PostTypeId": 1,
    "Title": "Android manifest POST_NOTIFICATIONS missing import",
    "Body": "Trying to implement the notification permission for android 13 or \"Tiramisu\" but failed to get the import for that permission.\nCurrently:\ntargeted SDK version is 32\ncompile SDK version is 32\nI've declared it also in manifiest as below:\n <uses-permission android:name=\"android.permission.POST_NOTIFICATIONS\"\n\nimport i'm using:\nimport android.Manifest\n\n\nBut even not getting import in my fragment.\n\n\n",
    "AcceptedAnswerId": 72390497,
    "AcceptedAnswer": "     android {\n     namespace 'com.example.myapplication'\n    compileSdkVersion 33//update this\n\n     defaultConfig {\n        applicationId \"com.example.myapplication\"\n        minSdk 23\n        targetSdkVersion 33//update this\n        versionCode 1\n        versionName \"1.0\"\n        \n        testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\"\n    }\n\n"
}
{
    "Id": 72025894,
    "PostTypeId": 1,
    "Title": "List differences: DTO, VO, Entity, Domain, Model",
    "Body": "Now I study about the Spring Boot that with JAVA platform.\nA problem I faced is how can you tell the difference between DTO, VO, Entity, Domain, and Model.\nHonestly it all look too similar to tell the difference.\nI already checked some stackoverflow answers about \"Difference between DTO and VO\" and something like that.\nHowever, I am still wondering how do they different each other in terms of developer with Spring Boot.\n",
    "AcceptedAnswerId": 72027443,
    "AcceptedAnswer": "\nEntity - is a class with an ID. In the case of relational DB it's usually a class that's mapped to a DB table with some primary key.\nDTO (Data Transfer Object) - is a class that maps well on what you're sending over the network. E.g. if you exchange JSON or XML data, it usually has fields just enough to fill those requests/responses. Note, that it may have fewer or more fields than Entity.\nVO (Value Object) is a class-value. E.g. you could create class like Grams or Money - it will contain some primitives (e.g. some double value) and it's possible to compare Value Objects using these primitives. They don't have a database ID. They help replacing primitives with more object-oriented classes related to our particular domain.\nDomain Model contains all Entities and Value Objects. And some other types of classes depending on the classification you use.\n\nIn order to get acquainted with these you should read:\n\nEnterprise Application Patterns by Fowler. Mentions Value Object and Domain Model.\nDomain Driven Design by Eric Evans. Mentions Entity, Value Object and Domain Model.\nAnd maybe get acquainted with Java EE design patterns. They mention DTO. But these are pretty badly written articles (if they are still even available on the internet). Confusingly, they also had Value Object which was defined very similarly to DTO, but no one uses that definition of VO.\n\n"
}
{
    "Id": 71810594,
    "PostTypeId": 1,
    "Title": "Spring Boot 2.6.4 -> 2.6.6 : strange NullPointerException within Logback when logging a mock Exception",
    "Body": "while upgrading from Spring Boot 2.6.4 to 2.6.6 , one of my tests (written in Kotlin), fails :\n    @Test\n    fun shouldLogProperMessageIfNotAbleToHitAPI() {\n\n        val configValidator = ConfigValidator(GitHubCrawlerProperties(SourceControlConfig(url = \"someIncorrectURL\",organizationName=\"someOrg\")),mockRemoteSourceControl)\n\n        `when`(mockRemoteSourceControl.validateRemoteConfig(\"someOrg\")).thenThrow(NoReachableRepositories(\"problem !\",mock(Exception::class.java)))\n\n        val validationErrors=configValidator.getValidationErrors()\n\n        assertThat(validationErrors).hasSize(1);\n\n    }\n\n\nthe build passes with Spring Boot 2.6.4. It works in Spring Boot 2.6.6 when I run the test individually in my IDE, but fails during the maven build.\nthe stacktrace was not showing by default, but after surrounding the call by a try/catch, I am able to get it, and it points to Logback :\njava.lang.NullPointerException: null\n        at ch.qos.logback.classic.spi.ThrowableProxy.(ThrowableProxy.java:99)\n        at ch.qos.logback.classic.spi.ThrowableProxy.(ThrowableProxy.java:89)\n        at ch.qos.logback.classic.spi.ThrowableProxy.(ThrowableProxy.java:62)\n        at ch.qos.logback.classic.spi.LoggingEvent.(LoggingEvent.java:119)\n        at ch.qos.logback.classic.Logger.buildLoggingEventAndAppend(Logger.java:419)\n        at ch.qos.logback.classic.Logger.filterAndLog_0_Or3Plus(Logger.java:383)\n        at ch.qos.logback.classic.Logger.error(Logger.java:538)\n        at com.societegenerale.githubcrawler.ConfigValidator.getValidationErrors(ConfigValidator.kt:48)\n\nLogback version doesn't seem to change, I still get v 1.2.11 .\nLooking at Logback source code, in ThrowableProxy :\n        if (GET_SUPPRESSED_METHOD != null) {\n            // this will only execute on Java 7\n            Throwable[] throwableSuppressed = extractSupressedThrowables(throwable);\n            \n            if (throwableSuppressed.length > 0) {\n                List suppressedList = new ArrayList(throwableSuppressed.length);\n                for (Throwable sup : throwableSuppressed) {\n...\n\nnote : I build with Java 11, so the comment saying in Logback source code that this will only execute on Java 7 , seems wrong.\nIt seems that throwableSuppressed is null, and I get the NPE when throwableSuppressed.size is called.\nThe test passes if instead of using a mock in NoReachableRepositories(\"problem !\",mock(Exception::class.java)) , I use NoReachableRepositories(\"problem !\",Exception())\nI realize it's probably better to use a real Exception rather than a mock, so my problem is solved in a way (after spending 2 hours on this..).\nHowever, I am curious : what could cause this issue after upgrading to Spring Boot 2.6.6 which should be a a minor change ?\n",
    "AcceptedAnswerId": 71823439,
    "AcceptedAnswer": "This issue was introduced in logback:1.2.11 by this commit. It is tracked in this Jira ticket.\nLogback was upgraded to 1.2.11 from spring boot 2.6.5, you can refer to this changelog. So you would have encountered this same error if you upgraded to 2.6.5.\nWhat we can do now is override the version of logback to 1.2.10 by adding this line in build.gradle file.\next[\"logback.version\"] = \"1.2.10\"\n\nIf you're using Maven dependencyManagement section for Spring Boot dependencies instead of the starter parent then you can try this:\n\n\n  \n    \n    \n      ch.qos.logback\n      logback-access\n      1.2.10\n    \n    \n      ch.qos.logback\n      logback-classic\n      1.2.10\n    \n    \n      ch.qos.logback\n      logback-core\n      1.2.10\n    \n\n    \n      org.springframework.boot\n      spring-boot-dependencies\n      2.7.5\n      pom\n      import\n    \n\n\n\nUpdate: Spring Boot 2 latest version (2.7.5) is still using logback:1.2.11.\n"
}
{
    "Id": 72598626,
    "PostTypeId": 1,
    "Title": "Official recommendation / coding style guide on using multiple @throws tags for the same exception in JavaDoc",
    "Body": "I just recently found out that one can use multiple @throws tags for the same exception in Javadoc.\nOne of my students used it to document one of his methods in Connect Four:\n/*\n * ...\n * @throws IllegalArgumentException if the number of rows or columns is invalid \n * @throws IllegalArgumentException if one of the players has {@link Stone#None} as stone\n * @throws IllegalStateException if both players use the same stone color\n */\npublic void doSomething(...) { ... }\n\nNow my (and his) question: Is there an official style guide or a general recommendation on whether to use a single @throws tag or \"is it fine\" to use multiple ones per exception type?\n",
    "AcceptedAnswerId": 72600530,
    "AcceptedAnswer": "There is an Oracle style guide for javadocs:\n\nHow to Write Doc Comments for the Javadoc Tool.\n\nWhether that counts as \"official\" depends on your point of view.  Either way, I cannot see any mention in that document of multiple tags for the same exception.\nHowever, according to the following Q&A, multiple @throws tags for the same exception is supported by the standard Javadoc tool chain; i.e. each of them will result in an entry in the generated HTML.\n\nCan I use multiple @throws tags for the same exception in Javadoc?\n\n(My personal opinion is the javadocs will be more readable if you don't do this, but that is just my opinion.)\n"
}
{
    "Id": 73163378,
    "PostTypeId": 1,
    "Title": "\"Suspicious assignment in copy constructor\" for byte[] - What is suspicious?",
    "Body": "I have a copy constructor for class, but Android Studio code inspection throws a warning I don't understand:\n\nSuspicious assignment in copy constructor of\n'java.util.Arrays.copyOf(other.value, other.value.length)' to field\nvalue\n\npublic class CpuVariable extends BaseIdentifier {\n    private int memoryType;\n    private byte[] value;\n\n    public CpuVariable(@NonNull CpuVariable other) {\n        super(other);\n        this.memoryType = other.memoryType;\n        if (other.value != null) {\n            this.value = java.util.Arrays.copyOf(other.value, other.value.length);\n        }\n    }\n}\n\nChanging code to\nthis.value = other.value\n\nwould remove the warning, but this is not an option since I need to create a deep copy or a clone for the field.\nAm I coding something wrong or is it safe to ignore or suppress the warning?\n",
    "AcceptedAnswerId": 73163884,
    "AcceptedAnswer": "It is clearly a false positive.  There is nothing actually wrong with your constructor.\nI think that the code that produced this warning is based on this code.  Note that this is not the real Android Studio code, but there are clues to suggest that Android Studio may have \"borrowed\" it via some path.\nIf you look at the constructorAssignsAllFields method (line 63), the intent of the code seems to be to look for code bugs where a copy constructor is copying the wrong fields; e.g. something like this:\nMyClass(MyClass other) {\n   this.x = other.x;\n   this.y = other.x; // Ooops\n}\n\nBut the method is not correctly dealing with the case where the copy constructor is transforming one of the fields.\nLooking at the code, you need to write this.value =  in a way that makes the checker not realize that it is assigning to a field.  For example, if you used a setter method something like this:\npublic CpuVariable(@NonNull CpuVariable other) {\n    super(other);\n    this.memoryType = other.memoryType;\n    this.value = other.value;  // Dummy\n    if (other.value != null) {\n        this.setValue(java.util.Arrays.copyOf(other.value, other.value.length));\n    }\n}\n\n"
}
{
    "Id": 72089617,
    "PostTypeId": 1,
    "Title": "How to write a method that takes in a List of Integer, Float, Double and calculate the average?",
    "Body": "I am trying to write a method that takes in a list of numeric values - eg List, List, List etc - and give me the average.\npublic double getAverage(List stats) {\n    double sum = 0.00;\n    if(!stats.isEmpty()) {\n        // sum = stats.stream()\n        //            .reduce(0, (a, b) -> a + b);\n        // return sum / stats.size();\n    }\n}\n\nThese are the errors I get:\n\nOperator '+' cannot be applied to 'capture', 'capture'\n\n",
    "AcceptedAnswerId": 72089958,
    "AcceptedAnswer": "\nOptionalDouble average()\nWhere, OptionalDouble is a container object  which may or may not\ncontain a double value.\n\n  public class Test {\n\n    public static OptionalDouble getAverage(List stats) {\n        return stats.\n                stream().\n                 mapToDouble(d -> d.doubleValue()).\n                    average();\n            \n    }\n    \n    public static void main(String[] args) throws IOException {\n\n        List list = Arrays.asList(1, 4, 5, 67, 3);\n        if(getAverage(list).isPresent());\n        {\n            Double average = getAverage(list).getAsDouble();\n            System.out.println(average);\n        }\n        \n    }\n}\n\nor\nUsing Goolge Guava\n Double averge = Stats.meanOf(list);\n\n      \n\nit gets syntactically simplified\n"
}
{
    "Id": 71737495,
    "PostTypeId": 1,
    "Title": "Getting the oracle database host name at runtime",
    "Body": "There is a Springboot application which connects to the Oracle data. The URL for the database is configured as\nspring.datasource.url=jdbc:oracle:thin:@(DESCRIPTION=\\\n  (LOAD_BALANCE=OFF)(FAILOVER=ON)\\\n  (ADDRESS=(PROTOCOL=TCP)(HOST=domainName1.com) (PORT=1521))\\\n  (ADDRESS=(PROTOCOL=TCP)(HOST=domainName2.com)(PORT=1521))\\\n  (CONNECT_DATA=(SERVICE_NAME=xyz)))\n\nThis URL is configured so that when one host is down then the application connects to second database.\nThe URL to the database is printed in the application healthcheck as shown below\nHello \nversion    : 4.0.0\nbuild      : 2022-03-3 \ndatasource :    oracle.jdbc.OracleDriver\ndb url     :    jdbc:oracle:thin:@(DESCRIPTION=(LOAD_BALANCE=OFF)(FAILOVER=ON)(ADDRESS=(PROTOCOL=TCP)(HOST=domainName1.com) (PORT=1521))(ADDRESS=(PROTOCOL=TCP)(HOST=domainName2.com)(PORT=1521))(CONNECT_DATA=(SERVICE_NAME=xyz)))\ndb status  :    ok \n\nMy question is how can I get just the host name of the database being used, that means how can I get the host currently being used (domainName1 or domainName2) by the application and display it on healthcheck? For example as shown below.\nHello \nversion    : 4.0.0\nbuild      : 2022-03-3\ndatasource :    oracle.jdbc.OracleDriver\ndb url     :    jdbc:oracle:thin:@domainName1.com: 1521/coldv1\ndb status  :    ok (LVZ count = 379)\n\nThe java code I used for this healthcheck is as shown below.\n@GetMapping(path = \"/healthcheck\",\n            produces = MediaType.APPLICATION_JSON_VALUE\n    )\n    public String getServiceStatus(){\n        String[] activeProfiles = environment.getActiveProfiles();\n        final BeanWrapper accessor = PropertyAccessorFactory.forBeanPropertyAccess(dataSource);\n        final String driverClassName = String.valueOf(accessor.getPropertyValue(\"driverClassName\"));\n        String url = null;\n\n        if(activeProfiles[1].equals(\"external_tomcat\")) {\n            url = String.valueOf(accessor.getPropertyValue(\"url\"));\n        }else{\n            try {\n                String[] dataSourceProperties = nameService.getDataSource();\n                url = dataSourceProperties[0];\n            } catch (SQLException ex) {\n//                throwables.printStackTrace();\n                log.error(ex.getMessage(), ex);\n            }\n        }\n\n        String version = buildProperties.getVersion();\n        String buildTimestamp = String.valueOf(buildProperties.getTime());\n        BigDecimal count = nameService.getCount(\"Table_name_of_database\");\n\n        StringBuilder result = new StringBuilder(\"Hello\")\n                .append(\"\\nversion    :\\t\")\n                .append(version)\n                .append(\"\\nbuild      :\\t\")\n                .append(buildTimestamp)\n                .append(\"\\ndatasource :\\t\")\n                .append(driverClassName)\n                .append(\"\\ndb url     :\\t\")\n                .append(url)\n                .append(\"\\ndb status  :\\tok  \")\n                .append(count.intValue())\n                .append(\")\");\n        return result.toString();\n    }\n\nNameService.java\n @Override\n    public String[] getDataSource() throws SQLException {\n        return getDataSourceProperties();\n    }\n\n\n   \n\n    public String[] getDataSourceProperties() {\n        String[] dataSourceProperties = new String[2];\n        HikariDataSource dataSource = getDataSourceFromHibernateEntityManager();\n        if(dataSource.getJdbcUrl() != null){\n            dataSourceProperties[0] = dataSource.getJdbcUrl();\n            dataSourceProperties[1] = dataSource.getDataSourceClassName();\n        }\n        return dataSourceProperties;\n    }\n\n",
    "AcceptedAnswerId": 71841619,
    "AcceptedAnswer": "@Olivier and @ik_zelf both answers works for me.\nAnd the way I implemented in spring boot application is using the following code snippet.\npublic String getHostNameFromUrl() {\n        String sql = \"SELECT host_name FROM v$instance\";\n//        String sql = \"SELECT sys_context('USERENV','SERVER_HOST') server_host FROM dual\"; this also works\n        Query query = entityManager.createNativeQuery(sql);\n        return query.getSingleResult().toString();\n}\n\nand later in the controller I call this method to display in the healthcheck.\n"
}
{
    "Id": 71737901,
    "PostTypeId": 1,
    "Title": "How to upgrade spring framework version in spring boot",
    "Body": "I am using spring-boot 2.3.3.RELEASE with the according spring-boot-starter-parent in maven.\n\n   org.springframework.boot\n   spring-boot-starter-parent\n   2.3.3.RELEASE\n    \n \n\nDue to the spring4shell CVE I wanted to upgrade the spring-framework to 5.2.20.RELEASE instead of the already included 5.2.8.RELEASE. I tried overriding the spring-framework.version property from spring-boot-dependencies.\n    5.2.20.RELEASE\n\nBut it did not work. I also looked up the spring-boot-starter-web-2.3.3.RELEASE.pom and it has the spring-web dependency hardcoded to 5.2.8.RELEASE.\nAre there any other ways of upgrading the spring-framework version in spring-boot besides  adding all the new versions as dependencies to the dependencyManagement section?\nThx\nFull POM:\n\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" \n  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 \n  http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n4.0.0\n\n\n  org.springframework.boot\n  spring-boot-starter-parent\n  2.3.3.RELEASE\n   \n\n\ngroup\napp\n3.1.0-SNAPSHOT\nwar\n\n\n  4.1.2\n  2.4.20\n  5.2.20.RELEASE\n  Hoxton.SR7\n  1.4.196\n\n\n\n\n\n  \n    org.springframework.cloud\n    spring-cloud-dependencies\n    ${spring-cloud.version}\n    pom\n    import\n  \n\n\n\n\n\n\n\n  org.springframework.boot\n  spring-boot-starter-actuator\n\n\n\n  org.springframework.boot\n  spring-boot-starter-jdbc\n\n\n\n  org.springframework.boot\n  spring-boot-starter-data-rest\n\n\n\n  org.springframework.boot\n  spring-boot-starter-webflux\n\n\n\n  org.springframework.boot\n  spring-boot-starter-web\n\n\n\n  org.springframework.boot\n  spring-boot-starter-test\n  test\n\n\n\n  org.springframework.boot\n  spring-boot-starter-tomcat\n  provided\n\n\n\n  org.springframework.boot\n  spring-boot-configuration-processor\n  true\n\n\n\n  org.mockito\n  mockito-core\n\n\n\n\n  org.codehaus.groovy\n  groovy-all\n  ${groovy.version}\n\n\n\n\n  com.fasterxml.jackson.dataformat\n  jackson-dataformat-xml\n\n\n\n\napp\n\n  \n    src/main/resources\n    true\n    \n      **/version.json\n      **/**.properties\n    \n  \n\n  \n    src/main/resources\n    false\n    \n      **/*.*\n    \n    \n      **/version.json\n      **/**.properties\n    \n  \n\n\n\n\nEDIT:\nThis is a part of mvn dependency:tree:\n+- org.springframework.boot:spring-boot-starter-webflux:jar:2.3.3.RELEASE:compile\n[INFO] |  +- org.springframework.boot:spring-boot-starter-json:jar:2.3.3.RELEASE:compile\n[INFO] |  |  +- com.fasterxml.jackson.datatype:jackson-datatype-jdk8:jar:2.11.2:compile\n[INFO] |  |  \\- com.fasterxml.jackson.module:jackson-module-parameter-names:jar:2.11.2:compile\n[INFO] |  +- org.springframework.boot:spring-boot-starter-reactor-netty:jar:2.3.3.RELEASE:compile\n[INFO] |  +- org.springframework:spring-web:jar:5.2.8.RELEASE:compile\n[INFO] |  +- org.springframework:spring-webflux:jar:5.2.8.RELEASE:compile\n[INFO] |  \\- org.synchronoss.cloud:nio-multipart-parser:jar:1.1.0:compile\n[INFO] |     \\- org.synchronoss.cloud:nio-stream-storage:jar:1.1.3:compile\n\nIf you have a look at the spring-boot-starter-webflux-2.3.3.RELEASE.pom which includes the problematic spring-web 5.2.8.RELEASE you will find that the spring version is hardcoded to 5.2.8.RELEASE. So setting the spring.framework property in maven will have no effect.\n    \n      org.springframework\n      spring-web\n      5.2.8.RELEASE\n      compile\n    \n\nOutput of mvn help:effective-pom:\n \n        org.springframework  \n        spring-web  \n        5.2.8.RELEASE  \n      \n      \n        org.springframework  \n        spring-webflux  \n        5.2.8.RELEASE  \n      \n\nEdit after Solution by @Inthai2002:\nI have additonally an internal lib pom imported in my pom.xml\n\n        \n            \n                internal\n                lib\n                4.4.0\n                import\n                pom\n            \n\n            \n                org.springframework.cloud\n                spring-cloud-dependencies\n                ${spring-cloud.version}\n                pom\n                import\n            \n\n        \n    \n\nand this internal lib has the spring-boot-dependencies pom directly imported which leads to the fact that spring-framework.version property is ignored:\n          \n                org.springframework.boot\n                spring-boot-dependencies\n                2.3.3.RELEASE\n                import\n                pom\n            \n\n",
    "AcceptedAnswerId": 72173843,
    "AcceptedAnswer": "I just tried your pom (with and without the spring-framework.version property) on a clean m2 repo. Without the property, spring-framework is 5.2.8, with the property, it is 5.2.20. Can you try on a clean repo?\nThe spring-framework-bom at version X is hardcoded to all the spring packages for version X (see https://repo1.maven.org/maven2/org/springframework/spring-framework-bom/5.2.8.RELEASE/spring-framework-bom-5.2.8.RELEASE.pom)\nThe spring-framework.version property is declared and used to pull the spring-framework-bom in spring-boot-dependencies and inherited by its descendants (see https://repo1.maven.org/maven2/org/springframework/boot/spring-boot-dependencies/2.3.3.RELEASE/spring-boot-dependencies-2.3.3.RELEASE.pom).\nspring-boot-dependencies is parent of spring-boot-starter-parent (see https://repo1.maven.org/maven2/org/springframework/boot/spring-boot-starter-parent/2.3.3.RELEASE/spring-boot-starter-parent-2.3.3.RELEASE.pom).\nBecause the property is inherited by descendant, you can override its value at the pom of your application. By overriding it with 5.2.20, you are swapping out spring-framework-bom 5.2.8 for 5.2.20 which effectively pull most of the spring packages for 5.2.20\n"
}
{
    "Id": 72169818,
    "PostTypeId": 1,
    "Title": "Sometime video buffering very slowly in exoplayer?",
    "Body": "I don't know why, but sometimes Exoplayer buffers my video very slowly. My server is responding properly and the internet is also fast but sometimes Exoplayer buffers my video slowly for less than 1 second. And it buffering always after every 1-2 seconds on playing.\n        int MIN_BUFFER_DURATION = 3000;\n        int MAX_BUFFER_DURATION = 8000;\n        int MIN_PLAYBACK_RESUME_BUFFER = 1500;\n        int MIN_PLAYBACK_START_BUFFER = 500;\n        LoadControl loadControl = new DefaultLoadControl.Builder()\n                .setAllocator(new DefaultAllocator(true, 16))\n                .setBufferDurationsMs(MIN_BUFFER_DURATION,\n                        MAX_BUFFER_DURATION,\n                        MIN_PLAYBACK_START_BUFFER,\n                        MIN_PLAYBACK_RESUME_BUFFER)\n                .setTargetBufferBytes(-1)\n                .setPrioritizeTimeOverSizeThresholds(true).createDefaultLoadControl();\n        TrackSelector trackSelector = new DefaultTrackSelector();\n        simpleExoPlayer = new ExoPlayer.Builder(this).setTrackSelector(trackSelector).setLoadControl(loadControl).build();\n        binding.exoPlayerView.setPlayer(simpleExoPlayer);\n        mediaItem = MediaItem.fromUri(getVid);\n        simpleExoPlayer.addMediaItem(mediaItem);\n        simpleExoPlayer.prepare();\n        simpleExoPlayer.play();\n\nI'm testing my video in my Exoplayer and Chrome Browser player. Chrome browserplayer plays my video 4X faster than my appExoplayer`? And I'm playing the same video and the same time. Someone also asked this question in exoplayer git but not got a good answer or result see their question exoplayer issue github this same issue causing me!\nDoes anyone know why this happens? Your answer will helpful for me.\n",
    "AcceptedAnswerId": 72293324,
    "AcceptedAnswer": "\nMake sure you are using the latest version of Exoplayer. As of this writing, that is 2.10.4.\n\nTry increasing the buffer duration values in your LoadControl:\n\n\nint MIN_BUFFER_DURATION = 3000; // 3 seconds \nint MAX_BUFFER_DURATION = 8000; // 8 seconds \nint MIN_PLAYBACK_RESUME_BUFFER = 1500; // 1.5 seconds \nint MIN_PLAYBACK_START_BUFFER = 500; // 0.5 seconds \nLoadControl loadControl = new DefaultLoadControl.Builder() .setAllocator(new DefaultAllocator(true, 16)) .setBufferDurationsMs(MIN_BUFFER_DURATION, MAX_BUFFER_DURATION, MIN_PLAYBACK_START_BUFFER, MIN_PLAYBACK_RESUME_BUFFER) .setTargetBufferBytes(-1) .setPrioritizeTimeOverSizeThresholds(true).createDefaultLoadControl()\n\n\nTry using a different LoadControl. For example, you could use DefaultLoadControl with a smaller target buffer (e.g. 25% of the video bitrate):\n\nint TARGET_BUFFER_BYTES = (int) (0.25 * videoBitrate); // 25% of the video bitrate in bytes \nLoadControl loadControl = new DefaultLoadControl(new DefaultAllocator(true, 16), TARGET_BUFFER_BYTES , DEFAULT _MIN _REBUFFER _MS , DEFAULT _MAX LOADING _MS, DEFAULT __MIN ELAPSED __MS_BEFORE STOPPING , false); \n\n\nTry using a different Allocator. For example, you could use a larger one:\n\nint allocatorSize = 2 * 1024 * 1024; // 2MB \nAllocator allocator = new DefaultAllocator(true, allocatorSize); \nLoadControl loadControl = new DefaultLoadControl(allocator , DEFAULT _TARGET_BUFFER _BYTES , DEFAULT __MIN REBUFFER MS , DEFAULT MAX LOADING MS , DEFAULT MIN ELAPSED MS BEFORE STOPPING , false); \n\n"
}
{
    "Id": 73126185,
    "PostTypeId": 1,
    "Title": "What is overhead of Java Native Memory Tracking in \"summary\" mode?",
    "Body": "I'm wondering what is the real/typical overhead when NMT is enabled via \u2011XX:NativeMemoryTracking=summary (the full command options I'm after are -XX:+UnlockDiagnosticVMOptions \u2011XX:NativeMemoryTracking=summary \u2011XX:+PrintNMTStatistics)\nI could not find much information anywhere - either on SO, blog posts or the official docs.\nThe docs say:\n\nNote: Enabling NMT causes a 5% -10% performance overhead.\n\nBut they do not say which mode is expected to have this performance overhead (both summary and detail?)\nand what this overhead really is (CPU, memory, ...).\nIn Native Memory Tracking guide they claim:\n\nEnabling NMT will result in a 5-10 percent JVM performance drop, and memory usage for NMT adds 2 machine words to all malloc memory as a malloc header. NMT memory usage is also tracked by NMT.\n\nBut again, is this true for both summary and detail mode?\nWhat I'm after is basically whether it's safe to add \u2011XX:NativeMemoryTracking=summary permanently for a production app (similar to continuous JFR recording) and what are potential costs.\nSo far, when testing this on our app, I didn't spot a difference but it's difficult to\nIs there an authoritative source of information containing more details about this performance overhead?\nDoes somebody have experience with enabling this permanently for production apps?\n",
    "AcceptedAnswerId": 73167790,
    "AcceptedAnswer": "The overhead of Native Memory Tracking obviously depends on how often the application allocates native memory. Usually, this is not something too frequent in a Java application, but cases may differ. Since you've already tried and didn't notice performance difference, your application is apparently not an exception.\nIn the summary mode, Native Memory Tracking roughly does the following things:\n\nincreases every malloc request in the JVM by 2 machine words (16 bytes);\nrecords the allocation size and flags in these 2 words;\natomically increments (or decrements on free) the counter corresponding to the given memory type;\nbesides malloc and free, it also handles changes in virtual memory reservation and allocations of new arenas, but these are even less frequent than malloc/free calls.\n\nSo, to me, the overhead is quite small; 5-10% is definitely a large overestimation (the numbers would make sense for detail mode which collects and stores stack traces, which is expensive, but summary doesn't do that).\nWhen many threads concurrently allocate/free native memory, the update of an atomic counter could become a bottleneck, but again, that's more like an extreme case. In short, if you measured a real application and didn't notice any degradation, you're likely safe to enable NMT summary in production.\n"
}
{
    "Id": 72596066,
    "PostTypeId": 1,
    "Title": "\"error: package R does not exist\" in Navigation after adding Assets folder: Android Studio",
    "Body": "Since adding an Assets folder to my project I now get:\nerror: package R does not exist\n\"return new ActionOnlyNavDirections(R.id.action_newAlarmFragment_to_homeFragment);\"\n\nwhich is from this auto generated code:\nimport androidx.annotation.NonNull;\nimport androidx.navigation.ActionOnlyNavDirections;\nimport androidx.navigation.NavDirections;\n\npublic class SetNewAlarmFragmentDirections {\n  private SetNewAlarmFragmentDirections() {\n  }\n\n  @NonNull\n  public static NavDirections actionNewAlarmFragmentToHomeFragment() {\n    return new ActionOnlyNavDirections(R.id.action_newAlarmFragment_to_homeFragment);\n  }\n}\n\nI have tried cleaning and rebuilding the project and tried \"Invalidate caches and restart\" as suggested in the comments\nLooking through other answered questions here it seems it can be an import of R. somewhere causing this, but I can't find anything..\nThe NavDirection itself comes from this fragment:\nimport android.os.Bundle\nimport android.view.LayoutInflater\nimport android.view.View\nimport android.view.ViewGroup\nimport android.widget.CompoundButton\nimport androidx.fragment.app.Fragment\nimport androidx.lifecycle.ViewModelProvider\nimport androidx.navigation.Navigation\nimport com.pleavinseven.alarmclockproject.alarmmanager.AlarmManager\nimport com.pleavinseven.alarmclockproject.data.model.Alarm\nimport com.pleavinseven.alarmclockproject.data.viewmodel.AlarmViewModel\nimport com.pleavinseven.alarmclockproject.databinding.FragmentSetNewAlarmBinding\nimport com.pleavinseven.alarmclockproject.util.TimePickerUtil\nimport java.util.*\n\n\nclass SetNewAlarmFragment : Fragment() {\n\n    private val timePickerUtil = TimePickerUtil()\n    lateinit var binding: FragmentSetNewAlarmBinding\n    private lateinit var alarmViewModel: AlarmViewModel\n\n\n    override fun onCreateView(\n        inflater: LayoutInflater, container: ViewGroup?,\n        savedInstanceState: Bundle?\n    ): View {\n\n        binding = FragmentSetNewAlarmBinding.inflate(inflater, container, false)\n\n           binding.fragmentCreateAlarmRecurring.setOnCheckedChangeListener(CompoundButton.OnCheckedChangeListener { _, isChecked ->\n        if (isChecked) {\n            binding.fragmentCreateAlarmRecurring.visibility = View.VISIBLE\n        } else {\n            binding.fragmentCreateAlarmRecurring.visibility = View.GONE\n        }\n    })\n\n    alarmViewModel = ViewModelProvider(this)[AlarmViewModel::class.java]\n\n\n    binding.fragmentBtnSetAlarm.setOnClickListener(View.OnClickListener { _ ->\n        scheduleAlarm()\n        Navigation.findNavController(requireView())\n            .navigate(com.pleavinseven.alarmclockproject.R.id.action_newAlarmFragment_to_homeFragment)\n    })\n    return binding.root\n\n\n}\n\nnav xml:\n?xml version=\"1.0\" encoding=\"utf-8\"?>\n<navigation xmlns:android=\"http://schemas.android.com/apk/res/android\"\nxmlns:app=\"http://schemas.android.com/apk/res-auto\"\nxmlns:tools=\"http://schemas.android.com/tools\"\nandroid:id=\"@+id/alarm_nav\"\napp:startDestination=\"@id/homeFragment\">\n\n<fragment\n    android:id=\"@+id/homeFragment\"\n     android:name=\"com.pleavinseven.alarmclockproject.fragments.HomeFragment\"\n    android:label=\"fragment_home\"\n    tools:layout=\"@layout/fragment_home\" >\n    <action\n        android:id=\"@+id/action_homeFragment_to_newAlarmFragment\"\n        app:destination=\"@id/newAlarmFragment\" />\n    <action\n        android:id=\"@+id/action_homeFragment_to_updateFragment\"\n        app:destination=\"@id/updateFragment\" />\n\n<fragment\n    android:id=\"@+id/newAlarmFragment\"\n    android:name=\"com.pleavinseven.alarmclockproject.fragments.SetNewAlarmFragment\"\n    android:label=\"NewAlarmFragment\" >\n    <action\n        android:id=\"@+id/action_newAlarmFragment_to_homeFragment\"\n        app:destination=\"@id/homeFragment\" />\n\n<fragment\n    android:id=\"@+id/updateFragment\"\n    android:name=\"com.pleavinseven.alarmclockproject.fragments.UpdateFragment\"\n    android:label=\"UpdateFragment\" >\n    <action\n        android:id=\"@+id/action_updateFragment_to_homeFragment\"\n        app:destination=\"@id/homeFragment\" />\n    <argument\n        android:name=\"currentAlarm\"\n        app:argType=\"com.pleavinseven.alarmclockproject.data.model.Alarm\" />\n\n\n\n",
    "AcceptedAnswerId": 72627732,
    "AcceptedAnswer": "Just move package name from build.gradle app level to manifest.\nfrom\nandroid  { \n    namespace 'com.example.app' //remove this\n}\n\nto\n<manifest xmlns:android=\"http://schemas.android.com/apk/res/android\"\n    package=\"com.example.app\"> //add this\n\n"
}
{
    "Id": 72668718,
    "PostTypeId": 1,
    "Title": "How to create Context using traceId in Open Telemetry",
    "Body": "I try to get all spans created in the following chain associated to the same trace context/traceId by context propagation:\nservice1 -> aws sqs queue -> service2\nAuto. context propagation is not working with aws sqs and aws sdk v2 atm (https://github.com/open-telemetry/opentelemetry-java-instrumentation/issues/3684), even though the AwsTraceHeader is actually set in the sqs message, I have to take care for it explicitly by\n\nservice1: Writing traceId in sqs message user attribute\ntraceId=Span.current().getSpanContext().getTraceId()\nservice2: Reading traceId from sqs message user attribute traceId and overwriting current span.traceId / essentially creating Context of service1\n\nHowever, it is now unclear how to actually overwrite span.traceId in the span that service2 created which is confusing because for example with Golang it seems to be straightforward: How to create opentelemetry span from a string traceid\nI see only getters e.g. Span.current().getSpanContext().getTraceId()\nbut no setters or builder methods.\nUpdate:\nEven by creating a new span and making it current (not sure if this goes in the right direction)  the tracer.spanBuilder does no offer setters for traceId AFAIU)\n@Inject\nio.opentelemetry.api.trace.Tracer tracer;\n\nSpan consumeMessageSpan = tracer.spanBuilder(\"consumeMessage\").startSpan();\n\nconsumeMessage.makeCurrent();\n\nUpdate 2\nThis snippet from otel official docs looks promising\n\nTo link spans from remote processes, it is sufficient to set\nthe\u00a0Remote Context\u00a0as parent.\n\nSpan childRemoteParent = tracer.spanBuilder(\"Child\").setParent(remoteContext).startSpan(); \n\nHowever, also no examples or ideas how to create remoteContext and setting traceId to the one extracted from the sqs message\nAny hints how to do that?\n",
    "AcceptedAnswerId": 72826169,
    "AcceptedAnswer": "I've done the following for a child JVM\n(that is running using the OTel auto-instrumentation agent):\n    public static void main(String[] args) {\n        Span span = createSpanLinkedToParent();\n        try (Scope scope = span.makeCurrent()) {\n            // do stuff\n        } finally {\n            span.end();\n        }\n    }\n\n    private static Span createSpanLinkedToParent() {\n        // Fetch the trace and span IDs from wherever you've stored them\n        String traceIdHex = System.getProperty(\"otel.traceid\");\n        String spanIdHex = System.getProperty(\"otel.spanid\");\n\n        SpanContext remoteContext = SpanContext.createFromRemoteParent(\n                traceIdHex,\n                spanIdHex,\n                TraceFlags.getSampled(),\n                TraceState.getDefault());\n\n        return GlobalOpenTelemetry.getTracer(\"\")\n                .spanBuilder(\"root span name\")\n                .setParent(Context.current().with(Span.wrap(remoteContext)))\n                .startSpan();\n    }\n\nThe next improvement I plan to make it to serialise the flags and state, perhaps using code here in Context Propagation https://opentelemetry.io/docs/instrumentation/java/manual/#context-propagation but the above works for now.\n"
}
{
    "Id": 72345283,
    "PostTypeId": 1,
    "Title": "getDeclaredMethods() return inherited methods if superclass is default",
    "Body": "I have two classes\n// BaseClass.java\nclass BaseClass {\n \n   public String getTest(){\n       return \"one\";\n   }\n \n   public String getTest2(T t){\n       return \"two\";\n   }\n   public String getTest3(T t){\n       return \"three\";\n   }\n}\n \n// OverrideClass.java\npublic class OverrideClass extends BaseClass{\n}\n \n\nI tried to run the following code\n// Test.java\npublic class Test {\n   public static void main(String[] args) {\n       Class overrideClass = OverrideClass.class;\n       Method[] declaredMethods = overrideClass.getDeclaredMethods();\n       System.out.println(Arrays.toString(declaredMethods));\n   }\n}\n\nand I think it should output\n[]\n\nbut in fact the output is\n[public java.lang.String OverrideClass.getTest()]\n\nThrough the bytecode, I thought this a bridge method, but I don't know why it generates, and if I make BaseClass public it will disappear.\n  // access flags 0x1041\n  public synthetic bridge getTest()Ljava/lang/String;\n   L0\n    LINENUMBER 1 L0\n    ALOAD 0\n    INVOKESPECIAL BaseClass.getTest ()Ljava/lang/String;\n    ARETURN\n   L1\n    LOCALVARIABLE this LOverrideClass; L0 L1 0\n    MAXSTACK = 1\n    MAXLOCALS = 1\n}\n\nMy question is:\n\nWhy getTest() generate a bridge method if BaseClass is default?\nWhy getTest2() and getTest3() did not generate their bridge method? This seems to be related to generics.\n\n",
    "AcceptedAnswerId": 72345557,
    "AcceptedAnswer": "I have analyzed the issue and here is the results. I have simplified a bit the example from the question.\nThis answer handles the first question of OP\n\nWhy getTest() generate a bridge method if BaseClass is default?\n\nFor second question regarding the inconsistency appearing with generics you can read Denis answer\nExample 1\nclass BaseClass {\n\n    public String getTest(){\n        return \"one\";\n    }\n\n    public String getTest2(){\n        return \"two\";\n    }\n    public String getTest3(){\n        return \"three\";\n    }\n}\n\n\npublic class OverrideClass extends BaseClass{}\n\n\npublic class Application {\n\npublic static void main(String[] args) throws Exception {\n    Class overrideClass1 = OverrideClass.class;\n    Method[] declaredMethods1 = overrideClass1.getDeclaredMethods();\n    System.out.println(Arrays.toString(declaredMethods1));\n   }\n}\n\nThe execution of this either with JDK 8 or with JDK 17 has always the same result\n[public java.lang.String OverrideClass.getTest(), public java.lang.String OverrideClass.getTest2(), public java.lang.String OverrideClass.getTest3()]\n\nExample 2\nJust modify the above example into\npublic class BaseClass {\n\n    public String getTest(){\n        return \"one\";\n    }\n\n    public String getTest2(){\n        return \"two\";\n    }\n    public String getTest3(){\n        return \"three\";\n    }\n}\n\nNote that the change is in the access modifier on Base class which now is public!\nThe execution of this produces the expected behavior of  []\nThis however is not a bug of JDK. It is intended to be this way.\nExplanation\nThe reason that in the example1 the getDeclaredMethods() has returned the same methods of the parent class is not because those methods are printed as inherited. It is because those are bridge methods that actually belong to that child class (OverrideClass).\nThis functionality has been added long ago and the explanation as you can see here from developers of oracle was\n\nThe proposal is to add bridge methods in these very rare cases to fix\na problem in reflection with no other forseen fix or workaround.\nSpecifically, we would generate a bridge method when a public method\nis inherited from a nonpublic class into a public class.\n\nAnd as you can also see here, the most recent comment from oracle developers was\n\nThe bridge methods are added in a case like this where a public class\npublic methods from a non-public superclass to allow for the\npossibility of reflective access of the subclasses methods\nJDK-6342411).\nClosing this issue as not a bug.\n\nSo this is happening only in non public parent classes because in this case the public methods that are inherited need to be added as bridge methods in that children class.\nIn the example 2 where bridge methods do not exist, if you try to print out the disassembled code using javap -c OverrideClass you will see the following\npublic class OverrideClass extends BaseClass {\n      public OverrideClass();\n        Code:\n           0: aload_0\n           1: invokespecial #1                  // Method BaseClass.\"\":()V\n           4: return\n    }\n\nIn the example 1 with bridge methods existing, if you try to print out the disassembled code using javap -c OverrideClass you will see the following\npublic class OverrideClass extends BaseClass {\n  public OverrideClass();\n    Code:\n       0: aload_0\n       1: invokespecial #1                  // Method BaseClass.\"\":()V\n       4: return\n\n  public java.lang.String getTest3();\n    Code:\n       0: aload_0\n       1: invokespecial #7                  // Method BaseClass.getTest3:()Ljava/lang/String;\n       4: areturn\n\n  public java.lang.String getTest2();\n    Code:\n       0: aload_0\n       1: invokespecial #11                 // Method BaseClass.getTest2:()Ljava/lang/String;\n       4: areturn\n\n  public java.lang.String getTest();\n    Code:\n       0: aload_0\n       1: invokespecial #14                 // Method BaseClass.getTest:()Ljava/lang/String;\n       4: areturn\n}\n\n"
}
{
    "Id": 73281636,
    "PostTypeId": 1,
    "Title": "Java Generics: Stream.map() returns \"capture of ?\" instead of \"?\"",
    "Body": "I'm trying to build a List of Classes that implement a certain interface called Interface:\nList> myList= myMap.entrySet().stream()\n    .filter(entry -> entry.getValue().equals(myValue))\n    .map(Map.Entry::getKey)   // Stream\n    .map(Interface::getClass) // Stream>\n    .distinct()\n    .toList();\n\nI added as comment the type of the elements in the Stream after map() is called.\nThe code iterates over all the entries in the map, and if their value is equal to myValue, then:\n\nfirst, gets the instance of type Interface (which is the key of the entry)\nthen, gets the Class implementing the Interface.\n\nmyMap is defined as:\nMap myMap = new HashMap()\n\nThe error I'm getting :\nIncompatible types.\nFound: 'java.util.List>>',\nrequired: 'java.util.List>'\n\nI am clearly missing something about how Generics work in Java, but I am at a loss here. I suppose it's something related to the fact that the compiler cannot correctly reify my ? wildcard.\n",
    "AcceptedAnswerId": 73281848,
    "AcceptedAnswer": "As @Slaw has pointed out in the comments, in this case getClass() is capable to provide the information about the generic type to the compiler.\nAccording to the documentation:\n\nThe actual result type is Class where |X| is the erasure of the static type of the expression on which getClass is called.\n\nHence, at compile time, we would have a type ? extends Interface and the reason of the observed behavior is related solely to peculiarities of type inference in Java.\nIn this case, when we are chaining methods after map() operation, the compiler fails to infer the type of the method reference Interface::getClass correctly based on the resulting type returned by the stream.\nIf we substitute toList, which expects elements of type T and produces List, with collect(Collectors.toList()), in which collector is of type Collector, the compiler would be able to do its job (here's a proof):\nList> myList = myMap.entrySet().stream()\n    .filter(entry -> Objects.equals(entry.getValue(), myValue))\n    .map(Map.Entry::getKey)   // Stream\n    .map(Interface::getClass) // Stream>\n    .distinct()\n    .collect(Collectors.toList());\n\nBut to make type inference working with toList() we need to provide the generic type explicitly.\nFor instance, this code would compile, because the type of Interface::getClass could be inferred from the assignment context (here there are no operations after map(), hence myStream directly says what should be the return type of map()):\nStream> myStream = myMap.entrySet().stream()\n    .filter(entry -> Objects.equals(entry.getValue(), myValue))\n    .map(Map.Entry::getKey)\n    .map(Interface::getClass);\n\nList> myList = myStream.distinct().toList();\n\nA more handy way would be to use a so-called Type Witness:\nMap myMap = Map.of(new ClasA(), 1, new ClasB(), 1);\n        \nint myValue = 1;\n        \nList> myList = myMap.entrySet().stream()\n    .filter(entry -> Objects.equals(entry.getValue(), myValue))\n    .map(Map.Entry::getKey)                               // Stream\n    .>map(Interface::getClass) // Stream>\n    .distinct()\n    .toList();\n        \nmyList.forEach(c -> System.out.println(c.getSimpleName()));\n\nOutput:\nClasA\nClasB\n\nDummy classes:\ninterface Interface {}\nclass ClasA implements Interface {}\nclass ClasB implements Interface {}\n\n"
}
{
    "Id": 73336136,
    "PostTypeId": 1,
    "Title": "Does having a wrapper object return value (e.g. Integer) cause auto boxing in Java?",
    "Body": "I couldn't find a definitive answer for this seemingly simple question. If I write a method like this:\npublic Integer getAnInt() {\n  int[] i = {4};\n  return i[0];\n}\n\nis the return value autoboxed into an Integer, or does it depend on what happens to the value after it's returned (e.g. whether the variable it is assigned to is declared as an Integer or int)?\n",
    "AcceptedAnswerId": 73336170,
    "AcceptedAnswer": "Yes, boxed\nIt will be (auto)boxed in the bytecode (.class file) because it's part of the public API, so other code might depend on the return value being an Integer.\nThe boxing and unboxing might be removed at runtime by the JITter under the right circumstances, but I don't know if it does that sort of thing.\n"
}
{
    "Id": 72841549,
    "PostTypeId": 1,
    "Title": "Container Fails to Start: Insufficient memory for the Java Runtime Environment to continue",
    "Body": "We have an enterprise application running on Java 8. The deployment environment is built & updated through Bitbucket pipelines. I have a graphic showing the high-level architecture of the environment.  We have two app servers running identical configurations apart from some application specific environment variables.\nIt was all working well until a week ago when after a successful pipeline run, the 2 app instances on one of the servers stopped working with the following error:\nThere is insufficient memory for the Java Runtime Environment to continue.\nCannot create GC thread. Out of system resources.\n\nBoth the instances are working fine on the other server. In contrast, the containers fail to start on this server.\nSolutions Tried\nThe error accompanies the following information:\nPossible reasons:\nThe system is out of physical RAM or swap space\nThe process is running with CompressedOops enabled, and the Java Heap may be blocking the growth of the native heap.\nPossible solutions:\n\nReduce memory load on the system\nIncrease physical memory or swap space\nCheck if swap backing store is full\nDecrease Java heap size (-Xmx/-Xms)\nDecrease number of Java threads\nDecrease Java thread stack sizes (-Xss)\nSet larger code cache with -XX:ReservedCodeCacheSize=\n\nWe have tried:\n\nAdding more swap memory. The server has 8GB of RAM while we have tried the swap from 4GB to 9GB.\nPlayed with the heap sizes Xms & Xmx from 128m to 4096m.\nIncreased the RAM on this server to 16GB while the other server that works still does on 8GB.\n\nHere is how the memory & swap consumption looks like:\nfree -mh\n              total        used        free      shared  buff/cache   available\nMem:           15Gi       378Mi        12Gi       1.0Mi       2.9Gi        14Gi\nSwap:           9Gi          0B         9Gi\n\nI have links to several related artifacts.  These include the complete docker logs output and the output of docker info on the failing server and the operational server.\nThis is what docker ps -a gets us:\n:~$ docker ps -a\nCONTAINER ID   IMAGE                                                                                  COMMAND                  CREATED        STATUS                    PORTS                                       NAMES\nd29747bf2ad3   :a7608a838625ae945bd0a06fea9451f8bf11ebe4   \"catalina.sh run\"        10 hours ago   Exited (1) 10 hours ago                                               jbbatch\n0951b6eb5d42   :a7608a838625ae945bd0a06fea9451f8bf11ebe4   \"catalina.sh run\"        10 hours ago   Exited (1) 10 hours ago                                               jbapp\n\nWe are out of ideas right now as we have tried almost all the solutions on stack overflow. What are we missing?\n",
    "AcceptedAnswerId": 72841934,
    "AcceptedAnswer": "I see that your Docker image uses Ubuntu 22.04 LTS as its base. Recently base Java images were rebuilt on top of this LTS version, which caused a lot of issues on older Docker runtimes. Most likely this is what you're experiencing. It has nothing to do with memory, but rather with Docker incompatibility with a newer Linux version used as a base image.\nYour operational server has Docker server version 20.10.10, while the failing server has version 20.10.09. The incompatibility issue was fixed exactly in Docker 20.10.10. Some more technical details on the incompatibility issue are available here.\nThe solution would be to upgrade the failing server to at least Docker 20.10.10.\n"
}
{
    "Id": 73337717,
    "PostTypeId": 1,
    "Title": "IntelliJ Idea debugger's evaluator gives different results than normal program for comparing Scala Long and Float variables",
    "Body": "\nAs the screenshot shows, While I'm comparing the same literal values with type of Float and Long, Scala says it's not equal\nBut the evaluator says they are equal to each other!\nI suspect this is a bug in Intellij Idea, since the same code will yield different results in a normal Scala runtime than in a evaluator runtime.\nIf the Evaluator's result is untrustworthy, this may cause trouble for developers.\nI wonder if there is anything wrong with my thinking and hope someone can point it out.\n",
    "AcceptedAnswerId": 73338149,
    "AcceptedAnswer": "I could not reproduce your example using the Intellij evaluator (though I don't use a Mac, this might be a bug on the Mac version of Intellij), but what I can say is that Java and Scala treat this differently. Actually, in Scala 2.13.x those values are equal.\nJava treats this code differently based on their types (primitive vs wrapper types):\n    long vl = 32294629407L;\n    float vf = 32294629407f;\n    Boolean res11 = vl == vf;\n    System.out.println(res11); // true\n\n    Long vl1 = 32294629407L;\n    Float vf1 = 32294629407f;\n    Boolean res22 = vl1.equals(vf1);\n    System.out.println(res22); // false\n\nSince Scala was designed to be a more regular language, such discrepancies were removed from the language, by special casing the == method for these classes:\n  val vl: Long  = 32294629407L\n  val vf: Float = 32294629407f\n  val res11     = vl == vf // true \n\n  println(res11) // true\n\n\nThe only case where == does not directly call equals is for Java's\nboxed numeric types.\n\nNOTE:\nFor prior versions of Scala, this does not hold, as it seems in Scala 2.12 this is not valid.\n"
}
{
    "Id": 71832118,
    "PostTypeId": 1,
    "Title": "sbt assembly cannot create jar getting java.lang.UnsupportedOperationException",
    "Body": "I am using\nscala 1.12.10\nakka 2.6.3\naddSbtPlugin(\"io.spray\" % \"sbt-revolver\" % \"0.9.1\")\naddSbtPlugin(\"com.eed3si9n\" % \"sbt-assembly\" % \"1.1.0\")\n\nHowever when executing sbt assembly I am getting:\njava.lang.UnsupportedOperationException: The Security Manager is deprecated and will be removed in a future release\n    at java.base/java.lang.System.setSecurityManager(System.java:416)\n    at sbt.TrapExit$.installManager(TrapExit.scala:53)\n    at sbt.StandardMain$.runManaged(Main.scala:109)\n    at sbt.xMain.run(Main.scala:76)\n    at xsbt.boot.Launch$$anonfun$run$1.apply(Launch.scala:111)\n    at xsbt.boot.Launch$.withContextLoader(Launch.scala:131)\n    at xsbt.boot.Launch$.run(Launch.scala:111)\n    at xsbt.boot.Launch$$anonfun$apply$1.apply(Launch.scala:37)\n    at xsbt.boot.Launch$.launch(Launch.scala:120)\n    at xsbt.boot.Launch$.apply(Launch.scala:20)\n    at xsbt.boot.Boot$.runImpl(Boot.scala:56)\n    at xsbt.boot.Boot$.main(Boot.scala:18)\n    at xsbt.boot.Boot.main(Boot.scala)\n[error] [launcher] error during sbt launcher: java.lang.UnsupportedOperationException: The Security Manager is deprecated and will be removed in a future release\n\nrunning java 18\njava -version\nopenjdk version \"18\" 2022-03-22\nOpenJDK Runtime Environment (build 18+36-2087)\nOpenJDK 64-Bit Server VM (build 18+36-2087, mixed mode, sharing)\n\n",
    "AcceptedAnswerId": 71847512,
    "AcceptedAnswer": "Using java 8 solved this issue as AminMal suggested\n"
}
{
    "Id": 72878610,
    "PostTypeId": 1,
    "Title": "Is there a reason to create the string variable before input?",
    "Body": "Newly learning java and for input, we did\nScanner scan = new Scanner(System.in);\nString name;\nSystem.out.println(\"What is your  name?\");\nname = scan.nextLine();\nSystem.out.println(name);\n\nHowever, I found that\nScanner scan = new Scanner(System.in);\nString name = scan.nextLine();\nSystem.out.println(name);\n\nworks the same. Is this being taught to me in the bigger form because it's more generally used/is clearer or am I just being taught the bigger form since I'm a beginner to avoid too much confusion? (Basically, are there any reasons why people would use the expanded version rather than the condensed version?)\n",
    "AcceptedAnswerId": 72878772,
    "AcceptedAnswer": "In your case its one and the same thing. It is more useful though when used in the context of variable scoping.\nCreating a reference variable before initializing it with a value is the preferred way while using code blocks, so that the reference can be used outside of the block as well. Check out this example:\nint sum = 0;\nfor(int idx=0; idx<5; idx++) {\n   sum+=idx;\n}\nreturn sum;\n\n"
}
{
    "Id": 73456148,
    "PostTypeId": 1,
    "Title": "Unit test: Collection being processed with for-loop but not with streams",
    "Body": "Issue with unit test is that the same collection is processed differently in a stream and in a for loop.\nThe collection in both cases is empty (data.size() = 0), but in the Case 1 that collection is somehow processed, in other words it will step in the for-loop.\nIn Case 2, that collection is just skipped (which is expected since it's empty).\nTests are using Mockito, and Result is comming for JOOQ.\nThe tests are old and unchanged, the only change is going from for-loop to stream.\nCase 1\nprivate SearchResult iterateData(\n      Result data, ...) {\n\n      for (Record record : data) {\n           doSomething(record);\n    }\n\nCase 2\nprivate SearchResult iterateData(\n      Result data, ...) {\n      data.stream().forEach(record -> doSomething(record)); \n\nScreenshot of Case 1\nfor loop example\nMocked Result object\nprivate DefaultSearchRequestModel rowSpecificValuesTestSetup(\n      parameters...) {\n    \n\n    DefaultSearchRequestModel searchRequest = new DefaultSearchRequestModel(\n        Arrays.asList(....),\n        Collections.singletonList(\n            new SearchFilter(\n                \"test\",\n                Collections.singletonList(...)));\n\n    List columns =\n        this.searchService.filterUserAllowedColumns(...);\n\n    Condition searchCondition =\n        this.searchRepositoryMock.getSearchConditions(...);\n\n    List joinMappings = ColumnHelper.getColumnTranslateDeviceJoinMappings(\n        columns,\n        searchRequest.getFilters());\n\n    Result deviceDataResultMock = Mockito.mock(Result.class);\n    Iterator resultIterator = Mockito.mock(Iterator.class);\n    final Table fromTableMock = Mockito.mock(Table.class);\n    when(resultIterator.hasNext()).thenReturn(true, false);\n    Record recordMock = Mockito.mock(Record.class);\n    when(resultIterator.next()).thenReturn(recordMock);\n    when(deviceDataResultMock.iterator()).thenReturn(resultIterator);\n    when(recordMock.get(CONTRACTID)).thenReturn(contractId);\n   ...\nwhen(this.userPermissions.getAccessPermissions()).thenReturn(searchRequest.getColumns().stream().map\n        (name -> Column.findByName(name).getId()).collect(\n        Collectors.toList()));\n    when(this.searchRepositoryMock.getCurrentTable(companyId))\n        .thenReturn(fromTableMock);\n    when(recordMock.get(TYPEID)).thenReturn(financialTypeId);\n    when(this.searchRepositoryMock.getDeviceData(\n        ArgumentMatchers.anyList(),\n        ArgumentMatchers.anyList(),\n        any(),\n        any(),\n        eq(searchRequest.getPageSize()),\n        eq(searchRequest.getPage()),\n        eq(searchRequest.getSortCriterias()),\n        eq(fromTableMock),\n        ArgumentMatchers.anyList(),\n        eq(Optional.empty()),\n        eq(this.dslContextMock)))\n        .thenReturn(deviceDataResultMock);\n\n    return searchRequest;\n  }```\n\n",
    "AcceptedAnswerId": 73469713,
    "AcceptedAnswer": "Why it didn't work\nYou're mocking Result.iterator():\nwhen(deviceDataResultMock.iterator()).thenReturn(resultIterator);\n\nBut you didn't mock Result.spliterator(), or at least I didn't see it, which is what's being called by Result.stream(), which is just Collection.stream():\ndefault Stream stream() {\n    return StreamSupport.stream(spliterator(), false);\n}\n\nSo, you'll have to mock the spliterator() method as well, and probably a few others, too! Alternatively, tell Mockito to call default methods:\nCan you make mockito (1.10.17) work with default methods in interfaces?\nA comment on mocking in general\nI'm not convinced that mocking the jOOQ API is a very good idea. The jOOQ API is vast, and you'll likely forget to mock this or that method as this question here has aptly shown. With your current setup, you're planning on updating your mock every time you project a new column? E.g. you're doing this:\nwhen(recordMock.get(DEVICEID.getName()).thenReturn(deviceId);\n\nWhat if the column is renamed? Or another column is projected? You'll have to update this test. That feels like quite the chore, and it's very error prone.\nWhile jOOQ itself has JDBC mocking capabilities, please consider the bold disclaimer on that manual page:\n\nDisclaimer: The general idea of mocking a JDBC connection with this jOOQ API is to provide quick workarounds, injection points, etc. using a very simple JDBC abstraction. It is NOT RECOMMENDED to emulate an entire database (including complex state transitions, transactions, locking, etc.) using this mock API. Once you have this requirement, please consider using an actual database product instead for integration testing, rather than implementing your test database inside of a MockDataProvider\n\nWhen working with databases, it's usually best to resort to running integration tests, see the following resources for some details:\n\nIntegration testing with Jooq\nUsing H2 as a Test Database Product with jOOQ\nHow to Integration Test Stored Procedures with jOOQ\nUsing Testcontainers to Generate jOOQ Code\n\nOf course, you can write a few smoke tests to ensure jOOQ works correctly if you don't trust jOOQ (jOOQ being an external dependency). But the jOOQ unit and integration tests are vast, so in general, you should be able to trust core types like Result or Record to do the right thing for you. What you really want to test is your query correctness, and that, you can only integration test against an actual database instance.\n"
}
{
    "Id": 73654810,
    "PostTypeId": 1,
    "Title": "Why does String creation using `newInstance()` method behave different when using `var` compared to using explicit type `String`?",
    "Body": "I am learning about reflection in Java. By accident, I discovered the following, for me unexpected behavior.\nBoth tests as written below succeed.\nclass NewInstanceUsingReflection {\n    @Test\n    void testClassNewInstance()\n        throws NoSuchMethodException, InvocationTargetException,\n        InstantiationException, IllegalAccessException\n    {\n        final var input = \"A string\";\n        final var theClass = input.getClass();\n        final var constructor = theClass.getConstructor();\n        final String newString = constructor.newInstance();\n\n        assertEquals(\"\", newString);\n    }\n\n    @Test\n    void testClassNewInstanceWithVarOnly()\n        throws NoSuchMethodException, InvocationTargetException,\n        InstantiationException, IllegalAccessException\n    {\n        final var input = \"A string\";\n        final var theClass = input.getClass();\n        final var constructor = theClass.getConstructor();\n        final var newString = constructor.newInstance();\n\n        assertEquals(\"A string\", newString);\n    }\n}\n\nThe only difference apart from the assertion is that the newString variable type is explicit in the first test and declared as var in the second test.\nI'm using java 17 and the junit5 test framework.\nWhy is the value of newString an empty string in the first test and the input string value in the second test?\nDoes it have something todo with the string-pool?\nOr is something else going on?\n",
    "AcceptedAnswerId": 73655162,
    "AcceptedAnswer": "Java17, same problem. The explanation is clearly: bug.\ndecompiling it, the relevant section:\n        20: anewarray     #2                  // class java/lang/Object\n        23: invokevirtual #35                 // Method java/lang/reflect/Constructor.newInstance:([Ljava/lang/Object;)Ljava/lang/Object;\n        26: checkcast     #41                 // class java/lang/String\n        29: astore        4\n        31: ldc           #23                 // String A string\n        33: ldc           #23                 // String A string\n        35: invokevirtual #43                 // Method java/lang/String.equals:(Ljava/lang/Object;)Z\n\nastore 4 is where the result goes, which is nowhere: slot 4 is not used any further. Instead, the same string constant is loaded twice, trivially resulting in, effectively, \"A string\".equals(\"A string\"), which is of course true.\nReplacing var with String, recompiling, and rerunning javap:\n        20: anewarray     #2                  // class java/lang/Object\n        23: invokevirtual #35                 // Method java/lang/reflect/Constructor.newInstance:([Ljava/lang/Object;)Ljava/lang/Object;\n        26: checkcast     #41                 // class java/lang/String\n        29: astore        4\n        31: ldc           #23                 // String A string\n        33: aload         4\n        35: invokevirtual #43                 // Method java/lang/String.equals:(Ljava/lang/Object;)Z\n\nIdentical in every way, except the second ldc is the correct aload 4.\nI'm having a hard time figuring out what's happening here. It feels more like the var is somehow causing that ldc to duplicate (in contrast to an analysis incorrectly thinking that the values are guaranteed to be identical; javac intentionally does very little such optimizations).\nI'm having a really hard time figuring out how this has been in 2 LTS releases. Impressive find.\nNext step is to verify on the latest JDK (18), and then to file a bug. I did a quick look if it has been reported already, but I'm not sure what search terms to use. I didn't find any report in my search, though.\nNB: The decompilation traces were produced using javap -c -v NewInstanceUsingReflection.\nEDIT: Just tried on ecj (Eclipse Compiler for Java(TM) v20210223-0522, 3.25.0, Copyright IBM Corp 2000, 2020. All rights reserved.) - bug doesn't happen there.\n"
}
{
    "Id": 72349380,
    "PostTypeId": 1,
    "Title": "How can I create a Locale with a specific script code?",
    "Body": "I'm trying to convert this String az_AZ_#Latn, found here, to a Locale but I'm unable to parse the #Latn part.\nIf I do new Locale(\"az_AZ_#Latn\") I lose the #Latn part (the Script code).\nI've tried as well using the LocaleUtils from commons-lang but I get an error saying that it's an invalid format.\n",
    "AcceptedAnswerId": 72349890,
    "AcceptedAnswer": "As written in the docs:\n\nIt is not possible to set a script code on a Locale object in a\nrelease earlier than JDK 7.\n\nBut you can use the Locale builder to make it like this:\nLocale locale = new Locale.Builder().setLanguage(\"az\").setRegion(\"AZ\").setScript(\"Latn\").build();\n\nYou can get the Script it by calling locale.getScript()\nEdit:\nHere's a method I made for converting a string into a locale (doesn't work for extensions):\npublic static Locale stringToLocale(String locale){\n    if(locale == null || locale.isEmpty()) return null;\n    String[] parts = locale.split(\"_\");\n    if(parts.length == 1) return new Locale(parts[0]);\n    if(parts.length == 2) return new Locale(parts[0],parts[1]);\n    if(parts.length == 3) \n        if(parts[2].charAt(0) != '#') return new Locale(parts[0],parts[1],parts[2]);\n        else return new Locale.Builder().setLanguage(parts[0]).setRegion(parts[1]).setScript(parts[2].substring(1)).build();\n    if(parts.length == 4) return new Locale.Builder().setLanguage(parts[0]).setRegion(parts[1]).setVariant(parts[2]).setScript(parts[3].charAt(0)=='#'? parts[3].substring(1):null).build();\n    return null;\n}\n    //works for the toString output expect for extensions. test: for(Locale l:  Locale.getAvailableLocales()) System.out.println(l.equals(stringToLocale(l.toString())));\n   // output : true true true...\n\nusage:\nLocale l = stringToLocale(\"az_AZ_#Latn\");\n\n"
}
{
    "Id": 71641264,
    "PostTypeId": 1,
    "Title": "How can I solve this issue on Mac M1 Caused by: java.lang.Exception: No native library is found for os.name=Mac and os.arch=aarch64",
    "Body": "I solved this issue with the code below in my build.gradle\n  allprojects {\nconfigurations.all {\n    resolutionStrategy {\n        force 'org.xerial:sqlite-jdbc:3.34.0'\n      }\n   }\n } \n\nBut it has an effect on the project I am working on. for some reason, it is not working with room sql implemented on the project.\nI get this error when i removed the code above.\nIs there a better approach to solve this.\nCaused by: java.lang.ExceptionInInitializerError\nat androidx.room.processor.DatabaseProcessor.doProcess(DatabaseProcessor.kt:82)\nat androidx.room.processor.DatabaseProcessor.process(DatabaseProcessor.kt:57)\nat androidx.room.RoomProcessor$DatabaseProcessingStep.process(RoomProcessor.kt:134)\nat com.google.auto.common.BasicAnnotationProcessor.process(BasicAnnotationProcessor.java:330)\nat com.google.auto.common.BasicAnnotationProcessor.process(BasicAnnotationProcessor.java:181)\nat org.jetbrains.kotlin.kapt3.base.incremental.IncrementalProcessor.process(incrementalProcessors.kt)\nat org.jetbrains.kotlin.kapt3.base.ProcessorWrapper.process(annotationProcessing.kt:161)\nat \n\n \n\njdk.compiler/com.sun.tools.javac.processing.JavacProcessingEnvironment.callProcessor(JavacProcessingEnvironment.java:980)\n... 39 more\nCaused by: java.lang.Exception: No native library is found for os.name=Mac and \nos.arch=aarch64. path=/org/sqlite/native/Mac/aarch64\nat org.sqlite.SQLiteJDBCLoader.loadSQLiteNativeLibrary(SQLiteJDBCLoader.java:333)\nat org.sqlite.SQLiteJDBCLoader.initialize(SQLiteJDBCLoader.java:64)\nat androidx.room.verifier.DatabaseVerifier.(DatabaseVerifier.kt:68)\n... 47 more\n\n",
    "AcceptedAnswerId": 71898182,
    "AcceptedAnswer": "update your room library\n   implementation \"androidx.room:room-runtime:2.4.2\"\n   implementation \"androidx.room:room-ktx:2.4.2\"\n   kapt \"androidx.room:room-compiler:2.4.2\"\n\nHere is Reference\n"
}
{
    "Id": 73038137,
    "PostTypeId": 1,
    "Title": "What's the best way to encode and decode parameter in springboot?",
    "Body": "I use @RequestParam to get the parameter value,but I find the if I pass the value like 'name=abc&def&id=123',I will get the name value 'abc' instead of 'abc&def'. I find the encode and decode the parameter value can solve my problem.But I have to write the encode and decode mehtod in every controller method,Do spring have the global mehtod that decode every  @RequestParam value?When using @RequestParam, is it necessary to encode and decode every value?\nHere is my code:\n@PostMapping(\"/getStudent\")\npublic Student getStudent(\n        @RequestParam String name,\n        @RequestParam String id) { \n        name= URLDecoder.decode(name, \"UTF-8\");  \n        //searchStudent\n        return Student;\n}\n\n@PostMapping(\"/getTeacher\")\npublic teacher getTeacher(\n        @RequestParam String name,\n        @RequestParam String teacherNo) { \n        name= URLDecoder.decode(name, \"UTF-8\");  \n        //searchTeacher\n        return teacher;\n}\n\nSomebody say the the Spring will have already done this,but I have try,the result is not right.Only use curl cmd is ok,but java code is not ok.\n@PostMapping(value = \"/example\")\npublic String handleUrlDecode1(@RequestParam String param) { \n    //print ello%26test\n    System.out.println(\"/example?param received: \" + param); \n    return \"success\";\n}\n\n@GetMapping(value = \"/request\")\npublic String request() {\n    String url =  \"http://127.0.0.1:8080/example?param=ello%26test\";\n    System.out.println(url);\n    RestTemplate restTemplate = new RestTemplate();\n    return restTemplate.postForObject(url, null, String.class);\n}\n\n",
    "AcceptedAnswerId": 73053590,
    "AcceptedAnswer": "You must create an HTTP entity and send the headers and parameter in body.\n@GetMapping(value = \"/request\")\npublic String request()  {\n    String url =  \"http://127.0.0.1:8080/example\";\n    System.out.println(url);\n    RestTemplate restTemplate = new RestTemplate(); \n    HttpHeaders headers = new HttpHeaders();\n    headers.setContentType(MediaType.APPLICATION_FORM_URLENCODED);\n    MultiValueMap map= new LinkedMultiValueMap();\n    map.add(\"param\",\"ello&test\");\n    map.add(\"id\",\"ab&c=def\");\n    HttpEntity> request = new HttpEntity>(map, headers); \n    return restTemplate.postForObject(url, request, String.class);\n}\n\n"
}
{
    "Id": 72362798,
    "PostTypeId": 1,
    "Title": "ZonedDateTime format and parsing exception with \u201cz\u201d in format pattern",
    "Body": "I have a problem with parsing ZonedDateTime:\nDateTimeFormatter format = DateTimeFormatter.ofPattern(\"yyyy-MM-ddzhh:mm\");\nZonedDateTime.parse(s, formatter);\n\nThis results in an error:\njava.time.format.DateTimeParseException:\n    Text '2022-05-24UTC12:15' could not be parsed at index 10\n\nwhats wrong with this code?\n",
    "AcceptedAnswerId": 72362956,
    "AcceptedAnswer": "The character z should be able to parse \"UTC\" (in most Locales) because UTC is considered a time-zone ID and a time-zone name in java.time. A VV can parse time-zone ids while zcan parse time-zone-names according to the JavaDocs of java.time.DateTimeFormatter, here's the relevant part of the docs:\nSymbol  Meaning                     Presentation      Examples\n------  -------                     ------------      -------\n(\u2026)\n\nV       time-zone ID                zone-id           America/Los_Angeles; Z; -08:30\nz       time-zone name              zone-name         Pacific Standard Time; PST\n\n(\u2026)\n\nThat means you can parse it using the character V without providing a specific Locale to your DateTimeFormatter. You will have to put two of them (VV) or you will get a nice IllegalArgumentException with the following message:\njava.lang.IllegalArgumentException: Pattern letter count must be 2: V\n\nIf you still want to use z, provide a Locale that considers UTC an abbreviation of Universal Time Coordinated, the Central European Summer Time is an abbreviation that definitely changes among different Locales, e.g.\n\nEnglish: CEST\nGerman:  MESZ\n\nOther Locales might have different abbreviations, which makes me wonder if your Locale actually even has a different one for UTC.\nProvide Locale.ENGLISH, for example and it should parse successfully.\nYou should provide one anyway because if you don't, the DateTimeFormatter will implicitly use the default Locale of your (Java Virtual) machine.\nSo you can try this:\nDateTimeFormatter format = DateTimeFormatter.ofPattern(\"uuuu-MM-ddVVHH:mm\");\n\nor this:\nDateTimeFormatter format = DateTimeFormatter.ofPattern(\"uuuu-MM-ddzHH:mm\", Locale.ENGLISH);\n\nboth should be able to parse an input like \"2022-05-24UTC12:15\" if you use HH instead of hh for hours of day (hh = 12h format, HH = 24h format).\n"
}
{
    "Id": 72046624,
    "PostTypeId": 1,
    "Title": "Firebase Tools and Java 11",
    "Body": "This question falls somewhere between Firebase Tools, MacOS and Java. Probably 75% Java, 20% Firebase Tools and 5% MacOS.\nStarting with v10.5, firebase-tools started stating that 'Support for Java version \nI run macOS v11.6.5 on a Macbook Pro from mid-2014. When I go to Java's Downloads page, it recommends Java 'Version 8 Update 331'. Not Java 11.\nInformation on downloading Java 11 seems to be scarce. Oracle's page of certified configurations includes MacOS 11, but I can't find anywhere obvious where Java 11 can be readily downloaded.\nA big part of the problem seems to be the terminology used. If I run java -version, I get:\njava version \"1.8.0_331\"\nJava(TM) SE Runtime Environment (build 1.8.0_331-b09)\nJava HotSpot(TM) 64-Bit Server VM (build 25.331-b09, mixed mode)\n\nOkay, I have build 1.8 of the Java Runtime Environment, aka the JRE if you are a Java enthusiast. That is apparently what is triggering the warning in Firebase Tools.\nThere is also a Java product out there called 'Java SE 11'. The product itself is ambiguous, but the checksums all say 'SDK'. (A Software Development Kit: a thing that enables developers to develop Java programs. The name doesn't imply a Runtime Environment: a thing that enables Java to run on an operating system.) There is an article out there which claims that, if you install Java SE 11 and run java -version, it will spit out java version \"11.0.7\". That will probably satisfy Firebase Tools.\nBut Oracle's release notes say: 'In Windows and macOS, installing the JDK in previous releases optionally installed a JRE. In JDK 11, this is no longer an option.' No longer an option... as in now you implicitly get JRE 11 with SDK 11? Or as in the SDK and JRE are now fully divorced, and the JRE must be ferreted out of its hiding like a wild beast?\nUPDATE 6/5/22: Java's checksums page now says 'JDK', and I guess that is better than 'SDK' because it implies 'Java Development Kit', which this Wikipedia article claims to include both a JRE ('java') and SDK (most of the other files).\n",
    "AcceptedAnswerId": 72046625,
    "AcceptedAnswer": "To install Java SE:\nGo here.\n\nScroll down to find your product. I chose Java SE 11. (Oracle will probably list later versions as they are made available.)\nChoose your operating system. I chose MacOS.\nChoose your file set. I chose the DMG installer.\nDownload your chosen file set.\n\n\n5. Do whatever is required by your platform to install Java SE using the downloaded file set from #5.\nAfter installing Java SE 11, java -version now says \"11.0.14\" and Firebase Tools is now satisfied. My best guess is that JRE 11 was implicitly downloaded, and that developers need to start ignoring the main Download page used by everyone else. (Why didn't the main Download page recommend Java 11 from the start?) Hopefully someone will see this question and clarify whether in the future, the 'Java SE' product implicitly includes both the JRE and SDK, and that the numbering system will always encompass both. In other words, hopefully when someone says we need 'Java 11', it means that we need to download SE 11, containing JRE 11 and SDK 11.\n"
}
{
    "Id": 72140664,
    "PostTypeId": 1,
    "Title": "Azure build error: \"Android Gradle plugin requires Java 11 to run. You are currently using Java 1.8\"",
    "Body": "When building Flutter app in azure devOps, I receive this error:\nBuild file 'D:\\a\\1\\s\\android\\app\\build.gradle' line: 24\n\n* What went wrong:\nA problem occurred evaluating project ':app'.\n> Failed to apply plugin 'com.android.internal.application'.\n   > Android Gradle plugin requires Java 11 to run. You are currently using Java 1.8.\n     You can try some of the following options:\n       - changing the IDE settings.\n       - changing the JAVA_HOME environment variable.\n       - changing `org.gradle.java.home` in `gradle.properties`.\n\nI've tried, these solutions:\n\nCreating jitpack.yml file, with - openjdk11 value.\nAdding below lines to app/build.gradle file inside android {} block:\n\n...\ncompileOptions {\n\nsourceCompatibility JavaVersion.VERSION_11\n\n    targetCompatibility JavaVersion.VERSION_11\n}\n\nkotlinOptions {\n    jvmTarget = JavaVersion.VERSION_11.toString()\n}\n\nAnd another solutions, but my error doesn't solve. By the way, I easily run app and build apk, locally on my mac without any errors, but when I push my code, Azure gives those build error.\n",
    "AcceptedAnswerId": 72140711,
    "AcceptedAnswer": "My error is solved by adding below lines into azure-pipelines.yml file:\nsteps:\n - task: JavaToolInstaller@0\n    inputs:\n      versionSpec: '11'\n      jdkArchitectureOption: 'x64'\n      jdkSourceOption: 'PreInstalled'\n\n"
}
{
    "Id": 73187929,
    "PostTypeId": 1,
    "Title": "Android Studio Chipmunk (2021.2.1) Java 8 library desugaring in D8 and R8 Build Error: \"Unsupported desugared library configuration version\"",
    "Body": "After updating my apps build gradle and dependencies (I did not update Android Studio itself), Android Studio is giving me this error: Error: Unsupported desugared library configuration version, please upgrade the D8/R8 compiler.\nBefore the update everything compiled fine.\nI am using:\n\ncom.android.tools:desugar_jdk_libs:1.2.0 (This was the newest version I could find)\nGradle plugin version 7.2.0\nGradle version 7.5\nAndroid Studio version Chipmunk (2021.2.1)\n\nDid I configuration something wrong? How can I fix this? Thanks in advance!\n",
    "AcceptedAnswerId": 73189430,
    "AcceptedAnswer": "According to this page, the minimum version of Android Gradle plugin required is 7.3.0-beta03 to be able to upgrade the desugar library to 1.2.0, and 7.3.x is not yet available for Android Studio Chipmunk.\n"
}
{
    "Id": 71080814,
    "PostTypeId": 1,
    "Title": "How to let JPArepository.save() do insert only and prevent update?",
    "Body": "I am using JPArepository.save() to insert the record to the database but it will automatically update the existing record in the database. What I want to do is let it throw exception if there are records with same primary key in the database.\nI searched the solution in Google and find a solution that said use saveAndFlush instead of save can solve it. However, it still update the existing record after I used saveAndFlush.\n",
    "AcceptedAnswerId": 73328759,
    "AcceptedAnswer": "Finally, I've found the solution.\nI just implement Persistable interface and ovrride the isNew() to be always true.\nExample:\n@Entity\npublic class ChessGame implements Persistable {\n \n    @Id\n    private Long id;\n\n \n    @Override\n    public boolean isNew() {\n        return true;\n    }\n}\n\n"
}
{
    "Id": 72508332,
    "PostTypeId": 1,
    "Title": "Android Studio: \"attempting to assign weaker access privileges\" error on Room Database implementation",
    "Body": "I am trying to implement room database, I have gone through steps on Official Website, and 'AppDatabase.java' file is like this:\nimport android.content.Context;\nimport androidx.room.Database;\nimport androidx.room.Room;\nimport androidx.room.RoomDatabase;\n\n@Database(entities = {User.class}, version = 1)\npublic abstract class AppDatabase extends RoomDatabase {\n\n    public static AppDatabase instance;\n    public static synchronized AppDatabase getInstance(Context context){\n        if (instance==null){\n            instance = Room.databaseBuilder(context.getApplicationContext(),\n                    AppDatabase.class, \"app_database\").fallbackToDestructiveMigration().build();\n        }\n        return instance;\n    }\n}\n\nAnd dependencies I have used for room:\n    // Room Database\n    def room_version = \"2.4.2\"\n\n    implementation \"androidx.room:room-runtime:$room_version\"\n    annotationProcessor \"androidx.room:room-compiler:$room_version\"\n\n    // optional - RxJava2 support for Room\n    implementation \"androidx.room:room-rxjava2:$room_version\"\n\n    // optional - RxJava3 support for Room\n    implementation \"androidx.room:room-rxjava3:$room_version\"\n\n    // optional - Guava support for Room, including Optional and ListenableFuture\n    implementation \"androidx.room:room-guava:$room_version\"\n\n    // optional - Test helpers\n    testImplementation \"androidx.room:room-testing:$room_version\"\n\n    // optional - Paging 3 Integration\n    implementation \"androidx.room:room-paging:2.5.0-alpha02\"\n\n    // Room Database\n\nIt returns 2 errors here:\nonCreate(SupportSQLiteDatabase) in  cannot override onCreate(SupportSQLiteDatabase) in Delegate\nattempting to assign weaker access privileges; was public\n\nonValidateSchema(SupportSQLiteDatabase) in  cannot override onValidateSchema(SupportSQLiteDatabase) in Delegate\nattempting to assign weaker access privileges; was public\n\nIt was working before the 'Chipmunk' version (was working in 'Bumblebee'), but it started throwing these errors.\nWhat is going on here?\n",
    "AcceptedAnswerId": 72518409,
    "AcceptedAnswer": "To fix this error for Jetpack Compose and Paging 3 you only need to use only this libraries\n//ROOM\nimplementation \"androidx.room:room-runtime:2.4.2\"\nkapt \"androidx.room:room-compiler:2.4.2\"\nimplementation \"androidx.room:room-ktx:2.4.2\"\nimplementation \"androidx.room:room-paging:2.4.2\"\n\n// Paging 3.0\nimplementation 'androidx.paging:paging-compose:1.0.0-alpha15'\n\n"
}
{
    "Id": 73330135,
    "PostTypeId": 1,
    "Title": "Regex for finding only single alphabets in a string and ignore consecutive double",
    "Body": "I have searched a lot but I am unable to find a regex that could select only single alphabets and double them while those alphabets which are already double, should remain untouched.\nI tried\nString str = \"yahoo\";\nstr = str.replaceAll(\"(\\\\w)\\\\1+\", \"$0$0\");\n\nBut since this (\\\\w)\\\\1+ selects all double elements, my output becomes yahoooo. I tried to add negation to it !(\\\\w)\\\\1+ but didn't work and output becomes same as input. I have tried\nstr.replaceAll(\".\", \"$0$0\");\n\nBut that doubles every character including which are already doubled.\nPlease help to write an regex that could replace all single character with double while double character should remain untouched.\nExample\nabc -> aabbcc\nyahoo -> yyaahhoo (o should remain untouched)\nopinion -> ooppiinniioonn\naaaaaabc -> aaaaaabbcc\n\n",
    "AcceptedAnswerId": 73330294,
    "AcceptedAnswer": "You can match using this regex:\n((.)\\2+)|(.)\n\nAnd replace it with:\n$1$3$3\n\nRegEx Demo\nRegEx Explanation:\n\n((.)\\2+): Match a character and capture in group #2 and using \\2+ next to it to make sure we match all multiple repeats of captured character. Capture all the repeated characters in group #1\n|: OR\n(.): Match any character and capture in group #3\n\nCode Demo:\nimport java.util.List;\n \nclass Ideone {\n \n    public static void main(String[] args) {\n        List input = List.of(\"aaa\", \"abc\", \"yahoo\",\n                \"opinion\", \"aaaaaabc\");\n \n        for (String s: input) {\n            System.out.println( s + \" => \" +\n                  s.replaceAll(\"((.)\\\\2+)|(.)\", \"$1$3$3\") );\n        }\n    }\n}\n\nOutput:\naaa => aaa\nabc => aabbcc\nyahoo => yyaahhoo\nopinion => ooppiinniioonn\naaaaaabc => aaaaaabbcc\n\n"
}
{
    "Id": 71281032,
    "PostTypeId": 1,
    "Title": "Spring Security exposing AuthenticationManager without WebSecurityConfigurerAdapter",
    "Body": "I'm trying incoming Spring Boot 2.7.0-SNAPSHOT, which uses Spring Security 5.7.0, which deprecate WebSecurityConfigurerAdapter.\nI read this blog post, but I'm not sure to understand how I can expose the default implementation of AuthenticationManager to my JWT authorization filter.\nThe old WebSecurityConfig, using WebSecurityConfigurerAdapter (works fine) :\n@Configuration\n@EnableGlobalMethodSecurity(prePostEnabled = true)\npublic class WebSecurityConfig extends WebSecurityConfigurerAdapter {\n\n    @Autowired\n    private JWTTokenUtils jwtTokenUtils;\n\n    @Bean\n    protected AuthenticationManager getAuthenticationManager() throws Exception {\n        return authenticationManager();\n    }\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        http\n                // disable CSRF as we do not serve browser clients\n                .csrf().disable()\n                // allow access restriction using request matcher\n                .authorizeRequests()\n                // authenticate requests to GraphQL endpoint\n                .antMatchers(\"/graphql\").authenticated()\n                // allow all other requests\n                .anyRequest().permitAll().and()\n                // JWT authorization filter\n                .addFilter(new JWTAuthorizationFilter(getAuthenticationManager(), jwtTokenUtils))\n                // make sure we use stateless session, session will not be used to store user's state\n                .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS);\n    }\n\n}\n\nThe new WebSecurityConfig :\n@Configuration\n@EnableGlobalMethodSecurity(prePostEnabled = true)\npublic class WebSecurityConfig {\n\n    @Autowired\n    private JWTTokenUtils jwtTokenUtils;\n\n    @Bean\n    public SecurityFilterChain filterChain(HttpSecurity http) throws Exception {\n        final AuthenticationManager authenticationManager = http.getSharedObject(AuthenticationManager.class);\n        http\n                // disable CSRF as we do not serve browser clients\n                .csrf().disable()\n                // allow access restriction using request matcher\n                .authorizeRequests()\n                // authenticate requests to GraphQL endpoint\n                .antMatchers(\"/graphql\").authenticated()\n                // allow all other requests\n                .anyRequest().permitAll().and()\n                // JWT authorization filter\n                .addFilter(new JWTAuthorizationFilter(authenticationManager, jwtTokenUtils))\n                // make sure we use stateless session, session will not be used to store user's state\n                .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS);\n        return http.build();\n    }\n\n}\n\nAs you see I have no AuthenticationManager exposed bean anymore. I cannot get it from the WebSecurityConfigurerAdapter. So I tried to get it directly from the HttpSecurity in the filterChain method, so I can pass it to my JWT filter directly.\nBut I still need an AuthenticationManager bean to be exposed to my JWTAuthorizationFilter :\n\nParameter 0 of constructor in com.example.config.security.JWTAuthorizationFilter required a bean of type 'org.springframework.security.authentication.AuthenticationManager' that could not be found.\n\nHow can I expose it?\nHere is the JWT authorization filter (checks the token and authenticate the user, I have a custom UserDetailsService which do the credentials check in the database) :\n@Component\npublic class JWTAuthorizationFilter extends BasicAuthenticationFilter {\n\n    private final JWTTokenUtils jwtTokenUtils;\n\n    public JWTAuthorizationFilter(AuthenticationManager authManager, JWTTokenUtils jwtTokenUtils) {\n        super(authManager);\n        this.jwtTokenUtils = jwtTokenUtils;\n    }\n\n    @Override\n    protected void doFilterInternal(HttpServletRequest req, HttpServletResponse res, FilterChain chain) throws IOException, ServletException {\n\n        // retrieve request authorization header\n        final String authorizationHeader = req.getHeader(\"Authorization\");\n\n        // authorization header must be set and start with Bearer\n        if (authorizationHeader != null && authorizationHeader.startsWith(\"Bearer \")) {\n\n            // decode JWT token\n            final JWTTokenPayload jwtTokenPayload = jwtTokenUtils.decodeToken(authorizationHeader);\n\n            // if user e-mail has been retrieved correctly from the token and if user is not already authenticated\n            if (jwtTokenPayload.getEmail() != null && SecurityContextHolder.getContext().getAuthentication() == null) {\n\n                // authenticate user\n                final UsernamePasswordAuthenticationToken authentication = new UsernamePasswordAuthenticationToken(jwtTokenPayload.getEmail(), null, Collections.singletonList(jwtTokenPayload.getRole()));\n\n                // set authentication in security context holder\n                SecurityContextHolder.getContext().setAuthentication(authentication);\n\n            } else {\n                log.error(\"Valid token contains no user info\");\n            }\n        }\n        // no token specified\n        else {\n            res.setStatus(HttpServletResponse.SC_BAD_REQUEST);\n        }\n\n        // pass request down the chain, except for OPTIONS requests\n        if (!\"OPTIONS\".equalsIgnoreCase(req.getMethod())) {\n            chain.doFilter(req, res);\n        }\n\n    }\n\n}\n\nEDIT :\nI realized I can manage to get the authenticationManager in my JWT filter using the method provided in this issue, but still I need an AuthenticationManager to be exposed globally because I also need it in my controller.\nHere is the authentication controller which need the authenticationManager to be injected :\n@RestController\n@CrossOrigin\n@Component\npublic class AuthController {\n\n    @Autowired\n    private JWTTokenUtils jwtTokenUtils;\n\n    @Autowired\n    private AuthenticationManager authenticationManager;\n\n    @RequestMapping(value = \"/authenticate\", method = RequestMethod.POST)\n    public ResponseEntity authenticate(@RequestBody JWTRequest userRequest) {\n\n        // try to authenticate user using specified credentials\n        final Authentication authentication = authenticationManager.authenticate(new UsernamePasswordAuthenticationToken(userRequest.getEmail(), userRequest.getPassword()));\n\n        // if authentication succeeded and is not anonymous\n        if (authentication != null && !(authentication instanceof AnonymousAuthenticationToken) && authentication.isAuthenticated()) {\n\n            // set authentication in security context holder\n            SecurityContextHolder.getContext().setAuthentication(authentication);\n\n            // get authorities, we should have only one role per member so simply get the first one\n            final GrantedAuthority grantedAuthority = authentication.getAuthorities().iterator().next();\n\n            // generate new JWT token\n            final String jwtToken = jwtTokenUtils.generateToken(authentication.getPrincipal(), grantedAuthority);\n\n            // return response containing the JWT token\n            return ResponseEntity.ok(new JWTResponse(jwtToken));\n        }\n\n        return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).build();\n\n    }\n\n}\n\n",
    "AcceptedAnswerId": 72598317,
    "AcceptedAnswer": "If you want the AuthenticationManager bean to be in the spring context, you can use the following solution.\n@Bean\npublic AuthenticationManager authenticationManager(AuthenticationConfiguration authenticationConfiguration) throws Exception {\n     return authenticationConfiguration.getAuthenticationManager();\n}\n\nThis approach has solved the problem for me and you can inject AuthenticationManager wherever you need.\n"
}
{
    "Id": 72111416,
    "PostTypeId": 1,
    "Title": "Error inflating class com.google.android.material.button.MaterialButton",
    "Body": "What i'm trying to achieve is having a gridview with some materialButton inside.\nI tried to create the gridview like :\n<GridView\n            android:id=\"@+id/login_gridview_code_input\"\n            android:layout_width=\"match_parent\"\n            android:layout_height=\"wrap_content\"\n            android:numColumns=\"3\"\n            android:horizontalSpacing=\"15dp\"\n            android:verticalSpacing=\"15dp\">\n        \n\nAnd the element to be inflated like:\n\n<androidx.constraintlayout.widget.ConstraintLayout xmlns:android=\"http://schemas.android.com/apk/res/android\"\n    xmlns:app=\"http://schemas.android.com/apk/res-auto\"\n    android:layout_width=\"match_parent\"\n    android:layout_height=\"match_parent\">\n\n        <com.google.android.material.button.MaterialButton\n            android:id=\"@+id/button_code_digit\"\n            style=\"@style/Widget.MaterialComponents.Button.OutlinedButton.Icon\"\n            android:layout_width=\"50dp\"\n            android:layout_height=\"50dp\"\n            android:insetLeft=\"0dp\"\n            android:insetTop=\"0dp\"\n            android:insetRight=\"0dp\"\n            android:insetBottom=\"0dp\"\n            android:padding=\"0dp\"\n            app:iconGravity=\"textStart\"\n            app:iconPadding=\"0dp\"\n            app:iconSize=\"40dp\"\n            app:layout_constraintBottom_toBottomOf=\"parent\"\n            app:layout_constraintEnd_toEndOf=\"parent\"\n            app:layout_constraintStart_toStartOf=\"parent\"\n            app:layout_constraintTop_toTopOf=\"parent\"\n            app:shapeAppearanceOverlay=\"@style/ShapeAppearanceOverlay.pswStorer.Button.Circle\" />\n\n\n\nthe adapter inflates the button :\ninflter = (LayoutInflater.from(applicationContext)); \nview = inflter.inflate(R.layout.button_code, null); // inflate the layout\n\nbut I always receive this stacktrace :\nError inflating class com.google.android.material.button.MaterialButton\nCaused by: java.lang.IllegalArgumentException: The style on this component requires your app theme to be Theme.MaterialComponents (or a descendant).\n\nI checked the appTheme but seems correct to me:\n\n        \n        @color/colorPrimary\n        @color/colorPrimaryDark\n        @color/colorAccent\n        @style/AlertDialogMaterialTheme\n    \n\nAny ideas?\nEDIT: I tried to check and my app has the correct theme\nandroid:theme=\"@style/AppTheme\"\n\nI also changed the theme to Theme.MaterialComponents.DayNight.NoActionBar.Bridge but nothing changed\n",
    "AcceptedAnswerId": 72169923,
    "AcceptedAnswer": "The issue is here.\ninflter = (LayoutInflater.from(applicationContext)); \n\nThe Application context doesn't have your app theme.\nYou have to use a themed context like an Activity.\n"
}
{
    "Id": 72684930,
    "PostTypeId": 1,
    "Title": "Convert List<char[]> into an Array char[] without using System.arraycopy()",
    "Body": "What's a simple way to convert/flatten a List to char[] in Java?\nI know I can do it by iterating the List and using System.arraycopy,  but I'm wondering is there a simpler way to do it using Java 8 streams?\nMaybe something like this, but without having to box the primitive char to Character:\nList listOfCharArrays = ...\n\nCharacter[] charArray =\n    Stream.of(listOfCharArrays )\n        .flatMap(List::stream)\n        .toArray(Character[]::new);\n\n",
    "AcceptedAnswerId": 72685373,
    "AcceptedAnswer": "I can think of only one thing, and that is to use CharBuffer. For efficiency reasons I would always first calculate the right size, and then perform the copy. Any solution that performs multiple copies and/or performs string handling will be inefficient.\nHere's the code. The first line calculates the total size of the array required, and then allocates just enough memory for it. The second line performs the copying using the aforementioned put method. The final line returns the char[] that is backing the CharBuffer.\nCharBuffer fullBuffer = CharBuffer.allocate(\n        listOfCharArrays.stream().mapToInt(array -> array.length).sum());\nlistOfCharArrays.forEach(fullBuffer::put);\nchar[] asCharArray = fullBuffer.array();\n\nOf course, I cannot guarantee that it won't use System.arrayCopy somewhere inside of the CharBuffer#put method. I would strongly expect that it will use System.arrayCopy or similar code internally. That probably goes for most solutions provided here though.\nIt is possible to avoid the first size calculation by using a large enough buffer if you can estimate a maximum size, but it would require an additional copy of the data in the buffer; CharBuffer#array simply returns the correctly sized backing array, which means that the data is copied only once.\n\nYou can also use CharBuffer directly if you want to use object oriented code. Beware that you need to make sure that you flip it after writing to it though, and that CharBuffer is mutable (you can pass copies using the duplicate or asReadOnly methods - the returned instances reference the same buffer, but have independent, mutable \"position\" and \"limit\" fields).\nThe Buffer and Java NIO classes are slightly tricky to understand, but once you do you get great benefits from them, e.g. when using them for CharEncoder or memory mapped files.\n"
}
{
    "Id": 74011238,
    "PostTypeId": 1,
    "Title": "Understanding Java 17 Vector slowness and performance with pow operator",
    "Body": "I have a question relating to the pow() function in Java's 17 new Vector API feature. I'm trying to implement the black scholes formula in a vectorized manner, but I'm having difficulty in obtaining the same performance as the scalar implementation\nThe code is as follows:\n\nI create an array of doubles (currently, just 5.0)\nI loop over elements of that array (different looping syntax for scalar and vector)\nI create DoubleVectors from the double arrays within and do calculations (or just calculations for scalar) I am trying to do e^(value), and I believe that is the problem\n\nHere are some code snippets:\n    public static double[] createArray(int arrayLength)\n    {\n        double[] array0 = new double[arrayLength];\n        for(int i=0;i<arrayLength;i++)\n        {\n            array0[i] = 2.0;\n        }\n        return array0;\n    } \n\n    @Param({\"256000\"})\n    int arraySize;\n    public static final VectorSpecies SPECIES = DoubleVector.SPECIES_PREFERRED;\n    DoubleVector vectorTwo =  DoubleVector.broadcast(SPECIES,2);\n    DoubleVector vectorHundred =  DoubleVector.broadcast(SPECIES,100);\n\n    double[] scalarTwo = new double[]{2,2,2,2};\n    double[] scalarHundred  = new double[]{100,100,100,100};\n\n    @Setup\n    public void Setup()\n    {\n        javaSIMD = new JavaSIMD();\n        javaScalar = new JavaScalar();\n        spotPrices = createArray(arraySize);\n        timeToMaturity = createArray(arraySize);\n        strikePrice = createArray(arraySize);\n        interestRate = createArray(arraySize);\n        volatility = createArray(arraySize);\n        e = new double[arraySize];\n        for(int i=0;i<arraySize;i++)\n        {\n            e[i] = Math.exp(1);\n        }\n        upperBound = SPECIES.loopBound(spotPrices.length);\n    }\n    @Benchmark\n    @BenchmarkMode(Mode.Throughput)\n    @OutputTimeUnit(TimeUnit.MILLISECONDS)\n    public void testVectorPerformance(Blackhole bh) {\n        var upperBound = SPECIES.loopBound(spotPrices.length);\n        for (var i=0;i<upperBound; i+= SPECIES.length())\n        {\n            bh.consume(javaSIMD.calculateBlackScholesSingleCalc(spotPrices,timeToMaturity,strikePrice,\n                    interestRate,volatility,e, i));\n        }\n    }\n\n    @Benchmark\n    @BenchmarkMode(Mode.Throughput)\n    @OutputTimeUnit(TimeUnit.MILLISECONDS)\n    public void testScalarPerformance(Blackhole bh) {\n        for(int i=0;i<arraySize;i++)\n        {\n            bh.consume(javaScalar.calculateBlackScholesSingleCycle(spotPrices,timeToMaturity,strikePrice,\n                    interestRate,volatility, i,normDist));\n        }\n    }\n\n    public DoubleVector calculateBlackScholesSingleCalc(double[] spotPrices, double[] timeToMaturity, double[] strikePrice,\n                                                        double[] interestRate, double[] volatility, double[] e,int i){\n...(skip lines)\n        DoubleVector vSpot = DoubleVector.fromArray(SPECIES, spotPrices, i);\n...(skip lines)\n        DoubleVector powerOperand = vRateScaled\n                .mul(vTime)\n                .neg();\n        DoubleVector call  = (vSpot\n                .mul(CDFVectorizedExcelOptimized(d1,vE)))\n                .sub(vStrike\n                .mul(vE\n                        .pow(powerOperand))\n                .mul(CDFVectorizedExcelOptimized(d2,vE)));\n        return call;\n\nHere are some JMH benchmarks (2 forks,2 warmups,2 iterations) on a Ryzen 5800X using WSL: Overall, it seems ~2x slower vs the scalar version.  I ran a simple time before vs time after separately, of the method without JMH and it seems inline.\nResult \"blackScholes.TestJavaPerf.testScalarPerformance\":\n  0.116 \u00b1(99.9%) 0.002 ops/ms [Average]\n       89873915287      cycles:u                  #    4.238 GHz                      (40.43%)\n      242060738532      instructions:u            #    2.69  insn per cycle   \n\n      \nResult \"blackScholes.TestJavaPerf.testVectorPerformance\":\n  0.071 \u00b1(99.9%) 0.001 ops/ms [Average]\n       90878787665      cycles:u                  #    4.072 GHz                      (39.25%)\n      254117779312      instructions:u            #    2.80  insn per cycle  \n\nI also enabled diagnostic options for the JVM. I see the following:\n\"-XX:+UnlockDiagnosticVMOptions\", \"-XX:+PrintIntrinsics\",\"-XX:+PrintAssembly\"\n\n  0x00007fe451959413:   call   0x00007fe451239f00           ; ImmutableOopMap {rsi=Oop }\n                                                            ;*synchronization entry\n                                                            ; - jdk.incubator.vector.DoubleVector::arrayAddress@-1 (line 3283)\n                                                            ;   {runtime_call counter_overflow Runtime1 stub}\n  0x00007fe451959418:   jmp    0x00007fe4519593ce\n  0x00007fe45195941a:   movabs $0x7fe4519593ee,%r10         ;   {internal_word}\n  0x00007fe451959424:   mov    %r10,0x358(%r15)\n  0x00007fe45195942b:   jmp    0x00007fe451193100           ;   {runtime_call SafepointBlob}\n  0x00007fe451959430:   nop\n  0x00007fe451959431:   nop\n  0x00007fe451959432:   mov    0x3d0(%r15),%rax\n  0x00007fe451959439:   movq   $0x0,0x3d0(%r15)\n  0x00007fe451959444:   movq   $0x0,0x3d8(%r15)\n  0x00007fe45195944f:   add    $0x40,%rsp\n  0x00007fe451959453:   pop    %rbp\n  0x00007fe451959454:   jmp    0x00007fe451231e80           ;   {runtime_call unwind_exception Runtime1 stub}\n  0x00007fe451959459:   hlt    \n   \n[Exception Handler]\n  0x00007fe451959460:   call   0x00007fe451234580           ;   {no_reloc}\n  0x00007fe451959465:   movabs $0x7fe46e76df9a,%rdi         ;   {external_word}\n  0x00007fe45195946f:   and    $0xfffffffffffffff0,%rsp\n  0x00007fe451959473:   call   0x00007fe46e283d40           ;   {runtime_call}\n  0x00007fe451959478:   hlt    \n[Deopt Handler Code]\n  0x00007fe451959479:   movabs $0x7fe451959479,%r10         ;   {section_word}\n  0x00007fe451959483:   push   %r10\n  0x00007fe451959485:   jmp    0x00007fe4511923a0           ;   {runtime_call DeoptimizationBlob}\n  0x00007fe45195948a:   hlt    \n\n--------------------------------------------------------------------------------\n\n============================= C2-compiled nmethod ==============================\n  ** svml call failed for double_pow_32\n                                            @ 3   jdk.internal.misc.Unsafe::loadFence (0 bytes)   (intrinsic)\n                                            @ 3   jdk.internal.misc.Unsafe::loadFence (0 bytes)   (intrinsic)\n                                          @ 2   java.lang.Math::pow (6 bytes)   (intrinsic)\n\nInvestigations/Questions:\n\nIm writing different implementations of the formula, it is not 1:1 - could this be the cause? Looking at the number of instructions according to JMH, there is roughly a 12billion difference in num of instructions. With vectorization the processor runs at a lower clock rate as well.\nIs the choice of input numbers a problem? I've tried i+10/(array.Length) as well.\nIs there a reason I see that the SVML call fail for double_pow_32 ? I don't see this problem for smaller input array sizes BTW\nI changed the pow to mul (for both,obviously the eq is now very different) but it seems to be much faster as a result, results are as expected scalar vs vector\n\nNote: I believe it is using 256bit width vectors (checked during debugging)\n",
    "AcceptedAnswerId": 74017185,
    "AcceptedAnswer": "This might be related to JDK-8262275, Math vector stubs are not called for double64 vectors\n\nFor Double64Vector, the svml math vector stubs intrinsification is failing and they are not being called from jitted code.\nBut we do have svml double64 vectors.\n\nYou might try alternative operations, e.g. instead of vE.pow(powerOperand) with vE being a vector of e, you can use powerOperand.lanewise(VectorOperators.EXP) to perform ex for all lanes.\nKeep in mind that this API is work in progress in incubator state\u2026\n"
}
{
    "Id": 72192789,
    "PostTypeId": 1,
    "Title": "CteInsertStrategy can only be used with Dialects that support CTE that can take UPDATE or DELETE statements as well",
    "Body": "Hibernate 6.0.1 with PostgreSQL JDBC driver 42.3.5 causes the following exception:\njava.lang.UnsupportedOperationException:\nCteInsertStrategy can only be used with Dialects that support CTE that can take UPDATE or DELETE statements as well\nat org.hibernate.query.sqm.mutation.internal.cte.CteInsertStrategy.(CteInsertStrategy.java:123)\nat org.hibernate.query.sqm.mutation.internal.cte.CteInsertStrategy.(CteInsertStrategy.java:107)\nat org.hibernate.dialect.PostgreSQLDialect.getFallbackSqmInsertStrategy(PostgreSQLDialect.java:704)\n...\n\nWhat's wrong and how can I fix the issue?\nMyEntity.java\nimport jakarta.persistence.*;\n\n@Entity\n@Table(name = \"my_entity\")\npublic class MyEntity {\n\n    private Long id;\n\n    @Id\n    @SequenceGenerator(name = \"id_sequence\", sequenceName = \"my_id_sequence\")\n    @GeneratedValue(strategy = GenerationType.AUTO, generator = \"id_sequence\")\n    public Long getId() {\n        return this.id;\n    }\n    public void setId(Long id) {\n        this.id = id;\n    }\n\n}\n\nMyTest.java\nimport static org.junit.Assert.assertNotNull;\n\nimport org.hibernate.*;\nimport org.hibernate.cfg.*;\nimport org.junit.*;\n\npublic class MyTest {\n\n    private static Configuration configuration;\n    private static SessionFactory sessionFactory;\n\n    @BeforeClass\n    public static void setUpBeforeClass() throws Exception {\n        configuration = new Configuration().configure();\n        sessionFactory = configuration.buildSessionFactory();\n    }\n\n    @AfterClass\n    public static void tearDownAfterClass() throws Exception {\n        sessionFactory.close();\n    }\n\n    private Session session;\n\n    @Before\n    public void setUp() throws Exception {\n        session = sessionFactory.openSession();\n    }\n\n    @After\n    public void tearDown() throws Exception {\n        session.close();\n    }\n\n    @Test\n    public void test() {\n        Transaction transaction = session.beginTransaction();\n        MyEntity entity = new MyEntity();\n        session.persist(entity);\n        assertNotNull(entity.getId());\n        transaction.commit();\n    }\n\n}\n\nhibernate.cfg.xml\n\n\n\n  \n    org.postgresql.Driver\n    org.hibernate.dialect.PostgreSQLDialect  \n    jdbc:postgresql://localhost:5432/mydb\n    update\n    postgres\n    false\n    1\n    30\n    120\n    100\n    \n  \n\n\nbuild.gradle\nplugins {\n    id 'java-library'\n}\n\nrepositories {\n    mavenCentral()\n}\n\next {\n    hibernateVersion = '6.0.1.Final'\n}\n\ndependencies {\n    implementation 'org.postgresql:postgresql:42.3.5'\n    implementation 'org.hibernate.orm:hibernate-c3p0:' + hibernateVersion\n    implementation 'org.hibernate.orm:hibernate-core:' + hibernateVersion\n    testImplementation 'junit:junit:4.13.2'\n}\n\nSee the full source code here.\n",
    "AcceptedAnswerId": 72207378,
    "AcceptedAnswer": "The configuration property use_jdbc_metadata_defaults must be true for Hibernate to detect the correct version of the PostgreSQL dialect.\nRemoving this line\nfalse\n\nfrom hibernate.cfg.xml resolves the issue.\n(Thanks to Christian at Hibernate Zulip channel for sorting this out.)\n"
}
{
    "Id": 72712390,
    "PostTypeId": 1,
    "Title": "Defining additional placeholder/property only in beans.xml",
    "Body": "I have a list of strings, that i would like to define in beans.xml.\n\n    #{ T(com.myapp.longname.verylong.WelcomeController).RED_FRACTION }\n    #{ T(com.myapp.longname.verylong.WelcomeController).BLUE_FRACTION }\n    #{ T(${my.prefix}).GREEN_FRACTION }\n\n\nIt works fine, but each time I need to write the full qualified constant's name com.myapp.longname.verylong.WelcomeController. I would like to write it only once. One solution I have found is to replace it with a property like my.prefix so I can write only my short prefix instead of the real full path. But then I will need to pollute the global \"namespace\" with property that is only needed once. I would like to define a placeholder only for this list or at least only for this beans.xml file. I have already tried to define a property directly in beans.xml with PropertyPlaceholderConfigurer and it works, but then all my inital properties are not available anymore.\nSo how can I avoid to  writing com.myapp.longname.verylong.WelcomeController each time in a list as a prefix and only define it once? Ideally something like\n\n    \n    #{ T(${my.prefix}).RED_FRACTION }\n    #{ T(${my.prefix}).BLUE_FRACTION }\n    #{ T(${my.prefix}).GREEN_FRACTION }\n\n\n",
    "AcceptedAnswerId": 72776113,
    "AcceptedAnswer": "Please give a try on this\n\n\n\n    com.myapp.longname.verylong.WelcomeController\n\n\n\n    #{ T(${shorthandHelperConstants['my.prefix']}).RED_FRACTION }\n    #{ T(${shorthandHelperConstants['my.prefix']}).BLUE_FRACTION }\n    #{ T(${shorthandHelperConstants['my.prefix']}).GREEN_FRACTION }\n\n\n"
}
{
    "Id": 74356407,
    "PostTypeId": 1,
    "Title": "How to get the date and time in format 2022-10-03T19:45:47.844Z in Java",
    "Body": "I need the current system date and time in 2022-10-03T19:45:47.844Z format in a java class.\nI tried using the zoneddatetime and simple date format but couldn't get the write syntax or code from online. I'm beginner in Java, any help is appreciated.\nThanks.\n",
    "AcceptedAnswerId": 74356572,
    "AcceptedAnswer": "I hope this solves your problem:\nimport java.time.ZoneId;\nimport java.time.ZonedDateTime;\nimport java.time.format.DateTimeFormatter;\n\npublic class Main {\n    public static void main(String[] args) {\n        ZonedDateTime zdt = ZonedDateTime.now(ZoneId.of(\"UTC\"));\n        DateTimeFormatter formatter =\n                DateTimeFormatter.ofPattern(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\");\n        System.out.println(zdt.format(formatter));\n    }\n}\n\n"
}
{
    "Id": 72989618,
    "PostTypeId": 1,
    "Title": "Does the order of if else matter for performance? e.g. put the most likely condition in the front is better",
    "Body": "I'm trying to measure if the order of if else affects performance.\nFor example, if\nif (condition == more likely condition) {}\nelse /** condition == rare condition **/ {}\n\nis faster than\nif (condition == rare condition) {}\nelse /** condition == more likely condition **/ {}\n\nI think maybe JIT should be able to optimise it no matter which order I put it? Couldn't find any documentation on this though.\nI tried to test it out myself with following benchmark. Based on it, I don't see strong evidence that the order matters. Because if it does, I think the throughput when bias=0.9 (probability of if (zeroOrOne == 1) is true is 0.9) should be higher than when bias=0.1 (else probability is 0.9).\npublic class BranchBench {\n    @Param({ \"0.02\", \"0.1\", \"0.9\", \"0.98\", })\n    private double bias;\n\n    @Param(\"10000\")\n    private int count;\n\n    private final List randomZeroOnes = new ArrayList(count);\n\n    @Setup\n    public void setup() {\n        Random r = new Random(12345);\n\n        for (int c = 0; c < count; c++) {\n            byte zeroOrOne = (byte) (c < (bias * count) ? 1 : 0);\n            randomZeroOnes.add(zeroOrOne);\n        }\n        Collections.shuffle(randomZeroOnes, r);\n    }\n\n    @Benchmark\n    public int static_ID_ifElse() {\n        int i = 0;\n        for (final Byte zeroOrOne : randomZeroOnes) {\n            if (zeroOrOne == 1) {\n                i++;\n            } else {\n                i--;\n            }\n        }\n        return i;\n    }\n}\n\nBenchmark                     (bias)  (count)   Mode  Cnt    Score   Error   Units\nBranchBench.static_ID_ifElse    0.02    10000  thrpt   15  137.409 \u00b1 1.376  ops/ms\nBranchBench.static_ID_ifElse     0.1    10000  thrpt   15  129.277 \u00b1 1.552  ops/ms\nBranchBench.static_ID_ifElse     0.9    10000  thrpt   15  125.640 \u00b1 5.858  ops/ms\nBranchBench.static_ID_ifElse    0.98    10000  thrpt   15  137.427 \u00b1 2.396  ops/ms\n\n",
    "AcceptedAnswerId": 72989924,
    "AcceptedAnswer": "On modern processors I don't think the order of your conditionals really matter that much anymore. As part of the instruction pipeline, processors will do what is called branch prediction; where it guesses which condition will be true and pre-loads the instructions into the pipeline.\nThese days, processors guess correctly >90% of the time, so any hand-written conditional tweaking is less important.\nThere are quite a lot of literature on branch prediction:\nhttps://dzone.com/articles/branch-prediction-in-java\nhttps://www.baeldung.com/java-branch-prediction\n"
}
{
    "Id": 72434319,
    "PostTypeId": 1,
    "Title": "entityManagerFactory bean not configured issue with hibernate 6.0.2.Final and spring boot 2.7.0",
    "Body": "so recently i thought of upgrading few dependency of my spring boot project project\nspecifically these components\n\njakarat ee 9\nspring boot 2.7\nhibernate 6.0.2.Final\n\nafter doing this all updates and code refraction: updating imports javax to jakarta, and for few hibernate annotations\nI removed the old hibernate from my local .m2 repository and run this command this mvn clean install test package\nand started the project in intellij and it gave be below error:\n16:15:42.410 [Thread-0] DEBUG org.springframework.boot.devtools.restart.classloader.RestartClassLoader - Created RestartClassLoader org.springframework.boot.devtools.restart.classloader.RestartClassLoader@429054cc\n\n  .   ____          _            __ _ _\n /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\n( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\n \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\n  '  |____| .__|_| |_|_| |_\\__, | / / / /\n =========|_|==============|___/=/_/_/_/\n :: Spring Boot ::                (v2.7.0)\n\n2022-05-30 16:15:42.787  INFO 99522 --- [  restartedMain] com.zee.oms.order.Order                  : Starting Order using Java 17.0.2 on ZL-BLR-MAC170.local with PID 99522 (/Users/manish.prasad/Documents/ZEE-Services/github/zee5-order/target/classes started by manish.prasad in /Users/manish.prasad/Documents/ZEE-Services/github/zee5-order)\n2022-05-30 16:15:42.787 DEBUG 99522 --- [  restartedMain] com.zee.oms.order.Order                  : Running with Spring Boot v2.7.0, Spring v5.3.20\n2022-05-30 16:15:42.787  INFO 99522 --- [  restartedMain] com.zee.oms.order.Order                  : No active profile set, falling back to 1 default profile: \"default\"\n2022-05-30 16:15:42.818  INFO 99522 --- [  restartedMain] .e.DevToolsPropertyDefaultsPostProcessor : Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable\n2022-05-30 16:15:42.818  INFO 99522 --- [  restartedMain] .e.DevToolsPropertyDefaultsPostProcessor : For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'\n2022-05-30 16:15:43.347  INFO 99522 --- [  restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.\n2022-05-30 16:15:43.433  INFO 99522 --- [  restartedMain] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 81 ms. Found 4 JPA repository interfaces.\n2022-05-30 16:15:43.862  INFO 99522 --- [  restartedMain] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)\n2022-05-30 16:15:43.868  INFO 99522 --- [  restartedMain] o.apache.catalina.core.StandardService   : Starting service [Tomcat]\n2022-05-30 16:15:43.868  INFO 99522 --- [  restartedMain] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.63]\n2022-05-30 16:15:43.902  INFO 99522 --- [  restartedMain] o.a.c.c.C.[.[localhost].[/order-srv]     : Initializing Spring embedded WebApplicationContext\n2022-05-30 16:15:43.902  INFO 99522 --- [  restartedMain] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 1084 ms\n2022-05-30 16:15:44.059  WARN 99522 --- [  restartedMain] ConfigServletWebServerApplicationContext : Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'orderController': Unsatisfied dependency expressed through field 'orderService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'orderServiceImpl': Unsatisfied dependency expressed through field 'orderRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'orderRepository' defined in com.zee.oms.order.repository.OrderRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Cannot create inner bean '(inner bean)#14203bc' of type [org.springframework.orm.jpa.SharedEntityManagerCreator] while setting bean property 'entityManager'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name '(inner bean)#14203bc': Cannot resolve reference to bean 'entityManagerFactory' while setting constructor argument; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'entityManagerFactory' available\n2022-05-30 16:15:44.061  INFO 99522 --- [  restartedMain] o.apache.catalina.core.StandardService   : Stopping service [Tomcat]\n2022-05-30 16:15:44.072  INFO 99522 --- [  restartedMain] ConditionEvaluationReportLoggingListener : \n\nError starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.\n2022-05-30 16:15:44.080 ERROR 99522 --- [  restartedMain] o.s.b.d.LoggingFailureAnalysisReporter   : \n\n***************************\nAPPLICATION FAILED TO START\n***************************\n\nDescription:\n\nField orderRepository in com.oms.order.service.impl.OrderServiceImpl required a bean named 'entityManagerFactory' that could not be found.\n\nThe injection point has the following annotations:\n    - @org.springframework.beans.factory.annotation.Autowired(required=true)\n\n\nAction:\n\nConsider defining a bean named 'entityManagerFactory' in your configuration.\n\n\nProcess finished with exit code 0 \n\nthis is my pom:\n\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0\n                             http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    4.0.0\n    \n        org.springframework.boot\n        spring-boot-starter-parent\n        2.7.0\n        \n    \n\n    com.zee\n    zee5-order\n    0.0.1-SNAPSHOT\n    order\n    Spring Boot project for order-service\n    \n        17\n        6.0.2.Final\n    \n\n    \n\n        \n            org.springframework.boot\n            spring-boot-starter-web\n        \n\n        \n            org.springframework.boot\n            spring-boot-devtools\n            runtime\n            true\n        \n        \n        \n            org.springframework.boot\n            spring-boot-starter-actuator\n        \n\n        \n            org.projectlombok\n            lombok\n            provided\n        \n        \n            org.springframework.boot\n            spring-boot-starter-test\n            test\n        \n        \n        \n            org.mockito\n            mockito-all\n            1.10.19\n            test\n        \n        \n            org.postgresql\n            postgresql\n            runtime\n        \n        \n            org.springframework.boot\n            spring-boot-starter-data-jpa\n        \n        \n            org.hibernate\n            hibernate-validator\n            7.0.4.Final\n        \n        \n            jakarta.validation\n            jakarta.validation-api\n            3.0.2\n        \n        \n            org.springdoc\n            springdoc-openapi-ui\n            1.6.8\n        \n        \n            org.springdoc\n            springdoc-openapi-data-rest\n            1.6.8\n        \n        \n            org.springdoc\n            springdoc-openapi-webmvc-core\n            1.6.8\n        \n        \n            org.springdoc\n            springdoc-openapi-webflux-ui\n            1.6.8\n        \n        \n            org.flywaydb\n            flyway-core\n            8.5.10\n        \n        \n            com.common-utility\n            common-utility\n            1.0\n        \n        \n            com.amazonaws\n            aws-java-sdk-secretsmanager\n            1.12.220\n        \n        \n            com.h2database\n            h2\n            2.1.212\n            test\n        \n        \n            com.vladmihalcea\n            hibernate-types-60\n            2.16.2\n        \n    \n\n    \n        \n            \n                org.springframework.boot\n                spring-boot-maven-plugin\n                \n                    \n                        \n                            org.projectlombok\n                            lombok\n                        \n                    \n                \n            \n        \n    \n\n\n\nattaching few screen shots for the added dependencies:\nspring and spring boot dependencies\njakarta dependencies\nany idea or solution if anybody have also upgraded to this version and able to run the project successfully.\nalso iam confused why javax-persistence is still there and not replaced when jakarata-persistence is already added/there.\n",
    "AcceptedAnswerId": 72434705,
    "AcceptedAnswer": "Hibernate 6 (and Hibernate Validator 7 as well) are JakartaEE implementations of respectivly the Jakarta Persistence API and Jakarta Validation API. None of which are currently supported by Spring nor Spring Boot.\nSupport for JakartaEE is coming in Spring Framework 6 and Spring Boot 3 which are scheduled for release later this year.\nFor now keep using the JavaEE versions. In your case you need to do 2 things\n\nRemove the hibernate.version property\nReplace the hibernate-validator and jakarta-validation-api with the spring-boot-starter-validation dependency.\n\nWhen you apply both fixes and later this year upgrade to Spring Boot 3 you will get the proper versions which are compatible.\n"
}
{
    "Id": 73377190,
    "PostTypeId": 1,
    "Title": "Bytecode transforming record class to be mutable",
    "Body": "I just saw that EBean does bytecode transformation of record class files in a way that feels odd to me and I seek an answer about whether this is legal from a JVM point of view.\nApparently, it is possible to have a class file, where the class extends java.lang.Record and defines record component attributes (so it's a \"record\" like javac would create it), but with the following additional \"features\" which javac would not allow:\n\nMake fields for record components non-final\nAdd additional fields that are not set through the canonical constructor, nor exposed through record component attributes\n\nTo me, this seems illegal and I would have expected a JVM verification error. I would like to know if this is something that is \"supported\", which I can build upon, or if the lack of verification is a JVM bug. Are records just a Java language feature without JVM support?! I read that final fields of records are \"truly final\" and can't be changed even through reflection and assumed there must be special JVM support that makes sure records match the Java language semantics...\n",
    "AcceptedAnswerId": 73390758,
    "AcceptedAnswer": "Your question posits a false dichotomy.  Records are a language feature, with some degree of JVM support (primarily for reflection), but that doesn't mean that the JVM will (or even can) enforce all the requirements on records that the language requires.  (Gaps like this are inevitable, as the JVM is a more general computing substrate, and which services other languages besides Java; for example, the JVM permits methods to be overloaded on return type, but the language does not.)\nThat said, the behavior you describe is a pretty serious party foul, and those who engage in it should be shamed out of the community.  (It is also possible they are doing so out of ignorance, in which case they might be educable.)  Most likely, these people think they are being \"clever\" in subverting rules they don't like, but in the process, poisoning the well by promoting behaviors that users may find astonishing.\nEDIT\nThe author of the transformer posted some further context here about what they were trying to accomplish.  I'll give them credit for making a good faith effort to conform with the semantics of records, but it undermines the final field semantics, and only appears to work for records that do not customize the constructor, accessors, equals, or hashCode methods.  This describes a lot of records, but not all.  This is a good cautionary tale; even when trying to preserve the semantics of a class while transforming it, it is easy to make questionable assumptions about what the class does or does not do that can get in the way.\nThe author waves away the concern about the final field semantics as \"not likely to cause a problem.\"  But this is not the bar.  The language provides certain semantics for records.  This transformation undermines those semantics, and yet still tells the user they are records.  Even if they are \"minor\" and \"unlikely\", you are breaking the semantics that the Java language promises.  \"99% compatible\" rounds to zero in this case.  So I stand by my assertion that this framework is taking inappropriate liberties with the language semantics.  They may have been well-intentioned, they may have tried hard to not break things, but break things they did.\n"
}
{
    "Id": 73035944,
    "PostTypeId": 1,
    "Title": "Best way to retrieve K largest elements from large unsorted arrays?",
    "Body": "I recently had a coding test during an interview. I was told:\n\nThere is a large unsorted array of one million ints. User wants to retrieve K largest elements. What algorithm would you implement?\n\nDuring this, I was strongly hinted that I needed to sort the array.\nSo, I suggested to use built-in sort() or maybe a custom implementation if performance really mattered. I was then told that using a Collection or array to store the k largest and for-loop it is possible to achieve approximately O(N), in hindsight, I think it's O(N*k) because each iteration needs to compare to the K sized array to find the smallest element to replace, while the need to sort the array would cause the code to be at least O(N log N).\nI then reviewed this link on SO that suggests priority queue of K numbers, removing the smallest number every time a larger element is found, which would also give O(N log N). Write a program to find 100 largest numbers out of an array of 1 billion numbers\nIs the for-loop method bad? How should I justify pros/cons of using the for-loop or the priorityqueue/sorting methods? I'm thinking that if the array is already sorted, it could help by not needing to iterate through the whole array again, i.e. if some other method of retrieval is called on the sorted array, it should be constant time. Is there some performance factor when running the actual code that I didn't consider when theorizing pseudocode?\n",
    "AcceptedAnswerId": 73036179,
    "AcceptedAnswer": "Another way of solving this is using Quickselect. This should give you a total average time complexity of O(n). Consider this:\n\nFind the kth largest number x using Quickselect (O(n))\nIterate through the array again (or just through the right-side partition) (O(n)) and save all elements \u2265 x\nReturn your saved elements\n\n(If there are repeated elements, you can avoid them by keeping count of how many duplicates of x you need to add to the result.)\nThe difference between your problem and the one in the SO question you linked to is that you have only one million elements, so they can definitely be kept in memory to allow normal use of Quickselect.\n"
}
{
    "Id": 73299265,
    "PostTypeId": 1,
    "Title": "Java Stream Collect() classifier can't detect type",
    "Body": "I have the following code reading lines from a text file:\ntry (BufferedReader br = new BufferedReader(new InputStreamReader(Uio.decodeFrom(url)))) {\n        return br.lines()\n                .parallel()\n                .map(s -> s.split(\"\\\\s+\")) // split by whitespace\n                .collect(\n                        Collectors.groupingByConcurrent(\n                                arr -> arr[0], // String 1\n                                Collectors.groupingByConcurrent(\n                                        arr -> arr[arr.length-1], // String 2\n                                        Collectors.counting()\n                                )\n                        )\n                );\n    } catch (IOException e) {\n        throw new UncheckedIOException(e);\n    }\n\nThe text file has data like\nString1     ... cols      ... String2\nstring1data ... otherdata ... string2data\n...\n\nAnd I'm trying to group by String1 and String2 and get their counts. Then end result should be a Map>. However, with the code above, the compiler is saying that the collect() returns a  ConcurrentMap >.\nWhy are the keys not Strings?\n",
    "AcceptedAnswerId": 73299327,
    "AcceptedAnswer": "I can duplicate this error message, but the replacement of String with Object in the error message appears to be a red herring.  The real problem is that Java's generics are invariant.\nIf the call to collect is returning a ConcurrentMap>, that doesn't match Map>, even though a ConcurrentMap is a Map.  The inner Map type must match exactly without a wildcard and bounds.\nIf you introduce an upper-bounded wildcard to the return type, it will compile without error.  Have it return the type Map>, so that the inner ConcurrentMap will match.\nA return type of Map> will also work.\nIt's unclear why String wasn't captured until the generics invariant issue was worked out.  Just a guess: the compiler didn't capture String yet, because it found the invariant generics issue first.  Once the invariant generics issue is resolved, it compiles without error, implying String does get inferred.\n"
}
{
    "Id": 73480342,
    "PostTypeId": 1,
    "Title": "Manifest for java:8-jre-alpine not found: manifest unknown: manifest unknown",
    "Body": "I'm facing this error while building on Ubuntu server:\n\nStep 1/10 : FROM java:8-jre-alpine\nERROR: Service 'XXXX' failed to build: manifest for java:8-jre-alpine not found: manifest unknown: manifest unknown\n\nIt was working fine since months, suddenly now its not working. What could be the reason?\n",
    "AcceptedAnswerId": 73490179,
    "AcceptedAnswer": "I change java:8 to openjdk:8 and it works.\n"
}
{
    "Id": 74377433,
    "PostTypeId": 1,
    "Title": "What is the difference between \".\" and \"/\" in java classname?",
    "Body": "I'm new to java. When I try to learn Maven in 5 minutes, I found that this command\njava -cp target/my-app-1.0-SNAPSHOT.jar com.mycompany.app.App\n\nworked the same way as\njava -cp target/my-app-1.0-SNAPSHOT.jar com/mycompany/app/App\n\nIt drives me crazy because the last argument in the second command is actually a path. What is the difference between \".\" and \"/\" in java classname?\nI have looked up some articles but still don't get it.\n",
    "AcceptedAnswerId": 74377496,
    "AcceptedAnswer": "This is an implementation detail leaking out.  Class names in the language are dot-separated; class names in the classfile format are slash-separated.  (https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-4.html#jvms-4.2.)  For the most part, internal names are not visible to users, but they do leak in some circumstances.  Many tools that deal with classfiles will convert from the external (dotted) to internal (slashed) name using something like replace('.', '/'), which has the effect that internal names are also accepted by the tool.  That's what's going on here.\n"
}
{
    "Id": 74500889,
    "PostTypeId": 1,
    "Title": "Serve response of an HTTP request after receiving another request",
    "Body": "My use case is to serve response of an HTTP request after receiving another request from separate server.\n\n\nI want to do this best possible way keeping scaling in mind.\nWe are using Golang 1.19 with Gin Framework.\nServer will have multiple pods thus channels will not work.\nThere will be timeouts for all request making initial request timed out after 60 seconds.\n\nMy current solution is to use a shared cache where each pod will keep checking the cache. I believe, I can optimize this with channels where rather than checking in cache one by one, system periodically checks for any completed response.\nI would also like to know how it could have been achieved in other programming languages.\nPS: This is design based query, I have some reputation here to share bounty thus asking here. Please feel free to edit if question is not clear.\n",
    "AcceptedAnswerId": 74503580,
    "AcceptedAnswer": "tl;dr\nproblem description\nSo assuming your server application called server_app for instance, has 3 pods:\n     +---------------------+\n     |  server_app_service |\n     +---------------------+\n     |  server_app_pod_a   |\n     |  server_app_pod_b   |\n     |  server_app_pod_c   |\n     +---------------------+\n\nyour service receives a request called \"request A\", and decides to pass it to server_app_pod_a. Now your server_app_pod_a forwards the request to some gateway, and waits for some sort of notification, to continue the processing of client's response. And as you already know, there's no assurance that when gateway does the request B, the service passes it to server_app_pod_a again. And even if it did so, your application's state management would become a difficult task to do.\nMessaging\nAs you might've noticed, I bolded the word \"notification\" in the past paragraph, that's because if you really think about it, the request \"B\" looks more like a notification with some message rather than a request for some resource. So my number 1 choice would be a message queue like kafka (there are plenty of those, again, as you know). And the idea is, if you could define an algorithm to calculate unique keys for your requests, you can expect the resulting notifications in your exact same pod. This way, state management would be much simpler, and also, the chance of getting the notification in the same pod would be much higher (this depends on many factors of course, like the state of the message queue). Taking a look at your questions:\n\n\nI want to do this best possible way keeping scaling in mind.\n\n\nSure thing, you can use these message queues like kafka, to achieve scaling and fewer data loss, both for the message queue and your application.\n\n\nThere will be timeouts for all request making initial request timed out after 60 seconds.\n\n\nThis one depends on how you manage timeouts in your codebase, using contexts would be a good idea.\n\nI would also like to know how it could have been achieved in other programming languages.\n\nUsing message queues is a general idea, which would be applicable to almost any programming language, but depending on the programming paradigms of a language, and language-specific libraries and tools, there might be some other approaches to this problem. For instance in Scala, if you use some specific tool called akka (which provides actor model programming paradigm), you can use something so called akka-cluster-sharding, to handle this problem. And the idea is pretty simple, we know that there must be some sort of superviser, which knows the exact location and state of its own subscribers. So when it receives some message, it just knows where and which actor (we're talking about actor model programming) to forward the request to. In other words, it can be used to share state between actors spawned on a cluster, either on the same machine or not. But as a personal preference, I wouldn't go for language-specific communications, and would stick to general ideas, because of the problems it might cause in the future.\nWrap-up\nLong enough explanations :). Just to make some sense of what I'm talking about, let's follow up the exact same scenario, with a difference in communication model:\n\nClient sends request \"A\" to server_app service.\nThe service, choses one of the pods (server_app_pod_b for instance) to handle the request.\nThe pod then tries to define some key for the request, and passes it to the gateway, along with the request, and waits for a message with the key, to be published in the queue.\nThe gateway does what it's supposed to, and sends a message with the key, to the message queue.\nThe exact same pod serer_app_pod_b receives the message with the key, fetches the data of the message, and continues to process the client's request.\n\nThere are probably other approaches available to address this issue, but this is what I would go for. Hope that it helps!\n"
}
{
    "Id": 73707768,
    "PostTypeId": 1,
    "Title": "upgrade to SnakeYaml 1.31 in spring-boot-starter-parent 2.7.3",
    "Body": "Have springboot project in which wanted to either exclude snakeyaml 1.30 or upgrade it 1.31 inorder to avoid fortify issue reporting\nwith snakeyaml 1.30 version there is security vulnerability\n\n        org.springframework.boot\n        spring-boot-starter-parent\n        2.7.3\n\n\nBelow is seen on the effective pom.xml of the project\n  \n          org.yaml\n          snakeyaml\n          1.30\n          compile\n        \n\nIs there any possibility to upgrade as the remediation says to upgrade the version to snakeyaml 1.31 ?\nRef : https://security.snyk.io/vuln/SNYK-JAVA-ORGYAML-2806360\n",
    "AcceptedAnswerId": 73708060,
    "AcceptedAnswer": "You can always change the version number through the  block in your pom.xml:\n\n    \n\n      \n        org.yaml\n        snakeyaml\n        1.31\n      \n\n   \n\n\nThis will automatically change the version your project will use. You can test this by running mvn dependency:tree afterwards. It should only show version 1.31 of snakeyaml.\nImportant remark: Make sure that you remove this block as soon as you integrate the next version of Spring Boot as it will very likely contain the increased version. Otherwise you may downgrade the version unintentionally after future updates.\nPlease also note that there may be incompatibilities between certain lib versions and Spring Boot, hence it may not always be possible to update the version this way.\n"
}
{
    "Id": 73749383,
    "PostTypeId": 1,
    "Title": "Why does LambdaMetafactory fail when using a custom functional interface (but Function works fine)?",
    "Body": "Given:\nimport java.lang.invoke.LambdaMetafactory;\nimport java.lang.invoke.MethodHandle;\nimport java.lang.invoke.MethodHandles;\nimport java.lang.invoke.MethodType;\nimport java.util.function.Function;\n\nclass Testcase\n{\n    @FunctionalInterface\n    public interface MyBuilder1\n    {\n        R apply(String message);\n    }\n\n    @FunctionalInterface\n    public interface MyBuilder2\n    {\n        R apply(Object message);\n    }\n\n    public static void main(String[] args) throws Throwable\n    {\n        Class clazz = IllegalArgumentException.class;\n\n        MethodHandles.Lookup lookup = MethodHandles.lookup();\n        MethodHandle mh = lookup.findConstructor(clazz, MethodType.methodType(void.class, String.class));\n        MethodHandle myFunctionConstructor = LambdaMetafactory.metafactory(\n            lookup,\n            \"apply\",\n            MethodType.methodType(Function.class),\n            mh.type().erase(),\n            mh,\n            mh.type()\n        ).getTarget();\n\n        MethodHandle myBuilderConstructor1 = LambdaMetafactory.metafactory(\n            lookup,\n            \"apply\",\n            MethodType.methodType(MyBuilder1.class),\n            mh.type().erase(),\n            mh,\n            mh.type()\n        ).getTarget();\n\n        MethodHandle myBuilderConstructor2 = LambdaMetafactory.metafactory(\n            lookup,\n            \"apply\",\n            MethodType.methodType(MyBuilder2.class),\n            mh.type().erase(),\n            mh,\n            mh.type()\n        ).getTarget();\n\n        @SuppressWarnings(\"unchecked\")\n        Function functionFactory =\n            (Function) myFunctionConstructor.invokeExact();\n\n        @SuppressWarnings(\"unchecked\")\n        MyBuilder1 myBuilder1Factory =\n            (MyBuilder1) myBuilderConstructor1.invokeExact();\n\n        @SuppressWarnings(\"unchecked\")\n        MyBuilder2 myBuilder2Factory =\n            (MyBuilder2) myBuilderConstructor2.invokeExact();\n\n        IllegalArgumentException runFunction = functionFactory.apply(\"test\");\n//      IllegalArgumentException runBuilder1 = myBuilder1Factory.apply(\"test\");\n        IllegalArgumentException runBuilder2 = myBuilder2Factory.apply(\"test\");\n\n    }\n}\n\nWhy do runFunction and runBuilder2 work while runBuilder1 throws the following exception?\n\njava.lang.AbstractMethodError: Receiver class Testcase$$Lambda$233/0x0000000800d21d88 does not define or inherit an implementation of the resolved method 'abstract java.lang.Object apply(java.lang.String)' of interface MyBuilder1.\n\nGiven that the IllegalArgumentException constructor takes a String parameter, not an Object, shouldn't the JVM accept runBuilder1 and complain about the parameter type of the other two?\n",
    "AcceptedAnswerId": 73749785,
    "AcceptedAnswer": "Your MyBuilder1 has a functional method\nR apply(String message);\n\nwhose erased type is\nObject apply(String message);\n\nIn other words, unlike Function or MyBuilder2, the erased parameter type is String, rather than Object. The erase() method of MethodType just replaces all reference types with Object, which was handy for Function and MyBuilder2 but is not suitable for MyBuilder1 anymore. There is no similarly simple method for non-trivial types. You have to include type transformation code specifically for your case (unless you want to lookup the interface method via Reflection).\nFor example, we can just change the return type to Object and keep the parameter types:\nclass Testcase\n{\n    @FunctionalInterface\n    public interface MyBuilder1\n    {\n        R apply(String message);\n    }\n\n    public static void main(String[] args) throws Throwable\n    {\n        Class clazz = IllegalArgumentException.class;\n\n        MethodHandles.Lookup lookup = MethodHandles.lookup();\n        MethodHandle mh = lookup.findConstructor(clazz,\n            MethodType.methodType(void.class, String.class));\n\n        MethodHandle myBuilderConstructor1 = LambdaMetafactory.metafactory(\n            lookup,\n            \"apply\",\n            MethodType.methodType(MyBuilder1.class),\n            mh.type().changeReturnType(Object.class), // instead of erase()\n            mh,\n            mh.type()\n        ).getTarget();\n\n        @SuppressWarnings(\"unchecked\")\n        MyBuilder1 myBuilder1Factory =\n            (MyBuilder1) myBuilderConstructor1.invokeExact();\n\n        IllegalArgumentException runBuilder1 = myBuilder1Factory.apply(\"test\");\n\n        runBuilder1.printStackTrace();\n    }\n\n\nRegarding your last question, the erased type is the type to implement, whereas the last parameter to metafactory determines the intended type, i.e. derived from the Generic interface type. The generated code may have type casts from the erased type to this type when necessary. Since this type matches the constructor signature in all cases, all variants can invoke the constructor.\n"
}
{
    "Id": 73492733,
    "PostTypeId": 1,
    "Title": "How to properly spy on an input stream",
    "Body": "My understanding is, that Mockito.spy(object) wraps a proxy around an existing object. This proxy delegates the method calls to the spied object and allows further verification (So it's different to a mock which provides no implementation).\nI want to spy on an input stream to ensure the close/read methods are properly called. But the following (simple) spy code doesn't work:\n// Create a spy input stream object\nString testData = \"Hello\";\nInputStream inputStream = new ByteArrayInputStream(testData.getBytes(StandardCharsets.UTF_8));\nInputStream spiedInputStream = spy(inputStream);\nassertEquals(testData.getBytes(StandardCharsets.UTF_8).length, spiedInputStream.available()); // Fails: Expected 5, Actual 0\n\n// Read the input stream\nbyte [] readData = new byte[testData.length()];\nassertEquals(testData.getBytes(StandardCharsets.UTF_8).length, spiedInputStream.read(readData)); // Fails: Expected 5, Actual -1\nassertEquals(testData, new String(readData, StandardCharsets.UTF_8)); // Fails, readData is fully zeroed\n\nSo what am I doing wrong (Ubuntu 22.04, Java 17, Mockito 4.7.0)\n",
    "AcceptedAnswerId": 73496579,
    "AcceptedAnswer": "The behaviour you described is reproducible only on the following configuration:\n\nmockito-core\nJDK 17+\n\nThe simplest way for you to proceed is to switch to mockito-inline.\nIn case of mockito-core and JDK 17, the fields in the spy are not properly initialized:\npublic ByteArrayInputStream(byte buf[]) {\n    this.buf = buf;\n    this.pos = 0;\n    this.count = buf.length;\n}\n\nThe count variable should be equal to buf.length, but in the spy it is set to 0.\nThe problem stems from the fact that subclass mock maker is fundamentally limited on JDK17, mockito team seems to be aware of the problem and even considers switching to inline mock maker as default on JDK 17:\nSwitch the default mockmaker to the inline mockmaker on JDK 17+ #2589:\n\nTLDR: more and more use cases are broken (by default) with Mockito and JDK 17. That's because the subclass mockmaker runs into fundamental limitations on JDK 17, but the inline mockmaker works as expected.\n\n"
}
{
    "Id": 72446186,
    "PostTypeId": 1,
    "Title": "Why doesn't instanceof pattern matching work with else if in this particular case?",
    "Body": "The following snippet does not compile on javac, version 17 (Temurin)\nclass Instanceof {\n    static void doesNotWork(Object o) {\n        if (o == null) {\n            throw new Error();\n        } else if (!(o instanceof String s)) {\n            throw new Error();\n        }   \n        System.out.println(s); // error here\n    }\n}\n\nIt generates this error: cannot find symbol\ncannot find symbol\nsymbol:   variable s\nlocation: class Instanceof\n\nHowever, the following (in my opinion) equivalent variations work:\nWith an explicit else block:\nstatic void doesWork(Object o) {\n    if (o == null) {\n        throw new Error();\n    } else if (!(o instanceof String s)) {\n        throw new Error();\n    } else {\n        System.out.println(s);\n    }\n}\n\nOr without an else:\nstatic void doesWork(Object o) {\n    if (o == null) {\n        throw new Error();\n    }\n    if (!(o instanceof String s)) {\n        throw new Error();\n    }\n    System.out.println(s);\n}\n\nOr with a single if:\nstatic void doesWork(Object o) {\n    if (o == null || !(o instanceof String s)) {\n        throw new Error();\n    }\n    System.out.println(s);\n}\n\nIs this a bug in javac?\nIf yes, should I report this, but where exactly?\n",
    "AcceptedAnswerId": 72446910,
    "AcceptedAnswer": "The doesNotWork case is equivalent to this:\nstatic void doesNotWork(Object o) {\n    if (o == null) {\n        throw new Error();\n    } else {\n        if (!(o instanceof String s)) {\n            throw new Error();\n        }\n    }\n    System.out.println(s); // error here\n}\n\nThis makes it more obvious that String s is inside a block bounded by curly brackets and is therefore out of scope in the same way that this doesn't work either:\nstatic void doesNotWork(Object o) {\n    {\n        if (!(o instanceof String s)) {\n            throw new Error();\n        }\n    }\n    System.out.println(s); // error here\n}\n\nIn the case where it does work, with the println inside the else, it's equivalent to this:\nif (o == null) {\n    throw new Error();\n} else {\n    if (!(o instanceof String s)) {\n        throw new Error();\n    } else {\n        System.out.println(s);\n    }\n}\n\nWhich shows the println being in scope.\n"
}
{
    "Id": 72453890,
    "PostTypeId": 1,
    "Title": "Why am I seeing a one-off error with Math.pow(11, 16)?",
    "Body": "I have to compute 11^16 for a project at my Uni. Somehow Math.pow(11,16) computes a solution exactly 1 less than WolframAlpha or my other computation method.\n\nMy code is:\npublic class Test {\n    public static void main(String args[]) {\n        long a = 11;\n        long b = 16;\n        System.out.println(\"\" + (long)Math.pow(a, b));\n        System.out.println(\"\" + squareAndMultiply(a, b));\n    }\n\n    public static long squareAndMultiply(long b, long e){\n        long result = 1;\n        long sq = b;\n        while(e>0){\n            if(e%2==1){\n                result *= sq;\n            }\n            sq = sq * sq;\n            e /= 2;\n        }\n        return result;\n    }\n}\n\nThe result from the code is:\nmath.pow(11,16):\n\n45949729863572160\n\nsquareAndMultiply(11,16):\n\n45949729863572161\n\n",
    "AcceptedAnswerId": 72454107,
    "AcceptedAnswer": "With floating-point arithmetic, you're in that gray zone where the precision of a double is less than that of a long (even if the range of a double is much bigger).\nA double has 53 bits of precision, whereas a long can devote all 64 bits to precision.  When you're dealing with values as high as 1116, the difference between one double value and the next one up becomes noticeable.\nJava has a built-in method Math.ulp (\"unit in last place\") that effectively gives the difference in values between consecutive representable values.  (There's a double version and a float version.)\nSystem.out.println(Math.ulp(Math.pow(11, 16)));\n\n\n8.0\n\nThat means the least possible double value greater than 45949729863572160 is 45949729863572168.\nThe long value 45949729863572161 is correct, but the value you're getting with Math.pow, 45949729863572160, is as close as a double can get to the true answer, given its limited (but still large) precision.\nCasting to a long makes no difference, because Math.pow already computes the result as a double, so the answer is off by one already.  Your long method of computing the value is correct.\nIf you're computing values that would overflow long, then instead of using double, you can use BigDecimal, which has its own pow method to retain a precision of 1.0.\n"
}
{
    "Id": 74264850,
    "PostTypeId": 1,
    "Title": "LocalBroadcastManager is now deprecated, how to send data from service to activity?",
    "Body": "I have a service that needs to notify the main activity. I use LocalBroadcastManager, and it works fine, but LocalBroadcastManager has been deprecated.\nThis is my actual code in the service:\npublic void onTokenRefresh() {\n      \n    /* build the intent */\n    Intent intent = new Intent(ACTION_TOKENREFRESHED);\n    intent.putExtra(\"token\", \"xxx\");\n    \n    /* send the data to registered receivers */\n    try{\n      LocalBroadcastManager.getInstance(this).sendBroadcast(intent);\n    } catch (Throwable e){\n      //no exception handling\n    }  \n  \n  }\n\nIn the main activity, I get informed of the notification like this :\ncontext.registerReceiver(broadcastReceiver, intentFilter);\n\nWhat can I use now to remove the deprecated warning? All examples I found regarding sending data from service to activity use LocalBroadcastManager. Can someone give me a workable model for migrating my existing code?\nNOTE\nIn my example, The onTokenRefresh is called from inside a background thread. That is very important because it means I can simultaneously receive several onTokenRefresh, and I must forward all these tokens to the activity. Most of the offered solutions use live data but make a declaration like :\npublic static final MutableLiveData tokenLiveData = new MutableLiveData();\n\nBackground Thread1:\ntokenLiveData.postValue(Token1);\n\nBackground Thread2 (at same time):\ntokenLiveData.postValue(Token2);\n\nWill forward ALL tokens received simultaneously to the main activity that observes the tokenLiveData? Will the main activity always receive for sure token1 and token2?\n",
    "AcceptedAnswerId": 74545041,
    "AcceptedAnswer": "Make a service class and define a LiveData to replace the LocalBroadcastManager responsibility like so:\n//This service sends an example token ten times to its observers\npublic class MyService extends Service {\n    //Define a LiveData to observe in activity\n    public static final MutableLiveData tokenLiveData = new MutableLiveData();\n\n    @Override\n    public IBinder onBind(Intent intent) {\n        return null;\n    }\n\n    @Override\n    public int onStartCommand(Intent intent, int flags, int startId) {\n        //You need a separate thread if you don not use IntentService\n\n        Thread thread1 = new Thread() {\n            public void run() {\n                for (int i = 0; i < 10; i++) {\n                    //send random strings az an example token ten times.\n                    //You can remove this loop and replace it with your logic\n                    String token1 = UUID.randomUUID().toString();\n                    new Handler(Looper.getMainLooper()).post(() -> sendTokenToObserver(\"Thread1: \" + token1));\n\n                }\n            }\n        };\n        thread1.start();\n\n        Thread thread2 = new Thread() {\n            public void run() {\n                for (int i = 0; i < 10; i++) {\n                    String token2 = UUID.randomUUID().toString();\n                    new Handler(Looper.getMainLooper()).post(() -> sendTokenToObserver(\"Thread2: \" + token2));\n                }\n            }\n        };\n        thread2.start();\n        return START_STICKY;\n    }\n\n    //Post token to observers\n    public void sendTokenToObserver(String token) {\n        tokenLiveData.setValue(token);\n\n    }\n}\n\nThen start the service in the activity and observe the LiveData like below:\npublic class MainActivity extends AppCompatActivity {\n\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n        setContentView(R.layout.activity_main);\n\n        //You can observe the emitted token here and do what you want(Show in view or notification). \n        //I've just logged it to the console.\n        startService(new Intent(this,MyService.class));\n        MyService.tokenLiveData.observe(this, token -> Log.d(\"token\", token));\n    }\n}\n\nYou can also start the service from another activity and observe it in the MainActivity;\n"
}
{
    "Id": 72040055,
    "PostTypeId": 1,
    "Title": "Wildfly org.jboss.nio -> FileNotFoundException: Invalid file path with Windows Java JDK 11.0.15+10",
    "Body": "Since the update to Eclipse Tamurin JDK 11.0.15+10 we notice a problem as soon a HTTP request reaches Wildfly 20.0.1.Final. The same behaviour exsists in Wildfly 26.1.0.Final This only happens with the JDK Windows version, the Linux JDK works fine.\nAs it is an \"Invalid file path\" error, an OS dependent BUG seems possible.\nUntil now SAP Machine is the only JDK that does not encounter this failure.\nI'm still not sure if this is a JDK or a Wildfly problem...\nYou can check that when opening the Wildfly Management Interface.\nERROR [io.undertow.request] (External Management Request Threads -- 1) UT005071: Undertow request failed HttpServerExchange{ GET /management}: java.io.IOError: java.io.FileNotFoundException: Invalid file path\n    at org.jboss.xnio@3.8.1.Final//org.xnio.channels.Channels$4.run(Channels.java:1103)\n    at org.jboss.xnio@3.8.1.Final//org.xnio.channels.Channels$4.run(Channels.java:1093)\n    at java.base/java.security.AccessController.doPrivileged(Native Method)\n    at org.jboss.xnio@3.8.1.Final//org.xnio.channels.Channels.(Channels.java:1093)\n    at io.undertow.core@2.1.3.Final//io.undertow.io.UndertowOutputStream.write(UndertowOutputStream.java:231)\n    at io.undertow.core@2.1.3.Final//io.undertow.io.BlockingSenderImpl.writeBuffer(BlockingSenderImpl.java:245)\n    at io.undertow.core@2.1.3.Final//io.undertow.io.BlockingSenderImpl.writeBuffer(BlockingSenderImpl.java:238)\n    at io.undertow.core@2.1.3.Final//io.undertow.io.BlockingSenderImpl.send(BlockingSenderImpl.java:75)\n    at io.undertow.core@2.1.3.Final//io.undertow.io.BlockingSenderImpl.send(BlockingSenderImpl.java:107)\n    at org.jboss.as.domain-http-interface@12.0.3.Final//org.jboss.as.domain.http.server.DomainUtil.writeResponse(DomainUtil.java:89)\n    at org.jboss.as.domain-http-interface@12.0.3.Final//org.jboss.as.domain.http.server.DomainApiHandler$1.doSendResponse(DomainApiHandler.java:177)\n    at org.jboss.as.domain-http-interface@12.0.3.Final//org.jboss.as.domain.http.server.ResponseCallback.sendResponse(ResponseCallback.java:32)\n    at org.jboss.as.domain-http-interface@12.0.3.Final//org.jboss.as.domain.http.server.DomainApiHandler.handleRequest(DomainApiHandler.java:232)\n    at io.undertow.core@2.1.3.Final//io.undertow.server.handlers.encoding.EncodingHandler.handleRequest(EncodingHandler.java:72)\n    at org.jboss.as.domain-http-interface@12.0.3.Final//org.jboss.as.domain.http.server.DomainApiCheckHandler.handleRequest(DomainApiCheckHandler.java:91)\n    at org.jboss.as.domain-http-interface@12.0.3.Final//org.jboss.as.domain.http.server.security.ElytronIdentityHandler.lambda$handleRequest$0(ElytronIdentityHandler.java:62)\n    at org.wildfly.security.elytron-private@1.12.1.Final//org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:328)\n    at org.wildfly.security.elytron-private@1.12.1.Final//org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:285)\n    at org.jboss.as.controller@12.0.3.Final//org.jboss.as.controller.AccessAuditContext.doAs(AccessAuditContext.java:254)\n    at org.jboss.as.controller@12.0.3.Final//org.jboss.as.controller.AccessAuditContext.doAs(AccessAuditContext.java:225)\n    at org.jboss.as.domain-http-interface@12.0.3.Final//org.jboss.as.domain.http.server.security.ElytronIdentityHandler.handleRequest(ElytronIdentityHandler.java:61)\n    at io.undertow.core@2.1.3.Final//io.undertow.server.handlers.BlockingHandler.handleRequest(BlockingHandler.java:56)\n    at io.undertow.core@2.1.3.Final//io.undertow.server.Connectors.executeRootHandler(Connectors.java:370)\n    at io.undertow.core@2.1.3.Final//io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830)\n    at org.jboss.threads@2.3.3.Final//org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35)\n    at org.jboss.threads@2.3.3.Final//org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:1982)\n    at org.jboss.threads@2.3.3.Final//org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1486)\n    at org.jboss.threads@2.3.3.Final//org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1348)\n    at java.base/java.lang.Thread.run(Thread.java:829)\n    at org.jboss.threads@2.3.3.Final//org.jboss.threads.JBossThread.run(JBossThread.java:485)\nCaused by: java.io.FileNotFoundException: Invalid file path\n    at java.base/java.io.FileOutputStream.(FileOutputStream.java:231)\n    at java.base/java.io.FileOutputStream.(FileOutputStream.java:126)\n    at org.jboss.xnio@3.8.1.Final//org.xnio.channels.Channels$4.run(Channels.java:1098)\n    ... 29 more\n\n\n\n\n\nJDK\nWorks with Wildfly\n\n\n\n\nEclipse Tamurin\nno\n\n\nAmazon Coretto\nno\n\n\nAzul Zulu\nno\n\n\nBellsoft\nno\n\n\nOracle OpenJDK\nno\n\n\nOracle JDK\nno\n\n\nSAP Machine\nyes\n\n\n\n",
    "AcceptedAnswerId": 72465068,
    "AcceptedAnswer": "This is an issue in the JDK. You can wait for JDK 11.0.16 or downgrade to a lower version like JDK 11.0.14.\n"
}
{
    "Id": 73878386,
    "PostTypeId": 1,
    "Title": "Lock-free array expansion in Java",
    "Body": "I have an array to which many threads are writing. However each thread has a pre-assigned range of indices which it may write to. Further, nothing will be reading from the array until all threads are done.\nSo far, so thread-safe. The problem arises when I need to expand the array, by which of course I mean swap it out for a larger array which copies the first. This is only done occasionally (similar to an ArrayList).\nCurrently I'm acquiring a lock for every single write to the array. Even though there is no need to lock in order to keep the array consistent, I'm having to lock in case the array is currently being copied/swapped.\nAs there are very many writes I don't want to require a lock for them. I'm okay with a solution which requires locking for writer threads only while the array is being copied and swapped, as this is infrequent.\nBut I can't just impose write locks only when the copy/swap is in progress, as threads may already be committing writes to the old array.\nI think I need some variety of barrier which waits for all writes to complete, then pauses the threads while I copy/swap the array. But CyclicBarrier would require me to know exactly how many threads are currently active, which is non-trivial and possibly susceptible to edge-cases in which   the barrier ends up waiting forever, or lowers itself too early. In particular I'm not sure how I'd deal with a new thread coming in while the barrier is already up, or how to deal with threads which are currently polling a job queue, so will never decrement the barrier count while there are no new jobs.\nI may have to implement something which (atomically) counts active threads and tries to pre-empt all the edge cases.\nBut this may well be a \"solved\" problem that I don't know about, so I'm hoping there may be a simpler (therefore better) solution than the Cyclic barrier/thread counting. Ideally one which uses an existing utility class.\nBy the way, I've considered CopyOnWriteArray. This is no use to me, as it copies for every write (a lot of them), not just array expansions.\nAlso note the structure written to pretty much has to be an array, or array-based.\nThanks\n",
    "AcceptedAnswerId": 73878933,
    "AcceptedAnswer": "Although it's technically not correct, you can probably use a ReadWriteLock. The threads that are writing to a single portion all use a read lock (this is the technically incorrect part, they're not reading...), and the resize uses a write lock. That way, all writing threads can work together. A resize has to wait until all portioned writes are done, which then blocks the entire array. Once that is done, all portioned writes can continue.\n"
}
{
    "Id": 74910066,
    "PostTypeId": 1,
    "Title": "@EnableGlobalMethodSecurity is deprecated in the new spring boot 3.0",
    "Body": "I use Spring Boot 3.0, and when I work on security configuration, I get a warning that the @EnableGlobalMethodSecurity is deprecated.\n@Configuration\n@EnableWebSecurity\n@AllArgsConstructor\n@EnableGlobalMethodSecurity(prePostEnabled = true)\npublic class SecurityConfig {\n\nWith what do I replace can replace @EnableGlobalMethodSecurity in Spring boot 3.0?\n",
    "AcceptedAnswerId": 74910079,
    "AcceptedAnswer": "You can use now:\n@EnableMethodSecurity\n\nCheck the documentation\nNote that you can avoid using prePostEnabled = true, because by default is true.\nboolean prePostEnabled() default true;\nboolean jsr250Enabled() default false;\nboolean proxyTargetClass() default false;\n\n"
}
{
    "Id": 73864285,
    "PostTypeId": 1,
    "Title": "What's the point of a write-only collection?",
    "Body": " makes for a read-only collection\n makes for a write-only collection\nI somehow get why use a read-only collection,for instance to use it in a multithreaded environment (any other cases?)\nBut why use a write-only collection? What's the point if you cannot read from it and use its values at some point? I know that you can get an Object out of it but that defies type safety.\nEdit:\n@Thomas the linked question (Difference between  and  in Java) does show how to make a write only collection but does not answer 'why' would you need one in the first place.So it's not a duplicate\n",
    "AcceptedAnswerId": 73864712,
    "AcceptedAnswer": "Note that \"write only collection\" depends on the point of view.\nLets write a method that adds a bunch of numbers to a collection:\npublic static void addNumbers(List target, int count) {\n    for (int i = 0; i < count; i++) {\n        target.add(i);\n    }\n}\n\nFor this method the list target is a write only list: the method can only add numbers to it, it can not use the values that it added to the list.\nOn the other side there is the caller:\npublic static void caller() {\n    List myList = new ArrayList();\n    addNumbers(myList, 10);\n    double sum = 0;\n    for (Number n: myList) {\n        sum += n.doubleValue();\n    }\n    System.out.println(sum);\n}\n\nThis method works with a specific list (myList) and therefore can read the values that addNumbers stuffed into it.\nFor this method the list is not a write only list, for this method it is an ordinary list.\n"
}
{
    "Id": 72506950,
    "PostTypeId": 1,
    "Title": "Flutter Error : Could not resolve all artifacts for configuration ':image_picker_android:debugUnitTestRuntimeClasspath'",
    "Body": "The application which I am working on is debugging fine in emulator or in mobiles but when I try to build the apk it gives the following Error:\nBuilding without sound null safety\nFor more information see https://dart.dev/null-safety/unsound-null-safety\n\nRunning Gradle task 'assembleRelease'...                        \n\n\nFAILURE: Build failed with an exception.\n\n* What went wrong:\nExecution failed for task ':app:lintVitalRelease'.\n> Could not resolve all artifacts for configuration ':image_picker_android:debugUnitTestRuntimeClasspath'.\n   > Failed to transform bcprov-jdk15on-1.68.jar (org.bouncycastle:bcprov-jdk15on:1.68) to match attributes {artifactType=processed-jar, org.gradle.category=library, org.gradle.libraryelements=jar, org.gradle.status=release, org.gradle.usage=java-runtime}.\n      > Execution failed for JetifyTransform: /home/cicada/.gradle/caches/modules-2/files-2.1/org.bouncycastle/bcprov-jdk15on/1.68/46a080368d38b428d237a59458f9bc915222894d/bcprov-jdk15on-1.68.jar.\n         > Failed to transform '/home/cicada/.gradle/caches/modules-2/files-2.1/org.bouncycastle/bcprov-jdk15on/1.68/46a080368d38b428d237a59458f9bc915222894d/bcprov-jdk15on-1.68.jar' using Jetifier. Reason: IllegalArgumentException, message: Unsupported class file major version 59. (Run with --stacktrace for more details.)\n           Suggestions:\n            - Check out existing issues at https://issuetracker.google.com/issues?q=componentid:460323&s=modified_time:desc, it's possible that this issue has already been filed there.\n            - If this issue has not been filed, please report it at https://issuetracker.google.com/issues/new?component=460323 (run with --stacktrace and provide a stack trace if possible).\n\n* Try:\nRun with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.\n\n* Get more help at https://help.gradle.org\n\nBUILD FAILED in 19s\nRunning Gradle task 'assembleRelease'...                           20.7s\nGradle task assembleRelease failed with exit code 1\nProcess finished with exit code 1\n\n",
    "AcceptedAnswerId": 72518904,
    "AcceptedAnswer": "This was my solution which I recommend to be the 2nd option:\nSolution 1:\nI added following lines in the android directory of app level build.gradle i.e android/app/build.gradle of my  project.\n   lintOptions {\n        disable 'InvalidPackage'\n        disable \"Instantiatable\"\n        checkReleaseBuilds false\n        abortOnError false\n    }\n\nAnd every thing started to work fine.\nCheck out my Gradle File\nSolution 2:\nHowever I suggest you people by the solution of @Vinadon and agree with the comment of @raiderOne:\n1st recommended solution should be:\nThe issues lies in image_picker_android being updated to gradle 7.1.2. See their changelog. Following an issue on GitHub you have to update your gradle version like so:\nIn android/gradle/wrapper/gradle-wrapper.properties update your distributionUrl to\ndistributionUrl=https\\://services.gradle.org/distributions/gradle-7.2-all.zip\n\nand in android/build.gradle change the gradle version to at least 7.1.2\nclasspath 'com.android.tools.build:gradle:7.1.2\n\nIn @Vinadon case, He had to update his Android Studio for a newer Java version too.\nUpvote Vindadon answer below for this solution. Thanks!\n"
}
{
    "Id": 74916107,
    "PostTypeId": 1,
    "Title": "ConcurrentHashMap computeIfAbsent tell if first time or not",
    "Body": "It's complicated for me to articulate a proper title for this. But an example should make it far simpler. Suppose I have this:\nfinal class Cache {\n   private static final ConcurrentHashMap> CACHE = ...\n\n   static List byName(String name) {\n      return CACHE.computeIfAbsent(name, x -> // some expensive operation)\n   }\n\n}\n\nThe idea is probably trivial, this acts as a LoadingCache, much like guava or caffeine (in reality it is more complicated, but that is irrelevant to the question).\nI would like to be able to tell if this was the first load into the CACHE, or it was a read of an existing mapping. Currently, I do this:\nfinal class Cache {\n   private static final ConcurrentHashMap> CACHE = ...\n\n   static List byName(String name) {\n      boolean b[] = new boolean[1];\n      List result = CACHE.computeIfAbsent(name, x -> {\n            b[0] = true;\n            // some expensive operation)\n      });\n\n      if(b[0]) {\n         // first load into the cache, do X\n      } else {\n         // do Y\n      }\n\n      return result;\n   }\n\n}\n\nThis works, but I am afraid I am missing something that ConcurrentHashMap can offer for me that would allow me to do the same. Thank you.\n",
    "AcceptedAnswerId": 74919640,
    "AcceptedAnswer": "If you want to avoid your single-element array to pass data out of the lambda (which I would rather do with an AtomicReference or AtomicBoolean), you could use a stateful callback object. It doesn't change the behavior or design of your code, but could be considered a little bit cleaner and more OOP-y.\nclass LoadingAction {\n  private boolean called = false;\n\n  public V load(final K key) {\n    called = true;\n    // load data\n    return ...;\n  }\n\n  public void executePostLoad() {\n    if (called) {\n      // loaded into cache, do X\n    } else {\n      // do Y\n    }\n  }\n}\n\nfinal class Cache {\n   private static final ConcurrentHashMap> CACHE = new ConcurrentHashMap();\n\n   static List byName(String name) {\n      final LoadingAction> loader = new LoadingAction();\n      final List result = CACHE.computeIfAbsent(name, loader::load);\n\n      loader.executePostLoad();\n\n      return result;\n   }\n\n}\n\nOr turn it inside-out:\nclass Loader {\n  private boolean called = false;\n\n  public V load(final Map map, final K key) {\n    final V result = map.computeIfAbsent(key, this::load);\n    this.executePostLoad();\n    return result;\n  }\n\n  private V load(final K key) {\n    called = true;\n    // load data\n    return ...;\n  }\n\n  private void executePostLoad() {\n    if (called) {\n      // loaded into cache, do X\n    } else {\n      // do Y\n    }\n  }\n}\n\nfinal class Cache {\n   private static final ConcurrentHashMap> CACHE = new ConcurrentHashMap();\n\n   static List byName(String name) {\n      final Loader> loader = new Loader();\n      return loader.load(CACHE, name);\n   }\n\n}\n\nConstruction and loading could be encapsulated in a static method:\nclass Loader {\n  private boolean called = false;\n\n  public static  V load(final Map map, final K key) {\n      final Loader loader = new Loader();\n      return loader.doLoad(map, key);\n  }\n\n  private V doLoad(final Map map, final K key) {\n    final V result = map.computeIfAbsent(key, this::load);\n    this.executePostLoad();\n    return result;\n  }\n\n  private V load(final K key) {\n    called = true;\n    // load data\n    return ...;\n  }\n\n  private void executePostLoad() {\n    if (called) {\n      // loaded into cache, do X\n    } else {\n      // do Y\n    }\n  }\n}\n\nfinal class Cache {\n   private static final ConcurrentHashMap> CACHE = new ConcurrentHashMap();\n\n   static List byName(String name) {\n      return Loader.load(CACHE, name);\n   }\n\n}\n\n"
}
{
    "Id": 72615382,
    "PostTypeId": 1,
    "Title": "Cannot resolve method 'of' in 'ImmutableList",
    "Body": "Debugging Details: Following tutorial to migrate from Android Billing 4.0 to 5.0 https://developer.android.com/google/play/billing/migrate-gpblv5, specifically in the section \"Showing products available to buy\"\nThe 'of' in ImmutableList is flagged red and the error in Android Studio is\n\nCannot resolve method 'of' in 'ImmutableList'\"\n\nHow can I resolve?\nMinimal reproducible code to get the Compilation Error:\nQueryProductDetailsParams queryProductDetailsParams =\n        QueryProductDetailsParams.newBuilder()\n                .setProductList(\n                        ImmutableList.of(\n                                QueryProductDetailsParams.Product.newBuilder()\n                                        .setProductId(PREMIUM_MONTHLY_VERSION_ID)\n                                        .setProductType(BillingClient.ProductType.SUBS)\n                                        .build()))\n                .build();\n\nHere are the specific details:\nDesired Behaviour: Code compiles fine.\nSpecific Problem or Error: Compilation error.\n",
    "AcceptedAnswerId": 72616597,
    "AcceptedAnswer": "ImmutableList, in context of 'a tutorial for Android Billing 5.0', is clearly referring to guava's ImmutableList - the full name of this type is com.google.common.collect.ImmutableList.\nThis class is baked into android as far as I remember (but not in plain java). It has always had an of method. Thus:\n\nMost likely you have some type in your package or source file called ImmutableList. Don't do that. Rename yours to something else.\nAlternatively, check your imports - you imported something else also named ImmutableList. You should have an import com.google.common.collect.ImmutableList; at the top, or possibly import com.google.common.collect.*; - if that is missing, consider adding it.\n\nAndroid doesn't \"have\" java 9 or java 11 - you just need java1 for this, the point is: It is not a java core class at all - only stuff that starts with java.* is. However, android is not (quite) java.\nI'm just not sure: I thought guava (the library that contains ImmutableList) is available by default on android, which means your IDE\"s setup is broken. Or perhaps it is not, in which case you need to add the 'guava' dependency. How? Well, that depends - I think android builds are based on gradle, which would mean: Look it up on search.maven.org and follow the gradle instructions.\n"
}
{
    "Id": 73817318,
    "PostTypeId": 1,
    "Title": "SSE core task scheduler startup problem in eclipse",
    "Body": "Whenever I'm launching my eclipse IDE with my project workspace, there is one popup window showing some internal error with the task scheduler. I'm attaching the picture of that popup window here.\n\nMy project is all in java language and also uses spring boot in it.\nThe error says something like\nAn internal error occurred during: \"SSE core task scheduler startup\"\nSorry I'm not able to add a direct image for this as Stack overflow is not allowing me to do that.\n",
    "AcceptedAnswerId": 73970552,
    "AcceptedAnswer": "I had the same problem today.\nUpdating Eclipse solved it for me:\nHelp -> About Eclipse -> Installation Details -> Update\n"
}
{
    "Id": 72703351,
    "PostTypeId": 1,
    "Title": "Java 19 Pattern Matching Compilation Error: \"the switch statement does not cover all possible input values\"",
    "Body": "Using the Brian Goetz article: https://www.infoq.com/articles/data-oriented-programming-java/\nsealed interface Opt { \n    record Some(T value) implements Opt { }\n    record None() implements Opt { }\n}\n\nThis compiles and runs as expected. The exhaustive pattern matching works:\nOpt optValue = doCalc(value);\nswitch (optValue) {\n  case Opt.Some some -> System.out.printf(\"got string: %s%n\", some.value());\n  case Opt.None none -> System.out.printf(\"got none%n\");\n};\n\nThis variation where I use the new Record patterns preview feature, breaks the exhaustive pattern matching, where this won't compile without adding a default case statement:\nOpt optValue = doCalc(value);\nswitch (optValue) {\n    case Opt.Some(String v) -> System.out.printf(\"got string: %s%n\", v);\n    case Opt.None none -> System.out.printf(\"got none%n\");\n};\n\nWith OpenJDK Runtime Environment (build 19-ea+32-2220), I get the compilation error: the switch statement does not cover all possible input values.\nWhen I add a default case statement, and the program works, but I don't get exhaustive pattern matching.\nIf I remove the record pattern matching, the program works.\nIf I create a variation of this without generics, that uses sealed classes, exhaustive pattern matching, and record patterns, it works.\nHowever, it seems the combination of record patterns, generics and exhaustive pattern matching does not work.\n",
    "AcceptedAnswerId": 73977879,
    "AcceptedAnswer": "This is a known bug in Java 19. This was confirmed by Brian Goetz himself on the amber-dev mailing list.\nUPDATE: This issue is completely fixed in Java 20.\n"
}
{
    "Id": 73999566,
    "PostTypeId": 1,
    "Title": "How to construct PickVisualMediaRequest for ActivityResultLauncher",
    "Body": "I am trying to use the Activity Result APIs to handle the picking of a single photo for an app I am developing. I am trying to use one of the predefined contracts to keep things simple. So, I am attempting to use the ActivityResultContracts.PickVisualMedia() contract.\nI am setting the Activity Result Launcher up as follows:\nprivate ActivityResultLauncher pickVisualMediaActivityResultLauncher;\n\n@Override\nprotected void onCreate(@Nullable Bundle savedInstanceState) {\n    pickVisualMediaActivityResultLauncher = registerForActivityResult(\n            new ActivityResultContracts.PickVisualMedia(),\n            this::onPickVisualMediaActivityResult\n    );\n}\n\nAnd I am attempting to construct a PickVisualMediaRequest and launch the Activity Result Launcher here:\nprivate void onSelectNewPhotoButtonClick() {\n    PickVisualMediaRequest request = new PickVisualMediaRequest.Builder()\n            .setMediaType(new ActivityResultContracts.PickVisualMedia.ImageOnly())\n            .build();\n    pickVisualMediaActivityResultLauncher.launch(request);\n}\n\nIssue is that Android Studio is complaining about ActivityResultContracts.PickVisualMedia.ImageOnly() not having proper visibility to be used, even though it is a valid VisualMediaType and the docs imply that it should be used this way:\n\nI can't really find any code samples on this particular scenario. Am I missing something? Does the API have a visibility defect or am I just dumb today?\n",
    "AcceptedAnswerId": 74000104,
    "AcceptedAnswer": "After some help from CommonsWare, I determined that setMediaType() accepts a Kotlin object instance. So, the above bad function I had should be:\nprivate void onSelectNewPhotoButtonClick() {\n    ActivityResultContracts.PickVisualMedia.VisualMediaType mediaType = (ActivityResultContracts.PickVisualMedia.VisualMediaType) ActivityResultContracts.PickVisualMedia.ImageOnly.INSTANCE;\n    PickVisualMediaRequest request = new PickVisualMediaRequest.Builder()\n            .setMediaType(mediaType)\n            .build();\n    pickVisualMediaActivityResultLauncher.launch(request);\n}\n\nAndroid Studio complains about the type casting, but the code does compile and work as expected. Very bizarre.\n\n\n"
}
{
    "Id": 72520506,
    "PostTypeId": 1,
    "Title": "How does spring create proxy for a final class?",
    "Body": "Maybe I have some outdated knowledge but it is the same as described here\nhttps://stackoverflow.com/a/2657465/2674303\nBut now I noticed that this example works without any exceptions:\n@Service\n@EnableScheduling\npublic final class MyService {\n    @PostConstruct\n    public void init(){\n        System.out.println(\"MyService started\");\n    }\n    @Scheduled(fixedDelay= 1000)\n    public void scheduleCall() {\n        System.out.println(\"scheduleCall\");    \n \n  }\n}\n\nCould you pease provide how does it work ?\n",
    "AcceptedAnswerId": 72624573,
    "AcceptedAnswer": "@Scheduled annotation does not require proxy creation. The mechanism is different. After bean initialization Spring called post-processor ScheduledAnnotationBeanPostProcessor. Post processor searches for all methods annotated with @Scheduled and registers them to TaskScheduller for execution. Method execution will be performed via reflection.\nSee ScheduledAnnotationBeanPostProcessor source code.\n@Scheduled\n\nProcessing of @Scheduled annotations is performed by registering a\nScheduledAnnotationBeanPostProcessor. This can be done manually or,\nmore conveniently, through the task:annotation-driven/ XML element\nor @EnableScheduling annotation.\n\nScheduledAnnotationBeanPostProcessor\n\nBean post-processor that registers methods annotated with @Scheduled\nto be invoked by a TaskScheduler according to the \"fixedRate\",\n\"fixedDelay\", or \"cron\" expression provided via the annotation. This\npost-processor is automatically registered by Spring's\ntask:annotation-driven XML element, and also by the\n@EnableScheduling annotation.\nAutodetects any SchedulingConfigurer instances in the container,\nallowing for customization of the scheduler to be used or for\nfine-grained control over task registration (e.g. registration of\nTrigger tasks). See the @EnableScheduling javadocs for complete usage\ndetails.\n\n@PostConstruct also implemented via post-processor InitDestroyAnnotationBeanPostProcessor when dependency injection performed for bean, method which marked @PostConstruct will be executed thru reflection without proxy.\nSee InitDestroyAnnotationBeanPostProcessor source code\nSummary:\nIn your example, Spring will create bean without proxy.\nIn case you will add a proxy-specific annotation, for example, @Transactional you will get an exception that proxy can not be created due to final class java.lang.IllegalArgumentException: Cannot subclass final class com.test.services.MyService\n@Service\n@EnableScheduling\npublic final class MyService {\n    @PostConstruct\n    public void init(){\n        System.out.println(\"MyService started\");\n    }\n    @Scheduled(fixedDelay= 1000)\n    @Transactional\n    public void scheduleCall() {\n        System.out.println(\"scheduleCall\");\n\n    }\n}\n\nBut the current problem you also can solve to force use JDK dynamic proxy. We need to create an interface for class and set property spring.aop.proxy-target-class = false according to Proxying mechanisms\n"
}
{
    "Id": 74240190,
    "PostTypeId": 1,
    "Title": "Numeric comparing option for Java Collator",
    "Body": "Problem:\nLet's say we have the following list of strings {\"Test1.txt\", \"Test2.txt\", \"Test11.txt\", \"Test22.txt\"}, sorting them using String::compareTo or Collator::compare would result in following order:\nTest1.txt\nTest2.txt\nTest22.txt\nTest3.txt\n\nWhich is inconvenient(arguably), while a more human-friendly outcome is:\nTest1.txt\nTest2.txt\nTest3.txt\nTest22.txt\n\nTo resolve this issues we can write our own compare method which is numeric sensitive.\nBut what if we want numeric sensitive sort as well as the benefit of using existing implementation of Collator (or to avoid implementing one) for internationalization?\nIs there a right way to handle this? or maybe a reliable library that addresses this problem?\nOther Languages:\nIn Javascript world the Intl.Collator's constructors accepts a CollatorOption which allows you to set configs to achieve such functionality and more:\nconst usCollator = Intl.Collator(\"us\", { numeric: true });\nconst list = [\"Test1.txt\", \"Test2.txt\", \"Test3.txt\", \"Test22.txt\"];\nlist.sort(usCollator.compare);\nconsole.log(list);\n\n",
    "AcceptedAnswerId": 74302933,
    "AcceptedAnswer": "You can use alphanumeric-comparator, which is available in Maven.\n"
}
{
    "Id": 74337681,
    "PostTypeId": 1,
    "Title": "Is the permits relationship of Java Sealed classes/interfaces transitive",
    "Body": "If I read the JLS \u00a78.1.6 and \u00a79.1.4 correctly, the classes that a sealed class/interface permits, are just the direct subclasses/interfaces.\nTo illustrate this, consider the following example:\npublic sealed interface I1 permits I2, C, D { /*...*/ }\npublic final class C implements I1 { /*...*/ }\npublic final class D implements I1 { /*...*/ }\n\npublic sealed interface I2 extends I1 permits E, F { /*...*/ }\npublic final class E implements I2 { /*...*/ }\npublic final class F implements I2 { /*...*/ }\n\nIf I understand the specification correctly, I1 obviously permits C and D but not E and F (via the extends hierarchy of I2 from I1). Is this correct?\nThe reason I'm asking is what patterns are allowed for switch expressions of the following kind:\nI1 i1 = // ...\nreturn switch (i1) {\n    case C c -> \"1\";\n    case D d -> \"2\";\n    case E e -> \"3\"; // Can we match over E?\n    case F f -> \"4\"; // Can we match over F?\n    default  -> \"5\";\n};\n\n",
    "AcceptedAnswerId": 74339207,
    "AcceptedAnswer": "\nI1 obviously permits C and D but not E and F. Is this correct?\n\nMore accurately, you can say that C and D are in the set of permitted direct subclasses of I1, which is a term defined in section 9.1.4. The JLS doesn't really define what \"I1 permits C and D\" means though.\nAs for your switch expression, the reason why it works is two-fold. First, you are able to write a type pattern in a switch label if the type of the switch selector expression is downcast-convertible to that type.\n14.11.1\n\nA pattern case element p is switch compatible with T if p is applicable at type T (14.30.3).\n\n14.30.3:\n\nA pattern p is said to be applicable at a type T if one of the following rules apply:\n\nA type pattern that declares a pattern variable of a reference type U is applicable at another reference type T if T is downcast convertible to U (5.5).\n\n\nObviously, E is downcast-convertible to I1 through a widening reference conversion, because E implements I1. Note that this fact has nothing to do with permits. It is simply a result of E implements I2 and I2 extends I1. Surely you would agree that implements and extends are transitive!\nSecond, switch expressions need to be exhaustive. Your switch expression is always exhaustive because it has a default case. However, it is still exhaustive even without the default case.\nFrom now on, we will consider your switch expression but without the default case, because that is where permits plays a role. The rules to determine whether the set of case labels you wrote are exhaustive are specified in 14.11.1.1. The important bit of your case is (this is kind of an inductive definition):\n\n\nA set of case elements is exhaustive for a type T if it contains a pattern that is unconditional at type T (14.30.3).\nA set of case elements is exhaustive for a type T that includes an abstract and sealed class or interface named C, if it is exhaustive\nfor every applicable permitted direct subtype of T.\n\n\n\"applicable permitted direct subtype of T\" in your case is really just the same as \"permitted direct subtype of T\". You can also treat \"a type T that includes an abstract and sealed class or interface named C\" as the same as T - the \"includes\" relationship isn't relevant to your case. With T=I1 in mind, we can start \"running\" this algorithm.\nWe use the second rule first - the permitted direct subtypes of I1 are I2, C and D. Since we have a C c and D d in the case elements, we know that our set of case elements is exhaustive for C and D (first rule). Is it also exhaustive for I2? To determine that, we use the second rule again. The permitted direct subtypes of I2 are E and F. Using the first rule, we know that the case elements E e and F f are exhaustive for E and F respectively. We have now proven that that the set of case elements are exhaustive for I2, C and D, so it is exhaustive for I1, according to the second rule.\nSo if you are talking about how switch patterns work, I think \"inductive\" is a better word to describe how the exhaustiveness of switch case labels are verified.\n"
}
{
    "Id": 72628636,
    "PostTypeId": 1,
    "Title": "How to create a new pom file with additional dependencies and add it during build time?",
    "Body": "I am currently using formsflow.ai opensource version 4.0.5.\nI want to include a new Listener to the bpm module which has a new library dependency which is not currently in the solution. Although, I managed to add the new library in main pom.xml, since the requirement is for one of my client I just cannot modify the root pom.xml file. Is their an option available in formsflow / maven to include profiles and choose pom?\nIf it already available in formsflow, then how can I configure the same?\nPlease give me a solution.\n",
    "AcceptedAnswerId": 72629089,
    "AcceptedAnswer": "You can checkout how to add profile on a pom.xml file from maven documentation how to add profile in maven.\nIn formsflow.ai we let our users manage the additional library dependency using an extra pom.xml (pom-.xml).\nYou can always refer to our internal documentation and also provided with a pom-default.xml to start with.\nThe facts about these profiling are.\n\nyou can add as many as number of unique profiling in pom.xml by mapping the default configuration.\nYou can add only 1 module per profile, since the docker build look up for the pom in the base directory and adding more than one module will override target.\nYou need to change profile param in Dockerfile before building it if you want to go with a profile other than default.\n\nHope this helps\n"
}
{
    "Id": 72683786,
    "PostTypeId": 1,
    "Title": "Error while importing Springboot 2.7 projects in intellij Idea with maven 3.8.5",
    "Body": "when Using start.spring.io\nprojects generated with springboot 2.7 comes with MavenProject 3.8.5 which when imported in intellij causes an error that is quite difficult to debug or not self speaking by itself.\nThe error\njava.lang.RuntimeException: org.codehaus.plexus.component.repository.exception.ComponentLookupException: com.google.inject.ProvisionException: Unable to provision, see the following errors:\n\n1) Error injecting constructor, java.lang.NoSuchMethodError: org.apache.maven.model.validation.DefaultModelValidator: method 'void ()' not found\n  at org.jetbrains.idea.maven.server.embedder.CustomModelValidator.(Unknown Source)\n  while locating org.jetbrains.idea.maven.server.embedder.CustomModelValidator\n  at ClassRealm[maven.ext, parent: ClassRealm[plexus.core, parent: null]] (via modules: org.eclipse.sisu.wire.WireModule -> org.eclipse.sisu.plexus.PlexusBindingModule)\n  while locating org.apache.maven.model.validation.ModelValidator annotated with @com.google.inject.name.Named(value=\"ide\")\n\n1 error\n      role: org.apache.maven.model.validation.ModelValidator\n  roleHint: ide\n\n",
    "AcceptedAnswerId": 72686220,
    "AcceptedAnswer": "That should have been fixed in 2022.1 in the scope of this bug\nPlease update your IDE\n"
}
{
    "Id": 74330854,
    "PostTypeId": 1,
    "Title": "OpenJDK 19 and compressed pointers",
    "Body": "I have a hard time understanding how compressed pointers works in Java 19, help is appreciated.\nIn Java 11 the reference size is 4 for heaps below 32GiB (compressed pointers) and 8 for a larger heap. In Java 19 they seem to take 4 bytes even for larger heaps (how?).\nDetails:\nJava versions: OpenJDK Java 11.0.12 and OpenJDK Java 19.0.1\nCommand lines:\n\n-XX:+UnlockExperimentalVMOptions -XX:+UseEpsilonGC  -Xlog:gc -Xlog:gc+heap+coops -Xms41g -Xmx41g -XX:+AlwaysPreTouch\n\n\n-XX:+UnlockExperimentalVMOptions -XX:+UseEpsilonGC  -Xlog:gc -Xlog:gc+heap+coops -Xms31g -Xmx31g -XX:+AlwaysPreTouch\n\nCode: https://github.com/cornelcreanga/fun/blob/master/src/main/java/com/ccreanga/various/RandomAllocate.java - the code is taken from https://shipilev.net/jvm/anatomy-quarks/23-compressed-references/\nRun this code with both Java 11 and 19 and you can see that the memory size is lower in Java 19 than in Java 11 for a heap > 32 GiB. For a smaller heap the size is almost identical.\n",
    "AcceptedAnswerId": 74349384,
    "AcceptedAnswer": "You are looking at the layout of a byte[] array and an instance of java.lang.Object. Neither of them contains a reference to an object inside the heap.\nThe difference you are seeing, is in the size of the class pointer which is not pointing to a location inside the heap memory. But for historical reasons, the option -XX:+UseCompressedClassPointers was bound to the presence of the -XX:+UseCompressedOops option. So when the heap size disallowed compressed object pointers, the compressed class pointers were disabled as a side effect.\nJDK-8241825, Make compressed oops and compressed class pointers independent addresses this and has been solved with JDK\u00a015.\nSo when I change your program to\nSystem.out.println(ClassLayout.parseInstance(new Object[3]).toPrintable());\n\nand run it with a 41GB heap, I get\n[Ljava.lang.Object; object internals:\nOFF  SZ               TYPE DESCRIPTION               VALUE\n  0   8                    (object header: mark)     0x0000000000000001 (non-biasable; age: 0)\n  8   8                    (object header: class)    0x000001f54bec41e0\n 16   4                    (array length)            3\n 20   4                    (alignment/padding gap)\n 24  24   java.lang.Object Object;.        N/A\nInstance size: 48 bytes\nSpace losses: 4 bytes internal + 0 bytes external = 4 bytes total\n\nprior to JDK\u00a015 and\n[Ljava.lang.Object; object internals:\nOFF  SZ               TYPE DESCRIPTION               VALUE\n  0   8                    (object header: mark)     0x0000000000000001 (non-biasable; age: 0)\n  8   4                    (object header: class)    0x000020fc\n 12   4                    (array length)            3\n 16  24   java.lang.Object Object;.        N/A\nInstance size: 40 bytes\nSpace losses: 0 bytes internal + 0 bytes external = 0 bytes total\n\nwith JDK\u00a015 or newer.\nThe difference is clearly caused by the class pointer and the padding, but the three object references require 24 bytes in each JVM version.\n"
}
{
    "Id": 74753700,
    "PostTypeId": 1,
    "Title": "Cannot resolve method 'antMatchers()' in AuthorizationManagerRequestMatcherRegistry",
    "Body": "I am currently following the Spring Documentation and some tutorials on Web Security. But now I have a problem, that I can't call the method antMatchers. This is the error I'm getting when building the project:\njava: cannot find symbol\n  symbol:   method antMatchers(java.lang.String)\n  location: variable requests of type org.springframework.security.config.annotation.web.configurers.AuthorizeHttpRequestsConfigurer.AuthorizationManagerRequestMatcherRegistry\n\nIn terms of my understanding, I should be able to use this method, so I can permit or not permit HTTP Requests to a certain URL. So my question is, why can't I use the antMatchers() method?\nSecurityConfiguration class:\npackage de.gabriel.vertretungsplan.security;\n\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.security.config.annotation.web.builders.HttpSecurity;\nimport org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;\nimport org.springframework.security.web.SecurityFilterChain;\n\n@Configuration\n@EnableWebSecurity\npublic class SecurityConfiguration {\n\n    @Bean\n    public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {\n        http\n                .authorizeHttpRequests((requests) -> requests\n                        .antMatchers(\"/vertretungsplan\").hasAnyRole(\"SCHUELER\", \"LEHRER\", \"VERWALTUNG\")\n                        .anyRequest().authenticated()\n                )\n                .formLogin((form) -> form\n                        .loginPage(\"/login\")\n                        .permitAll()\n                )\n                .logout((logout) -> logout.permitAll());\n\n        return http.build();\n    }\n\n}\n\npom.xml:\n\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    4.0.0\n    \n        org.springframework.boot\n        spring-boot-starter-parent\n        3.0.0\n         \n    \n    de.gabriel\n    vertretungsplan\n    0.0.1-SNAPSHOT\n    vertretungsplan\n    Demo project for Spring Boot\n    \n        17\n    \n    \n        \n            org.springframework.boot\n            spring-boot-starter-data-jpa\n        \n        \n            org.springframework.boot\n            spring-boot-starter-security\n        \n        \n            org.springframework.boot\n            spring-boot-starter-web\n        \n        \n            com.mysql\n            mysql-connector-j\n            runtime\n        \n\n        \n            org.springframework.boot\n            spring-boot-starter-test\n            test\n        \n        \n            org.springframework.security\n            spring-security-test\n            test\n        \n    \n\n    \n        \n            \n                org.springframework.boot\n                spring-boot-maven-plugin\n            \n        \n    \n\n\n\n",
    "AcceptedAnswerId": 74753955,
    "AcceptedAnswer": "In antMatchers() (as well as mvcMathcers() and regexMatchers()) have been deprecated and removed with Spring Security 6.0. Thus, you can't use them in a Spring Boot 3 project.\nHave a look at this link if you wonder what was the rationale behind this change: Deprecate trailing slash match.\nOverloaded method requestMatchers() was provided as a uniform mean for securing requests. It facilitates all the functionality of the configuration methods that have been removed from the API.\n@Bean\npublic SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {\n    http\n        .authorizeHttpRequests(requests -> requests\n            .requestMatchers(\"/vertretungsplan\").hasAnyRole(\"SCHUELER\", \"LEHRER\", \"VERWALTUNG\")\n            .anyRequest().authenticated()\n        )\n        .formLogin(form -> form\n            .loginPage(\"/login\")\n            .permitAll()\n        )\n        .logout(logout -> logout\n            .permitAll());\n    \n    return http.build();\n}\n\n"
}
{
    "Id": 72724816,
    "PostTypeId": 1,
    "Title": "Running unit tests with Spark 3.3.0 on Java 17 fails with IllegalAccessError: class StorageUtils cannot access class sun.nio.ch.DirectBuffer",
    "Body": "According to the release notes, and specifically the ticket Build and Run Spark on Java 17 (SPARK-33772), Spark now supports running on Java 17.\nHowever, using Java 17 (Temurin-17.0.3+7) with Maven (3.8.6) and maven-surefire-plugin (3.0.0-M7), when running a unit test that uses Spark (3.3.0) it fails with:\n\njava.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x1e7ba8d9) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x1e7ba8d9\n\nThe stack is:\njava.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x1e7ba8d9) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x1e7ba8d9\n  at org.apache.spark.storage.StorageUtils$.(StorageUtils.scala:213)\n  at org.apache.spark.storage.StorageUtils$.(StorageUtils.scala)\n  at org.apache.spark.storage.BlockManagerMasterEndpoint.(BlockManagerMasterEndpoint.scala:114)\n  at org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:353)\n  at org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:290)\n  at org.apache.spark.SparkEnv$.create(SparkEnv.scala:339)\n  at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:194)\n  at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:279)\n  at org.apache.spark.SparkContext.(SparkContext.scala:464)\n  at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2704)\n  at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:953)\n  at scala.Option.getOrElse(Option.scala:189)\n  at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:947)\n  [...]\n\nThe question Java 17 solution for Spark - java.lang.NoClassDefFoundError: Could not initialize class org.apache.spark.storage.StorageUtils was asked only 2 months ago, but this pre-dated the Spark 3.3.0 release, and thus predated official support for Java 17.\nWhy can't I run my Spark 3.3.0 test with Java 17, and how can we fix it?\n",
    "AcceptedAnswerId": 72724817,
    "AcceptedAnswer": "Even though Spark now supports Java 17, it still references the JDK internal class sun.nio.ch.DirectBuffer:\n  // In Java 8, the type of DirectBuffer.cleaner() was sun.misc.Cleaner, and it was possible\n  // to access the method sun.misc.Cleaner.clean() to invoke it. The type changed to\n  // jdk.internal.ref.Cleaner in later JDKs, and the .clean() method is not accessible even with\n  // reflection. However sun.misc.Unsafe added a invokeCleaner() method in JDK 9+ and this is\n  // still accessible with reflection.\n  private val bufferCleaner: DirectBuffer => Unit = [...]\n\nUnder the Java module system, access to this class is restricted.  The Java 9 migration guide says:\n\nIf you must use an internal API that has been made inaccessible by default, then you can break encapsulation using the --add-exports command-line option.\n\nWe need to open access to our module.  To do this for Surefire, we add this configuration to the plugin:\n\n  org.apache.maven.plugins\n  maven-surefire-plugin\n  3.0.0-M7\n  \n    --add-exports java.base/sun.nio.ch=ALL-UNNAMED\n  \n\n\nBased on a discussion with one of the Spark developers, Spark adds the following in order to execute all of its internal unit tests.\n\nThese options are used to pass all Spark UTs, but maybe you don't need all.\n\n--add-opens=java.base/java.lang=ALL-UNNAMED\n--add-opens=java.base/java.lang.invoke=ALL-UNNAMED\n--add-opens=java.base/java.lang.reflect=ALL-UNNAMED\n--add-opens=java.base/java.io=ALL-UNNAMED\n--add-opens=java.base/java.net=ALL-UNNAMED\n--add-opens=java.base/java.nio=ALL-UNNAMED\n--add-opens=java.base/java.util=ALL-UNNAMED\n--add-opens=java.base/java.util.concurrent=ALL-UNNAMED\n--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED\n--add-opens=java.base/sun.nio.ch=ALL-UNNAMED\n--add-opens=java.base/sun.nio.cs=ALL-UNNAMED\n--add-opens=java.base/sun.security.action=ALL-UNNAMED\n--add-opens=java.base/sun.util.calendar=ALL-UNNAMED\n\nIt was also commented:\n\nHowever, these Options needn't explicit add when using spark-shell, spark-sql and spark-submit\n\n"
}
{
    "Id": 74683791,
    "PostTypeId": 1,
    "Title": "Java CompletableFuture for sequential code",
    "Body": "My new team is writing a Java gRPC service and to ensure that we never block the request thread we ended-up wrapping more or less ALL methods inside a CompletableFuture even if those endpoints are conceptually a sequential list of operation (no parallelism).\nSo the code look something like (a Java example is available at the end if needed) :\n  methodA()\n    methodB()\n      methodD() (let say this one is a 15ms RPC call)\n      methodE()\n    methodC()\n      methodF() (let say this one is a 5ms CPU intensive work)\n      methodG()\n \n\nContext:\n\nIn practice the application is much bigger and there're many more layers of functions\nEach application host need to handle 1000 QPS, so you can imagine that methodA is called at that rate\nSome function (few) make a RPC call that can take 5-30ms (IO)\nSome function (very few) run CPU intensive work (\n\nEdit 1: After more reading online yesterday, I understand that if, and only if, we are using true non-blocking HTTP and DB Client (and it doesn't seem like JDBC is non-blocking), this pattern can reduce the total number of threads required. My understanding is that if we have enough memory to keep one thread per request, using a synchronous code would still probably be the most efficient implementation (reduce the overhead of switching threads and loading data), but if we didn't have enough memory to keep that many threads alive, then this notion of making the whole code non-blocking can reduce the number of thread and thus allow the application to scale to more request.\nQuestion 1:\nI understand this unblocks the \"request thread\", but in practice what's the advantage? Are we truly saving CPU time? In the example below, it feels like \"some\" thread will be alive the whole time anyways (in the example below, mostly the thread from CompletableFuture.supplyAsync in methodD), it just happens that it\u2019s not the same thread as the one who received the initial request.\nQuestion 2:\nIs that pattern truly a \"best practice\" and all services should follow a similar pattern? Outside of making the code a bit harder to read I feel, per request 50+ methods gets invoked and 50+ times we call a mix of CompletableFuture .thenCompose() or .supplyAsync. It seems like it's would be adding some overhead. Was CompletableFuture designed to be used that way across the whole code base in every method?\nAnnex (java example):\n  public void myEndpoint(MyRequest request, StreamObserver responseObserver) {\n    methodA(10)\n        .thenApply((response) -> responseObserver.next(response));\n    \n  }\n\n  public CompletableFuture methodA(Integer input) {\n    return CompletableFuture.completedFuture(input)\n        .thenCompose(this::methodB)\n        .thenCompose(this::methodC)\n        .thenApply((i) -> {\n          System.out.println(\"MethodA executed by \".concat(Thread.currentThread().getName() + \": \" + i));\n          return i;\n        });\n  }\n\n  public CompletableFuture methodB(Integer input) {\n    return CompletableFuture.completedFuture(input)\n        .thenCompose(this::methodD)\n        .thenCompose(this::methodE)\n        .thenApply((i) -> {\n          System.out.println(\"MethodB executed by \".concat(Thread.currentThread().getName() + \": \" + i));\n          return i;\n        });\n  }\n\n  public CompletableFuture methodC(Integer input) {\n    return CompletableFuture.completedFuture(input)\n        .thenCompose(this::methodF)\n        .thenCompose(this::methodG)\n        .thenApply((i) -> {\n          System.out.println(\"MethodC executed by \".concat(Thread.currentThread().getName() + \": \" + i));\n          return i;\n        });\n  }\n\n  public CompletableFuture methodD(Integer input) {\n    return CompletableFuture.supplyAsync(() -> {\n      try {\n        // Assume it's a RPC call that takes 5-30ms\n        Thread.sleep(20);\n        System.out.println(\"MethodD executed by \".concat(Thread.currentThread().getName() + \": \" + input));\n      } catch (InterruptedException e) {\n        throw new RuntimeException(e);\n      }\n      return input + 1;\n    });\n  }\n\n  public CompletableFuture methodE(Integer input) {\n    return CompletableFuture.supplyAsync(() -> {\n      System.out.println(\"MethodE executed by \".concat(Thread.currentThread().getName() + \": \" + input));\n      return input + 1;\n    });\n  }\n\n  public CompletableFuture methodF(Integer input) {\n    return CompletableFuture.supplyAsync(() -> {\n      try {\n        // Let's assume it's a CPU intensive work that takes 2-5ms\n        Thread.sleep(5);\n        System.out.println(\"MethodF executed by \".concat(Thread.currentThread().getName() + \": \" + input));\n      } catch (InterruptedException e) {\n        throw new RuntimeException(e);\n      }\n      return input + 1;\n    });\n  }\n\n  public CompletableFuture methodG(Integer input) {\n    return CompletableFuture.supplyAsync(() -> {\n      System.out.println(\"MethodG executed by \".concat(Thread.currentThread().getName() + \": \" + input));\n      return input + 1;\n    });\n  }\n\n",
    "AcceptedAnswerId": 74796834,
    "AcceptedAnswer": "The premise is that threads are a scarce resource, which is not intrinsic to threads but a consequence of using a pool of threads with a configured maximum. The reason today\u2019s frameworks use a pool is that threads, as implemented today, are expensive and creating too many of them can cause significant performance problems.\nYou wrote\n\nMy understanding is that if we have enough memory to keep one thread per request, using a synchronous code would still probably be the most efficient implementation\u2026\n\nwhich is going into the right direction, but it\u2019s important to keep in mind that there might be more constraints than memory. Some operating system\u2019s schedulers become significantly less efficient with a large number of threads, some may even have a fixed limit on how many threads a process is allowed to create.\nSo, when you block a thread by waiting for another, you are limiting the parallel processing capabilities of the thread pool. This applies if you are using, as you put it, a \u201ctrue non-blocking\u201d API, or just any already existing API that returns futures. Submitting your own operations via supplyAsync has no point as the supplier\u2019s code still is executed by a thread, as you correctly pointed out.\nBut when you have an existing future returned by an operation, you should rather chain dependent processing steps instead of waiting for its result via join and friends. Note that calling join() on existing futures can make things even worse than just blocking threads:\nWhen you call join() on a CompletableFuture, it tries to compensate the problem. When the caller is a worker thread of a Fork/Join pool, one of two things can happen:\n\nInstead of doing nothing, it may try to fetch pending jobs and execute them in-place, similar to awaitQuiescence.\n\nIn the best case, it will directly pick up the job you just scheduled with supplyAsync (if using the same pool) and execute it, almost as if you executed it without CompletableFuture (just consuming far more stack space).\nIn the worst case, the thread will be busy executing a long running, entirely unrelated job while the job it\u2019s actually waiting for has been completed long ago. Imagine what happens if that unrelated job also calls join.\n\n\nIt may end up actually blocking the thread but using ForkJoinPool.managedBlock(\u2026), which may start a new worker thread to ensure that the pool\u2019s configured parallelism is kept. Great to solve the problem of reduced parallelism, but on the other hand, reintroducing the very problem of resource consumption you actually wanted to solve with thread pools.\n\nThe worst of all is that you can\u2019t even predict which of the two things will happen.\n\nThere are, however, cases where not blocking a request thread by utilizing other threads has a point. Most notably when the response time for the request itself matters and the results of the background computation are delivered independent of the initial response. The most prominent example of this pattern is the event dispatch thread of GUI frameworks which must be kept free of long running operations, to be able to process subsequent user input.\n\nNote that there is a general solution on the way, to make 99% of all future chains obsolete. Virtual Threads, which are in preview state in JDK\u00a019, are cheap to create and allow to create one thread per request, just like you envisioned in the cite above. When a virtual thread gets blocked, it will release the underlying platform thread for the next virtual thread, so there is no reason to hesitate to call join() on any future, even those belonging to \u201ctrue non-blocking\u201d APIs.\nThe best way to interoperate with this concept and the status quo is to design methods to not return futures, but perform the operation in-place. It\u2019s still possible to design a future chain when necessary, i.e. by using .thenApplyAsync(this::inPlaceEvalMethod) instead of .thenCompose(this::futureReturningMethod). But at the same time, you can write a plain sequential version just calling these methods, which can be executed by a virtual thread. In fact, you could even add the plain sequential version today and benchmark both approaches. The results might convince your team members that \u201cnot blocking the request thread\u201d is not necessarily an improvement.\n"
}
{
    "Id": 74816992,
    "PostTypeId": 1,
    "Title": "Why does Spring Security 6 not create sessions when authenticating with curl and basic auth?",
    "Body": "I recently upgraded to Spring Security 6, and have found that authenticating using basic auth from JS or from curl no longer works but authenticating with basic auth using Java's HttpClient does work. My goal is to be able to authenticate with all approaches.\nThe app uses Java 17, Spring Security 6, and Spring Session 3. It has a \"login\" endpoint which is just a convenience endpoint that is expected to be hit with basic auth and create a session, and it returns a User object. The session id should be used for subsequent requests to other endpoints.\nThe curl command is like so:\n curl -kv --user admin:admin \"https://localhost:9000/login\"\n\nVS the HttpClient is configured like so and calling HttpClient.get(loginUrl)\nHttpClient.newBuilder()\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.connectTimeout(Duration.ofSeconds(300))\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.cookieHandler(new CookieManager())\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.authenticator(new BasicAuthenticator(username, password))\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.sslContext(createSsl())\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.build();\n\npublic class BasicAuthenticator extends Authenticator {\n\n\u00a0\u00a0\u00a0private PasswordAuthentication authentication;\n\n\u00a0\u00a0\u00a0public BasicAuthenticator(String username, String password) {\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0authentication = new PasswordAuthentication(username, password.toCharArray());\n\u00a0\u00a0\u00a0}\n\n\u00a0\u00a0\u00a0@Override\n\u00a0\u00a0\u00a0public PasswordAuthentication getPasswordAuthentication() {\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return authentication;\n\u00a0\u00a0\u00a0}\n}\n\nThe security configuration is the block below... In upgrading to SpringSecurity 6 I added the requireExplicitSave() method, I have suspicions around this because my trouble is around saving sessions, but the added code is supposed to have spring security using the old functionality.\nhttp\n\u00a0\u00a0\u00a0.securityContext( securityContext -> securityContext.requireExplicitSave(false))\n\u00a0\u00a0\u00a0.authorizeHttpRequests((authz) -> authz\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.requestMatchers(openEndpoints).permitAll()\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.anyRequest().authenticated()\n\u00a0\u00a0\u00a0)\n\u00a0\u00a0\u00a0.httpBasic()\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.and()\n\u00a0\u00a0\u00a0.csrf()\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.disable()\n\u00a0\u00a0\u00a0.exceptionHandling()\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.accessDeniedHandler((req, resp, e) -> e.printStackTrace() )\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.and()\n\u00a0\u00a0\u00a0.logout()\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.invalidateHttpSession(true)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0.clearAuthentication(true);\n\nI turned on request logging, security logging, and SQL logging. The SQL is all the same, and the basic auth request is always authenticated for all scenarios. The headers are different, but I can't see the headers for the HttpClient preflight call, and of the headers I do see, I don't know why authentication or session creation would work for one set of headers but not the other.\nThe core of the problem seems to be that the login request from the HttpClient ends with a session being created and the request from curl does not. Note that the big difference in the server logs when using curl is \"Failed to create a session, as response has been committed. Unable to store SecurityContext.\" However even stepping through the spring security code I can't tell what is causing the difference.\u00a0\nSee logs here:\nCURL\n2022-12-14T16:38:07.594-05:00 DEBUG 92726 --- [nio-9000-exec-1] o.s.security.web.FilterChainProxy        : Securing GET /login\n2022-12-14T16:38:07.597-05:00 DEBUG 92726 --- [nio-9000-exec-1] s.s.w.c.SecurityContextPersistenceFilter : Set SecurityContextHolder to empty SecurityContext\n2022-12-14T16:38:07.704-05:00 DEBUG 92726 --- [nio-9000-exec-1] org.hibernate.SQL                        : select u1_0.id,u1_0.display_name,u1_0.email,u1_0.enabled,u1_0.password,u1_0.registration_time,r1_0.user_id,r1_0.role_id,u1_0.username from app_user u1_0 join user_role r1_0 on u1_0.id=r1_0.user_id where u1_0.username=?\n2022-12-14T16:38:07.797-05:00 DEBUG 92726 --- [nio-9000-exec-1] o.s.s.a.dao.DaoAuthenticationProvider    : Authenticated user\n2022-12-14T16:38:07.799-05:00 DEBUG 92726 --- [nio-9000-exec-1] o.s.s.w.a.www.BasicAuthenticationFilter  : Set SecurityContextHolder to UsernamePasswordAuthenticationToken [Principal=org.springframework.security.core.userdetails.User [Username=admin, Password=[PROTECTED], Enabled=true, AccountNonExpired=true, credentialsNonExpired=true, AccountNonLocked=true, Granted Authorities=[ROLE_ADMIN, ROLE_USER]], Credentials=[PROTECTED], Authenticated=true, Details=WebAuthenticationDetails [RemoteIpAddress=127.0.0.1, SessionId=null], Granted Authorities=[ROLE_ADMIN, ROLE_USER]]\n2022-12-14T16:38:07.801-05:00 DEBUG 92726 --- [nio-9000-exec-1] o.s.security.web.FilterChainProxy        : Secured GET /login\n2022-12-14T16:38:07.805-05:00 DEBUG 92726 --- [nio-9000-exec-1] o.s.w.f.CommonsRequestLoggingFilter      : Before request [GET /login, headers=[host:\"localhost:9000\", authorization:\"Basic YWRtaW46YWRtaW4=\", user-agent:\"curl/7.84.0\", accept:\"*/*\"]]\n2022-12-14T16:38:07.816-05:00 DEBUG 92726 --- [nio-9000-exec-1] horizationManagerBeforeMethodInterceptor : Authorizing method invocation ReflectiveMethodInvocation: public com.seebie.dto.User com.seebie.server.controller.UserController.login(java.security.Principal); target is of class [com.seebie.server.controller.UserController]\n2022-12-14T16:38:07.822-05:00 DEBUG 92726 --- [nio-9000-exec-1] horizationManagerBeforeMethodInterceptor : Authorized method invocation ReflectiveMethodInvocation: public com.seebie.dto.User com.seebie.server.controller.UserController.login(java.security.Principal); target is of class [com.seebie.server.controller.UserController]\n2022-12-14T16:38:07.826-05:00 DEBUG 92726 --- [nio-9000-exec-1] org.hibernate.SQL                        : select u1_0.id,u1_0.display_name,u1_0.email,u1_0.enabled,u1_0.password,u1_0.registration_time,u1_0.username from app_user u1_0 where u1_0.username=?\n2022-12-14T16:38:07.832-05:00 DEBUG 92726 --- [nio-9000-exec-1] org.hibernate.SQL                        : select r1_0.user_id,r1_0.role_id from user_role r1_0 where r1_0.user_id=?\n2022-12-14T16:38:07.836-05:00 DEBUG 92726 --- [nio-9000-exec-1] org.hibernate.SQL                        : select a1_0.user_id,a1_0.id,a1_0.city,a1_0.line1,a1_0.state,a1_0.zip from address a1_0 where a1_0.user_id=?\n2022-12-14T16:38:07.840-05:00 DEBUG 92726 --- [nio-9000-exec-1] org.hibernate.SQL                        : select s1_0.principal_name,s1_0.primary_id,s1_0.session_id from spring_session s1_0 where s1_0.principal_name=?\n2022-12-14T16:38:07.871-05:00 DEBUG 92726 --- [nio-9000-exec-1] o.s.w.f.CommonsRequestLoggingFilter      : REQUEST DATA : GET /login, headers=[host:\"localhost:9000\", authorization:\"Basic YWRtaW46YWRtaW4=\", user-agent:\"curl/7.84.0\", accept:\"*/*\"]]\n2022-12-14T16:38:07.873-05:00  WARN 92726 --- [nio-9000-exec-1] w.c.HttpSessionSecurityContextRepository : Failed to create a session, as response has been committed. Unable to store SecurityContext.\n2022-12-14T16:38:07.873-05:00 DEBUG 92726 --- [nio-9000-exec-1] s.s.w.c.SecurityContextPersistenceFilter : Cleared SecurityContextHolder to complete request\n\nHttpClient\n2022-12-14T06:31:28.390-05:00 DEBUG 85610 --- [o-auto-1-exec-1] o.s.security.web.FilterChainProxy        : Securing GET /login\n2022-12-14T06:31:28.420-05:00 DEBUG 85610 --- [o-auto-1-exec-1] s.s.w.c.SecurityContextPersistenceFilter : Set SecurityContextHolder to empty SecurityContext\n2022-12-14T06:31:28.913-05:00 DEBUG 85610 --- [o-auto-1-exec-1] org.hibernate.SQL                        : select u1_0.id,u1_0.display_name,u1_0.email,u1_0.enabled,u1_0.password,u1_0.registration_time,r1_0.user_id,r1_0.role_id,u1_0.username from app_user u1_0 join user_role r1_0 on u1_0.id=r1_0.user_id where u1_0.username=?\n2022-12-14T06:31:29.102-05:00 DEBUG 85610 --- [o-auto-1-exec-1] o.s.s.a.dao.DaoAuthenticationProvider    : Authenticated user\n2022-12-14T06:31:29.103-05:00 DEBUG 85610 --- [o-auto-1-exec-1] o.s.s.w.a.www.BasicAuthenticationFilter  : Set SecurityContextHolder to UsernamePasswordAuthenticationToken [Principal=org.springframework.security.core.userdetails.User [Username=admin, Password=[PROTECTED], Enabled=true, AccountNonExpired=true, credentialsNonExpired=true, AccountNonLocked=true, Granted Authorities=[ROLE_ADMIN, ROLE_USER]], Credentials=[PROTECTED], Authenticated=true, Details=WebAuthenticationDetails [RemoteIpAddress=127.0.0.1, SessionId=19ab0971-5fb3-47fd-a4f9-cdde1ad24883], Granted Authorities=[ROLE_ADMIN, ROLE_USER]]\n2022-12-14T06:31:29.108-05:00 DEBUG 85610 --- [o-auto-1-exec-1] o.s.security.web.FilterChainProxy        : Secured GET /login\n2022-12-14T06:31:29.136-05:00 DEBUG 85610 --- [o-auto-1-exec-1] o.s.w.f.CommonsRequestLoggingFilter      : Before request [GET /login, headers=[authorization:\"Basic YWRtaW46YWRtaW4=\", content-length:\"0\", host:\"localhost:64723\", user-agent:\"Java-http-client/17.0.2\", cookie:\"SESSION=MTlhYjA5NzEtNWZiMy00N2ZkLWE0ZjktY2RkZTFhZDI0ODgz\", Content-Type:\"application/json;charset=UTF-8\"]]\n2022-12-14T06:31:29.274-05:00 DEBUG 85610 --- [o-auto-1-exec-1] horizationManagerBeforeMethodInterceptor : Authorizing method invocation ReflectiveMethodInvocation: public com.seebie.dto.User com.seebie.server.controller.UserController.login(java.security.Principal); target is of class [com.seebie.server.controller.UserController]\n2022-12-14T06:31:29.332-05:00 DEBUG 85610 --- [o-auto-1-exec-1] horizationManagerBeforeMethodInterceptor : Authorized method invocation ReflectiveMethodInvocation: public com.seebie.dto.User com.seebie.server.controller.UserController.login(java.security.Principal); target is of class [com.seebie.server.controller.UserController]\n2022-12-14T06:31:29.373-05:00 DEBUG 85610 --- [o-auto-1-exec-1] org.hibernate.SQL                        : select u1_0.id,u1_0.display_name,u1_0.email,u1_0.enabled,u1_0.password,u1_0.registration_time,u1_0.username from app_user u1_0 where u1_0.username=?\n2022-12-14T06:31:29.392-05:00 DEBUG 85610 --- [o-auto-1-exec-1] org.hibernate.SQL                        : select r1_0.user_id,r1_0.role_id from user_role r1_0 where r1_0.user_id=?\n2022-12-14T06:31:29.409-05:00 DEBUG 85610 --- [o-auto-1-exec-1] org.hibernate.SQL                        : select a1_0.user_id,a1_0.id,a1_0.city,a1_0.line1,a1_0.state,a1_0.zip from address a1_0 where a1_0.user_id=?\n2022-12-14T06:31:29.413-05:00 DEBUG 85610 --- [o-auto-1-exec-1] org.hibernate.SQL                        : select s1_0.principal_name,s1_0.primary_id,s1_0.session_id from spring_session s1_0 where s1_0.principal_name=?\n2022-12-14T06:31:29.678-05:00 DEBUG 85610 --- [o-auto-1-exec-1] o.s.w.f.CommonsRequestLoggingFilter      : REQUEST DATA : GET /login, headers=[authorization:\"Basic YWRtaW46YWRtaW4=\", content-length:\"0\", host:\"localhost:64723\", user-agent:\"Java-http-client/17.0.2\", cookie:\"SESSION=MTlhYjA5NzEtNWZiMy00N2ZkLWE0ZjktY2RkZTFhZDI0ODgz\", Content-Type:\"application/json;charset=UTF-8\"]]\n2022-12-14T06:31:29.680-05:00 DEBUG 85610 --- [o-auto-1-exec-1] w.c.HttpSessionSecurityContextRepository : Stored SecurityContextImpl [Authentication=UsernamePasswordAuthenticationToken [Principal=org.springframework.security.core.userdetails.User [Username=admin, Password=[PROTECTED], Enabled=true, AccountNonExpired=true, credentialsNonExpired=true, AccountNonLocked=true, Granted Authorities=[ROLE_ADMIN, ROLE_USER]], Credentials=[PROTECTED], Authenticated=true, Details=WebAuthenticationDetails [RemoteIpAddress=127.0.0.1, SessionId=19ab0971-5fb3-47fd-a4f9-cdde1ad24883], Granted Authorities=[ROLE_ADMIN, ROLE_USER]]] to HttpSession [org.springframework.session.web.http.SessionRepositoryFilter$SessionRepositoryRequestWrapper$HttpSessionWrapper@7ba784f2]\n2022-12-14T06:31:29.680-05:00 DEBUG 85610 --- [o-auto-1-exec-1] s.s.w.c.SecurityContextPersistenceFilter : Cleared SecurityContextHolder to complete request\n\nNote the session in headers for the HttpClient call... I think HttpClient makes a preflight auth call that gets a 401 and then makes the \"real\" call with the credentials, at least that's how it was in Java 11.\nI think if I understood the difference in how these calls are being made/handled that causes one technique to work but not the other, I would be able to solve the problem. So that really is the question: What is the difference in spring security 6 (along with spring session) handling session creation when using Java 17's HttpClient vs curl?\n[UPDATE] to anyone who read this far: the behavior is actually expected behavior for Spring Security. A full discussion and explanation are in the spring security issue that I had opened here\n",
    "AcceptedAnswerId": 74838578,
    "AcceptedAnswer": "Well, if we are not going to investigate why preflight requests make sense (IMO, that seems to be a bug), the explanation of what has been changed in spring 6 is following:\nas was mentioned in Session Management Migrations now Spring does not enable SecurityContextPersistenceFilter by default, however in Spring 5 SecurityContextPersistenceFilter was responsible for saving SecurityContext in http session (and hence creating it) unless that was explicitly disabled. Now in order to return previous behaviour you desire you need to setup SecurityContextRepository via:\nhttp.securityContext(securityContext -> securityContext.\n      securityContextRepository(new HttpSessionSecurityContextRepository())\n)\n\n"
}
{
    "Id": 74639116,
    "PostTypeId": 1,
    "Title": "What is the difference between green threads and virtual threads?",
    "Body": "Green Threads have been implemented with Java 1.1 and dropped in subsequent Java versions, according to https://en.wikipedia.org/wiki/Green_thread.\nJava 19 introduced Virtual Threads as a preview feature.\nhttps://openjdk.org/jeps/425\nBoth threads seem to work in User Space and not in Kernel Space as Javas Native Threads do.\nWhat's the difference between them, and are the previous limitations of Green Threads omitted with the new Virtual Threads?\n",
    "AcceptedAnswerId": 74639215,
    "AcceptedAnswer": "Short Answer:\nGreen Threads had an N:1 mapping with OS Threads. All the Green Threads ran on a single OS Thread. With Virtual Threads, multiple virtual threads can run on multiple native threads (n:m mapping)\nA bit more details from the JEP 425\n\nJava's green threads all shared one OS thread (M:1 scheduling) and were eventually outperformed by platform threads (Java's Native Threads) implemented as wrappers for OS threads (1:1 scheduling)\n\nVirtual threads employ M:N scheduling, where a large number (M) of virtual threads is scheduled to run on a smaller number (N) of OS threads.\n\n\nJust a small overview\n\n\n\n\nThread Type\nDescription\nJava Thread Type (M) : Native Threads(N)\n\n\n\n\nPlatform Threads\nA wrapper for OS Threads.\n1:1\n\n\nGreen Threads\nRuns multiple \"Green Threads\" on a single OS Thread.\nM:1\n\n\nVirtual Threads\nRuns multiple Virtual Threads on Multiple OS threads\nM:N (M > N)\n\n\n\nFull Quote from JEP\n\nVirtual threads are a lightweight implementation of threads that is\nprovided by the JDK rather than the OS. They are a form of user-mode\nthreads, which have been successful in other multithreaded languages\n(e.g., goroutines in Go and processes in Erlang). User-mode threads\neven featured as so-called \"green threads\" in early versions of Java,\nwhen OS threads were not yet mature and widespread. However, Java's\ngreen threads all shared one OS thread (M:1 scheduling) and were\neventually outperformed by platform threads, implemented as wrappers\nfor OS threads (1:1 scheduling). Virtual threads employ M:N\nscheduling, where a large number (M) of virtual threads is scheduled\nto run on a smaller number (N) of OS threads.\n\n"
}
{
    "Id": 74695402,
    "PostTypeId": 1,
    "Title": "BUG! exception in phase 'semantic analysis' in source unit '_BuildScript_' Unsupported class file major version 63",
    "Body": "Bug when first trying to run a brand new React Native application.\nBUG! exception in phase 'semantic analysis' in source unit 'BuildScript' Unsupported class file major version 63\nI encountered this error when I first installed the latest version of Java\n\njava 19.0.1\n\nand creating a React Native application that auto generated with\n\nreact-native dependency v0.70.6\n\n",
    "AcceptedAnswerId": 74695403,
    "AcceptedAnswer": "SOLUTION:\nThis is a dependency issue and we need the latest version of Gradle to support Java 19.\nIn your React Native application folder, nav to android/gradle/wrapper/gradle-wrapper.properties\nFind the distributionUrl variable and change the end path to gradle-7.6-all.zip\n"
}
{
    "Id": 72761919,
    "PostTypeId": 1,
    "Title": "Class SpringHibernateJpaPersistenceProvider does not implement the requested interface PersistenceProvider",
    "Body": "I'm stumped - I haven't used Hibernate in several years and then, never with Spring Boot.  Spring Boot but never with Hibernate or JPA.  So i'm trying to figure out how to get this to work for my job - I'm supposed to demo something Monday and if I can get 'this' to work, I'll copy it over to my work laptop and change the details of course.  Btw - here's the message I get - I had to shorten it in the title:\n\"Class org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider does not implement the requested interface javax.persistence.spi.PersistenceProvider\"\nI have the \"main\" class - TestWebApplication:\npackage net.draconia.testWeb;\n\nimport java.util.Properties;\n\nimport javax.sql.DataSource;\n\nimport org.apache.commons.dbcp2.BasicDataSource;\n\nimport org.springframework.boot.SpringApplication;\n\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\n\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.orm.hibernate5.HibernateTransactionManager;\nimport org.springframework.orm.hibernate5.LocalSessionFactoryBean;\nimport org.springframework.orm.jpa.JpaTransactionManager;\nimport org.springframework.orm.jpa.JpaVendorAdapter;\nimport org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean;\nimport org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter;\nimport org.springframework.transaction.PlatformTransactionManager;\n\n@SpringBootApplication(scanBasePackages = {\"com.draconia.testWeb.controller\"})\npublic class TestWebApplication\n{\n    \n    @Bean\n    public DataSource getDatasource()\n    {\n        BasicDataSource objDatasource = new BasicDataSource();\n        \n        objDatasource.setDriverClassName(\"com.mysql.jdbc.Driver\");\n        objDatasource.setUrl(\"jdbc:mysql://localhost:3306/Test\");\n        objDatasource.setUsername(\"root\");\n        objDatasource.setPassword(\"R3g1n@ M1lL$ 1$ My Qu3eN!\");\n        \n        return(objDatasource);\n    }\n    \n    @Bean\n    public LocalContainerEntityManagerFactoryBean getEntityManagerFactory()\n    {\n          LocalContainerEntityManagerFactoryBean objEntityManager = new LocalContainerEntityManagerFactoryBean();\n          \n          objEntityManager.setDataSource(getDatasource());\n          objEntityManager.setPackagesToScan(new String[] { \"net.draconia.testWeb.beans\" });\n\n          JpaVendorAdapter objVendorAdapter = new HibernateJpaVendorAdapter();\n          objEntityManager.setJpaVendorAdapter(objVendorAdapter);\n          objEntityManager.setJpaProperties(getHibernateProperties());\n\n          return(objEntityManager);\n   }\n    \n    protected Properties getHibernateProperties()\n    {\n        Properties objHibernateProperties = new Properties();\n        \n        objHibernateProperties.setProperty(\"hibernate.hbm2ddl.auto\", \"create-drop\");\n        objHibernateProperties.setProperty(\"hibernate.dialect\", \"org.hibernate.dialect.MySQLDialect\");\n        \n        return(objHibernateProperties);\n    }\n    \n    @Bean\n    public JpaTransactionManager getHibernateTransactionManager()\n    {\n        JpaTransactionManager objTransactionManager = new JpaTransactionManager();\n        \n        objTransactionManager.setEntityManagerFactory(getEntityManagerFactory().getObject());\n        \n        return(objTransactionManager);\n    }\n    \n    public static void main(String[] args)\n    {\n        SpringApplication.run(TestWebApplication.class, args);\n    }\n}\n\n, the entity bean:\npackage net.draconia.testWeb.beans;\n\nimport javax.persistence.Column;\nimport javax.persistence.Entity;\nimport javax.persistence.GeneratedValue;\nimport javax.persistence.GenerationType;\nimport javax.persistence.Id;\n\n@Entity(name = \"Books\")\npublic class Book\n{\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Integer miId;\n    \n    @Column(columnDefinition = \"varchar(200) not null\", insertable = true, length = 200, name = \"BookName\", nullable = false, table = \"Books\", unique = false, updatable = true)\n    private String msBookName;\n    \n    @Column(columnDefinition = \"varchar(100) not null\", insertable = true, length = 100, name=\"Author\", nullable = false, table = \"Books\", unique = false, updatable = true)\n    private String msAuthor;\n    \n    public String getAuthor()\n    {\n        if(msAuthor == null)\n            msAuthor = \"\";\n        \n        return(msAuthor);\n    }\n    \n    public String getBookName()\n    {\n        if(msBookName == null)\n            msBookName = \"\";\n        \n        return(msBookName);\n    }\n    \n    public int getId()\n    {\n        if(miId == null)\n            miId = 0;\n        \n        return(miId);\n    }\n    \n    public void setAuthor(final String sAuthor)\n    {\n        if(sAuthor == null)\n            msAuthor = \"\";\n        else\n            msAuthor = sAuthor;\n    }\n    \n    public void setBookName(final String sBookName)\n    {\n        if(sBookName == null)\n            msBookName = \"\";\n        else\n            msBookName = sBookName;\n    }\n    \n    public void setId(final Integer iId)\n    {\n        if(iId == null)\n            miId = 0;\n        else\n            miId = iId;\n    }\n}\n\n, the DAOConcrete class (the interface is just one method which is logical but if you want I'll post that too):\npackage net.draconia.testWeb.dao;\n\nimport java.util.List;\n\nimport javax.persistence.EntityManager;\nimport javax.persistence.EntityManagerFactory;\n\nimport org.springframework.beans.factory.annotation.Autowired;\n\nimport org.springframework.stereotype.Repository;\n\nimport net.draconia.testWeb.beans.Book;\n\n@Repository(\"bookDAO\")\npublic class BookDAOImpl implements BookDAO\n{\n    @Autowired\n    private EntityManagerFactory mObjEntityManagerFactory;\n    \n    public List getAllBooks()\n    {\n        EntityManager objEntityManager = getEntityManagerFactory().createEntityManager();\n        List lstBooks = objEntityManager.createQuery(\"from Books\", Book.class).getResultList();\n        \n        return(lstBooks);\n    }\n    \n    protected EntityManagerFactory getEntityManagerFactory()\n    {\n        return(mObjEntityManagerFactory);\n    }\n}\n\n, and the Controller class for the REST endpoints/MVC Controller:\npackage net.draconia.testWeb.controllers;\n\nimport java.util.List;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.GetMapping;\n\nimport net.draconia.testWeb.beans.Book;\nimport net.draconia.testWeb.dao.BookDAO;\n\n@Controller\npublic class TestController\n{\n    @Autowired\n    private BookDAO mObjDAO;\n    \n    @GetMapping(\"/Books\")\n    public List getBooks()\n    {\n        return(getDAO().getAllBooks());\n    }\n    \n    protected BookDAO getDAO()\n    {\n        return(mObjDAO);\n    }\n}\n\nThe POM file is here just for completeness but I don't think it's necessarily a problem unless I'm missing a dependency:\n\n\n    4.0.0\n    \n        org.springframework.boot\n        spring-boot-starter-parent\n        2.7.1\n         \n    \n    \n    net.draconia\n    testWeb\n    0.0.1-SNAPSHOT\n    testWeb\n    Demo project for Spring Boot\n    \n    \n        6.1.0.Final\n        11\n        8.0.29\n        5.3.2\n    \n    \n    \n        \n            com.fasterxml.jackson.core\n            jackson-core\n            2.13.3\n        \n        \n            jakarta.persistence\n            jakarta.persistence-api\n            3.0.0\n        \n        \n            javax.persistence\n            javax.persistence-api\n            2.2\n        \n        \n            mysql\n            mysql-connector-java\n            ${mysql.version}\n        \n        \n            org.apache.commons\n            commons-dbcp2\n            2.9.0\n        \n        \n            org.hibernate.orm\n            hibernate-core\n            ${hibernate.version}\n        \n        \n            org.springframework.boot\n            spring-boot-starter-test\n            test\n        \n        \n            org.springframework.boot\n            spring-boot-starter-web\n        \n        \n            org.springframework\n            spring-orm\n            ${spring.version}\n        \n    \n\n    \n        \n            \n                org.springframework.boot\n                spring-boot-maven-plugin\n            \n        \n    \n\n\nIf you'll note, i'm including a dependency for the Jackson library because the list of books should return as a JSON object.  I don't think that's a poblem but just saying - and I could probably have remoed that for this but then when it runs, the list of books would be unintelligible to me getting a response when/if it worked.  What am I doing wrong???\n",
    "AcceptedAnswerId": 72763415,
    "AcceptedAnswer": "Change hibernate to version 5.6.9.Final (or any higher 5.6.x):\n5.6.9.Final\n\n"
}
{
    "Id": 74701738,
    "PostTypeId": 1,
    "Title": "Spring Boot 3 springdoc-openapi-ui doesn't work",
    "Body": "I'm trying to add swagger-ui (OpenAPI 3.0) to a Spring Boot v3 application.\nI've added the openapi-ui maven dependency, and it should work as per the documentation.\n\n    org.springdoc\n    springdoc-openapi-ui\n    1.6.11\n\n\nBut apparently, it still doesn't work and localhost:8080/swagger-ui.html returns an 404 error.\nWhat am I missing?\n\n",
    "AcceptedAnswerId": 74701779,
    "AcceptedAnswer": "According to the documentation:\n\nFor spring-boot 3 support, make sure you use springdoc-openapi v2\n\nhttps://springdoc.org/v2/\n\nFor the integration between spring-boot and swagger-ui, add the\nlibrary to the list of your project dependencies (No additional\nconfiguration is needed)\n\n\n    org.springdoc\n    springdoc-openapi-starter-webmvc-ui\n    2.0.0\n\n\n\nThis will automatically deploy swagger-ui to a spring-boot\napplication:\nDocumentation will be available in HTML format, using the official\nswagger-ui jars\nThe Swagger UI page will then be available at\nhttp://server:port/context-path/swagger-ui.html and the OpenAPI\ndescription will be available at the following url for json format:\nhttp://server:port/context-path/v3/api-docs\n\nserver: The server name or IP\n\nport: The server port\n\ncontext-path: The context path of the application\n\nDocumentation can be available in yaml format as well, on the following path : /v3/api-docs.yaml\n\n\nPlease note that modules have been renamed:\nhttps://springdoc.org/v2/#migrating-from-springdoc-v1\n\n"
}
{
    "Id": 72738837,
    "PostTypeId": 1,
    "Title": "In Java, what does the / (i.e., forward slash) mean in object references like $Lambda$15/0x00000008000a9440@32e6e9c3)?",
    "Body": "In JShell, if I do this:\ninterface Foo { String foo(); }\n(Foo) () -> \"hi\"\n\nI get\n|  created interface Foo\n$2 ==> $Lambda$15/0x00000008000a9440@32e6e9c3\n\nFrom the research below, I know the following:\n$Lambda = an in-memory reference, as opposed to one persisted to disk by an anonymous inner class (AIC), to the generated bytecode\n$15 = an object reference to the AIC\n@32e6e9c3 = the sequential number of the object created--at least, in IntelliJ\nBut what does the / (slash) indicate, as in /0x00000008000a9440?\n",
    "AcceptedAnswerId": 72887915,
    "AcceptedAnswer": "Summary\n$Lambda$15/0x00000008000a9440 is the name of the created hidden class.\nAs it will be shown below, 0x00000008000a9440 is called a suffix.\nThe name of the class can be retrieved by calling the java.lang.Class.getName() method.\nTherefore:\n\nFor example, the same class names can be retrieved by a Java program (not through JShell).\nThe question does not seem to be about JShell, but about the Java language and the Java Virtual Machine.\n\nExample program to show name of hidden class\nProgram class\npackage info.brunov.stackoverflow.question72804142;\n\nimport java.util.function.Supplier;\n\npublic final class Program {\n    public static void main(final String args[]) {\n        printRuntimeInformation();\n\n        final Supplier supplier1 = () -> \"\";\n        final Supplier supplier2 = () -> \"\";\n        final Supplier supplier3 = () -> \"\";\n        System.out.println(\n            String.format(\"Supplier 1: %s\", supplier1.getClass().getName())\n        );\n        System.out.println(\n            String.format(\"Supplier 2: %s\", supplier2.getClass().getName())\n        );\n        System.out.println(\n            String.format(\"Supplier 3: %s\", supplier3.getClass().getName())\n        );\n    }\n\n    private static void printRuntimeInformation() {\n        System.out.println(\n            String.format(\n                \"Java Virtual Machine specification name: %s\",\n                System.getProperty(\"java.vm.specification.name\")\n            )\n        );\n        System.out.println(\n            String.format(\n                \"Java Virtual Machine specification version: %s\",\n                System.getProperty(\"java.vm.specification.version\")\n            )\n        );\n        System.out.println(\n            String.format(\n                \"Java Virtual Machine specification vendor: %s\",\n                System.getProperty(\"java.vm.specification.vendor\")\n            )\n        );\n        System.out.println(\n            String.format(\n                \"Java Virtual Machine implementation name: %s\",\n                System.getProperty(\"java.vm.name\")\n            )\n        );\n        System.out.println(\n            String.format(\n                \"Java Virtual Machine implementation version: %s\",\n                System.getProperty(\"java.vm.version\")\n            )\n        );\n        System.out.println(\n            String.format(\n                \"Java Virtual Machine implementation vendor: %s\",\n                System.getProperty(\"java.vm.vendor\")\n            )\n        );\n    }\n}\n\nProgram output\nJava Virtual Machine specification name: Java Virtual Machine Specification\nJava Virtual Machine specification version: 18\nJava Virtual Machine specification vendor: Oracle Corporation\nJava Virtual Machine implementation name: OpenJDK 64-Bit Server VM\nJava Virtual Machine implementation version: 18.0.1-ea+10-Debian-1\nJava Virtual Machine implementation vendor: Debian\nSupplier 1: info.brunov.stackoverflow.question72804142.Program$$Lambda$18/0x0000000800c031f0\nSupplier 2: info.brunov.stackoverflow.question72804142.Program$$Lambda$19/0x0000000800c033f8\nSupplier 3: info.brunov.stackoverflow.question72804142.Program$$Lambda$20/0x0000000800c03600\n\nDocumentation references\nJEP 371: Hidden Classes\nThe hidden classes have been introduced since JDK 15.\nFor additional details, please, refer to the JEP: JEP 371: Hidden Classes.\nHere is an excerpt from the JEP on the hidden class names:\n\nThe major difference in how a hidden class is created lies in the name it is given. A hidden class is not anonymous. It has a name that is available via Class::getName and may be shown in diagnostics (such as the output of java -verbose:class), in JVM TI class loading events, in JFR events, and in stack traces. However, the name has a sufficiently unusual form that it effectively makes the class invisible to all other classes. The name is the concatenation of:\n\nThe binary name in internal form (JVMS 4.2.1) specified by this_class in the ClassFile structure, say A/B/C;\nThe '.' character; and\nAn unqualified name (JVMS 4.2.2) that is chosen by the JVM implementation.\n\nFor example, if this_class specifies com/example/Foo (the internal form of the binary name com.example.Foo), then a hidden class derived from the ClassFile structure may be named com/example/Foo.1234. This string is neither a binary name nor the internal form of a binary name.\nGiven a hidden class whose name is A/B/C.x, the result of Class::getName is the concatenation of:\n\nThe binary name A.B.C (obtained by taking A/B/C and replacing each '/' with '.');\nThe '/' character; and\nThe unqualified name x.\n\nFor example, if a hidden class is named com/example/Foo.1234, then the result of Class::getName is com.example.Foo/1234. Again, this string is neither a binary name nor the internal form of a binary name.\nThe namespace of hidden classes is disjoint from the namespace of normal classes. Given a ClassFile structure where this_class specifies com/example/Foo/1234, invoking cl.defineClass(\"com.example.Foo.1234\", bytes, ...) merely results in a normal class named com.example.Foo.1234, distinct from the hidden class named com.example.Foo/1234. It is impossible to create a normal class named com.example.Foo/1234 because cl.defineClass(\"com.example.Foo/1234\", bytes, ...) will reject the string argument as being not a binary name.\n\nJavadoc: java.lang.Class#getName() method\nLet's refer to the method documentation: Class (Java SE 15 & JDK 15).\nAn excerpt from the documentation:\n\npublic\u00a0String\u00a0getName()\nReturns the name of the entity (class, interface, array class, primitive type, or void) represented by this Class object.\nIf this Class object represents a class or interface, not an array class, then:\n\nIf the class or interface is not hidden, then the binary name of the class or interface is returned.\nIf the class or interface is hidden, then the result is a string of the form: N + '/' +  where N is the binary name indicated by the class file passed to Lookup::defineHiddenClass, and  is an unqualified name.\n\n\nImplementation details: OpenJDK Java Virtual Machine: Hidden class name\nIntroduction\nLet's consider the source code of OpenJDK 18.\nLet's refer to the tag: openjdk/jdk18 at jdk-18+37.\nPlease, note that:\n\nThe below execution paths are theoretical: I am using the mentioned source code tag.\nThe below call stacks are real: I am using OpenJDK 18.0.1-ea+10-Debian-1.\n\nHidden class name mangling\nHidden class creation (the java.lang.invoke.MethodHandles.Lookup.defineHiddenClass() method) includes the mangling of its name.\nLet's consider the following call stack:\n\"main@1\" prio=5 tid=0x1 nid=NA runnable\n  java.lang.Thread.State: RUNNABLE\n      at java.lang.System$2.defineClass(System.java:2346)\n      at java.lang.invoke.MethodHandles$Lookup$ClassDefiner.defineClass(MethodHandles.java:2432)\n      at java.lang.invoke.MethodHandles$Lookup$ClassDefiner.defineClassAsLookup(MethodHandles.java:2413)\n      at java.lang.invoke.MethodHandles$Lookup.defineHiddenClass(MethodHandles.java:2119)\n      at java.lang.invoke.InnerClassLambdaMetafactory.generateInnerClass(InnerClassLambdaMetafactory.java:385)\n      at java.lang.invoke.InnerClassLambdaMetafactory.spinInnerClass(InnerClassLambdaMetafactory.java:293)\n      at java.lang.invoke.InnerClassLambdaMetafactory.buildCallSite(InnerClassLambdaMetafactory.java:228)\n      at java.lang.invoke.LambdaMetafactory.metafactory(LambdaMetafactory.java:341)\n      at java.lang.invoke.DirectMethodHandle$Holder.invokeStatic(DirectMethodHandle$Holder:-1)\n      at java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder:-1)\n      at java.lang.invoke.BootstrapMethodInvoker.invoke(BootstrapMethodInvoker.java:134)\n      at java.lang.invoke.CallSite.makeSite(CallSite.java:315)\n      at java.lang.invoke.MethodHandleNatives.linkCallSiteImpl(MethodHandleNatives.java:279)\n      at java.lang.invoke.MethodHandleNatives.linkCallSite(MethodHandleNatives.java:269)\n      at info.brunov.stackoverflow.question72804142.Program.main(Program.java:9)\n\nThen let's consider the following execution path as the continuation of the call stack:\nClass java.lang.ClassLoader#defineClass0(ClassLoader loader, Class lookup, String name, byte[] b, int off, int len, ProtectionDomain pd, boolean initialize, int flags, Object classData)\n\n// Native calls below.\njclass Unsafe_DefineClass0(JNIEnv *env, jobject unsafe, jstring name, jbyteArray data, int offset, int length, jobject loader, jobject pd)\njclass Unsafe_DefineClass_impl(JNIEnv *env, jstring name, jbyteArray data, int offset, int length, jobject loader, jobject pd)\nJNIEXPORT jclass JNICALL\njclass JVM_DefineClass(JNIEnv *env, const char *name, jobject loader, const jbyte *buf, jsize len, jobject pd)\njclass jvm_define_class_common(const char *name, jobject loader, const jbyte *buf, jsize len, jobject pd, const char *source, TRAPS)\nInstanceKlass* SystemDictionary::resolve_from_stream(ClassFileStream* st, Symbol* class_name, Handle class_loader, const ClassLoadInfo& cl_info, TRAPS)\nInstanceKlass* SystemDictionary::resolve_hidden_class_from_stream(ClassFileStream* st, Symbol* class_name, Handle class_loader, const ClassLoadInfo& cl_info, TRAPS)\nInstanceKlass* KlassFactory::create_from_stream(ClassFileStream* stream, Symbol* name, ClassLoaderData* loader_data, const ClassLoadInfo& cl_info, TRAPS)\nInstanceKlass* ClassFileParser::create_instance_klass(bool changed_by_loadhook, const ClassInstanceInfo& cl_inst_info, TRAPS)\nvoid ClassFileParser::mangle_hidden_class_name(InstanceKlass* const ik)\n\nLet's refer to the piece of source code: jdk18/classFileParser.cpp at jdk-18+37 \u00b7 openjdk/jdk18:\nvoid ClassFileParser::mangle_hidden_class_name(InstanceKlass* const ik) {\n  ResourceMark rm;\n  // Construct hidden name from _class_name, \"+\", and &ik. Note that we can't\n  // use a '/' because that confuses finding the class's package.  Also, can't\n  // use an illegal char such as ';' because that causes serialization issues\n  // and issues with hidden classes that create their own hidden classes.\n  char addr_buf[20];\n  if (DumpSharedSpaces) {\n    // We want stable names for the archived hidden classes (only for static\n    // archive for now). Spaces under default_SharedBaseAddress() will be\n    // occupied by the archive at run time, so we know that no dynamically\n    // loaded InstanceKlass will be placed under there.\n    static volatile size_t counter = 0;\n    Atomic::cmpxchg(&counter, (size_t)0, Arguments::default_SharedBaseAddress()); // initialize it\n    size_t new_id = Atomic::add(&counter, (size_t)1);\n    jio_snprintf(addr_buf, 20, SIZE_FORMAT_HEX, new_id);\n  } else {\n    jio_snprintf(addr_buf, 20, INTPTR_FORMAT, p2i(ik));\n  }\n\nPlease, note that the + character is used as the separator.\nGet hidden class name\nThe java.lang.Class#getName() method includes the character replacement: + is replaced with /.\nLet's consider the following execution path:\nString java.lang.Class.getName()\nString java.lang.Class.initClassName()\n\n// Native calls below.\nJNIEXPORT jstring JNICALL JVM_InitClassName(JNIEnv *env, jclass cls)\noop java_lang_Class::name(Handle java_class, TRAPS)\nconst char* java_lang_Class::as_external_name(oop java_class)\nconst char* Klass::external_name() const\nstatic char* convert_hidden_name_to_java(Symbol* name)\n\nLet's refer to the piece of source code: jdk18/klass.cpp at jdk-18+37 \u00b7 openjdk/jdk18:\n// Replace the last '+' char with '/'.\nstatic char* convert_hidden_name_to_java(Symbol* name) {\n\n"
}
{
    "Id": 72897155,
    "PostTypeId": 1,
    "Title": "Alternate for EC2MetadataUtils",
    "Body": "In our code, to get the ec2 instance's region we are using EC2MetadataUtils.getEC2InstanceRegion(), and we just realized we must not use EC2MetadataUtils because it is an internal API that is subject to change.\n\nNote: this is an internal API subject to change. Users of the SDK should not depend on this.\n\nDid some google searches but was unable to find an alternate solution, Is there any alternative solution available to get the ec2 instance's region?\nThanks for any help!\n",
    "AcceptedAnswerId": 72928313,
    "AcceptedAnswer": "This is the implementation of the class: https://github.com/aws/aws-sdk-java/blob/master/aws-java-sdk-core/src/main/java/com/amazonaws/util/EC2MetadataUtils.java\nI have found no Java alternative for this, despite searching on google, so, I have realized that a deeper research is needed. I describe the possibilities that you have as follows:\n1. You can leave this as it is\nThe warning clearly suggests that it's a good idea to use an alternative, but the nonexistence of a ready-made alternative and possible goodies of future versions of the class are good counter-arguments, so you can ignore this note for now.\n2. You can download the open-source library and search for calls of this method\nIf you find the calls for this method somewhere else in the library and you are able to somehow use it instead, then that may be an alternative. For instance, after cloning with\ngit clone git@github.com:aws/aws-sdk-java.git\n\nand searching for occurrences of this method with:\ngrep -rn 'yourpath' -e \"getEC2InstanceRegion\"\n\nI have got these results:\n/aws-sdk-java/aws-java-sdk-core/src/main/java/com/amazonaws/util/EC2MetadataUtils.java:286:    public static String getEC2InstanceRegion() {\n/aws-sdk-java/aws-java-sdk-core/src/main/java/com/amazonaws/regions/InstanceMetadataRegionProvider.java:59:            return EC2MetadataUtils.getEC2InstanceRegion();\n/aws-sdk-java/aws-java-sdk-core/src/main/java/com/amazonaws/regions/Regions.java:110:            final String region = EC2MetadataUtils.getEC2InstanceRegion();\n\nThe first match is the definition of the method.\nThe second match looks like this:\n/*\n * Copyright 2011-2022 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\").\n * You may not use this file except in compliance with the License.\n * A copy of the License is located at\n *\n *  http://aws.amazon.com/apache2.0\n *\n * or in the \"license\" file accompanying this file. This file is distributed\n * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n * express or implied. See the License for the specific language governing\n * permissions and limitations under the License.\n */\npackage com.amazonaws.regions;\n\nimport com.amazonaws.AmazonClientException;\nimport com.amazonaws.SDKGlobalConfiguration;\nimport com.amazonaws.util.EC2MetadataUtils;\nimport org.apache.commons.logging.Log;\nimport org.apache.commons.logging.LogFactory;\n\n/**\n * Attempts to load region information from the EC2 Metadata service. If the application is not\n * running on EC2 or {@link SDKGlobalConfiguration#isEc2MetadataDisabled()} returns true,\n * this provider will return null.\n */\npublic class InstanceMetadataRegionProvider extends AwsRegionProvider {\n\n    private static final Log LOG = LogFactory.getLog(InstanceMetadataRegionProvider.class);\n\n    /**\n     * Cache region as it will not change during the lifetime of the JVM.\n     */\n    private volatile String region;\n\n    /**\n     * @throws AmazonClientException if {@link SDKGlobalConfiguration#isEc2MetadataDisabled()} is true\n     */\n    @Override\n    public String getRegion() {\n        if (SDKGlobalConfiguration.isEc2MetadataDisabled()) {\n            throw new AmazonClientException(\"AWS_EC2_METADATA_DISABLED is set to true, not loading region from EC2 Instance \"\n                                         + \"Metadata service\");\n        }\n\n        if (region == null) {\n            synchronized (this) {\n                if (region == null) {\n                    this.region = tryDetectRegion();\n                }\n            }\n        }\n        return region;\n    }\n\n    private String tryDetectRegion() {\n        try {\n            return EC2MetadataUtils.getEC2InstanceRegion();\n        } catch (AmazonClientException sce) {\n            LOG.debug(\"Ignoring failure to retrieve the region: \" + sce.getMessage());\n            return null;\n        }\n    }\n}\n\nSo, it seems that the getRegion method of InstanceMetadataRegionProvider looks like the alternative that you were looking for.\nThe third match looks like this:\n/*\n * Copyright 2013-2022 Amazon Technologies, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at:\n *\n *    http://aws.amazon.com/apache2.0\n *\n * This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES\n * OR CONDITIONS OF ANY KIND, either express or implied. See the\n * License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.amazonaws.regions;\n\nimport com.amazonaws.AmazonClientException;\nimport org.apache.commons.logging.LogFactory;\n\nimport com.amazonaws.util.EC2MetadataUtils;\n\n/**\n * Enumeration of region names\n */\npublic enum Regions {\n\n    GovCloud(\"us-gov-west-1\", \"AWS GovCloud (US)\"),\n    US_GOV_EAST_1(\"us-gov-east-1\", \"AWS GovCloud (US-East)\"),\n    US_EAST_1(\"us-east-1\", \"US East (N. Virginia)\"),\n    US_EAST_2(\"us-east-2\", \"US East (Ohio)\"),\n    US_WEST_1(\"us-west-1\", \"US West (N. California)\"),\n    US_WEST_2(\"us-west-2\", \"US West (Oregon)\"),\n    EU_WEST_1(\"eu-west-1\", \"EU (Ireland)\"),\n    EU_WEST_2(\"eu-west-2\", \"EU (London)\"),\n    EU_WEST_3(\"eu-west-3\", \"EU (Paris)\"),\n    EU_CENTRAL_1(\"eu-central-1\", \"EU (Frankfurt)\"),\n    EU_NORTH_1(\"eu-north-1\", \"EU (Stockholm)\"),\n    EU_SOUTH_1(\"eu-south-1\", \"EU (Milan)\"),\n    AP_EAST_1(\"ap-east-1\", \"Asia Pacific (Hong Kong)\"),\n    AP_SOUTH_1(\"ap-south-1\", \"Asia Pacific (Mumbai)\"),\n    AP_SOUTHEAST_1(\"ap-southeast-1\", \"Asia Pacific (Singapore)\"),\n    AP_SOUTHEAST_2(\"ap-southeast-2\", \"Asia Pacific (Sydney)\"),\n    AP_SOUTHEAST_3(\"ap-southeast-3\", \"Asia Pacific (Jakarta)\"),\n    AP_NORTHEAST_1(\"ap-northeast-1\", \"Asia Pacific (Tokyo)\"),\n    AP_NORTHEAST_2(\"ap-northeast-2\", \"Asia Pacific (Seoul)\"),\n    AP_NORTHEAST_3(\"ap-northeast-3\", \"Asia Pacific (Osaka)\"),\n\n    SA_EAST_1(\"sa-east-1\", \"South America (Sao Paulo)\"),\n    CN_NORTH_1(\"cn-north-1\", \"China (Beijing)\"),\n    CN_NORTHWEST_1(\"cn-northwest-1\", \"China (Ningxia)\"),\n    CA_CENTRAL_1(\"ca-central-1\", \"Canada (Central)\"),\n    ME_SOUTH_1(\"me-south-1\", \"Middle East (Bahrain)\"),\n    AF_SOUTH_1(\"af-south-1\", \"Africa (Cape Town)\"),\n    US_ISO_EAST_1(\"us-iso-east-1\", \"US ISO East\"),\n    US_ISOB_EAST_1(\"us-isob-east-1\", \"US ISOB East (Ohio)\"),\n    US_ISO_WEST_1(\"us-iso-west-1\", \"US ISO West\")\n    ;\n\n    /**\n     * The default region that new customers in the US are encouraged to use\n     * when using AWS services for the first time.\n     */\n    public static final Regions DEFAULT_REGION = US_WEST_2;\n\n    private final String name;\n    private final String description;\n\n    private Regions(String name, String description) {\n        this.name = name;\n        this.description = description;\n    }\n\n    /**\n     * The name of this region, used in the regions.xml file to identify it.\n     */\n    public String getName() {\n        return name;\n    }\n\n    /**\n     * Descriptive readable name for this region.\n     */\n    public String getDescription() {\n        return description;\n    }\n\n    /**\n     * Returns a region enum corresponding to the given region name.\n     *\n     * @param regionName\n     *            The name of the region. Ex.: eu-west-1\n     * @return Region enum representing the given region name.\n     */\n    public static Regions fromName(String regionName) {\n        for (Regions region : Regions.values()) {\n            if (region.getName().equals(regionName)) {\n                return region;\n            }\n        }\n        throw new IllegalArgumentException(\"Cannot create enum from \" + regionName + \" value!\");\n    }\n\n    /**\n     * Returns a Region object representing the region the application is\n     * running in, when running in EC2. If this method is called from a non-EC2\n     * environment, it will return null.\n     */\n    public static Region getCurrentRegion() {\n        try {\n            final String region = EC2MetadataUtils.getEC2InstanceRegion();\n            if (region != null)\n                return RegionUtils.getRegion(region);\n        } catch (AmazonClientException e) {\n            LogFactory.getLog(Regions.class).debug(\n                \"Ignoring failure to retrieve the region: \" + e.getMessage());\n        }\n        return null;\n    }\n}\n\nSo, getCurrentRegion at Regions looks like another alternative. If you manage to use one of these for your purpose successfully, then it will be easy to refactor and it also makes sense to refactor accordingly.\n3. Copy and rename the class\nIf the first two options are unfeasible for you, then you can copy and rename the class, so you will be able to make sure that this method will remain unchanged even if the internal API is changed. This is not a very elegant approach and it is not easy to implement either, as the class has dependencies, so, as a result, you will have some difficulties to resolve, but we know in advance that this is a possible solution.\n4. Finally the do-it-yourself approach\nThis is an article about retrieving instance metadata: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instancedata-data-retrieval.html\nAs we can see, among the metadata information of the instance, you can find the region: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instancedata-data-categories.html\n\nA command example that uses curl and jq that looks like\ncurl -s http://169.254.169.254/latest/dynamic/instance-identity/document | jq -r .region\n\ncan be found here: https://www.howtouselinux.com/post/find-ec2-instance-region-info-in-aws\n"
}
{
    "Id": 74781733,
    "PostTypeId": 1,
    "Title": "vulnerable dependency maven:org.yaml:snakeyaml",
    "Body": "I am periodically checking vulnerabilities on my pom.xml and generally fix these problems by updating the dependency versions. However, I get the following error:\n\nProvides transitive vulnerable dependency maven:org.yaml:snakeyaml:1.30 CVE-2022-25857 7.5 Uncontrolled Resource Consumption vulnerability pending CVSS allocation CVE-2022-38752 6.5\nOut-of-bounds Write vulnerability with medium severity found CVE-2022-38749 6.5 Out-of-bounds Write vulnerability pending CVSS allocation CVE-2022-38750 5.5\nOut-of-bounds Write vulnerability pending CVSS allocation CVE-2022-38751 6.5 Out-of-bounds Write vulnerability pending CVSS allocation CVE-2022-41854 6.5\nStack-based Buffer Overflow vulnerability with medium severity found CVE-2022-1471 9.8\nDeserialization of Untrusted Data vulnerability with high severity found\nResults powered by Checkmarx(c)\n\nI I try to add  to the spring-boot-starter-web in my pom.xml, but it does not make any sense.\nSo, how can I fix this problem properly? I use IntelliJ default features to fix this kind of problems, but should I do any an extra useful plugins etc.?\n",
    "AcceptedAnswerId": 74781869,
    "AcceptedAnswer": "Unfortunately, Spring Boot 2.7.x still uses an older, vulnerable version of SnakeYAML (1.30). They still have not upgraded it to the last version (1.33). Spring Boot 3.0.0 does depend on version 1.33.\nAssuming you cannot upgrade to Spring Boot 3.0.0 yet, the only thing that should work is to add a dependency to SnakeYAML 1.33 in your project. That version should then take precedence over Spring Boot's transitive dependency.\nHowever, SnakeYAML 1.33 still has a vulnerability. Since that is the last version (SnakeYAML 2.x is not compatible with 1.x), that's something you can't get rid off until the SnakeYAML team fixes that.\nEdit: with SnakeYAML 2.x, I meant this one. SnakeYAML 1.33 recently had a follow-up 2.0 version which is a different one. Compatibility between 1.33 and 2.0 is still not 100%, but Spring Boot 2.7.10+ and Spring Boot 3.x should support both.\n"
}
{
    "Id": 72692978,
    "PostTypeId": 1,
    "Title": "Eclipse: Project 'PROJECT_NAME' has no explicit encoding set",
    "Body": "I downgraded from Windows 11 to Windows 10 today and had to reinstall the Eclipse-IDE.\nAfter successfully importing my workspaces and fixing the projects, a warning appeared for every project saying \"Project XXX has no explicit encoding set\". I've already searched for a solution and only got some fixes for VSCode.\nI had Eclipse 2021-6 and installed Eclipse 2022-6\n",
    "AcceptedAnswerId": 72947638,
    "AcceptedAnswer": "Yes, the warning for projects with no explicit default encoding is a new thing in Eclipse 2022-06 (4.24).\nTo set an explicit default encoding do one of the following:\n\nIn the Problems view, select the warning, hit Ctrl+1 and apply the provided Quick Fix (sets the project encoding explicitly to the workspace encoding)\nChange the project manually in Project > Properties: Resource\n\nSee also my video showing and explaining this.\n"
}
{
    "Id": 73077902,
    "PostTypeId": 1,
    "Title": "Accessing protected method of anonymous object vs by a named reference",
    "Body": "Say I have this abstract class:\npackage test.one;\n\npublic abstract class One {\n  \n  protected abstract void whatever();\n\n  public void run() {\n    whatever();\n  }\n  \n}\n\nAnd use it like this:\npackage test.two;\n\nimport test.one.One;\n\npublic class Three {\n\n  public static void main(String[] args) {\n    One one = new One() {\n      @Override\n      protected void whatever() {\n        System.out.println(\"Do whatever..\");\n      }\n    };\n    one.whatever();\n  }\n}\n\nThis code fails on compilation which is pretty much expected.\ntest/two/Three.java:14: error: whatever() has protected access in One\n    one.whatever();\n       ^\n1 error\n\nBut the below code compiles successfully which seems surprisingly:\npackage test.two;\n\nimport test.one.One;\n\npublic class Two {\n\n  public static void main(String[] args) {\n    new One() {\n      @Override\n      protected void whatever() {\n        System.out.println(\"Do whatever..\");\n      }\n    }.whatever();\n  }\n}\n\nThe difference is that in the latter case I'm accessing the method without a named reference. Why does the compiler allow such access?\n",
    "AcceptedAnswerId": 73078028,
    "AcceptedAnswer": "\nThe difference is that in the latter case I'm accessing the method without a named reference. Why does the compiler allow such access?\n\nNo, the difference is that in the latter case you're accessing the method on the anonymous class rather than on a reference of type One.\nLeaving aside the oddities around protected access, you can see the difference very easily by just creating an anonymous class with a public method:\nclass Test {\n    public static void main(String[] args) {\n        // This is fine...\n        new Object() {\n            public void method() {\n                System.out.println(\"Called\");\n            }\n        }.method();\n        \n        // This is not, because Object doesn't contain a method called \"method\".\n        Object o = new Object() {\n            public void method() {\n                System.out.println(\"Called\");\n            }\n        };\n        o.method();        \n    }\n}\n\nAs noted in comments, another way to see the same effect is to use var, so that the compile-time type of the variable is the anonymous class.\nEven private members within anonymous classes can be accessed within the containing scope, just as if they were normal nested classes.\n"
}
{
    "Id": 72635074,
    "PostTypeId": 1,
    "Title": "Java Record with @Builder.Default",
    "Body": "I'm wondering is there any way to combine java record with lombok's @Builder.Default?\nLet's consider an example with properties object for new file creation.\nBefore java 14\n@Value\n@Builder\npublic class FileProperties {\n    @Builder.Default\n    String directory = System.getProperty(\"user.home\");\n    @Builder.Default\n    String name = \"New file\";\n    @Builder.Default\n    String extension = \".txt\";\n}\n\nJava 14\n@Builder\npublic record FileProperties (\n        String directory,\n        String name,\n        String extension\n) {}\n\nBut in case if I try to use something like\n@Builder\npublic record FileProperties (\n        @Builder.Default\n        String directory = System.getProperty(\"user.home\")\n) {}\n\nCompiler will fail with an error, revealing that such syntax is not allowed. Do we have any solution to this problem?\n",
    "AcceptedAnswerId": 75812314,
    "AcceptedAnswer": "This functionality is not available at the moment. Please check the first comment under the question\n\nNot right now, I hadn't considered that when extending support of @Builder to records.\n\n"
}
{
    "Id": 73162834,
    "PostTypeId": 1,
    "Title": "Why writing map entries to a HashSet is slower than to a CopyOnWriteArraySet in Java",
    "Body": "I think writing to a HashSet will be faster than to a CopyOnWriteArraySet; I'm not doing multi threading here. However I surpisingly got benchmark results indicate writing map entries to a CopyOnWriteArraySet is faster.\nI did benchmarking on writing 1000 of Map.Entry into a HashSet vs CopyOnWriteArraySet.\nBenchmark          (n)   Mode  Cnt     Score    Error  Units\nA.writeToCOWAS    1000  thrpt    4  1269.214 \u00b1 40.635  ops/s\nA.writeToHashSet  1000  thrpt    4   223.118 \u00b1 34.955  ops/s\n\nIn addition to that, I got benchmark results of equals() and hashCode() of Map.Entry reveal that the former is more expensive.\nBenchmark           Mode  Cnt          Score          Error  Units\nMapEntry.equals    thrpt    4  177773394.054 \u00b1 75436098.388  ops/s\nMapEntry.hashCode  thrpt    4  272240403.923 \u00b1 38794396.671  ops/s\n\nI believe writing to a HashSet calls to hashCode() while CopyOnWriteArraySet calls to equals().\nIn the case of writing Integer or String,HashSet is way faster. Then I'm wondering what happens with Map.Entry type and why CopyOnWriteArraySet is faster according to my analysis?\nMy perf test:\n@State(Scope.Benchmark)\n@Fork(value = 2)\n@Warmup(iterations = 2, time = 3)\n@Measurement(iterations = 2, time = 3)\npublic class A {\n    public Set> set;\n\n    @Param({\"1000\"})\n    public int n;\n\n    @Setup\n    public void setup() {\n        set = new HashSet((int) (n / 0.75f + 1f), 0.75f);\n        for (int i = 0; i < n; i++)\n            set.add(Map.entry(i, i));\n    }\n\n    private void eliminateDeadCode(Set> out, Blackhole hole) {\n        int hash = 0;\n        for (Map.Entry o : out)\n            hash += o.hashCode();\n        hole.consume(hash);\n        if (out.size() != set.size())\n            throw new RuntimeException(out.size() + \" != \" + set.size());\n    }\n\n    @Benchmark\n    public void writeToCOWAS(Blackhole hole) {\n        Set> out = new CopyOnWriteArraySet(set);\n        eliminateDeadCode(out, hole);\n    }\n\n    @Benchmark\n    public void writeToHashSet(Blackhole hole) {\n        Set> out = new HashSet(set);\n        eliminateDeadCode(out, hole);\n    }\n\n    public static void main(String[] args) throws RunnerException {\n        Options opt = new OptionsBuilder()\n                .include(A.class.getSimpleName())\n                .build();\n        new Runner(opt).run();\n    }\n}\n\n",
    "AcceptedAnswerId": 73188382,
    "AcceptedAnswer": "Hulk's answer is very instructive. However the problem is not necessarily the Map.entry() hashCode implementation, which is this, at least in Java 11:\npublic int hashCode() {\n    return key.hashCode() ^ value.hashCode();\n}\n\nThe problem is that the hash codes of key and value are always the same, both in the OP's test, and in Hulk's test, hence the hash codes combined via XOR will always end up as 0. Change it so that key and value are different, and performance will change.\n"
}
{
    "Id": 73226675,
    "PostTypeId": 1,
    "Title": "Why does this test take longer without garbage collection overhead?",
    "Body": "I ran into this scenario in the process of developing a lightweight library for asynchronous messaging. Trying to get an idea of the cost of creating lots of medium sized objects with short lifetimes, I wrote the following test:\nimport java.nio.ByteBuffer;\nimport java.util.Random;\n\n\npublic class MemPressureTest {\n    static final int SIZE = 4096;\n    static final class Bigish {\n        final ByteBuffer b;\n\n\n        public Bigish() {\n            this(ByteBuffer.allocate(SIZE));\n        }\n\n        public Bigish(ByteBuffer b) {\n            this.b = b;\n        }\n\n        public void fill(byte bt) {\n            b.clear();\n            for (int i = 0; i < SIZE; ++i) {\n                b.put(bt);\n            }\n        }\n    }\n\n\n    public static void main(String[] args) {\n        Random random = new Random(1);\n        Bigish tmp = new Bigish();\n        for (int i = 0; i < 3e7; ++i) {\n            tmp.fill((byte)random.nextInt(255));\n        }\n    }\n}\n\nOn my laptop, with default GC settings, it runs in about 95 seconds:\n/tmp$ time java -Xlog:gc MemPressureTest\n[0.006s][info][gc] Using G1\n\nreal    1m35.552s\nuser    1m33.658s\nsys 0m0.428s\n\nThis is where things get strange. I tweaked the program to allocate a new object for each iteration:\n...\n        Random random = new Random(1);\n        for (int i = 0; i < 3e7; ++i) {\n            Bigish tmp = new Bigish();\n            tmp.fill((byte)random.nextInt(255));\n        }\n...\n\nIn theory, this should add some small overhead, but none of the objects should ever be promoted out of Eden. At best, I'd expect the runtimes to be close to identical. However, this test completes in ~17 seconds:\n/tmp$ time java -Xlog:gc MemPressureTest\n[0.007s][info][gc] Using G1\n[0.090s][info][gc] GC(0) Pause Young (Normal) (G1 Evacuation Pause) 23M->1M(130M) 1.304ms\n[0.181s][info][gc] GC(1) Pause Young (Normal) (G1 Evacuation Pause) 76M->1M(130M) 0.870ms\n[0.247s][info][gc] GC(2) Pause Young (Normal) (G1 Evacuation Pause) 76M->0M(130M) 0.844ms\n[0.317s][info][gc] GC(3) Pause Young (Normal) (G1 Evacuation Pause) 75M->0M(130M) 0.793ms\n[0.381s][info][gc] GC(4) Pause Young (Normal) (G1 Evacuation Pause) 75M->0M(130M) 0.859ms\n[lots of similar GC pauses, snipped for brevity]\n[16.608s][info][gc] GC(482) Pause Young (Normal) (G1 Evacuation Pause) 254M->0M(425M) 0.765ms\n[16.643s][info][gc] GC(483) Pause Young (Normal) (G1 Evacuation Pause) 254M->0M(425M) 0.580ms\n[16.676s][info][gc] GC(484) Pause Young (Normal) (G1 Evacuation Pause) 254M->0M(425M) 0.841ms\n\nreal    0m16.766s\nuser    0m16.578s\nsys 0m0.576s\n\nI ran both versions several times, with near identical results to the above. I feel like I must be missing something very obvious. Am I going insane? What could explain this difference in performance?\n=== EDIT ===\nI rewrote the test using JMH as per apangin and dan1st's suggestions:\nimport org.openjdk.jmh.annotations.*;\nimport org.openjdk.jmh.infra.Blackhole;\n\nimport java.nio.ByteBuffer;\nimport java.util.Random;\n\n\npublic class MemPressureTest {\n    static final int SIZE = 4096;\n\n    @State(Scope.Benchmark)\n    public static class Bigish {\n        final ByteBuffer b;\n        private Blackhole blackhole;\n\n\n        @Setup(Level.Trial)\n        public void setup(Blackhole blackhole) {\n            this.blackhole = blackhole;\n        }\n\n        public Bigish() {\n            this.b = ByteBuffer.allocate(SIZE);\n        }\n\n        public void fill(byte bt) {\n            b.clear();\n            for (int i = 0; i < SIZE; ++i) {\n                b.put(bt);\n            }\n            blackhole.consume(b);\n        }\n    }\n\n    static Random random = new Random(1);\n\n\n    @Benchmark\n    public static void test1(Blackhole blackhole) {\n        Bigish tmp = new Bigish();\n        tmp.setup(blackhole);\n        tmp.fill((byte)random.nextInt(255));\n        blackhole.consume(tmp);\n    }\n\n    @Benchmark\n    public static void test2(Bigish perm) {\n        perm.fill((byte) random.nextInt(255));\n    }\n}\n\nStill, the second test much slower:\n> Task :jmh\n# JMH version: 1.35\n# VM version: JDK 18.0.1.1, OpenJDK 64-Bit Server VM, 18.0.1.1+2-6\n# VM invoker: /Users/xxx/Library/Java/JavaVirtualMachines/openjdk-18.0.1.1/Contents/Home/bin/java\n# VM options: -Dfile.encoding=UTF-8 -Djava.io.tmpdir=/Users/xxx/Dev/MemTests/build/tmp/jmh -Duser.country=US -Duser.language=en -Duser.variant\n# Blackhole mode: compiler (auto-detected, use -Djmh.blackhole.autoDetect=false to disable)\n# Warmup: 5 iterations, 10 s each\n# Measurement: 5 iterations, 10 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Throughput, ops/time\n# Benchmark: com.xxx.MemPressureTest.test1\n\n# Run progress: 0.00% complete, ETA 00:16:40\n# Fork: 1 of 5\n# Warmup Iteration   1: 2183998.556 ops/s\n# Warmup Iteration   2: 2281885.941 ops/s\n# Warmup Iteration   3: 2239644.018 ops/s\n# Warmup Iteration   4: 1608047.994 ops/s\n# Warmup Iteration   5: 1992314.001 ops/s\nIteration   1: 2053657.571 ops/s3s]\nIteration   2: 2054957.773 ops/sm 3s]\nIteration   3: 2051595.233 ops/sm 13s]\nIteration   4: 2054878.239 ops/sm 23s]\nIteration   5: 2031111.214 ops/sm 33s]\n\n# Run progress: 10.00% complete, ETA 00:15:04\n# Fork: 2 of 5\n# Warmup Iteration   1: 2228594.345 ops/s\n# Warmup Iteration   2: 2257983.355 ops/s\n# Warmup Iteration   3: 2063130.244 ops/s\n# Warmup Iteration   4: 1629084.669 ops/s\n# Warmup Iteration   5: 2063018.496 ops/s\nIteration   1: 1939260.937 ops/sm 33s]\nIteration   2: 1791414.018 ops/sm 43s]\nIteration   3: 1914987.221 ops/sm 53s]\nIteration   4: 1969484.898 ops/sm 3s]\nIteration   5: 1891440.624 ops/sm 13s]\n\n# Run progress: 20.00% complete, ETA 00:13:23\n# Fork: 3 of 5\n# Warmup Iteration   1: 2228664.719 ops/s\n# Warmup Iteration   2: 2263677.403 ops/s\n# Warmup Iteration   3: 2237032.464 ops/s\n# Warmup Iteration   4: 2040040.243 ops/s\n# Warmup Iteration   5: 2038848.530 ops/s\nIteration   1: 2023934.952 ops/sm 14s]\nIteration   2: 2041874.437 ops/sm 24s]\nIteration   3: 2002858.770 ops/sm 34s]\nIteration   4: 2039727.607 ops/sm 44s]\nIteration   5: 2045827.670 ops/sm 54s]\n\n# Run progress: 30.00% complete, ETA 00:11:43\n# Fork: 4 of 5\n# Warmup Iteration   1: 2105430.688 ops/s\n# Warmup Iteration   2: 2279387.762 ops/s\n# Warmup Iteration   3: 2228346.691 ops/s\n# Warmup Iteration   4: 1438607.183 ops/s\n# Warmup Iteration   5: 2059319.745 ops/s\nIteration   1: 1112543.932 ops/sm 54s]\nIteration   2: 1977077.976 ops/sm 4s]\nIteration   3: 2040147.355 ops/sm 14s]\nIteration   4: 1975766.032 ops/sm 24s]\nIteration   5: 2003532.092 ops/sm 34s]\n\n# Run progress: 40.00% complete, ETA 00:10:02\n# Fork: 5 of 5\n# Warmup Iteration   1: 2240203.848 ops/s\n# Warmup Iteration   2: 2245673.994 ops/s\n# Warmup Iteration   3: 2096257.864 ops/s\n# Warmup Iteration   4: 2046527.740 ops/s\n# Warmup Iteration   5: 2050379.941 ops/s\nIteration   1: 2050691.989 ops/sm 35s]\nIteration   2: 2057803.100 ops/sm 45s]\nIteration   3: 2058634.766 ops/sm 55s]\nIteration   4: 2060596.595 ops/sm 5s]\nIteration   5: 2061282.107 ops/sm 15s]\n\n\nResult \"com.xxx.MemPressureTest.test1\":\n  1972203.484 \u00b1(99.9%) 142904.698 ops/s [Average]\n  (min, avg, max) = (1112543.932, 1972203.484, 2061282.107), stdev = 190773.683\n  CI (99.9%): [1829298.786, 2115108.182] (assumes normal distribution)\n\n\n# JMH version: 1.35\n# VM version: JDK 18.0.1.1, OpenJDK 64-Bit Server VM, 18.0.1.1+2-6\n# VM invoker: /Users/xxx/Library/Java/JavaVirtualMachines/openjdk-18.0.1.1/Contents/Home/bin/java\n# VM options: -Dfile.encoding=UTF-8 -Djava.io.tmpdir=/Users/xxx/Dev/MemTests/build/tmp/jmh -Duser.country=US -Duser.language=en -Duser.variant\n# Blackhole mode: compiler (auto-detected, use -Djmh.blackhole.autoDetect=false to disable)\n# Warmup: 5 iterations, 10 s each\n# Measurement: 5 iterations, 10 s each\n# Timeout: 10 min per iteration\n# Threads: 1 thread, will synchronize iterations\n# Benchmark mode: Throughput, ops/time\n# Benchmark: com.xxx.MemPressureTest.test2\n\n# Run progress: 50.00% complete, ETA 00:08:22\n# Fork: 1 of 5\n# Warmup Iteration   1: 282751.407 ops/s\n# Warmup Iteration   2: 283333.984 ops/s\n# Warmup Iteration   3: 293785.079 ops/s\n# Warmup Iteration   4: 268403.105 ops/s\n# Warmup Iteration   5: 280054.277 ops/s\nIteration   1: 279093.118 ops/s9m 15s]\nIteration   2: 282782.996 ops/s9m 25s]\nIteration   3: 282688.921 ops/s9m 35s]\nIteration   4: 291578.963 ops/s9m 45s]\nIteration   5: 294835.777 ops/s9m 55s]\n\n# Run progress: 60.00% complete, ETA 00:06:41\n# Fork: 2 of 5\n# Warmup Iteration   1: 283735.550 ops/s\n# Warmup Iteration   2: 283536.547 ops/s\n# Warmup Iteration   3: 294403.173 ops/s\n# Warmup Iteration   4: 284161.042 ops/s\n# Warmup Iteration   5: 281719.077 ops/s\nIteration   1: 276838.416 ops/s10m 56s]\nIteration   2: 284063.117 ops/s11m 6s]\nIteration   3: 282361.985 ops/s11m 16s]\nIteration   4: 289125.092 ops/s11m 26s]\nIteration   5: 294236.625 ops/s11m 36s]\n\n# Run progress: 70.00% complete, ETA 00:05:01\n# Fork: 3 of 5\n# Warmup Iteration   1: 284567.336 ops/s\n# Warmup Iteration   2: 283548.713 ops/s\n# Warmup Iteration   3: 294317.511 ops/s\n# Warmup Iteration   4: 283501.873 ops/s\n# Warmup Iteration   5: 283691.306 ops/s\nIteration   1: 283462.749 ops/s12m 36s]\nIteration   2: 284120.587 ops/s12m 46s]\nIteration   3: 264878.952 ops/s12m 56s]\nIteration   4: 292681.168 ops/s13m 6s]\nIteration   5: 295279.759 ops/s13m 16s]\n\n# Run progress: 80.00% complete, ETA 00:03:20\n# Fork: 4 of 5\n# Warmup Iteration   1: 284823.519 ops/s\n# Warmup Iteration   2: 283913.207 ops/s\n# Warmup Iteration   3: 294401.483 ops/s\n# Warmup Iteration   4: 283998.027 ops/s\n# Warmup Iteration   5: 283987.408 ops/s\nIteration   1: 278014.618 ops/s14m 17s]\nIteration   2: 283431.491 ops/s14m 27s]\nIteration   3: 284465.945 ops/s14m 37s]\nIteration   4: 293202.934 ops/s14m 47s]\nIteration   5: 290059.807 ops/s14m 57s]\n\n# Run progress: 90.00% complete, ETA 00:01:40\n# Fork: 5 of 5\n# Warmup Iteration   1: 285598.809 ops/s\n# Warmup Iteration   2: 284434.916 ops/s\n# Warmup Iteration   3: 294355.547 ops/s\n# Warmup Iteration   4: 284307.860 ops/s\n# Warmup Iteration   5: 284297.362 ops/s\nIteration   1: 283676.043 ops/s15m 57s]\nIteration   2: 283609.750 ops/s16m 7s]\nIteration   3: 284575.124 ops/s16m 17s]\nIteration   4: 293564.269 ops/s16m 27s]\nIteration   5: 216267.883 ops/s16m 37s]\n\n\nResult \"com.xxx.MemPressureTest.test2\":\n  282755.844 \u00b1(99.9%) 11599.112 ops/s [Average]\n  (min, avg, max) = (216267.883, 282755.844, 295279.759), stdev = 15484.483\n  CI (99.9%): [271156.731, 294354.956] (assumes normal distribution)\n\nThe JMH Blackhole should prevent code removal and the fact that JMH is now in charge of running separate iterations should prevent parallelization, right? Shouldn't Blackhole also stop the object from being confined to the stack? Also, wouldn't there be more variation between warmup iterations if hotspot were still doing a significant amount of optimization?\n",
    "AcceptedAnswerId": 73268952,
    "AcceptedAnswer": "Creating a new ByteBuffer right before filling, indeed helps JIT compiler to produce better optimized code, when you use relative put methods, and here is why.\n\nJIT compilation unit is a method. HotSpot JVM does not perform a whole-program optimization, which is quite hard even in theory due to dynamic nature of Java and the open world runtime environment.\nWhen the JVM compiles test1 method, buffer instantiation appears in the same compilation scope as filling:\n\nBigish tmp = new Bigish();\ntmp.setup(blackhole);\ntmp.fill((byte)random.nextInt(255));\n\nThe JVM knows everything about the created buffer: its exact size and its backing array, it knows the buffer has not been published yet, no other thread sees it. So, the JVM can agressively optimize the fill loop: vectorize it using AVX instructions and unroll it to set 512 bytes at a time:\n  0x000001cdf60c9ae0:   mov    %r9d,%r8d\n  0x000001cdf60c9ae3:   movslq %r8d,%r9\n  0x000001cdf60c9ae6:   add    %r11,%r9\n  0x000001cdf60c9ae9:   vmovdqu %ymm0,0x10(%rcx,%r9,1)\n  0x000001cdf60c9af0:   vmovdqu %ymm0,0x30(%rcx,%r9,1)\n  0x000001cdf60c9af7:   vmovdqu %ymm0,0x50(%rcx,%r9,1)\n  0x000001cdf60c9afe:   vmovdqu %ymm0,0x70(%rcx,%r9,1)\n  0x000001cdf60c9b05:   vmovdqu %ymm0,0x90(%rcx,%r9,1)\n  0x000001cdf60c9b0f:   vmovdqu %ymm0,0xb0(%rcx,%r9,1)\n  0x000001cdf60c9b19:   vmovdqu %ymm0,0xd0(%rcx,%r9,1)\n  0x000001cdf60c9b23:   vmovdqu %ymm0,0xf0(%rcx,%r9,1)\n  0x000001cdf60c9b2d:   vmovdqu %ymm0,0x110(%rcx,%r9,1)\n  0x000001cdf60c9b37:   vmovdqu %ymm0,0x130(%rcx,%r9,1)\n  0x000001cdf60c9b41:   vmovdqu %ymm0,0x150(%rcx,%r9,1)\n  0x000001cdf60c9b4b:   vmovdqu %ymm0,0x170(%rcx,%r9,1)\n  0x000001cdf60c9b55:   vmovdqu %ymm0,0x190(%rcx,%r9,1)\n  0x000001cdf60c9b5f:   vmovdqu %ymm0,0x1b0(%rcx,%r9,1)\n  0x000001cdf60c9b69:   vmovdqu %ymm0,0x1d0(%rcx,%r9,1)\n  0x000001cdf60c9b73:   vmovdqu %ymm0,0x1f0(%rcx,%r9,1)\n  0x000001cdf60c9b7d:   mov    %r8d,%r9d\n  0x000001cdf60c9b80:   add    $0x200,%r9d\n  0x000001cdf60c9b87:   cmp    %r10d,%r9d\n  0x000001cdf60c9b8a:   jl     0x000001cdf60c9ae0\n\n\nYou use relative put method. It not only sets a byte in a ByteBuffer, but also updates the position field. Note that the above vectorized loop does not update the position in memory. JVM sets it just once after the loop - it is allowed to do so as long as nobody can observe an inconsistent state of the buffer.\nNow try to publish ByteBuffer before filling:\n\nBigish tmp = new Bigish();\nvolatileField = tmp;  // publish\ntmp.setup(blackhole);\ntmp.fill((byte)random.nextInt(255));\n\nThe loop optimization breaks; now the array bytes are filled one by one, and the position field is incremented accordingly.\n  0x000001829b18ca5c:   nopl   0x0(%rax)\n  0x000001829b18ca60:   cmp    %r11d,%esi\n  0x000001829b18ca63:   jge    0x000001829b18ce34           ;*if_icmplt {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - java.nio.Buffer::nextPutIndex@10 (line 721)\n                                                            ; - java.nio.HeapByteBuffer::put@6 (line 209)\n                                                            ; - bench.MemPressureTest$Bigish::fill@22 (line 33)\n                                                            ; - bench.MemPressureTest::test1@28 (line 47)\n  0x000001829b18ca69:   mov    %esi,%ecx\n  0x000001829b18ca6b:   add    %edx,%ecx                    ;*getfield position {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - java.nio.Buffer::nextPutIndex@1 (line 720)\n                                                            ; - java.nio.HeapByteBuffer::put@6 (line 209)\n                                                            ; - bench.MemPressureTest$Bigish::fill@22 (line 33)\n                                                            ; - bench.MemPressureTest::test1@28 (line 47)\n  0x000001829b18ca6d:   mov    %esi,%eax\n  0x000001829b18ca6f:   inc    %eax                         ;*iinc {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - bench.MemPressureTest$Bigish::fill@26 (line 32)\n                                                            ; - bench.MemPressureTest::test1@28 (line 47)\n  0x000001829b18ca71:   mov    %eax,0x18(%r10)              ;*putfield position {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - java.nio.Buffer::nextPutIndex@25 (line 723)\n                                                            ; - java.nio.HeapByteBuffer::put@6 (line 209)\n                                                            ; - bench.MemPressureTest$Bigish::fill@22 (line 33)\n                                                            ; - bench.MemPressureTest::test1@28 (line 47)\n  0x000001829b18ca75:   cmp    %r8d,%ecx\n  0x000001829b18ca78:   jae    0x000001829b18ce14\n  0x000001829b18ca7e:   movslq %esi,%r9\n  0x000001829b18ca81:   add    %r14,%r9\n  0x000001829b18ca84:   mov    %bl,0x10(%rdi,%r9,1)         ;*bastore {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - java.nio.HeapByteBuffer::put@13 (line 209)\n                                                            ; - bench.MemPressureTest$Bigish::fill@22 (line 33)\n                                                            ; - bench.MemPressureTest::test1@28 (line 47)\n  0x000001829b18ca89:   cmp    $0x1000,%eax\n  0x000001829b18ca8f:   jge    0x000001829b18ca95           ;*if_icmpge {reexecute=0 rethrow=0 return_oop=0}\n                                                            ; - bench.MemPressureTest$Bigish::fill@14 (line 32)\n                                                            ; - bench.MemPressureTest::test1@28 (line 47)\n  0x000001829b18ca91:   mov    %eax,%esi\n  0x000001829b18ca93:   jmp    0x000001829b18ca5c\n\nThat's exactly what happens in test2. Since the ByteBuffer object is external to the compilation scope, JIT can't optimize it as freely as a local not-yet-published object.\n\nIs it possible at all to optimize the fill loop in case of an external buffer?\n\nThe good news, it is possible. Just use the absolute put method instead of relative. In this case, position field remains unchanged, and JIT can easily vectorize the loop without a risk of breaking ByteBuffer invariants.\nfor (int i = 0; i < SIZE; ++i) {\n    b.put(i, bt);\n}\n\nWith this change, the loop will be vectorized in both cases. Even better, now test2 becomes a lot faster than test1, proving that an object creation indeed has a performance overhead.\nBenchmark               Mode  Cnt      Score     Error   Units\nMemPressureTest.test1  thrpt   10   2447,370 \u00b1 146,804  ops/ms\nMemPressureTest.test2  thrpt   10  15677,575 \u00b1 136,075  ops/ms\n\nConclusion\n\nThe counterintuitive performance difference was caused by the JVM inability to vectorize the fill loop when the ByteBuffer object creation is not in the compilation scope.\nPrefer absolute get/put methods to relative ones where possible. Absolute methods are usually much faster, since they do not update the internal state of ByteBuffer, and JIT can apply more agressive optimizations.\nObject creation indeed has an overhead, as the modified benchmark shows.\n\n"
}
{
    "Id": 73470158,
    "PostTypeId": 1,
    "Title": "Stream.peek() can be skipped for optimization",
    "Body": "I've come across a rule in Sonar which says:\n\nA key difference with other intermediate Stream operations is that the Stream implementation is free to skip calls to peek() for optimization purpose. This can lead to peek() being unexpectedly called only for some or none of the elements in the Stream.\n\nAlso, it's mentioned in the Javadoc which says:\n\nThis method exists mainly to support debugging, where you want to see the elements as they flow past a certain point in a pipeline\n\nIn which case can java.util.Stream.peek() be skipped? Is it related to debugging?\n",
    "AcceptedAnswerId": 73470740,
    "AcceptedAnswer": "Not only peek but also map can be skipped. It is for sake of optimization.\nFor example, when the terminal operation count() is called, it makes no sense to peek or map the individual items as such operations do not change the number/count of the present items.\nHere are two examples:\n\n1. Map and peek are not skipped because the filter can change the number of items beforehand.\nlong count = Stream.of(\"a\", \"aa\")\n    .peek(s -> System.out.println(\"#1\"))\n    .filter(s -> s.length() < 2)\n    .peek(s -> System.out.println(\"#2\"))\n    .map(s -> {\n        System.out.println(\"#3\");\n        return s.length();\n    })\n    .count();\n\n\n#1\n#2\n#3\n#1\n1\n\n\n\n2. Map and peek are skipped because the number of items is unchanged.\nlong count = Stream.of(\"a\", \"aa\")\n    .peek(s -> System.out.println(\"#1\"))\n  //.filter(s -> s.length() < 2)\n    .peek(s -> System.out.println(\"#2\"))\n    .map(s -> {\n        System.out.println(\"#3\");\n        return s.length();\n    })\n    .count();\n\n\n2\n\n\n\nImportant: The methods should have no side-effects (they do above, but only for the sake of example).\n\nSide-effects in behavioral parameters to stream operations are, in general, discouraged, as they can often lead to unwitting violations of the statelessness requirement, as well as other thread-safety hazards.\n\nThe following implementation is dangerous. Assuming callRestApi method performs a REST call, it won't be performed as the Stream violates the side-effect.\nlong count = Stream.of(\"url1\", \"url2\")\n    .map(string -> callRestApi(HttpMethod.POST, string))\n    .count();\n\n/**\n * Performs a REST call\n */\npublic String callRestApi(HttpMethod httpMethod, String url);\n\n"
}
{
    "Id": 73414289,
    "PostTypeId": 1,
    "Title": "Granular media permissions Android 13 API 33",
    "Body": "I've been upgrading my project to SDK 33.\nI changed the permissions where I needed to access media files, such as photos, with the new permission READ_MEDIA_IMAGES and it is working fine.\nBut I need to access documents such as PDF files in order to upload them to the server, but I cannot find any information concerning android 13 and documents.\nBefore the upgrade I had READ_EXTERNAL_STORAGE permission and I accessed all the files.\nIn the andorid documentation on the link below, only these three permissions are provided READ_MEDIA_IMAGES, READ_MEDIA_VIDEO, READ_MEDIA_AUDIO instead of using READ_EXTERNAL_STORAGE.\nhttps://developer.android.com/about/versions/13/behavior-changes-13#granular-media-permissions\nAny ideas on how to fix this and what steps to follow?\n",
    "AcceptedAnswerId": 73535271,
    "AcceptedAnswer": "According to Google storage documentation. It seems that for non-media files no permission is needed. https://developer.android.com/training/data-storage.\n"
}
{
    "Id": 73457793,
    "PostTypeId": 1,
    "Title": "ClassCastException when stopping Tomcat 10 inside Eclipse",
    "Body": "I am using Eclipse 2022-06 and Tomcat 10.0.10.\nOften, when shutting down Tomcat running inside Eclipse, I get\nWARNUNG: Failed to clear soft references from ObjectStreamClass$Caches for web application [ROOT]\njava.lang.ClassCastException: class java.io.ObjectStreamClass$Caches$1 cannot be cast to class java.util.Map (java.io.ObjectStreamClass$Caches$1 and java.util.Map are in module java.base of loader 'bootstrap')\n    at org.apache.catalina.loader.WebappClassLoaderBase.clearCache(WebappClassLoaderBase.java:2363)\n\n...\nI have found this question, but it does not really apply: It's a different class (Map instead of String) and I cannot find a file called \"SESSIONS.ser\". I also have already removed everything from the actual web service part (so the code is doing nothing). I just have not started to remove all the jar files linked that are probably loaded automatically.\nIs there any way to find out which class actually causes the problem?\nBy the way, if by deploying a WAR file to a Tomcat installation outside Eclipse, I was not able to reproduce the error in the log. I am unsure whether that means it does not appear.\n",
    "AcceptedAnswerId": 73551982,
    "AcceptedAnswer": "I got the same problem after upgrading my IDE.\nAfter comparing the both tomcat logs, I saw that there were using 2 different jvm's.\nIndeed I had upgraded the jdk and the ide!\nThe problem is appeared with jvm11.0.16, no exception with jvm11.0.11 even on the latest ide version.\nThis is the explanation, but the solution consisting to keep the old jvm may be not very good...\nSo I did upgrade Tomcat to the latest version (8.5.82 in my case) and it solved the problem. I guess it is due to this feature (see tomcat changelog):\n\nDisable the memory leak correction code enabled by the Context\nattribute clearReferencesObjectStreamClassCaches when running on a JRE\nthat includes a fix for the underlying memory leak. (markt)\n\n"
}
{
    "Id": 73573742,
    "PostTypeId": 1,
    "Title": "Large size of HashSet throwing StackOverflow Error",
    "Body": "I have 81K records of Long object and I am trying to store it in HashSet. My code snippet looks like this:\nprivate static HashSet hashSet = new HashSet(Arrays.asList(*81K records*));\n\nWhile compiling this is giving me StackOverflow Error. I am not understanding why only 81K records are being problem here? Solutions are appreciated.\nJava version. :\nopenjdk version \"1.8.0_322\"\nOpenJDK Runtime Environment Corretto-8.322.06.1 (build 1.8.0_322-b06)\nOpenJDK 64-Bit Server VM Corretto-8.322.06.1 (build 25.322-b06, mixed mode)\n\nStack Trace:\n[javac] \n    [javac] \n    [javac] The system is out of resources.\n    [javac] Consult the following stack trace for details.\n    [javac] java.lang.StackOverflowError\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n    [javac]     at com.sun.tools.javac.code.Type.map(Type.java:220)\n\n\nLine 220 of Type:\n 208     /**\n 209      * Return the least specific subtype of t that starts with symbol\n 210      * sym.  If none exists, return null.  The least specific subtype\n 211      * is determined as follows:\n 212      *\n 213      * If there is exactly one parameterized instance of sym that is a\n 214      * subtype of t, that parameterized instance is returned.\n 215      * Otherwise, if the plain type or raw type `sym' is a subtype of\n 216      * type t, the type `sym' itself is returned.  Otherwise, null is\n 217      * returned.\n 218      */\n 219     public Type asSub(Type t, Symbol sym) {\n 220         return asSub.visit(t, sym);\n 221     }\n 222     // where\n 223         private final SimpleVisitor asSub = new SimpleVisitor() {\n\n",
    "AcceptedAnswerId": 73574421,
    "AcceptedAnswer": "The HashSet is irrelevant here. The problematic part is the varargs invocation of Arrays.asList with 81,000 elements.\nTo reproduce the issue, we can use the following code\nclass Tmp {\n  static final String ARGUMENTS = \">\";\n\n  static final List TEMPLATE = Arrays.asList(\n      \"import java.util.Arrays;\",\n      \"import java.util.List;\",\n      \"\",\n      \"class Tmp {\",\n      \"  static final List L = Arrays.asList(\",\n           ARGUMENTS,\n      \"  );\",\n      \"}\");\n\n  public static void main(String[] args) throws IOException {\n    Path p = Files.createTempFile(\"Test\", \".java\");\n    Files.write(p, () -> TEMPLATE.stream()\n        .flatMap(line -> line.equals(ARGUMENTS)? varargsArgument(): Stream.of(line))\n        .iterator());\n    JavaCompiler c = ToolProvider.getSystemJavaCompiler();\n    c.run(System.in, System.out, System.err, p.toString());\n  }\n\n  static Stream varargsArgument() {\n    return IntStream.range(0, 8100).mapToObj(i -> IntStream.range(0, 10)\n            .mapToObj(j -> i * 10 + j + (i < 8099 || j < 9? \", \": \"\"))\n            .collect(Collectors.joining()));\n  }\n}\n\nWith OpenJDK 8, it produces the\njava.lang.StackOverflowError\n    at com.sun.tools.javac.code.Type.map(Type.java:220)\n   \u2026\n\nOn recent JDKs, e.g. JDK\u00a012, it produces\n/tmp/Test14992292170362927520.java:6: error: code too large\n  static final List L = Arrays.asList(\n                             ^\n\nshowing that even when the compiler bug has been fixed, such code can\u2019t get compiled.\nSuch amount of data should be included as embedded resource which you read in once at startup.\n"
}
{
    "Id": 73603358,
    "PostTypeId": 1,
    "Title": "Understanding javadoc for ZonedDateTime::plusDays",
    "Body": "I am not able to understand one specific part of doc provided for the plusDays() method in ZonedDateTimeClass. Doc states:\n\nReturns a copy of this ZonedDateTime with the specified number of days\nadded.\nThis operates on the local time-line, adding days to the local\ndate-time. This is then converted back to a ZonedDateTime, using the\nzone ID to obtain the offset.\nWhen converting back to ZonedDateTime, if the local date-time is in an\noverlap, then the offset will be retained if possible, otherwise the\nearlier offset will be used. If in a gap, the local date-time will be\nadjusted forward by the length of the gap.\nThis instance is immutable and unaffected by this method call.\nParams: days \u2013 the days to add, may be negative\nReturns: a ZonedDateTime based on this date-time with the days added,\nnot null\nThrows: DateTimeException \u2013 if the result exceeds the supported date\nrange\n\nHow I understand this: Assume we have ZonedDateTime object representing September 4, 2022 6 PM in America/New_York TimeZone. So this method will first convert it to LocalDateTime, that is, it will lose timezone information and just retain September 4, 2022 6 PM. It will add some number of days to it, let's say 7, so that the result is September 11, 2022 6 PM, and now it will convert it back to ZonedDateTime object by providing back the information related to timezone.\nHowever, I am not able to understand the latter part of documentation, that is,\n\nWhen converting back to ZonedDateTime, if the local date-time is in an\noverlap, then the offset will be retained if possible, otherwise the\nearlier offset will be used. If in a gap, the local date-time will be\nadjusted forward by the length of the gap.\n\nWhat do they mean by local date-time is in an overlap? ...then the offset will be retained if possible, otherwise the earlier offset will be used. - what are these two different offsets? If in a gap... - what is this gap?\n",
    "AcceptedAnswerId": 73604362,
    "AcceptedAnswer": "The \"gap\" and \"overlap\" terms are defined in the class-level Javadoc of the ZonedDateTime class:\n\nThis class handles conversion from the local time-line of LocalDateTime to the instant time-line of Instant. The difference between the two time-lines is the offset from UTC/Greenwich, represented by a ZoneOffset.\nConverting between the two time-lines involves calculating the offset using the rules accessed from the ZoneId. Obtaining the offset for an instant is simple, as there is exactly one valid offset for each instant. By contrast, obtaining the offset for a local date-time is not straightforward. There are three cases:\n\nNormal, with one valid offset. For the vast majority of the year, the normal case applies, where there is a single valid offset for the local date-time.\nGap, with zero valid offsets. This is when clocks jump forward typically due to the spring daylight savings change from \"winter\" to \"summer\". In a gap there are local date-time values with no valid offset.\nOverlap, with two valid offsets. This is when clocks are set back typically due to the autumn daylight savings change from \"summer\" to \"winter\". In an overlap there are local date-time values with two valid offsets.\n\n\nExample\nLet's use your specific example of the America/New_York time zone.  Per timeanddate.com, the daylight saving time changes in New York for 2022 are:\n\nMar 13, 2022 - Daylight Saving Time Started\nWhen local standard time was about to reach\nSunday, March 13, 2022, 2:00:00 am clocks were turned forward 1 hour to\nSunday, March 13, 2022, 3:00:00 am local daylight time instead.\nNov 6, 2022 - Daylight Saving Time Ends\nWhen local daylight time is about to reach\nSunday, November 6, 2022, 2:00:00 am clocks are turned backward 1 hour to\nSunday, November 6, 2022, 1:00:00 am local standard time instead.\n\nTherefore, there are no times between 2:00 and 2:59 on March 13 in the New York time zone.  1:59 occurs in standard time.  When that minute ends, no 2:00 hour occurs, and instead the local time jumps to 3:00 daylight time.\nAdditionally, the times between 1:00 and 1:59 occur twice on November 6: one in daylight time and then one in standard time.\nJava ZonedDateTime example\nZoneId zone = ZoneId.of(\"America/New_York\");\n\n// 2022-03-13T03:15:30-04:00[America/New_York] (no 2:15)\nSystem.out.println(\n        ZonedDateTime.of(LocalDateTime.parse(\"2022-03-12T02:15:30\"), zone)\n        .plusDays(1));\n\nSince 2:15 AM on March 12 doesn't exist and is within a 1-hour gap, the following logic you quoted applies, adding 1 hour to the local time:\n\nIf in a gap, the local date-time will be adjusted forward by the length of the gap.\n\nTherefore, 3:15 AM is used when adding 1 day to March 11 at 1:15 AM.\nZoneId zone = ZoneId.of(\"America/New_York\");\n\n// 2022-11-06T01:15:30-04:00[America/New_York] (First 1:15)\nSystem.out.println(\n        ZonedDateTime.of(LocalDateTime.parse(\"2022-11-05T01:15:30\"), zone)\n        .plusDays(1));\n\n// 2022-11-06T01:15:30-05:00[America/New_York] (Second 1:15)\nSystem.out.println(\n        ZonedDateTime.of(LocalDateTime.parse(\"2022-11-05T01:15:30\"), zone)\n        .plusDays(1).plusHours(1));\n\nSince 1:15 AM is during an overlap \u2014 1:15 AM occurs twice on November 6 \u2014 the following logic you quoted applies, using the same -04:00 zone offset as 1:15 AM on November 5:\n\nif the local date-time is in an overlap, then the offset will be retained if possible\n\nTherefore, adding 1 day to November 5 at 1:15 uses the first 1:15 on November 6.  This is made more evident by the second call, which shows that adding an hour to this timestamp returns the second 1:15 of November 6.  The fact that these are different points on the timeline despite both being 1:15 local time is evident by their differing zone offsets: -04:00 & -05:00.\n"
}
{
    "Id": 73630599,
    "PostTypeId": 1,
    "Title": "Java regex inside text blocks",
    "Body": "I surely hoped that this would be supported:\nprivate static void regex() {\n    String plain = \"\\\\w+\";\n    String withTextBlocks = \"\"\"\n        \\w+\n    \"\"\";\n}\n\nbut withTextBlocks does not compile under Java-17. Isn\u2019t it the point of text blocks that we should not escape? I have been through the JEP and maybe the explanation is there, but I can't grok through it. And a second question in case someone knows, is there a future JEP for this? Thank you.\n",
    "AcceptedAnswerId": 73639221,
    "AcceptedAnswer": "You are conflating text blocks with raw strings.  These are different features, though they were explored together and this may explain why you mentally folded them together.  There is no support yet for raw strings (which turn out to be somewhat more slippery than they might first appear.)\n\nIsn\u2019t it the point of text blocks that we should not escape?\n\nNo, that is not the point of text blocks.  The point of text blocks is to allow us to represent two dimensional blocks of text in code, preserving the block's relative indentation but not absolute indentation.  This allows us to freely indent the source representation of the text block itself to match surrounding code, without affecting the indentation of the string the text block describes.\nAn additional design goal is that text blocks should differ from ordinary string literals only in ways that pertain to their two-dimensional nature.  There should not be a different set of escape characters, or different escaping rules.  (If we ever do raw strings, it should apply equally to text blocks and traditional string literals.)  If text blocks worked the way you wanted, you'd probably be complaining that you can't do the same with single-line strings.  These aspects are orthogonal and the language should treat them orthogonally.\n"
}
{
    "Id": 73841877,
    "PostTypeId": 1,
    "Title": "Regex (?U)\\p{Punct} is missing some Unicode punctuation signs in Java",
    "Body": "First of all, I want to remove all punctuation signs in a String. I wrote the following code.\nPattern pattern = Pattern.compile(\"\\\\p{Punct}\");\nMatcher matcher = pattern.matcher(\"!\\\"#$%&'()*+,-./:;?@[\\\\]^_`{|}~\uff08hello\uff09\");\nif (matcher.find())\n    System.out.println(matcher.replaceAll(\"\"));\n\nAfter replacement I got this output: \uff08hello\uff09.\nSo the pattern matches the one of !\"#$%&'()*+,-./:;?@[\\]^_{|}~`, which matches the official docs.\nBut I want to remove \"\uff08\" Fullwidth Left Parenthesis U+FF08* and \"\uff09\" Fullwidth Right Parenthesis U+FF09 as well, so I changed my code to this:\nPattern pattern = Pattern.compile(\"(?U)\\\\p{Punct}\");\n        Matcher matcher = pattern.matcher(\"!\\\"#$%&'()*+,-./:;?@[\\\\]^_`{|}~\uff08\uff09\");\n        if (matcher.find())\n            System.out.println(matcher.replaceAll(\"\"));\n\nAfter replacement, I got this output: $+^|~`\nIt indeed matched \"\uff08\" Fullwidth Left Parenthesis U+FF08* and \"\uff09\" Fullwidth Right Parenthesis U+FF09, bit it missed $+^|~`.\nI am so confused. Why did that happen? Can anyone give some help?\n",
    "AcceptedAnswerId": 73841931,
    "AcceptedAnswer": "Unicode (that is when you use (?U)) and POSIX (when not using (?U)) disagrees on what counts as a punctuation.\nWhen you don't use (?U), \\p{Punct} matches the POSIX punctuation character class, which is just\n!\"#$%&'()*+,-./:;?@[\\]^_`{|}~\n\nWhen you use (?U), \\p{Punct} matches the Unicode Punctuation category, which does not include some of the characters in the above list, namely:\n$+^`|~\n\nFor example, the Unicode category for $ is \"Symbol, Currency\", or Sc. See here.\nIf you want to match $+^`|~, plus all the Unicode punctuations, you can put them both in a character class. You can also just directly use the Unicode category \"P\", rather than turning on Unicode mode with (?U).\nPattern pattern = Pattern.compile(\"[\\\\p{P}$+^`|~]\");\nMatcher matcher = pattern.matcher(\"!\\\"#$%&'()*+,-./:;?@[\\\\]^_`{|}~\uff08\uff09\");\n// you don't need \"find\" first\nSystem.out.println(matcher.replaceAll(\"\"));\n\n"
}
{
    "Id": 73911550,
    "PostTypeId": 1,
    "Title": "How can I reduce the time complexity from O(n^2) to O(n)",
    "Body": "I recently attended an interview and they asked me to solve the below problem by using O(n) time complexity. (Hackerranker)\nProblem:\nGiven an integer array and there will be l integer and r integer. Need to find the which are all the pair of elements sum will be equal and in between l and r value;\n\nExample:\nint[] array = {2,3,4,5}; int l=5, int r=7;\n\nOutput: 4\n\nInput properties:\n\nThe input is unsorted.\nThe input will have duplicate elements.\nThe input array is non-negative.\n\nThe below combination will return the sum which will be equal and in between l and r range value, where if the pair is less than l or greater than r it should be skipped. And pairs can't be duplicated:\narray[0] + array[1] = 5 -> counter++\narray[0] + array[2] = 6 -> counter++\narray[0] + array[3] = 7 -> counter++\narray[1] + array[2] = 7 -> counter++\narray[1] + array[3] = 8 -> greater than r, no counter increment\n\nI tried the below approach and it works fine but its time complexity is O(n^2):\n public static int sumPairs(int[] array,int l, int r)\n    {\n        int counter=0;\n        for(int i=0;i<array.length;i++)\n        {\n            for(int j=i+1;j<array.length;j++)\n            {\n                int sum = array[i]+array[j];\n                \n                if(sum=l)\n                {\n                    counter++;\n                }\n            }\n        }\n        \n        return counter;\n    }\n\nCan someone help me to find a way to optimize the above code to become O(n) time complexity?\n",
    "AcceptedAnswerId": 73922249,
    "AcceptedAnswer": "Here's my approach using a cumulative histogram instead of a sort. In c++, sorry.\nstatic int sumPairsLinear(int *pArray,int iArraySize, int l, int r)\n{\n    int iResult = 0;\n    // 1. Iterate the array and toss any entries larger than r\n    for (int i=0;i<iArraySize;)\n    {\n        if (pArray[i] > r)\n            pArray[i] = pArray[--iArraySize];\n        else\n            i++;\n    }\n    // 2. Allocate a zero initialised array of ints, of size `r+1`.\n    int *pHistogram = new int[r+1];\n    memset(pHistogram, 0, sizeof(int)*(r+1));\n    // 3. Fill the histogram\n    for (int i=0;i<iArraySize;i++)\n    {\n        pHistogram[pArray[i]]++;\n    }\n    // 4. Convert it to a cumulative histogram. \n    for (int i=1;i<=r;i++)\n    {\n        pHistogram[i] += pHistogram[i-1];\n    }\n    // 5. Iterate through the values again. Use the cumulative histogram to calculate the number of valid pairs.\n    for (int i=0;i<iArraySize;i++)\n    {\n        int iVal = pArray[i];\n        int iIndex = l-iVal-1;\n        iResult += pHistogram[r-iVal] - ((iIndex >= 0) ? pHistogram[iIndex] : 0);\n        // Don't pair with self\n        iVal *= 2;\n        if (iVal <= r &&\n            iVal >= l)\n        {\n            iResult--;\n        }\n    }\n    // 6. Half iResult because we counted each pair twice.\n    iResult /= 2;\n\n    delete[] pHistogram;\n    return iResult;\n}\n\nHorrible performance if r is large but otherwise reasonable and still O(N).\n"
}
{
    "Id": 74045604,
    "PostTypeId": 1,
    "Title": "can not create a maven archetype project, the progress bar get stuck in 33%",
    "Body": "I installed Eclipse IDE for Enterprise Java and Web Developers (includes Incubating components)\nVersion: 2022-09 (4.25.0)\nBuild id: 20220908-1902\nIt includes already maven, and I have tried to create some maven archetype projects, but without success, always get stuck in the progress bar.\nAnyone has some clues? Thank you!\n\n",
    "AcceptedAnswerId": 74086551,
    "AcceptedAnswer": "I had this too, it took me a long time to spot the very simple fix.  If you look in the console you'll see that the maven project generation is in interactive mode.  You just need to click Y (yes) in the console to confirm that you are happy with the configuration and it will finish.\n"
}
{
    "Id": 71142680,
    "PostTypeId": 1,
    "Title": "co.elastic.clients.transport.TransportException: [es/search] Missing [X-Elastic-Product] header",
    "Body": "I'm following the tutorial from elastic search java api client here: https://www.elastic.co/guide/en/elasticsearch/client/java-api-client/current/connecting.html\nMy code is as following.\n// Create the low-level client\nRestClient restClient = RestClient.builder(\n new HttpHost(\"localhost\", 9200)).build();\n\n// Create the transport with a Jackson mapper\nElasticsearchTransport transport = new RestClientTransport(\n restClient, new JacksonJsonpMapper());\n\n// And create the API client\nElasticsearchClient client = new ElasticsearchClient(transport);\n\ntry {\n SearchResponse search = client.search(s -> s\n   .index(\"*:*\"),\n   Object.class);\n} catch (IOException e) {\n System.out.println(e.getMessage());\n}\n\nThis code is throwing out the following exception:\nco.elastic.clients.transport.TransportException: [es/search] Missing [X-Elastic-Product] header. Please check that you are connecting to an Elasticsearch instance, and that any networking filters are preserving that header.\n\nI've tried manually putting this header via the setDefaultHeaders method like this:\nRestClientBuilder builder = RestClient.builder(\n new HttpHost(\"localhost\", 9200, \"http\"));\nHeader[] defaultHeaders = new Header[]{new BasicHeader(\"X-Elastic-Product\", \"Elasticsearch\")};\nbuilder.setDefaultHeaders(defaultHeaders);\nRestClient restClient = builder.build();\n\nBut the error is the same.\nI've tried both version 7.16 and 8.0.0, same result.\n",
    "AcceptedAnswerId": 74102828,
    "AcceptedAnswer": "The default headers the RestClientBuilder allows you to specify are the request headers, not the response headers. The error you are getting is because older Elasticsearch [server] versions do not include the X-Elastic-Product=Elasticsearch header in any of the API responses, but the recent distributions do (7.14+?), so the newer versions of elasticsearch-java (i.e. client) expects them.\nI am in the same boat \u2014 I use 8.4.2 of elasticsearch-java with an Elasticsearch server version of 7.2.0.\nI ran into two format-based compatibility issues:\n\nThe client passing a Content-Type not known to the server, and so its request getting rejected with a 406\nThe client validating if the response has X-Elastic-Product=Elasticsearch header\n\nFortunately, the RestClientBuilder allows you to customize the underlying http client through: setHttpClientConfigCallback. The callback looks like this, so basically you can intercept the request and responses, manipulate headers, and thereby get around these issues:\n    public interface HttpClientConfigCallback {\n        /**\n         * Allows to customize the {@link CloseableHttpAsyncClient} being created and used by the {@link RestClient}.\n         * Commonly used to customize the default {@link org.apache.http.client.CredentialsProvider} for authentication\n         * or the {@link SchemeIOSessionStrategy} for communication through ssl without losing any other useful default\n         * value that the {@link RestClientBuilder} internally sets, like connection pooling.\n         */\n        HttpAsyncClientBuilder customizeHttpClient(HttpAsyncClientBuilder httpClientBuilder);\n    }\n\nSpecifically, here's what worked for me:\nvar httpClientConfigCallback = httpClientBuilder ->\n        httpClientBuilder\n            .setDefaultCredentialsProvider(credentialsProvider)\n            // this request & response header manipulation helps get around newer (>=7.16) versions\n            // of elasticsearch-java client not working with older (<7.14) versions of Elasticsearch\n            // server\n            .setDefaultHeaders(\n                List.of(\n                    new BasicHeader(\n                        HttpHeaders.CONTENT_TYPE, ContentType.APPLICATION_JSON.toString())))\n            .addInterceptorLast(\n                (HttpResponseInterceptor)\n                    (response, context) ->\n                        response.addHeader(\"X-Elastic-Product\", \"Elasticsearch\"));\nvar restClient =\n        RestClient.builder(elasticsearchHosts)\n            .setHttpClientConfigCallback(httpClientConfigCallback)\n            .build();\n\n\nNote that there could still be behavioral differences between the aforementioned product and API versions as they are way too apart. The above only fixes format-based incompatibilities. For this reason, it's always best to use at least the same major versions of these components, if not the exact versions.\n"
}
{
    "Id": 74081398,
    "PostTypeId": 1,
    "Title": "Android Studio : Cause: dagger/hilt/android/plugin/HiltGradlePlugin has been compiled by a more recent version of the Java Runtime",
    "Body": "I am getting this error while opening a project\nCause: dagger/hilt/android/plugin/HiltGradlePlugin has been compiled by a more recent version of the Java Runtime (class file version 55.0), this version of the Java Runtime only recognizes class file versions up to 52.0\nWhat i tried are :\nPlugin [id: 'dagger.hilt.android.plugin'] was not found in any of the following sources\nhttps://github.com/google/dagger/issues/3495\nDagger-hilt error while compiling project\nClass has been compiled by a more recent version of the Java Environment\nHow to resovle Java Runtime (class file version 55.0), this version of the Java Runtime only recognizes class file versions up to 52.0 error?\njava.lang.UnsupportedClassVersionError while integrating firebase performance library in react native app\njava.lang.unsupportedclassversionerror in gradle build\nThe Hilt Android Gradle plugin is applied but no com.google.dagger:hilt-android-compiler dependency was found\n",
    "AcceptedAnswerId": 74247022,
    "AcceptedAnswer": "The youtube link solution reported fixed the issue in my case, however here the instructions for the very latest Android Studio version (Android Studio Dolphin | 2021.3.1 Patch 1) on MacOS\n\nSelect your project App main folder in the Android Studio Project panel\nRight click -> Open Module Settings\nSelect the Project entry below the Project Settings section\nIn the dropdown menu next to SDK, select the Java 11 version\nClick on Apply and OK\nRebuild the project\n\nIf this doesn't work could be something deeper messed up in your machine JDK configuration or IDE configuration, would be easier I think to uninstall completely the IDE, clean the configuration file and install from scratch.\nIt could be overkill but sometime this is the most reliable way especially when nothing works.\n"
}
{
    "Id": 74837939,
    "PostTypeId": 1,
    "Title": "How to delete an \"Island\" of numbers in a 2D array in Java",
    "Body": "I'm creating a method that takes a 2D array and scans throughout the array to find \"Chunks\" of numbers that are completely surrounded by zeros and convert those Chunks (I call them the islands) into zeros.\nI'm trying to delete all of the \"islands\" except for the largest one.\nFor example, for this 2D array\n1 2 3 2 2 1 \n3 2 2 1 2 3\n3 2 2 1 3 2\n2 3 2 3 2 2\n2 2 3 1 1 2\n3 2 1 2 3 2\n2 3 1 2 3 2\n2 2 0 0 0 0\n0 0 0 1 2 0\n0 0 0 0 0 0 \n\nAfter the method the 2D array should now be:\n1 2 3 2 2 1 \n3 2 2 1 2 3\n3 2 2 1 3 2\n2 3 2 3 2 2\n2 2 3 1 1 2\n3 2 1 2 3 2\n2 3 1 2 3 2\n2 2 0 0 0 0\n0 0 0 0 0 0\n0 0 0 0 0 0 \n\nthe small chunk of 1 2  is \"deleted\"\nHere is a second example, as the method should also take chunks of numbers that are not part of the \"main\" chunk as Islands and that are on the edges as well.\nThe original array would be:\n1 2 3 2 2 1 \n3 2 2 1 2 3\n3 2 2 1 3 2\n2 3 2 3 2 2\n2 2 3 1 1 2\n3 2 1 2 3 2\n2 3 1 2 3 2\n2 2 0 0 0 0\n0 0 0 1 2 3\n0 0 0 0 3 2 \n\nAfter the method execution, it should be:\n1 2 3 2 2 1 \n3 2 2 1 2 3\n3 2 2 1 3 2\n2 3 2 3 2 2\n2 2 3 1 1 2\n3 2 1 2 3 2\n2 3 1 2 3 2\n2 2 0 0 0 0\n0 0 0 0 0 0\n0 0 0 0 0 0 \n\nIn this case, the island\n1 2 3 \n  3 2\n\nis deleted because it is separate from the big chunk and is surrounded by zeros.\nThe following code is the one I have so far, and it does not work as intended. It's wrong because I believe that it's taking the main chunk as an Island, and what happens is that it converts the entire array into zeros instead of deleting only the small Islands. It includes an example, and you should see what It does when you run it.\npublic class destroyIslands {\n    public static void main(String[] args) {\n        int[][] example = { {1, 2, 3, 1, 2},\n                            {2, 3, 2, 1, 2},\n                            {3, 2, 1, 2, 2},\n                            {0, 2, 0, 0, 0},\n                            {0, 0, 0, 2, 1} };\n        \n        example = deleteIslandBoard(example);\n        printGrid(example);\n    }\n    \n    public static int[][] deleteIslandBoard(int[][] array) {\n      // Create a boolean array to track which cells have been visited\n      boolean[][] visited = new boolean[array.length][array[0].length];\n    \n      // Iterate \n      for (int i = 0; i < array.length; i++) {\n        for (int j = 0; j < array[0].length; j++) {\n            // If the cell is not visited and is part of an island\n            if (!visited[i][j] && array[i][j] != 0) {\n                // Delete the island by setting all cells to 0\n                deleteIsland(array, i, j, visited);\n            }\n        }\n      }\n      // Return the modified array\n      return array;\n    }\n\n    public static void deleteIsland(int[][] array, int i, int j, boolean[][] visited) {\n      // Check if the current cell is out of board or if it has already been visited\n      if (i = array.length || j = array[0].length || visited[i][j]) {\n        return;\n      }\n      // Mark the current cell as visited\n      visited[i][j] = true; // If the current cell is part of the island, set it to 0\n      if (array[i][j] != 0) {\n        array[i][j] = 0;\n        // Recursively delete the neighboring cells that are part of the island\n        deleteIsland(array, i - 1, j, visited);\n        deleteIsland(array, i + 1, j, visited);\n        deleteIsland(array, i, j - 1, visited);\n        deleteIsland(array, i, j + 1, visited);\n      }\n    }\n    \n    public static void printGrid(int[][] grid) {\n        for(int i = 0; i < grid.length; i++) {\n            for(int j = 0; j < grid[i].length; j++) {\n                System.out.print(grid[i][j] + \" \");\n            }\n            System.out.println();\n        }\n    }\n}\n\nAny idea of what should I change?\n",
    "AcceptedAnswerId": 74839246,
    "AcceptedAnswer": "This problem can be solved in linear time O(n) by treating the cells of the given Matrix as the Vertexes of an undirected disjointed Graph.\nThe task boils down to exploring all Connected components (islands) in a Graph, and comparing them with each other.\nAnd for that we would need to implement of the Graph-traversal algorithms. I've chosen the Depth first search algorithm for that purpose.\nTo keep things simple, a Vertex of a graph would be represented as an array int[] of two elements containing coordinates of a cell (feel free to reimplement it by defining a separate class for a Vertex to make each vertex aware of it neighbors by holding a reference to a collection of Vertices)\nFor convenience, I've made several changes to your DestroyIslands class:\n\nIntroduced an inner class Island, which wraps a list of cells that constitute an Island (Connected component of the Graph). This class implements Comparable in based on size of the cells to make it easier to find the largest Island. And defines the method destroy() to nullify the rest Islands.\nIntroduced a static array NEIGHBOURS of type int[][] representing all possible adjacent cells, which should be considered while iterating through the matrix from left to right and from top to bottom.\nReference to the Matrix is stored in the instance field grid, and all methods of DestroyIslands are defined as instance methods (if you want to keep them static, fill free to change them as you see fit, it would be easy if you grasp the algorithm itself).\n\nThat's how implementation might look like:\npublic class DestroyIslands {\n    public static final int[][] NEIGHBOURS = // adjacent cells\n        {{0, 1},   // horizontal -\n         {1, 0},   // vertical   |\n         {1, 1},   // diagonal   \\\n         {1, -1}}; // diagonal   /\n\n    private List islands = new ArrayList(); // collection of Islands\n    private int[][] grid; // matrix\n    \n    public DestroyIslands(int[][] grid) {\n        this.grid = grid;\n    }\n    \n    public class Island implements Comparable {\n        private List cells = new ArrayList();\n        \n        public void addCell(int[] cell) {\n            cells.add(cell);\n        }\n        \n        public void destroy() {\n            cells.forEach(cell -> grid[cell[0]][cell[1]] = 0);\n        }\n        \n        @Override\n        public int compareTo(Island other) {\n            return Integer.compare(cells.size(), other.cells.size());\n        }\n    }\n    \n    public void deleteIslandBoard() {\n        exploreIslands();\n        deleteSmallerIslands();\n    }\n    \n    public void exploreIslands() {\n        boolean[][] visited = new boolean[grid.length][grid[0].length];\n        \n        for (int i = 0; i < grid.length; i++) {\n            for (int j = 0; j < grid[0].length; j++) {\n                \n                if (!visited[i][j] && grid[i][j] != 0) { // if a New Island was found\n                    exploreIsland(new int[]{i, j}, visited); // explore the Island, i.e. index all its cell and mark them as visited\n                }\n            }\n        }\n    }\n    \n    /**\n     * Depth first search implementation\n     */\n    public void exploreIsland(int[] cell, boolean[][] visited) {\n        Island island = new Island();\n        islands.add(island); // updating the list of Islands\n        \n        Deque stack = new ArrayDeque();\n        stack.push(cell);\n        \n        while (!stack.isEmpty()) {\n            int[] next = stack.poll();\n            island.addCell(next);\n            \n            for (int[] shift : NEIGHBOURS) {\n                int row = next[0] + shift[0];\n                int col = next[1] + shift[1];\n                \n                if (isValid(row, col) && !visited[row][col]) { // if cell exist, non-zero and not visited yet\n                    stack.push(new int[]{row, col});\n                    visited[row][col] = true;\n                }\n            }\n        }\n    }\n    \n    public boolean isValid(int row, int col) {\n        return row >= 0 && row < grid.length\n            && col >= 0 && col < grid[0].length\n            && grid[row][col] != 0;\n    }\n    \n    public void deleteSmallerIslands() {\n        if (islands.isEmpty()) return; // otherwise Collections.max() would throw NoSuchElementException\n\n        Island largest = Collections.max(islands);\n        for (Island next : islands) {\n            if (next != largest) next.destroy();\n        }\n    }\n    \n    public void printGrid() {\n        for (int i = 0; i < grid.length; i++) {\n            for (int j = 0; j < grid[i].length; j++) {\n                System.out.print(grid[i][j] + \" \");\n            }\n            System.out.println();\n        }\n    }\n}\n\nmain()\npublic static void main(String[] args) {\n        int[][] example = {\n            {1, 2, 3, 1, 2},\n            {2, 3, 2, 1, 2},\n            {3, 2, 1, 2, 2},\n            {0, 2, 0, 0, 0},\n            {0, 0, 0, 2, 1}};\n        \n        DestroyIslands destroyIslands = new DestroyIslands(example);\n        destroyIslands.deleteIslandBoard();\n        destroyIslands.printGrid();\n    }\n\nOutput:\n1 2 3 1 2 \n2 3 2 1 2 \n3 2 1 2 2 \n0 2 0 0 0 \n0 0 0 0 0\n\nA link to Online Demo\n"
}
{
    "Id": 74847682,
    "PostTypeId": 1,
    "Title": "Why have nothing to override, but still can put @Override without syntax error?",
    "Body": "I am using Java language level 17 on JDK 19. I have\npackage ocp17.ch07;\n\npublic record BeardedDragon(boolean fun) {\n    \n    @Override\n    public boolean fun() {\n        return false;\n    }\n    \n}\n\n\nWhy have nothing to override, but still can put @Override without syntax error?\n",
    "AcceptedAnswerId": 74847710,
    "AcceptedAnswer": "You are indeed overriding the fun method (which is bad in this case1). With Java records, the accessor name (which it automatically gives for you) doesn't have the get prefix - it is fun() and not getFun() or isFun().\nThe Record Members section of JLS states\n\nFurthermore, for each record component, a record class has a method with the same name as the record component and an empty formal parameter list. This method, which is declared explicitly or implicitly, is known as an accessor method.\n\nThe Records JEP also says,\n\nThe meaning of the @Override annotation was extended to include the case where the annotated method is an explicitly declared accessor method for a record component.\n\n@Sweeper's answer points to the appropriate section of JLS for this\nSo whatever you've done now counts as overriding.\n\n1 Why is it bad?\nLet's say you have an instance of BeardedDragon like,\nBeardedDragon dragon = new BeardedDragon(true);\nif (dragon.fun()) {\n     System.out.println(\"Yay!!\");\n} else {\n    System.out.println(\"Dang it.. It was supposed to be fun\");\n}\n\nIt will return false when you call fun(). I'm not sure if that is what you want.\nAlso, it violates the below requirement from the JLS.\n\nConsider a record class R that has components c1, ..., cn, and an\nimplicitly declared accessor method for every component, and an\nimplicitly declared equals method. If an instance r1 of R is copied in\nthe following way:\nR r2 = new R(r1.c1(), r1.c2(), ..., r1.cn());\nthen, assuming r1 is not the null reference, it is always the case\nthat the expression r1.equals(r2) will evaluate to true. Explicitly\ndeclared accessor methods and equals methods should respect this\ninvariant. It is not generally possible for a compiler to check\nwhether explicitly declared methods respect the invariant.\n\nUsing the example from @Johannes Kuhn (from the comments).\nvar b1 = new BeardedDragon(true); \nvar b2 = new BeardedDragon(b1.fun()); \nassert b1.equals(b2); // This will fail \n\n"
}
{
    "Id": 74752707,
    "PostTypeId": 1,
    "Title": "GitHub Actions : How to resolve : \"The process '/usr/bin/gpg' failed with exit code 2\" problem on actions/setup-java@v3",
    "Body": "Introduction\nCurrently, I'm trying to contribute on a GitHub Action that automatically publishes a java library.\nThe branch where I'm developing: https://github.com/MathieuSoysal/Java-maven-library-publisher/tree/2-add-automated-tests\nThe yaml code of the Action :\nname: Java maven library publisher\nauthor: \"Mathieu Soysal (@MathieuSoysal)\"\ndescription: \"Build automatically Java Maven library and publish it to GitHub Packages and Maven Central.\"\nbranding:\n  icon: \"package\"\n  color: \"gray-dark\"\n\ninputs:\n  nexus-username:\n    description: \"Nexus username\"\n    required: true\n  nexus-password:\n    description: \"Nexus password\"\n    required: true\n  gpg-private-key:\n    description: \"GPG private key\"\n    required: true\n  gpg-passphrase:\n    description: \"GPG passphrase\"\n    required: true\n  github-token:\n    description: \"GitHub token\"\n    required: true\n  # Java version to use\n  java-version:\n    description: \"Java version to use\"\n    required: true\n    default: \"17\"\n  # Library version\n  library-version:\n    description: \"Library version\"\n    required: false\n    default: \"\"\n\nruns:\n  using: \"composite\"\n\n  steps:\n    - name: Checkout\n      uses: actions/checkout@v3\n\n    - name: Set up JDK 17 for deploy to OSSRH\n      uses: actions/setup-java@v3\n      with:\n        distribution: \"adopt\"\n        java-version: ${{ inputs.java-version }}\n        server-id: ossrh\n        server-username: ${{ inputs.nexus-username }}\n        server-password: ${{ inputs.nexus-password }}\n        gpg-private-key: ${{ inputs.gpg-private-key }}\n        gpg-passphrase: ${{ inputs.gpg-passphrase }}\n\n    - name: Build with Maven\n      run: mvn -B package --file pom.xml\n      shell: bash\n\n    - name: Update package version\n      if: ${{ inputs.library-version != '' }}\n      run: mvn versions:set -DnewVersion=${{ inputs.library-version }}\n      shell: bash\n\n    - name: Prepare Maven environnement with Java 17 for deployment to OSSRH\n      run: export MAVEN_OPTS=\"--add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.desktop/java.awt.font=ALL-UNNAMED\"\n      shell: bash\n\n    - name: Publish to Apache Maven Central\n      run: mvn deploy -PossrhDeploy\n      shell: bash\n      env:\n        MAVEN_USERNAME: ${{ inputs.nexus-username }}\n        MAVEN_CENTRAL_TOKEN: ${{ inputs.nexus-password }}\n        MAVEN_GPG_PASSPHRASE: ${{ inputs.gpg-passphrase }}\n\n    - name: Set up JDK 17 for deploy to github packages\n      uses: actions/setup-java@v3\n      with:\n        distribution: \"adopt\"\n        java-version: ${{ inputs.java-version }}\n        server-id: github\n\n    - name: Publish to GitHub Packages Apache Maven\n      run: mvn deploy -PgithubDeploy\n      shell: bash\n      env:\n        GITHUB_TOKEN: ${{ inputs.github-token }}\n\nlink to the code: https://github.com/MathieuSoysal/Java-maven-library-publisher/blob/2-add-automated-tests/action.yaml\nThe workflow that execute the Action:\nname: Test Actions\n\non: [push]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Maven Library build and publish\n        uses: ./\n        with:\n          nexus-username: ${{ secrets.NEXUS_USERNAME }}\n          nexus-password: ${{ secrets.NEXUS_PASSWORD }}\n          gpg-private-key: ${{ secrets.GPG_PRIVATE_KEY }}\n          gpg-passphrase: ${{ secrets.GPG_PASSPHRASE }}\n          library-version: $GITHUB_RUN_NUMBER\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          java-version: 17\n\nLink to the code: https://github.com/MathieuSoysal/Java-maven-library-publisher/blob/2-add-automated-tests/.github/workflows/test-action.yml\nProblem\nWhen i'm trying to execute the action I obtain this error:\nGetting action download info\nDownload action repository 'actions/setup-java@v3' (SHA:c3ac5dd0ed8db40fedb61c32fbe677e6b355e94c)\nRun ./\nRun actions/checkout@v3\nSyncing repository: ***/Java-maven-library-publisher\nGetting Git version info\nTemporarily overriding HOME='/home/runner/work/_temp/45376e45-02aa-4aa5-b536-5f744f7e10d3' before making global git config changes\nAdding repository directory to the temporary git global config as a safe directory\n/usr/bin/git config --global --add safe.directory /home/runner/work/Java-maven-library-publisher/Java-maven-library-publisher\n/usr/bin/git config --local --get remote.origin.url\nhttps://github.com/***/Java-maven-library-publisher\nRemoving previously created refs, to avoid conflicts\nCleaning the repository\nDisabling automatic garbage collection\nSetting up auth\nFetching the repository\nDetermining the checkout info\nChecking out the ref\n/usr/bin/git log -1 --format='%H'\n'0e8da131bf626b218ddccbd08a661c7921dfb8da'\nRun actions/setup-java@v3\nInstalled distributions\nCreating settings.xml with server-id: ossrh\nWriting to /home/runner/.m2/settings.xml\nImporting private gpg key\nError: The process '/usr/bin/gpg' failed with exit code 2\n\nQuestion\nSomeone know how we can fix this The process '/usr/bin/gpg' failed with exit code 2 for actions/setup-java@v3 ?\n",
    "AcceptedAnswerId": 74848449,
    "AcceptedAnswer": "Can you make sure GPG private key is in the correct format. The key should be in the ASCII Armored format, which can be done by running the following command:\ngpg --armor --export-secret-keys  > gpg_key.asc\n\nOnce the key is in the correct format, add it as an input variable in the Action and pass it to the action in the workflow.\n"
}
{
    "Id": 74875058,
    "PostTypeId": 1,
    "Title": "How to get jwt token value in spring webflux? (to exchange it with Minio STS token)",
    "Body": "I have sping-boot application with rest services written using Spring web flux.\nFor now I access minio using login/password authorizaton and it works fine.\nFor now I want to exchange application JWT token with STS minio token and I implemented method to test:\n@PostMapping\npublic boolean test(JwtAuthenticationToken token) throws ServerException, InsufficientDataException, ErrorResponseException, IOException, NoSuchAlgorithmException, InvalidKeyException, InvalidResponseException, XmlParserException, InternalException {\n    MinioClient minioClient =\n            MinioClient.builder()\n                    .region(...)\n                    .endpoint(...)              \n                    .credentialsProvider(new WebIdentityProvider(\n                           \n                            () -> new Jwt(token.getToken().getTokenValue(), 1000),\n                            String.valueOf(...),\n                            null,\n                            null,\n                            null,\n                            null,\n                            null))\n                    .build();\n    return minioClient.bucketExists(\"mybucket\").build());\n}\n\nThis code successfully works and returns true because mybucket actually exists.\nBut it is only test and I need to move minioClient to the configuration. The issue here that I have to have credentials provider there.\nSo I've created folowing configuration:\n@Bean\npublic MinioClient minioClient() {\n    return MinioClient.builder()\n            .region(...)\n            .endpoint(...)\n            .credentialsProvider(new WebIdentityProvider(\n                   \n                    () -> {\n                        String block = null;\n                        try {\n                            block = ReactiveSecurityContextHolder\n                                .getContext()\n                                .map(context -> {\n                                            return context\n                                                    .getAuthentication()\n                                                    .getPrincipal();\n\n                                        }\n                                )\n                                .cast(Jwt.class)\n                                .map(Jwt::token)\n                                .block();\n                        } catch (Exception e) {\n                            // it fails here     <=======\n                            System.out.println(e);\n                        }\n\n                        Jwt jwt = new Jwt(String.valueOf(block),\n                                1000);\n                        return jwt; },\n                    String.valueOf(...),\n                    null,\n                    null,\n                    null,\n                    null,\n                    null))\n            .build();\n}\n\nBut unfortunately method block() fails with exception:\njava.lang.IllegalStateException: block()/blockFirst()/blockLast() are blocking, which is not supported in thread reactor-http-nio-6 \n\nAny ideas how to fix it?\nP.S.\n_\nI tried\n.toFuture()\n.get();\n\ninstead of .block();\nbut it returns null\n",
    "AcceptedAnswerId": 74883975,
    "AcceptedAnswer": "As Numichi stated in the comment you have to stay in the reactor context.\nOne option is to create a bean of type Mono.\n    @Bean\n    @Scope(BeanDefinition.SCOPE_PROTOTYPE)\n    public Mono reactiveMinio() {\n        return ReactiveSecurityContextHolder.getContext()\n                .map(securityContext ->\n                        (Jwt)securityContext.getAuthentication().getPrincipal())\n                .map(jwt -> MinioClient.builder()\n                        .region(\"someRegion\")\n                        .endpoint(\"someEndpoint\")\n                        .credentialsProvider(webIdentityProvider(jwt.token()))\n                        .build());\n    }\n\n    private WebIdentityProvider webIdentityProvider(String token) {\n        return new WebIdentityProvider(() -> new Jwt(token, 1000),\n                \"stsEndpoint\",\n                null,\n                null,\n                null,\n                null,\n                null);\n    }\n\nI think bean scope should be prototype since MinioClient is bound to security context.\nHere is the sample usage of reactive MinioClient:\n\n@RestController\npublic class MinioTest {\n\n    private Mono minioClient;\n\n    public MinioTest(Mono minioClient) {\n        this.minioClient = minioClient;\n    }\n\n    @GetMapping(\"/minio\")\n    public Mono client() {\n        return minioClient\n                .map(minio -> {\n                    try {\n                        return minio.bucketExists(BucketExistsArgs\n                                .builder()\n                                .bucket(\"my-bucketname\")\n                                .build());\n                    } catch (Exception e) {\n                        return new Exception(e);\n                    }\n                });\n    }\n}\n\n\n\n"
}
{
    "Id": 73095898,
    "PostTypeId": 1,
    "Title": "RCTModernEventEmitter fires twice for android fabric component",
    "Body": "I am trying to create a fabric component for android, specifically I want to use the onClickHandler of the button component and pass a callback to react-native side via RCTModernEventEmitter. It works fine for iOS but for android the RCTModernEventEmitter emits twice every time I click the button\nThis is my spec\nimport type {HostComponent, ViewProps} from 'react-native';\nimport type {\n  DirectEventHandler\n} from 'react-native/Libraries/Types/CodegenTypes';\nimport codegenNativeComponent from 'react-native/Libraries/Utilities/codegenNativeComponent';\n\ntype Event = Readonly<{\n  text?: string;\n}>;\n\ninterface NativeProps extends ViewProps {\n  text: string;\n  onClickHandler?: DirectEventHandler; ////Event name should start with on\n}\n\nexport default codegenNativeComponent(\n  'MyButtonView',\n) as HostComponent;\n\nOn native side I have created following files\npublic class MyButtonViewManager extends SimpleViewManager {\n\n    public static final String NAME = \"MyButtonView\";\n    ReactApplicationContext mCallerContext;\n\n    public MyButtonViewManager(ReactApplicationContext reactContext) {\n        mCallerContext = reactContext;\n    }\n \n    @NonNull\n    @Override\n    public String getName() {\n        return NAME;\n    }\n\n    @NonNull\n    @Override\n    protected MyButtonView createViewInstance(@NonNull ThemedReactContext reactContext) {\n        return new MyButtonView(reactContext);\n    }\n\n    @ReactProp(name = \"text\")\n    public void setQrCodeText(MyButtonView view, String text) {\n        view.setText(text);\n    }\n\n\n    @Nullable\n    @Override\n    public Map getExportedCustomDirectEventTypeConstants() {\n        return MapBuilder.of(\"topOnClickHandler\",\n                MapBuilder.of(\"registrationName\", \"onClickHandler\")\n        );\n    }\n\n}\n\npublic class MyButtonClickEvent extends Event {\n\n    public MyButtonClickEvent(int viewId) {\n        super(viewId);\n    }\n \n    @Override\n    public String getEventName() {\n        return \"topOnClickHandler\";\n    }\n\n//    @Override\n//    public void dispatch(RCTEventEmitter rctEventEmitter) {\n//        super.dispatch(rctEventEmitter);\n//        rctEventEmitter.receiveEvent(getViewTag(), getEventName(), Arguments.createMap());\n//    }\n\n    @Override\n    public void dispatchModern(RCTModernEventEmitter rctEventEmitter) {\n        super.dispatchModern(rctEventEmitter);\n        rctEventEmitter.receiveEvent(-1,\n                getViewTag(),getEventName(),\n                Arguments.createMap()\n        );\n    }\n\n    @Nullable\n    @Override\n    protected WritableMap getEventData() {\n        WritableMap event = Arguments.createMap();\n        event.putString(\"message\", \"MyMessage\");\n        return event;\n    }\n}\n\npublic class MyButtonView extends androidx.appcompat.widget.AppCompatButton {\n\n    public MyButtonView(Context context) {\n        super(context);\n        configureViews();\n    }\n\n    private void configureViews(){\n        setBackgroundColor(Color.YELLOW);\n        setOnClickListener(view -> {\n            ReactContext reactContext = (ReactContext)getContext();\n            EventDispatcher eventDispatcher = UIManagerHelper.getEventDispatcherForReactTag(\n                    reactContext ,getId()\n            );\n            eventDispatcher.dispatchEvent(new MyButtonClickEvent(getId()));\n        });\n    }\n}\n\nOn JS side\n<MyButtonView\n  style={{height: 100, width: 100, margin: 20}}\n  onClickHandler={(value: any) => {\n    console.log('Hello ok bye', value.nativeEvent);\n  }}\n  text=\"Hello\"\n/>\n\nI get value in onClickHandler of MyButtonView twice even though I press the button once\nFullrepo is here https://github.com/PritishSawant/ReactNativeFabricEventListenerExample\nEdit:\nI have updated my code to 0.71.1 and you can find it here\n",
    "AcceptedAnswerId": 75318050,
    "AcceptedAnswer": "Commenting  super.dispatchModern(rctEventEmitter); from dispatchModern resolved the issue\n"
}
