{
    "Id": 70552008,
    "PostTypeId": 1,
    "Title": "Java hidden properties without Spring",
    "Body": "I am currently creating a Java program that uses a MongoDB database and I am storing the connection information in a properties file.\nBut my project is opensource on GitHub and I cannot store the connection information in the properties file.\nAnd so I wanted to ask you if it is possible to give the login information from docker run.\nexample : docker run registry/image -args db.password=psw db.username=user\nI have seen solutions in stackoverflow but all solutions use Spring features, but my project does not use Spring framework.\n",
    "AcceptedAnswerId": 70556743,
    "AcceptedAnswer": "We have multiple solutions for this:\nSecret Docker\nCreate a file with the properties syntax:\n//secret-file.txt\ndb.password=psw\ndb.username=user\n\nWith this file create a docker secret in your docker :\n$ docker secret create test-secret secret-file.txt\n\nAnd use this with the java library docker-secrets in your java program :\nMap secrets = DockerSecrets.loadFromFile(\"test-secret\");\nSystem.out.println(secrets.get(\"db.password\")) // readonly\n\nFor more example, look here.\n\nEnvironment variables\nSet the environment variables in the docker with -e argument :\n$ docker run -e DB_PASSWORD=pwd -e DB_USERNAME=user registry/image:tag\n\nAnd use these variables with System::getenv in your java program :\nSystem.out.println(System.getenv(\"DB_PASSWORD\"))\n\n\nVM Arguments\nThis solution depends on your base image that was used to create your Docker container.\nGive VM Arguments to the docker run command :\n$ docker run -e JAVA_OPTS=\"-Ddb.password=pwd -Ddb.username=user\" registry/image:tag\n\nAnd use these variables with System::getProperty in your java program :\nSystem.out.println(System.getProperty(\"db.password\"))\n\n\nProgram arguments\nGive arguments to docker run command :\nIt is important to give the arguments after declaring the image.\n$ docker run registry/image:tag pwd user\n\nAnd use these arguments with main method in your java program :\npublic static void main(String[] args) {\n    System.out.println(\"The password: \" + args[0]);\n    System.out.println(\"The username: \" + args[1]);\n}\n\nFor better handling of arguments, you can use the Apache's commons-cli java library or use a another library.\n"
}
{
    "Id": 70601508,
    "PostTypeId": 1,
    "Title": "Can I use Java 16 record with JPA entity?",
    "Body": "I am trying to do something similar like below.\n@Entity\n@Table(name=\"Sample\")\npublic record Sample(Integer id, String name) {\n\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    @Column(name=\"user_id\")\n    private Integer id;\n\n    @Column(name=\"username\")\n    private String name;\n\n}\n\nHowever, it gives me error \"User declared non-static fields id are not permitted in a record\"\nand same for name field as well.\nIs there a way to use new java feature \"record\" with JPA annotation?\n",
    "AcceptedAnswerId": 70601646,
    "AcceptedAnswer": "See the article, Using Records as Projections in JPA by Billy Korando. The following is a brief summary.\nRecords cannot be Entities\nJakarta Persistence  (JPA; formerly Java Persistence API) implementations such as Hibernate depend on features either forbidden or not recommended by the JEP 395: Records spec: no-arg constructors, non-final fields, setters, etc.\n\u27a5 So, no, records cannot be used as JPA Entity.\nOther uses of records\nYou can use records with:\n\nCriteriaBuilder\nTypedQuery\nNativeQuery\nMapping definition\n\nSpring data has some support as well.\nSee that article linked above for details, and for links to two other articles.\n"
}
{
    "Id": 70601178,
    "PostTypeId": 1,
    "Title": "Java Generics: What is the benefit of using wildcards here?",
    "Body": "The Collections.fill method has the following header:\npublic static  void fill(List list, T obj)\n\nWhy is the wildcard necessary? The following header seems to work just as well:\npublic static  void fill(List list, T obj)\n\nI cannot see a reason why the wildcard is needed; code such as the following works with the second header as well as the first:\nList nums = new ArrayList();\nInteger i = 43;\nfill(nums, i); //fill method written using second header\n\nMy question is: For what specific call of fill would the first header work but not the second? And if there is no such call, why include the wildcard? In this case, the wildcard does not make the method more concise nor add to readability (in my opinion).\n",
    "AcceptedAnswerId": 70627059,
    "AcceptedAnswer": "This is a really good question and the simple answer was guessed already:\n\nFor the current version of the fill(List list, T obj) there is no\nsuch input that would be rejected given the signature is changed to fill(List list, T obj), so there is no benefit and the devs are likely followed the PECS principle\n\nThe above statement derives from the principle that: if there is a such type X so that\nX is a supertype of T then List is a supertype of List because of type contravariance.\nSince we can always find such X (at the worst case it's the Object class) - the compiler can infer a suitable List argument type given either form of fill.\nSo, knowing that fact we can interfere with the compiler and infer the type ourselves using \"type witness\" so the code breaks:\nList target = new ArrayList();\n//Compiles OK as we can represent List as List and it fits\nCollections.fill(target, 1);\n\n//Compilation error as List is invariant to List and not a valid substitute\nCollections.fillNew(target, 1);\n\nThis is all of course purely theoretical and nobody in their right mind would use the type argument there.\nHOWEVER\nWhile answering the question \"What is the benefit of using wildcards here?\" we yet considered only one side of the equation - us, consumers of the method and our experience but not library developers.\nHence this question is somewhat similar to why Collections.enumeration(final Collection c) is declared the way it is and not enumeration(Collection c) as final seems superfluous for the end-user.\nWe can speculate here about the real intention, but I can give a few subjective reasons:\n\nFirst: using List (as well as final for enumeration) immediately disambiguates the code that tiny bit more and for the  specifically - it useful to show that only partial knowledge about the\ntype parameter is required and the list cannot be used to produce values of T, but only to consume them.\nQuote:\n\n\nWildcards are useful in situations where only partial knowledge about the type parameter is required.\nJLS 4.5.1. Type Arguments of Parameterized Types\n\n\nSecond: it gives some freedom to the library owners to improve/update the method without breaking backward compatibility while conforming to the existing constraints.\n\n\nNow let's try make up some hypothetical \"improvements\" to see what I mean (I'll call the form of fill that uses List as fillNew):\n#1 The decision is to make method to return the obj value (used to fill up the list) back:\npublic static  void fill(List list, T obj)\n//becomes \u2193\u2193\u2193\npublic static  T fill(List list, T obj)\n\nThe updated method would work just fine for fill signature, but for fillNew - the inferred return type now isn't that obvious:\nList target = new ArrayList();\nLong val = fill(target, 1L); //<<Here Long is the most specific type that fits both arguments\n//Compilation error\nLong val = fillNew(target, 1L); //<<Here Number is, so it cannot be assigned back\n\n//More exotic case:\nInteger val = fill(asList(true), 0); //val is Integer as expected\nComparable val = fillNew(asList(true), 0); //val is now Comparable as the most specific type \n\n#2 The decision to add an overloaded version of fill that is 10x more performant in cases when T is Comparable:\n/* Extremely performant 10x version */\npublic static > void fill(List list, T value)\n/* Normal version */\npublic static void fill(List list, T value)\n\nList target = new ArrayList();\nfill(target, 1);  //\nfillNew(target, 1); //<< Still uses the slow version just because T is inferred to Number which is not Comparable\n    \n\nTo sum up - the current signature of fill is more flexible/descriptive in my opinion for all parties (developers and library designers)\n"
}
{
    "Id": 70681453,
    "PostTypeId": 1,
    "Title": "How to implement fixed points of functors in Java",
    "Body": "I recently discovered how to simulate higher order types in Java  in a somewhat roundabout way like so\ninterface H { }\n\nHere H encodes a higher order type that takes a type parameter F which itself takes parameter T.\nNow this leaves me to wonder, can we use this to implement some more advanced constructs? E.g. fixed point of functors\nlike Fix in Haskell and its corresponding catamorphisms?\n",
    "AcceptedAnswerId": 70681454,
    "AcceptedAnswer": "Indeed this can be done by carefully translating the corresponding Haskell counterparts. Although this introduces a lot of line noise,\nthe implementation is quite close to the original:\n\n// Encoding of higher kinded type F of T\npublic interface H { }\n\npublic interface Functor {\n     H map(Function f);\n}\n\n// newtype Fix f = Fix {unfix::f (Fix f)}\npublic static record Fix & Functor, T>(F f) {\n    public Functor> unfix() {\n        return (Functor>) f;\n    }\n}\n\n// type Algebra f a = f a -> a\npublic interface Algebra extends Function, T> {}\n\n // cata :: Functor f => Algebra f a -> Fix f -> a\n // cata alg = alg . fmap (cata alg) . unfix\npublic static  & Functor, T> Function, T> cata(Algebra alg) {\n    return fix -> alg.apply(fix.unfix().map(cata(alg)));\n}\n\nAmazingly this works and can be used to implement e.g. interpreters for expression algebras\n// evalExprF :: Algebra ExprF Int\n// evalExprF (Const n) = n\n// evalExprF (Add m n) = m + n\n// evalExprF (Mul m n) = m * n\npublic static class ExprAlg implements Algebra {\n    @Override\n    public Integer apply(H hExpr) {\n        return Expr.expr(hExpr).match(\n            conzt -> conzt.n,\n            add   -> add.t1 + add.t2,\n            mul   -> mul.t1 * mul.t2);\n    }\n}\n\nFull working example in my GitHub repository.\n"
}
{
    "Id": 70654559,
    "PostTypeId": 1,
    "Title": "How to give certificate to Java Websocket?",
    "Body": "Forgive me for the newb question, but I am confused and obviously not understanding the fundamentals or explanations of how to use a Websocket server hosted over HTTPS. Everything I find online leads me to have more questions than answers.\nI have a Websocket server hosted on my HTTPS website using Java code.\nThis is my WebsocketServer.java file:\nimport org.java_websocket.WebSocket;\nimport org.java_websocket.handshake.ClientHandshake;\nimport org.java_websocket.server.WebSocketServer;\n\nimport java.net.InetSocketAddress;\nimport java.util.HashSet;\nimport java.util.Set;\n\nimport org.apache.logging.log4j.LogManager;\nimport org.apache.logging.log4j.Logger;\n\npublic class WebsocketServer extends WebSocketServer {\n\n    private static final Logger logger = LogManager.getLogger(WebsocketServer.class);\n\n    private static int TCP_PORT = 6868;\n\n    private static Set conns;\n\n    public WebsocketServer() {\n        super(new InetSocketAddress(TCP_PORT));\n        conns = new HashSet();\n    }\n\n    @Override\n    public void onOpen(WebSocket conn, ClientHandshake handshake) {\n        conns.add(conn);\n        logger.info(\"New connection from \" + conn.getRemoteSocketAddress().getAddress().getHostAddress());\n        logger.info(\"Size of connection list: \" + conns.size());\n    }\n\n    @Override\n    public void onClose(WebSocket conn, int code, String reason, boolean remote) {\n        conns.remove(conn);\n        logger.info(\"Closed connection to \" + conn.getRemoteSocketAddress().getAddress().getHostAddress());\n    }\n\n    @Override\n    public void onMessage(WebSocket conn, String message) {\n        logger.info(\"Message from client: {}\", message);\n        // for (WebSocket sock : conns) {\n        // sock.send(\"SENDING BACK\" + message);\n        // }\n    }\n\n    @Override\n    public void onError(WebSocket conn, Exception ex) {\n\n        // ex.printStackTrace();\n        try {\n            if (conn != null) {\n                conns.remove(conn);\n                // do some thing if required\n            }\n            logger.info(\"ERROR from {}\", conn.getRemoteSocketAddress().getAddress().getHostAddress());\n        } catch (Exception e) {\n            logger.info(\"onError: WebSocketServer may already be running\");\n\n        }\n\n    }\n\n    public Set getConns() {\n        return conns;\n    }\n\n}\n\n\nThen I started the WebsocketServer like this:\nWebsocketServer websocketServer;\n// Start socket server\nwebsocketServer = new WebsocketServer();\nwebsocketServer.start();\n\nAnd on the client side, I connect to it like this:\n    // APP_WEB_SOCKET is the url to my site: api.my_custom_domain.com\n    var connection = new WebSocket(\"wss://\" + APP_WEB_SOCKET + \":6868\");\n\nQUESTIONS:\nI keep reading that I need a certificate if I want to use wss over HTTPS, but cannot find any documents that explain what this means in a way that I can understand.\nMy app is hosted in AWS Elastic Beanstalk environment. Do I need to somehow add a certificate to the setup of the WebsocketServer in my Java code?\nExample:\nWebsocketServer websocketServer;\n// Start socket server\nwebsocketServer = new WebsocketServer();\n\n// example guessing\nwebsocketServer.cert = \"SOMETHING\";??\nwebsocketServer.start();\n\nDoes the client code need to be changed at all?\nWho needs the certificate?\nIf someone could please explain what I am missing or point me in the correct direction, I would really appreciate it.\n",
    "AcceptedAnswerId": 70698577,
    "AcceptedAnswer": "Keep it easy.\nCerts inside your application are complex - they are hard to manage and you will get problems to run your application in a modern cloud environment (start new environments, renew certs, scale your application, ...).\nSimple conclusion: Dont implement any certs.\nHow-to get encrypted connections?\nAs Mike already pointed out in the comments: WebSockets are just upgraded HTTP(S) connections. A normal webserver (nginx, apache) takes care about the certs. It can be done in kubernetes (as ingress-controller) or with a \"bare-metal\" webserver.\nBoth of them should act as a reverse-proxy. This means: Your java-application doesn't know anything about certs. It has just unencrypted connections - like in your code on port 6868.\nBut the client will not use this port. 6868 is only internally reachable.\nThe client will call your reverse-proxy at the normal HTTPS port (=443). The reverse-proxy will forward the connection to your java-application.\nHere some links for further information:\n\nnginx reverse-proxy\nnginx reverse-proxy for websocket\ntutorial for java behind reverse-proxy\nLetsEncrypt for automatic and free certs\n\n"
}
{
    "Id": 70860253,
    "PostTypeId": 1,
    "Title": "Java map function throws non-static method compiler error",
    "Body": "I have an odd problem, where I am struggling to understand the nature of \"static context\" in Java, despite the numerous SO questions regarding the topic.\nTL;DR:\nI have a design flaw, where ...\nThis works:\nList list = orderType.getOrderExtnTransList();\nthis.dtoOrderExtnTransList = list.stream().map(OrderExtnTrans::toDto).collect(Collectors.toList());\n\nBut this does not:\nthis.dtoOrderExtnTransList = orderType.getOrderExtnTransList().stream().map(OrderExtnTrans::toDto).collect(Collectors.toList());\n\n\nThe error shown in the second version is \"Non-static method cannot be referenced from a static context\".\nThe long version:\nObject Model:\nThe model consists of Business Type specific orders (eg. Stock exchange, payments), which inherit from a an order entity via an \"InheritanceType.JOINED\" inheritance strategy.\nThe parent order can be parameterized with the business type specific DTO object of that order, so for example DtoStockExchangeOrder. This is to enable, that JPA objects can be mapped to their DTO equivalent within the Entity, rather than in a service (which I did previously. It worked, but its \"less clean\").\nJPA Order:\n@Entity\n@Table(name = \"ORDER_BASE\")\n@Inheritance(strategy = InheritanceType.JOINED)\npublic class Order implements Serializable {\n\n    @OneToMany(fetch = FetchType.LAZY, mappedBy = \"order\", orphanRemoval = true)\n    private List orderExtnTransList = new ArrayList();\n\n}\n\nJPA Order - Business Type specific example:\n@Entity\n@Table(name = \"ORDER_STEX\")\n@Inheritance(strategy = InheritanceType.JOINED)\npublic class OrderStex extends Order implements Serializable {\n\nLikewise, DTO orders follow the same pattern, where they can be parameterized with the business type specific JPA entity, to enable the relevant mapping:\nDTO Order:\npublic class DtoOrder extends DtoEntity {\n\nDTO Order - Business Type Specific Example\npublic class DtoOrderStex extends DtoOrder {\n\nThe DTOEntity class it inherits from is just a \"wrapper\" class, consisting of an ID and a name.\nNow the tricky part:\nThe DTOOrder class has a constructor which populates the fields that are common to all business types, like the list of process status transitions, an order goes through in its life cycle (placed, cancelled, executed, etc..). Staying with the example of the process status transitions, these are also modelled as JPA entities in the database, with their corresponding DTO counterparts (likewise parameterized, that part works fine).\nHere the constructor:\npublic DtoOrder(OrderType orderType) {\n    super(orderType);\n    // this is the part from above, which works (but it shows a warning: Unchecked assignment: 'java.util.List' to 'java.util.List' )\n    List list = orderType.getOrderExtnTransList();\n    this.dtoOrderExtnTransList = list.stream().map(OrderExtnTrans::toDto).collect(Collectors.toList());\n    // this is how I would have expected it to work, but it does not, with the error shown above: \"Non-static method cannot be referenced from a static context\"\n    this.dtoOrderExtnTransList = orderType.getOrderExtnTransList().stream().map(OrderExtnTrans::toDto).collect(Collectors.toList());\n}\n\nIf I comment out the non-working version, the application behaves as expected and throws no error, so \"logically\", this works. But JAVA does not allow it as developed in the second version.\nIf instead of OrderType I use \"Order\", it works as well, but obviously throws errors elsewhere, because the signature of the constructor changed. I assume another approach would be to parameterise the method based on the the caller of the constructor or to parameterise the parent class DtoOrder to know the type of the child class, but there should be a better way?\nWhat am I doing wrong, and why does the upper version work as expected?\n",
    "AcceptedAnswerId": 70873247,
    "AcceptedAnswer": "Thanks for an interesting question, that shows some unexpected behaviour, that is behaving according to spec.\nTL;DR (ie, the correct way of quickly and easily fixing this) is to add the  generic wildcard to Order in the DtoOrder class declaration, so :\npublic class DtoOrder> extends DtoEntity {\n\nThis will make the all-in-one-line way in the constructor work \u200b:\n\u200bthis.dtoOrderExtnTransList = orderType.getOrderExtnTransList().stream().map(OrderExtnTrans::toDto).collect(Collectors.toList());\n\nAs for why this is the fix, this is because you have defined Order as a Generic type :\npublic class Order \n\nBy NOT specifying the generic type, you are declaring it (and therefore making OrderType as well) as a raw-type.\nGenerally we are used to List being generic, that at run-time undergoes type-erasure.  Further, that if we have old code like :\nList myRawTypeVariable = new ArrayList();\n\nthat myRawType is a raw type, in that we can add any Object and only get Objects out.\nHowever, it turns out that (as you have discovered) raw types go further than that, and type-erasure has compile-time implications as well.\nThe Java Language Specification (JLS) says this (source : https://docs.oracle.com/javase/specs/jls/se8/html/jls-4.html#jls-4.8 )\n\nThe type of a constructor (\u00a78.8), instance method (\u00a78.4, \u00a79.4), or\nnon-static field (\u00a78.3) of a raw type C that is not inherited from its\nsuperclasses or superinterfaces is the raw type that corresponds to\nthe erasure of its type in the generic declaration corresponding to C.\n\nNote that this is NOT limiting type erasure to ONLY those of the generic type;  The types of ALL instance methods get taken to their raw types !\nIn other words, by not specifying the generic type of Order, you are making Order a raw type - and therefore turning off all Generic type-checking for that class (except for methods, etc otherwise specified, from inheritance or interfaces).\nSo even though getOrderExtnTransList() is declared as returning a List, because you are using Order as a raw-type, it's dropping the  generic and treating that method as simply returning a List (effectively a List ).\nYou can confirm this by trying to insert a peek, so :\n   \u200bthis.dtoOrderExtnTransList = orderType.getOrderExtnTransList().stream().peek(s -> s.\n\nthen try to do an auto-complete.   You'll find that the options are only the members for Object, not the endsWith, etc members for String.\nThis, in turn, means that when it hits .map(OrderExtnTrans::toDto), instead of interpreting this for a OrderExtnTrans coming down the stream :\n `.map(o -> o.toDto())`, \n\nit thinks you mean\n  `.map(o -> OrderExtnTrans.toDto(o))` \n\nwhich is what is appropriate for an Object coming down the stream - and that is why it complains about toDto being a non-static method.\nAs stated, the solution is to simply not treat Order as a raw-type, instead to make it generic by adding the  as above.\n"
}
{
    "Id": 71006506,
    "PostTypeId": 1,
    "Title": "Java collector teeing a list of inputs",
    "Body": "I am trying to implement a simple collector, which takes a list of collectors and simultaneously collects values in slightly different ways from a stream.\nIt is quite similar to Collectors.teeing, but differs in that it\n\nReceives a list of collectors instead of just two\nRequires all collectors to produce a value of the same type\n\nThe type signature I want to have is\npublic static  Collector> list(\n      final List> downstreamCollectors);\n\nOne way to create such a collector would be to recursively pair up teeing collectors, like so:\npublic static  Collector> list(\n    final List> downstreamCollectors) {\n  return listrec(\n      Collectors.collectingAndThen(downstreamCollectors.get(0), List::of),\n      downstreamCollectors.stream().skip(1).toList());\n}\n\nprivate static  Collector> listrec(\n    final Collector> teedCollectors,\n    final List> downstreamCollectors) {\n  if (downstreamCollectors.size() == 0) {\n    return teedCollectors;\n  } else {\n    return listrec(\n        teeing(\n            teedCollectors,\n            downstreamCollectors.get(0),\n            (l, s) -> Stream.concat(l.stream(), Stream.of(s)).toList()),\n        downstreamCollectors.stream().skip(1).toList());\n  }\n}\n\nSomething feels a little \"off\" with this solution, so I am trying to create the collector myself, something like:\npublic static  Collector> list2(\n    final List> downstreamCollectors) {\n  return Collector.of(\n      () -> downstreamCollectors.stream().map(c -> c.supplier().get()).toList(),\n      (accumulators, t) ->\n          IntStream.range(0, downstreamCollectors.size())\n              .forEach(\n                  i -> downstreamCollectors.get(i).accumulator().accept(accumulators.get(i), t)),\n      (accumulator1, accumulator2) ->\n          IntStream.range(0, downstreamCollectors.size())\n              .mapToObj(\n                  i ->\n                      downstreamCollectors\n                          .get(i)\n                          .combiner()\n                          .apply(accumulator1.get(i), accumulator2.get(i)))\n              .toList(),\n      accumulators ->\n          IntStream.range(0, downstreamCollectors.size())\n              .mapToObj(i -> downstreamCollectors.get(i).finisher().apply(accumulators.get(i)))\n              .toList());\n}\n\nBecause of the unbounded wildcard in the downstream collectors' accumulator type, this doesn't compile. Changing the type signature to\npublic static  Collector> list2(\n    final List> downstreamCollectors);\n\nsolves the problem, but unfortunately renders the method much less usable as the downstream collectors (like the built in collectors from java.util.stream.Collectors) typically would have a unbounded wildcard in the accumulator type.\nIs there another way to implement this, keeping the wildcard in the method signature?\nI am using OpenJDK 17.0.2.\n",
    "AcceptedAnswerId": 71019502,
    "AcceptedAnswer": "Handling a list of collectors with arbitrary accumulator types as a flat list can\u2019t be done in a type safe way, as it would require declaring n type variables to capture these types, where n is the actual list size.\nTherefore, you can only implement the processing as a composition of operations, each with a finite number of components know at compile time, like your recursive approach.\nThis still has potential for simplifications, like replacing downstreamCollectors.size() == 0 with downstreamCollectors.isEmpty() or downstreamCollectors.stream().skip(1).toList() with a copying free downstreamCollectors.subList(1, downstreamCollectors.size()).\nBut the biggest impact has replacing the recursive code with a Stream Reduction operation:\npublic static  Collector> list(List> collectors) {\n    return collectors.stream()\n            .>>map(c-> Collectors.collectingAndThen(c, List::of))\n            .reduce((c1, c2) -> teeing(c1, c2,\n                        (l1, l2) -> Stream.concat(l1.stream(), l2.stream()).toList()))\n            .orElseThrow(() -> new IllegalArgumentException(\"no collector specified\"));\n}\n\nThis may work fairly well if you don\u2019t have a really large number of collectors to compose. A disadvantage of this concise solution is that every result will be wrapped into a single element list before the actual merging of results and even the result merging may bear multiple list copying operations.\nThis result processing can be optimized using\npublic static  Collector> list(List> collectors) {\n    int num = collectors.size();\n    switch(num) {\n        case 0: throw new IllegalArgumentException(\"no collector specified\");\n        case 1: return collectingAndThen(collectors.get(0), List::of);\n        case 2: return teeing(collectors.get(0), collectors.get(1), List::of);\n        case 3: return teeing(teeing(collectors.get(0), collectors.get(1), List::of),\n                           collectors.get(2), (l,r) -> List.of(l.get(0), l.get(1), r));\n        default:\n    }\n    Collector> c = teeing(collectors.get(0), collectors.get(1), (r1, r2) -> {\n        var list = new ArrayList(num);\n        list.add(r1);\n        list.add(r2);\n        return list;\n    });\n    for(int ix = 2; ix < num; ix ++) {\n        c = teeing(c, collectors.get(ix), (list, r) -> { list.add(r); return list; });\n    }\n    return collectingAndThen(c, List::copyOf);\n}\n\nThis provides special cases for small numbers of collectors whose results can be used to construct an immutable result list directly. For the other cases, all results are added to an ArrayList first, preventing excessive list copying, before converting the list to the final immutable list. This last step could be omitted, if getting an immutable result list is not important, I just tried to be as close to the Stream.toList() behavior of the original approach as possible.\nThere\u2019s still an unbalanced recursive structure behind the scenes during the Stream processing which prohibits really large numbers of collectors. There are two approaches to solve this.\n\nImplement your own type safe variant of teeing which exposes the intermediate container type, to allow to build a balanced tree and collecting all results into a list by traversing this tree without additional intermediate storage.\n\nAbandon the type safety and implement the collector with a flat list and raw types. Try to limit the unsafe code as much as possible.\n\n\nBut this might not be needed when you have an estimate of the expected number of collectors to \u201ctee\u201d and find the first solution working good enough.\n"
}
{
    "Id": 70756414,
    "PostTypeId": 1,
    "Title": "java.lang.reflect.InaccessibleObjectException: Unable to make field private final java.util.Comparator java.util.TreeMap.comparator accessible:module",
    "Body": "This is my first cucumber project and i followed a tutorial when setting everything up. It all seems to be the same but for some reason i get this:\njava.lang.ExceptionInInitializerError.\nCaused by: java.lang.reflect.InaccessibleObjectException: Unable to make field private final java.util.Comparator java.util.TreeMap.comparator accessible: module java.base does not \"opens java.util\" to unnamed module @74ad1f1f\nAny idea how to solve this error ?\nBelow i have posted everything that comes out in my console as well as my pom file in case there is an issue with my dependencies eventhough the guy from the tutorial's pom file is identical.\nThis is everything that comes out in my Console.\n[31mFailed scenarios:[0m\n[31muni/login/Login.feature:3 [0m# Scenario: Enter the system.\n1 Scenarios ([31m1 failed[0m)\n5 Steps ([31m1 failed[0m, [36m4 skipped[0m)\n0m0.185s\n\njava.lang.ExceptionInInitializerError\n    at cucumber.deps.com.thoughtworks.xstream.XStream.setupConverters(XStream.java:820)\n    at cucumber.deps.com.thoughtworks.xstream.XStream.(XStream.java:574)\n    at cucumber.deps.com.thoughtworks.xstream.XStream.(XStream.java:530)\n    at cucumber.runtime.xstream.LocalizedXStreams$LocalizedXStream.(LocalizedXStreams.java:50)\n    at cucumber.runtime.xstream.LocalizedXStreams.newXStream(LocalizedXStreams.java:37)\n    at cucumber.runtime.xstream.LocalizedXStreams.get(LocalizedXStreams.java:29)\n    at cucumber.runtime.StepDefinitionMatch.runStep(StepDefinitionMatch.java:37)\n    at cucumber.runtime.Runtime.runStep(Runtime.java:300)\n    at cucumber.runtime.model.StepContainer.runStep(StepContainer.java:44)\n    at cucumber.runtime.model.StepContainer.runSteps(StepContainer.java:39)\n    at cucumber.runtime.model.CucumberScenario.run(CucumberScenario.java:44)\n    at cucumber.runtime.junit.ExecutionUnitRunner.run(ExecutionUnitRunner.java:102)\n    at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:63)\n    at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:18)\n    at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)\n    at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)\n    at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:413)\n    at cucumber.runtime.junit.FeatureRunner.run(FeatureRunner.java:70)\n    at cucumber.api.junit.Cucumber.runChild(Cucumber.java:95)\n    at cucumber.api.junit.Cucumber.runChild(Cucumber.java:38)\n    at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)\n    at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)\n    at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:413)\n    at cucumber.api.junit.Cucumber.run(Cucumber.java:100)\n    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:93)\n    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:40)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:529)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:756)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:452)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:210)\n    at \u273d.Given \u041f\u043e\u0442\u0440\u0435\u0431\u0438\u0442\u0435\u043b\u044f\u0442 \u043e\u0442\u0432\u0430\u0440\u044f \u0435\u043a\u0440\u0430\u043d\u0430 \u0437\u0430 \u0432\u0445\u043e\u0434 \u0432 \u0441\u0438\u0441\u0442\u0435\u043c\u0430\u0442\u0430(uni/login/Login.feature:4)\nCaused by: java.lang.reflect.InaccessibleObjectException: Unable to make field private final java.util.Comparator java.util.TreeMap.comparator accessible: module java.base does not \"opens java.util\" to unnamed module @74ad1f1f\n    at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:357)\n    at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:297)\n    at java.base/java.lang.reflect.Field.checkCanSetAccessible(Field.java:177)\n    at java.base/java.lang.reflect.Field.setAccessible(Field.java:171)\n    at cucumber.deps.com.thoughtworks.xstream.core.util.Fields.locate(Fields.java:39)\n    at cucumber.deps.com.thoughtworks.xstream.converters.collections.TreeMapConverter.(TreeMapConverter.java:50)\n    at cucumber.deps.com.thoughtworks.xstream.XStream.setupConverters(XStream.java:820)\n    at cucumber.deps.com.thoughtworks.xstream.XStream.(XStream.java:574)\n    at cucumber.deps.com.thoughtworks.xstream.XStream.(XStream.java:530)\n    at cucumber.runtime.xstream.LocalizedXStreams$LocalizedXStream.(LocalizedXStreams.java:50)\n    at cucumber.runtime.xstream.LocalizedXStreams.newXStream(LocalizedXStreams.java:37)\n    at cucumber.runtime.xstream.LocalizedXStreams.get(LocalizedXStreams.java:29)\n    at cucumber.runtime.StepDefinitionMatch.runStep(StepDefinitionMatch.java:37)\n    at cucumber.runtime.Runtime.runStep(Runtime.java:300)\n    at cucumber.runtime.model.StepContainer.runStep(StepContainer.java:44)\n    at cucumber.runtime.model.StepContainer.runSteps(StepContainer.java:39)\n    at cucumber.runtime.model.CucumberScenario.run(CucumberScenario.java:44)\n    at cucumber.runtime.junit.ExecutionUnitRunner.run(ExecutionUnitRunner.java:102)\n    at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:63)\n    at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:18)\n    at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)\n    at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)\n    at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:413)\n    at cucumber.runtime.junit.FeatureRunner.run(FeatureRunner.java:70)\n    at cucumber.api.junit.Cucumber.runChild(Cucumber.java:95)\n    at cucumber.api.junit.Cucumber.runChild(Cucumber.java:38)\n    at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)\n    at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)\n    at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:413)\n    at cucumber.api.junit.Cucumber.run(Cucumber.java:100)\n    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:93)\n    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:40)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:529)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:756)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:452)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:210)\n\nAnd this is my pom.xml\n\n  4.0.0\n  uni.ais\n  first-cucumber-project\n  1.1.0-SNAPSHOT\n  first-cucumber-project-gr\n  \n    1.8\n    1.8\n    UTF-8\n  \n  \n    \n        info.cukes\n        cucumber-java\n        1.2.5\n    \n    \n        info.cukes\n        cucumber-junit\n        1.2.5\n    \n  \n\n\n",
    "AcceptedAnswerId": 70776589,
    "AcceptedAnswer": "I solved my problem. Turns out the JRE that eclipse had automatically downloaded and was using wasn't compatible with this version of cucumber. I manually changed the path to a jre 1.8 that i had in my ProgramFilex(x86)/Java folder and now everything works fine.\n"
}
{
    "Id": 70786275,
    "PostTypeId": 1,
    "Title": "Reading encrypted private key in PKCS#8 format through bouncycastle, Java failing in docker container",
    "Body": "I am trying to read a PKCS#8 private key which looks like following:\nkey.k8 --> (Sample key. Passphrase - 123456):\n-----BEGIN ENCRYPTED PRIVATE KEY-----\nMIIFLTBXBgkqhkiG9w0BBQ0wSjApBgkqhkiG9w0BBQwwHAQILbKY9hPxYSoCAggA\nMAwGCCqGSIb3DQIJBQAwHQYJYIZIAWUDBAEqBBCvaGt2Hmm2NpHpxbLvHKyOBIIE\n0IQ7dVrAGXLZl0exYIvyxLAu6zO00jL6b3sb/agTcCFOz8JU6fBanxY0d5aYO4Dn\nmynQG7BoljU470s0zIwW/wk0MmdUFl4nXWBX/4qnG0sZqZ9KZ7I8R/WrBkmpX8C/\n4pjdVhu8Ht8dfOYbkbjMBTohDJz8vJ0QwDIXi9yFjjef+QjwrFOl6kAeDJFVMGqc\ns7K/wOnhsL1XxfW9uTulPiZh5YTZKcatMkeGDR7c+cg5I+Mutim92diWuCekhNoa\nuvhUy1M3cbs7Azp1Mhz+V0CDKklI95EvN4u23WhiJPCjAofC/e45/heOP3Dwm7WZ\nzHEY1C/X8PsTl6MEEIF3ZJP+4Vr0corAs1L2FqE6oOng8dFFYmF5eRyBx6bxFd05\niYbfOH24/b3qtFKPC689kGEd0gWp1dwES35SNNK+cJqVRTjgI0oKhOai3rhbGnmp\ntx4+JqploQgTorj4w9asbtZ/qZA2mYSSR/Q64SHv7LfoUCI9bgx73MqRQBgvI5yS\nb4BoFBnuEgOduZLaGKGjKVW3m5/q8oiDAaspcSLCJMIrdOTYWJB+7mfxX4Xy0vEe\n5m2jXpSLQmrfjgpSTpHDKi/3b6OzKOcHjSFBf8IoiHuLc5DVvLECzDUxxaMrTZ71\n0YXvEPwl2R9BzEANwwR9ghJvFg1Be/d5W/WA1Efe6cNQNBlmErxD6l+4KDUgGjTr\nAaksp9SZAv8uQAsg7C57NFHpTA5Hznr5JctL+WlO+Gk0cAV6i4Py3kA6EcfatsnS\nPqP2KbxT+rb2ATMUZqgWc20QvDt6j0CTA1BuVD1PNhnAUFvb2ocyEEXOra22DPPS\nUPu6jirSIyFcjqFjJ9A1FD9L4/UuX2UkDSLqblFlYB1+G55KZp+EKz8SZoN5qXy1\nLyMtnacEP5OtRDrOjopzVNiuV1Uv63M9QVi1hZlVLJEomgjWuvuyEuIwDaY2uryW\nvx+jJEZyySFkb1JwAbrm+p6sCTFnbQ/URKC2cit/FJyKqNim6VQvGL8Sez34qV3z\nD13QJgTZfsy+BaZoaQ6cJTXtJ8cN0IcQciOiDNBKMW66zO6ujS8G+KNviNQypDm6\nh4sOgjMqLaZ4ezPEdNj/gaxV7Y15nVRu0re8dVkaa5t9ft/sh6A+yeTD5tS5hHkf\nNI7uJPTaTXVoz7xq2PAJUTWujMLMZKtmNOzNqYvxWRy3tCOFobBQkMxqEBEwHd+x\nSA+gFcJKJ+aNfCGZJ5fFr8rNlhtOF6uMwOAlfiUlP/pCUDUCKPjZVj4K95yNc8Io\njSZSPb5tGPe0HqXgc6IAfQarlUZt90oVtzL0OfOfTxe1bEzS2ccNadbx/6vjLBc4\nq5UuUBppl3rXpbuZ7J1Rp3n2byF4APxFdT2LHKq+MYMfWUToau/TCMT4lFIM9tM8\n7TuuyUT2PKzf/xlsl4iScw96z9xxGPQrXn7IA2W5iL+0eCLztJdjNRX1FisdfIBL\nPraOVlmF8jHKbFdRZ8Yi8pApbQjvHi24g7dX7u/cq1FH/VE+nJ0O8YVCYVDw13CW\nh0p7yD7BuB0R+0WnR0yvkp30vK4/rtCB+Ob8bH/+HvAZrAU5X8jq/wsQbLkrLHZV\n6A6GGfX8+hy5AoaXsH1BHnMyXkaF6Mv29z8JcslDJxX/\n-----END ENCRYPTED PRIVATE KEY-----\n\nFollowing code is being used to parse the private key:\n InputStream privateKeyInputStream = getPrivateKeyInputStream(); // reads the key file from classpath and share as DataStream\n logger.info(\"InputStreamExists --> {} \", privateKeyInputStream.available());\n PEMParser pemParser = new PEMParser(new InputStreamReader(privateKeyInputStream));\n Object pemObject = pemParser.readObject();\n if (pemObject instanceof PKCS8EncryptedPrivateKeyInfo) {\n     // Handle the case where the private key is encrypted.\n     PKCS8EncryptedPrivateKeyInfo encryptedPrivateKeyInfo = (PKCS8EncryptedPrivateKeyInfo) pemObject;\n     InputDecryptorProvider pkcs8Prov =\n            new JceOpenSSLPKCS8DecryptorProviderBuilder().build(passphrase.toCharArray());\n     privateKeyInfo = encryptedPrivateKeyInfo.decryptPrivateKeyInfo(pkcs8Prov); // fails here\n}\n\n\nInputStream resourceAsStream = null;\n    if (\"local\".equals(privateKeyMode)) {\n      resourceAsStream = this.getClass().getResourceAsStream(privateKeyPath);\n    } else {\n      File keyFile = new File(privateKeyPath);\n      logger.info(\n          \"Key file found in {} mode. FileName : {}, Exists : {}\",\n          privateKeyMode,\n          keyFile.getName(),\n          keyFile.exists());\n      try {\n        resourceAsStream = new DataInputStream(new FileInputStream(keyFile));\n      } catch (FileNotFoundException e) {\n        e.printStackTrace();\n      }\n\nWhen I am running this code through intelliJ on windows, the code works fine but when I run it through docker container I am getting following exception:\norg.bouncycastle.pkcs.PKCSException: unable to read encrypted data: failed to construct sequence from byte[]: Extra data detected in stream\nsnowflake-report-sync    |      at org.bouncycastle.pkcs.PKCS8EncryptedPrivateKeyInfo.decryptPrivateKeyInfo(Unknown Source) ~[bcpkix-jdk15on-1.64.jar!/:1.64.00.0]\nsnowflake-report-sync    |      at com.optum.snowflakereportsync.configuration.SnowFlakeConfig.getPrivateKey(SnowFlakeConfig.java:103) ~[classes!/:na]\nsnowflake-report-sync    |      at com.optum.snowflakereportsync.configuration.SnowFlakeConfig.getConnectionProperties(SnowFlakeConfig.java:67) ~[classes!/:na]\n\nFollowing is Dockerfile used:\nFROM adoptopenjdk/openjdk11-openj9:latest\nCOPY build/libs/snowflake-report-sync-*.jar snowflake-report-sync.jar\nRUN mkdir /encryption-keys\nCOPY encryption-keys/ /encryption-keys/ #keys are picked from docker filesystem when running in container\nEXPOSE 8080\nCMD java -Dcom.sun.management.jmxremote -noverify ${JAVA_OPTS} -jar snowflake-report-sync.jar\n\nOptions tried:\n\nEnsured that key file is being read while running in container. Logger \"InputStreamExists --> {}\" gives number of bytes\nRan dos2unix on key.k8 just to make sure there are no Window's \"^M\" characters which be could be causing issue as container is linux one : FROM adoptopenjdk/openjdk11-openj9:latest\n\nNot sure what I am doing wrong but any help or pointers would be appreciated.\n",
    "AcceptedAnswerId": 70905140,
    "AcceptedAnswer": "Like @Bragolgirith suspected, BouncyCastle seems to have problems with OpenJ9. I guess it is not a Docker issue, because I can reproduce it on GitHub Actions, too. It is also not limited to BouncyCastle 1.64 or 1.70, it happens in both versions. It also happens on OpenJ9 JDK 11, 14, 17 on Windows, MacOS and Linux, but for the same matrix of Java and OS versions it works on Adopt-Hotspot and Zulu.\nHere is an example Maven project and a failed matrix build. So if you select another JVM type, you should be fine. I know that @Bragolgirith already suggested that, but I wanted to make the problem reproducible for everyone and also provide an MCVE, in case someone wants to open a BC or OpenJ9 issue.\nP.S.: It is also not a character set issue with the InputStreamReader. This build fails exactly the same as before after I changed the constructor call.\n\nUpdate: I have created BC-Java issue #1099. Let's see what the maintainers can say about this.\n\nUpdate 2: The solution to your problem is to explicitly set the security provider to BC for your input decryptor provider. Thanks to David Hook for his helpful comment in #1099.\nBouncyCastleProvider securityProvider = new BouncyCastleProvider();\nSecurity.addProvider(securityProvider);\n\n// (...)\n\nInputDecryptorProvider pkcs8Prov = new JceOpenSSLPKCS8DecryptorProviderBuilder()\n  // Explicitly setting security provider helps to avoid ambiguities\n  // which otherwise can cause problems, e.g. on OpenJ9 JVMs\n  .setProvider(securityProvider)\n  .build(passphrase.toCharArray());\n\nSee this commit and the corresponding build, now passing on all platforms, Java versions and JVM types (including OpenJ9).\nBecause @Bragolgirith mentioned it in his answer: If you want to avoid the explicit new JceOpenSSLPKCS8DecryptorProviderBuilder().setProvider(securityProvider), the call Security.insertProviderAt(securityProvider, 1) instead of simply Security.addProvider(securityProvider) would in this case also solve the problem. But this holds true only as long as no other part of your code or any third-party library sets another provider to position 1 afterwards, as explained in the Javadoc. So maybe it is not a good idea to rely on that.\n"
}
{
    "Id": 70995023,
    "PostTypeId": 1,
    "Title": "What's the difference between String.format() and str.formatted() in Java?",
    "Body": "I know that method String.format() is nearly the same as method System.out.printf() except it returns a String. But I could hardly find the introduction about method \"formatted\" which is defined as follows:\npublic String formatted(Object... args) {\n        return new Formatter().format(this, args).toString();\n}\n\nAnd I know the functions of two codes below are the same.\nString str1 = String.format(\"%s\", \"abab\");\nSystem.out.println(str1);\n\nString str2;\nstr2 = \"%s\".formatted(\"abab\");\nSystem.out.println(str2);\n\nTherefore I'm wandering what's the difference between them. Thank you!\n",
    "AcceptedAnswerId": 70997302,
    "AcceptedAnswer": "Make sure you use a good IDE so that you have easy access to browse into JDK source code. In Eclipse say, use F3 to open to any declaration. IntelliJ IDEA has similar feature.\nIf you view the source code for both methods, you can see these calls are identical except that variables this is interchanged with format when comparing the instance vs static method:\npublic String formatted(Object... args) {\n    return new Formatter().format(this, args).toString();\n}\npublic static String format(String format, Object... args) {\n    return new Formatter().format(format, args).toString();\n}\n\nSo as you've observed: String.format(str, args) is same as str.formatted(args)\n"
}
{
    "Id": 71059252,
    "PostTypeId": 1,
    "Title": "Mac The operation couldn\u2019t be completed. Unable to locate a Java Runtime that supports jarsigner",
    "Body": "My purpose is to use jarsigner to sign apk.\nI get the following prompt\uff1a\n% jarsigner     \nThe operation couldn\u2019t be completed. Unable to locate a Java Runtime that supports jarsigner.\nPlease visit http://www.java.com for information on installing Java.\n\nmy java version hint\uff1a\n% java -version\njava version \"1.8.0_321\"\nJava(TM) SE Runtime Environment (build 1.8.0_321-b07)\nJava HotSpot(TM) 64-Bit Server VM (build 25.321-b07, mixed mode)\n\nMac version is 11.6.3\nHow can I solve this problem please?\n",
    "AcceptedAnswerId": 71059860,
    "AcceptedAnswer": "I finally solved it by downloading the JDK\n"
}
{
    "Id": 70925555,
    "PostTypeId": 1,
    "Title": "How can we provide Jackson annotations for java 17 record class",
    "Body": "How can we create add field level annotations for java 17 record class?\nrecord Rectangle(double length, double width) { }\n\n",
    "AcceptedAnswerId": 70925601,
    "AcceptedAnswer": "yes we can use field level annotations (annotation with @Target(ElementType.FIELD) in the defination.\n@JsonInclude(Include.NON_NULL)\nrecord Rectangle(\n    @JsonProperty(\"lengthAlias\") double length,\n    double width) { }\n\n"
}
{
    "Id": 71296783,
    "PostTypeId": 1,
    "Title": "JUINT test giving error java.lang.reflect.InaccessibleObjectException: Unable to make protected void java.lang.Object.finalize()",
    "Body": "While running the test I am getting the error , I am not able to understand why am I getting this error , this code is working with fine in java 8 , while running it in java 17 it is giving error. googled this error but found nothing useful. Please help me to understand this error.\nThanks in advance:)\n@RunWith(PowerMockRunner.class)\n@PrepareForTest({PopulatedAuthorizedUser.class})\n@SpringBootTest(classes = MockServletContext.class)\n@PowerMockIgnore({\"javax.management.*\", \"javax.net.ssl.*\", \n\"jdk.internal.reflect.*\"})\npublic class ProjectUserControllerTest {\n\nprivate ProjectUserController controller;\n\nprivate UUID projectId = UUID.randomUUID();\nprivate UUID groupId = UUID.randomUUID();\nprivate String email = \"project.user@email.com\";\n\n@Mock\nprivate ProjectUserService projectUserService;\n\nprivate ObjectMapper objectMapper = new ObjectMapper();\n\n@Mock\nprotected AuthorizedUser au;\n\n@Before\npublic void setUp() throws Exception {\n    controller = new ProjectUserController();\n    FieldUtils.writeField(controller, \"projectUserService\", projectUserService, true);\n    FieldUtils.writeField(controller, \"objectMapper\", objectMapper, true);\n    PowerMockito.mockStatic(PopulatedAuthorizedUser.class);\n    Mockito.when(PopulatedAuthorizedUser.get()).thenReturn(mockAuthorizedUser());\n}\n\n@Test\npublic void testGetProjectUsers() {\n    Mockito.doReturn(Arrays.asList(mockProjectUser())).when(projectUserService)\n            .findProjectUsersByProjectId(projectId);\n    Mockito.doNothing().when(projectUserService).enrichUserDetails(any(ProjectUserDto.class));\n    ResponseEntity> response=controller.getProjectUsers(projectId);\n    assertNotNull(response);\n    ProjectUserDto projectUserDto = response.getBody().get(0);\n    assertEquals(groupId, projectUserDto.getGroupId());\n    assertEquals(email, projectUserDto.getUsername());\n    assertTrue(projectUserDto.getEmailNotification());\n    assertEquals(ProjectUserRole.OWNER.toString(), projectUserDto.getRole());\n   }\n\n }\n\nException:\n java.lang.reflect.InaccessibleObjectException: Unable to make protected void java.lang.Object.finalize() throws java.lang.Throwable accessible: module java.base does not \"opens java.lang\" to unnamed module @5ba23b66\n\nat java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:354)\nat java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:297)\nat java.base/java.lang.reflect.Method.checkCanSetAccessible(Method.java:199)\nat java.base/java.lang.reflect.Method.setAccessible(Method.java:193)\nat org.powermock.reflect.internal.WhiteboxImpl.doGetAllMethods(WhiteboxImpl.java:1492)\nat org.powermock.reflect.internal.WhiteboxImpl.getAllMethods(WhiteboxImpl.java:1467)\nat org.powermock.reflect.internal.WhiteboxImpl.findMethodOrThrowException(WhiteboxImpl.java:847)\nat org.powermock.reflect.internal.WhiteboxImpl.doInvokeMethod(WhiteboxImpl.java:807)\nat org.powermock.reflect.internal.WhiteboxImpl.invokeMethod(WhiteboxImpl.java:790)\nat org.powermock.reflect.Whitebox.invokeMethod(Whitebox.java:466)\nat org.powermock.modules.junit4.common.internal.impl.PowerMockJUnit4RunListener.testFinished(PowerMockJUnit4RunListener.java:55)\nat org.junit.runner.notification.SynchronizedRunListener.testFinished(SynchronizedRunListener.java:87)\nat org.junit.runner.notification.RunNotifier$9.notifyListener(RunNotifier.java:225)\nat org.junit.runner.notification.RunNotifier$SafeNotifier.run(RunNotifier.java:72)\nat org.junit.runner.notification.RunNotifier.fireTestFinished(RunNotifier.java:222)\nat org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.testAborted(PowerMockJUnit44RunnerDelegateImpl.java:229)\nat org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.invokeTestMethod(PowerMockJUnit44RunnerDelegateImpl.java:206)\nat org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.runMethods(PowerMockJUnit44RunnerDelegateImpl.java:160)\nat org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl$1.run(PowerMockJUnit44RunnerDelegateImpl.java:134)\nat org.junit.internal.runners.ClassRoadie.runUnprotected(ClassRoadie.java:34)\nat org.junit.internal.runners.ClassRoadie.runProtected(ClassRoadie.java:44)\nat org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.run(PowerMockJUnit44RunnerDelegateImpl.java:136)\nat org.powermock.modules.junit4.common.internal.impl.JUnit4TestSuiteChunkerImpl.run(JUnit4TestSuiteChunkerImpl.java:121)\nat org.powermock.modules.junit4.common.internal.impl.AbstractCommonPowerMockRunner.run(AbstractCommonPowerMockRunner.java:57)\nat org.powermock.modules.junit4.PowerMockRunner.run(PowerMockRunner.java:59)\nat org.junit.runner.JUnitCore.run(JUnitCore.java:137)\nat com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)\nat com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33)\nat com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:235)\nat com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:54)\n\n",
    "AcceptedAnswerId": 71296829,
    "AcceptedAnswer": "In Java 9 and above, the module system can cause these errors. I've had the same issues with JUnit 5 itself because I omit the public from my test classes and methods.\nHere's what I have in my POM to solve this:\n\n  org.apache.maven.plugins\n  maven-surefire-plugin\n  \n    \n    --add-opens /=ALL-UNNAMED\n  \n\n\nIn your case you probably need to use java.base/java.lang=ALL_UNNAMED.\n"
}
{
    "Id": 71044636,
    "PostTypeId": 1,
    "Title": "JMH using java 17, no dead code elimination",
    "Body": "I run sample JHM benchmark which suppose to show dead code elimination. Code is rewritten for conciseness from jhm github sample.\nimport org.openjdk.jmh.annotations.*;\nimport java.util.concurrent.TimeUnit;\n\n@State(Scope.Thread)\n@BenchmarkMode(Mode.AverageTime)\n@OutputTimeUnit(TimeUnit.NANOSECONDS)\n@Fork(1)\npublic class Sample08DeadCode {\n\n    private double x = Math.PI;\n\n    @Benchmark\n    public void benchmark() {}\n\n    @Benchmark\n    public void measureIncorrect() { Math.log(x); }\n\n    @Benchmark\n    public double measureCorrect() { return Math.log(x); }\n}\n\nRun using JDK 1.8.0_211, Java HotSpot(TM) 64-Bit Server VM, 25.211-b12 produces following results:\nBenchmark                          Mode  Cnt   Score   Error  Units\nSample08DeadCode.benchmark         avgt    5   0,229 \u00b1 0,018  ns/op\nSample08DeadCode.measureCorrect    avgt    5  12,013 \u00b1 0,047  ns/op\nSample08DeadCode.measureIncorrect  avgt    5   0,228 \u00b1 0,016  ns/op\n\nbut using java JDK 17.0.2, Java HotSpot(TM) 64-Bit Server VM, 17.0.2+8-LTS-86 the results have no sign of dead code elimination:\nBenchmark                          Mode  Cnt  Score   Error  Units\nSample08DeadCode.benchmark         avgt    5  0,341 \u00b1 0,004  ns/op\nSample08DeadCode.measureCorrect    avgt    5  6,244 \u00b1 0,072  ns/op\nSample08DeadCode.measureIncorrect  avgt    5  6,263 \u00b1 0,094  ns/op\n\nWhy does the measureIncorrect() method is not optimized using java 17?\n",
    "AcceptedAnswerId": 71053938,
    "AcceptedAnswer": "Those samples depend on JDK internals.\nLooks like since JDK 9 and JDK-8152907, Math.log is no longer intrinsified into C2 intermediate representation. Instead, a direct call to a quick LIBM-backed stub is made. This is usually faster for the code that actually uses the result. Notice how measureCorrect is faster in JDK 17 output in your case.\nBut for JMH samples, it limits the the compiler optimizations around the Math.log, and dead code / folding samples do not work properly. The fix it to make samples that do not rely on JDK internals without a good reason, and instead use a custom written payload.\nThis is being done in JMH here:\n\nhttps://bugs.openjdk.java.net/browse/CODETOOLS-7903094\nhttps://github.com/openjdk/jmh/pull/60\n\n"
}
{
    "Id": 71494924,
    "PostTypeId": 1,
    "Title": "How does Java know which overloaded method to call with lambda expressions? (Supplier, Consumer, Callable, ...)",
    "Body": "First off, I have no idea how to decently phrase the question, so this is up for suggestions.\nLets say we have following overloaded methods:\nvoid execute(Callable callable) {\n    try {\n        callable.call();\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n}\n\n T execute(Supplier supplier) {\n    return supplier.get();\n}\n\nvoid execute(Runnable runnable) {\n    runnable.run();\n}\n\nGoing off from this table, I got from another SO question\nSupplier       ()    -> x\nConsumer       x     -> ()\nBiConsumer     x, y  -> ()\nCallable       ()    -> x throws ex\nRunnable       ()    -> ()\nFunction       x     -> y\nBiFunction     x,y   -> z\nPredicate      x     -> boolean\nUnaryOperator  x1    -> x2\nBinaryOperator x1,x2 -> x3\n\nThese are the results I get locally:\n// Runnable -> expected as this is a plain void  \nexecute(() -> System.out.println()); \n\n// Callable -> why is it not a Supplier? It does not throw any exceptions..\nexecute(() -> null);\n\n// Supplier -> this returns an Object, but how is that different from returning null?\nexecute(() -> new Object());\n\n// Callable -> because it can throw an exception, right?\nexecute(() -> {throw new Exception();});\n\nHow does the compiler know which method to call?\nHow does it for example make the distinction between what's a Callable and what's a Runnable?\n",
    "AcceptedAnswerId": 71496000,
    "AcceptedAnswer": "I believe I have found where this is described in official documentation, although a bit hard to read.\nHere is mentioned:\n\n15.27.3. Type of a Lambda Expression\nNote that while boxing is not allowed in a strict invocation context,\nboxing of lambda result expressions is always allowed - that is, the\nresult expression appears in an assignment context, regardless of the\ncontext enclosing the lambda expression. However, if an explicitly\ntyped lambda expression is an argument to an overloaded method, a\nmethod signature that avoids boxing or unboxing the lambda result is\npreferred by the most specific check (\u00a715.12.2.5).\n\nand then here (15.12.2.5) is described analytically how the most specific method is chosen.\nSo according to this for example as described\n\nOne applicable method m1 is more specific than another applicable\nmethod m2, for an invocation with argument expressions e1, ..., ek, if\nany of the following are true:\nm2 is generic, and m1 is inferred to be more specific than m2 for\nargument expressions e1, ..., ek\n\nSo\n// Callable -> why is it not a Supplier?\nexecute(() -> null);   <-- Callable shall be picked from 2 options as M2 is generic and M1 is inferred to be more specific\n\nvoid execute(Callable callable) {  // <------ M1 \n   try {\n    callable.call();\n  } catch (Exception e) {\n      e.printStackTrace();\n  }\n}\n\n\n  T execute(Supplier supplier) {  // <------ M2 is Generic\n    return supplier.get();\n }\n\nWhy M1 is inferred to be more specific can be traced down from this process described here (18.5.4 More Specific Method Inference)\n"
}
{
    "Id": 71500951,
    "PostTypeId": 1,
    "Title": "maven-checkstyle-plugin failed to parse Java 'record'",
    "Body": "I'm trying to setup checkstyle in our project - but seems like Maven (v3.8.3) or maven-checkstyle-plugin (v3.1.1) itself are not aware of Java 14's record (we use Java 17).\n\r\n\r\nCaused by: java.lang.IllegalStateException: /Users/dmitry.adonin/IdeaProjects/raap/src/main/java/com/xxx/web/dto/Request.java:3:8: unexpected token: record\n    at com.puppycrawl.tools.checkstyle.JavaParser$1.reportError (JavaParser.java:93)\n    at com.puppycrawl.tools.checkstyle.grammar.GeneratedJavaRecognizer.typeDefinition (GeneratedJavaRecognizer.java:411)\n    at com.puppycrawl.tools.checkstyle.grammar.GeneratedJavaRecognizer.compilationUnit (GeneratedJavaRecognizer.java:202)\n    at com.puppycrawl.tools.checkstyle.JavaParser.parse (JavaParser.java:99)\n    at com.puppycrawl.tools.checkstyle.TreeWalker.processFiltered (TreeWalker.java:159)\n    at com.puppycrawl.tools.checkstyle.api.AbstractFileSetCheck.process (AbstractFileSetCheck.java:85)\n    at com.puppycrawl.tools.checkstyle.Checker.processFile (Checker.java:329)\n    at com.puppycrawl.tools.checkstyle.Checker.processFiles (Checker.java:291)\n    at com.puppycrawl.tools.checkstyle.Checker.process (Checker.java:216)\n    at org.apache.maven.plugins.checkstyle.exec.DefaultCheckstyleExecutor.executeCheckstyle (DefaultCheckstyleExecutor.java:202)\n    at org.apache.maven.plugins.checkstyle.CheckstyleViolationCheckMojo.execute (CheckstyleViolationCheckMojo.java:545)\n    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:137)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:210)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:156)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:148)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:305)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:972)\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:293)\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:196)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:566)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:282)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:225)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:406)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:347)\nCaused by: antlr.NoViableAltException: unexpected token: record\n    at com.puppycrawl.tools.checkstyle.grammar.GeneratedJavaRecognizer.typeDefinitionInternal (GeneratedJavaRecognizer.java:584)\n    at com.puppycrawl.tools.checkstyle.grammar.GeneratedJavaRecognizer.typeDefinition (GeneratedJavaRecognizer.java:389)\n    at com.puppycrawl.tools.checkstyle.grammar.GeneratedJavaRecognizer.compilationUnit (GeneratedJavaRecognizer.java:202)\n    at com.puppycrawl.tools.checkstyle.JavaParser.parse (JavaParser.java:99)\n    at com.puppycrawl.tools.checkstyle.TreeWalker.processFiltered (TreeWalker.java:159)\n    at com.puppycrawl.tools.checkstyle.api.AbstractFileSetCheck.process (AbstractFileSetCheck.java:85)\n    at com.puppycrawl.tools.checkstyle.Checker.processFile (Checker.java:329)\n    at com.puppycrawl.tools.checkstyle.Checker.processFiles (Checker.java:291)\n    at com.puppycrawl.tools.checkstyle.Checker.process (Checker.java:216)\n    at org.apache.maven.plugins.checkstyle.exec.DefaultCheckstyleExecutor.executeCheckstyle (DefaultCheckstyleExecutor.java:202)\n    at org.apache.maven.plugins.checkstyle.CheckstyleViolationCheckMojo.execute (CheckstyleViolationCheckMojo.java:545)\n    at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo (DefaultBuildPluginManager.java:137)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:210)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:156)\n    at org.apache.maven.lifecycle.internal.MojoExecutor.execute (MojoExecutor.java:148)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:117)\n    at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject (LifecycleModuleBuilder.java:81)\n    at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build (SingleThreadedBuilder.java:56)\n    at org.apache.maven.lifecycle.internal.LifecycleStarter.execute (LifecycleStarter.java:128)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:305)\n    at org.apache.maven.DefaultMaven.doExecute (DefaultMaven.java:192)\n    at org.apache.maven.DefaultMaven.execute (DefaultMaven.java:105)\n    at org.apache.maven.cli.MavenCli.execute (MavenCli.java:972)\n    at org.apache.maven.cli.MavenCli.doMain (MavenCli.java:293)\n    at org.apache.maven.cli.MavenCli.main (MavenCli.java:196)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0 (Native Method)\n    at jdk.internal.reflect.NativeMethodAccessorImpl.invoke (NativeMethodAccessorImpl.java:62)\n    at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke (DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke (Method.java:566)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced (Launcher.java:282)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.launch (Launcher.java:225)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode (Launcher.java:406)\n    at org.codehaus.plexus.classworlds.launcher.Launcher.main (Launcher.java:347)\r\n\r\n\r\n\nThere are the following configs:\npom.xml:\n\r\n\r\n\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n    xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    4.0.0\n\n    \n        org.springframework.boot\n        spring-boot-starter-parent\n        2.6.2\n        \n    \n\n    ...\n    ...\n    0.0.1-SNAPSHOT\n    ...\n\n    \n        17\n    \n\n    \n    ...\n    \n\n    \n        \n            \n                org.springframework.boot\n                spring-boot-maven-plugin\n                \n                    \n                        \n                            org.projectlombok\n                            lombok\n                        \n                    \n                \n            \n            \n                org.apache.maven.plugins\n                maven-checkstyle-plugin\n                3.1.1\n                \n                    project-checks.xml\n                    UTF-8\n                    true\n                    true\n                    true\n                    false\n                \n                \n                    \n                        checkstyle-validation\n                        validate\n                        \n                            check\n                        \n                    \n                \n            \n        \n    \n\n\r\n\r\n\r\n\nproject-checks.xml:\n\r\n\r\n\n\n<!DOCTYPE module PUBLIC\n        \"-//Checkstyle//DTD Checkstyle Configuration 1.3//EN\"\n        \"https://checkstyle.org/dtds/configuration_1_3.dtd\">\n\n<!--\n    Checkstyle configuration that checks the Google coding conventions from Google Java Style\n    that can be found at https://google.github.io/styleguide/javaguide.html\n    Checkstyle is very configurable. Be sure to read the documentation at\n    https://checkstyle.org (or in your downloaded distribution).\n    To completely disable a check, just comment it out or delete it from the file.\n    To suppress certain violations please review suppression filters.\n    Authors: Max Vetrenko, Ruslan Diachenko, Roman Ivanov.\n -->\n\n\n    \n\n    \n\n    \n    \n    \n    \n        \n    \n    \n    \n    \n        \n        \n    \n\n    \n    \n    \n        \n    \n\n    \n        \n        \n        \n    \n\n    \n        \n        \n            \n            <property name=\"format\"\n                      value=\"\\\\u00(09|0(a|A)|0(c|C)|0(d|D)|22|27|5(C|c))|\\\\(0(10|11|12|14|15|42|47)|134)\"/>\n            <property name=\"message\"\n                      value=\"Consider using special escape sequence instead of octal value or Unicode escaped value.\"/>\n        \n        \n            \n            \n            \n        \n        \n        \n        \n        \n            \n        \n        \n            \n            <property name=\"tokens\"\n                      value=\"LITERAL_TRY, LITERAL_FINALLY, LITERAL_IF, LITERAL_ELSE, LITERAL_SWITCH\"/>\n        \n        \n            <property name=\"tokens\"\n                      value=\"LITERAL_DO, LITERAL_ELSE, LITERAL_FOR, LITERAL_IF, LITERAL_WHILE\"/>\n        \n        \n            <property name=\"tokens\"\n                      value=\"ANNOTATION_DEF, CLASS_DEF, CTOR_DEF, ENUM_CONSTANT_DEF, ENUM_DEF,\n                    INTERFACE_DEF, LAMBDA, LITERAL_CASE, LITERAL_CATCH, LITERAL_DEFAULT,\n                    LITERAL_DO, LITERAL_ELSE, LITERAL_FINALLY, LITERAL_FOR, LITERAL_IF,\n                    LITERAL_SWITCH, LITERAL_SYNCHRONIZED, LITERAL_TRY, LITERAL_WHILE, METHOD_DEF,\n                    OBJBLOCK, STATIC_INIT\"/>\n        \n        \n            \n            <property name=\"tokens\"\n                      value=\"LITERAL_TRY, LITERAL_CATCH, LITERAL_FINALLY, LITERAL_IF, LITERAL_ELSE,\n                    LITERAL_DO\"/>\n        \n        \n            \n            \n            <property name=\"tokens\"\n                      value=\"CLASS_DEF, METHOD_DEF, CTOR_DEF, LITERAL_FOR, LITERAL_WHILE, STATIC_INIT,\n                    INSTANCE_INIT, ANNOTATION_DEF, ENUM_DEF\"/>\n        \n        \n            \n            \n            <property name=\"query\" value=\"//RCURLY[parent::SLIST[count(./*)=1]\n                                                 or preceding-sibling::*[last()][self::LCURLY]]\"/>\n        \n        \n            \n            \n            \n            \n            \n            <property name=\"tokens\"\n                      value=\"ASSIGN, BAND, BAND_ASSIGN, BOR, BOR_ASSIGN, BSR, BSR_ASSIGN, BXOR,\n                    BXOR_ASSIGN, COLON, DIV, DIV_ASSIGN, DO_WHILE, EQUAL, GE, GT, LAMBDA, LAND,\n                    LCURLY, LE, LITERAL_CATCH, LITERAL_DO, LITERAL_ELSE, LITERAL_FINALLY,\n                    LITERAL_FOR, LITERAL_IF, LITERAL_RETURN, LITERAL_SWITCH, LITERAL_SYNCHRONIZED,\n                     LITERAL_TRY, LITERAL_WHILE, LOR, LT, MINUS, MINUS_ASSIGN, MOD, MOD_ASSIGN,\n                     NOT_EQUAL, PLUS, PLUS_ASSIGN, QUESTION, RCURLY, SL, SLIST, SL_ASSIGN, SR,\n                     SR_ASSIGN, STAR, STAR_ASSIGN, LITERAL_ASSERT, TYPE_EXTENSION_AND\"/>\n            <message key=\"ws.notFollowed\"\n                     value=\"WhitespaceAround: ''{0}'' is not followed by whitespace. Empty blocks may only be represented as '{}' when not part of a multi-block statement (4.1.3)\"/>\n            <message key=\"ws.notPreceded\"\n                     value=\"WhitespaceAround: ''{0}'' is not preceded with whitespace.\"/>\n        \n        \n        \n        \n        \n        \n        \n        \n        \n            <property name=\"tokens\"\n                      value=\"PACKAGE_DEF, IMPORT, STATIC_IMPORT, CLASS_DEF, INTERFACE_DEF, ENUM_DEF,\n                    STATIC_INIT, INSTANCE_INIT, METHOD_DEF, CTOR_DEF, VARIABLE_DEF\"/>\n            \n            \n            \n        \n        \n            \n            \n            \n        \n        \n            \n            \n            \n        \n        \n            \n            \n            \n            \n        \n        \n            \n            \n            \n            \n        \n        \n            \n            \n            \n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Package name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Type name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Member name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Parameter name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Lambda parameter name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Catch parameter name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Local variable name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Class type name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Method type name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Interface type name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n            \n            <message key=\"name.invalidPattern\"\n                     value=\"Method name ''{0}'' must match pattern ''{1}''.\"/>\n        \n        \n        \n            <message key=\"ws.followed\"\n                     value=\"GenericWhitespace ''{0}'' is followed by whitespace.\"/>\n            <message key=\"ws.preceded\"\n                     value=\"GenericWhitespace ''{0}'' is preceded with whitespace.\"/>\n            <message key=\"ws.illegalFollow\"\n                     value=\"GenericWhitespace ''{0}'' should followed by whitespace.\"/>\n            <message key=\"ws.notPreceded\"\n                     value=\"GenericWhitespace ''{0}'' is not preceded with whitespace.\"/>\n        \n        \n            \n            \n            \n            \n            \n            \n        \n        \n            \n            \n            <property name=\"tokens\"\n                      value=\"CLASS_DEF, INTERFACE_DEF, ENUM_DEF, ANNOTATION_DEF, ANNOTATION_FIELD_DEF,\n                    PARAMETER_DEF, VARIABLE_DEF, METHOD_DEF\"/>\n        \n        \n        \n        \n            \n            \n            \n            \n            \n            \n        \n        \n            <property name=\"tokens\"\n                      value=\"CTOR_DEF, LITERAL_NEW, METHOD_CALL, METHOD_DEF,\n                    SUPER_CTOR_CALL, ENUM_CONSTANT_DEF\"/>\n        \n        \n            <property name=\"tokens\"\n                      value=\"COMMA, SEMI, POST_INC, POST_DEC, DOT, ELLIPSIS, METHOD_REF\"/>\n            \n        \n        \n            <property name=\"tokens\"\n                      value=\"ANNOTATION, ANNOTATION_FIELD_DEF, CTOR_CALL, CTOR_DEF, DOT, ENUM_CONSTANT_DEF,\n                    EXPR, LITERAL_CATCH, LITERAL_DO, LITERAL_FOR, LITERAL_IF, LITERAL_NEW,\n                    LITERAL_SWITCH, LITERAL_SYNCHRONIZED, LITERAL_WHILE, METHOD_CALL,\n                    METHOD_DEF, QUESTION, RESOURCE_SPECIFICATION, SUPER_CTOR_CALL, LAMBDA\"/>\n        \n        \n            \n            <property name=\"tokens\"\n                      value=\"BAND, BOR, BSR, BXOR, DIV, EQUAL, GE, GT, LAND, LE, LITERAL_INSTANCEOF, LOR,\n                    LT, MINUS, MOD, NOT_EQUAL, PLUS, QUESTION, SL, SR, STAR, METHOD_REF \"/>\n        \n        \n            \n            <property name=\"tokens\"\n                      value=\"CLASS_DEF, INTERFACE_DEF, ENUM_DEF, METHOD_DEF, CTOR_DEF\"/>\n        \n        \n            \n            \n            \n        \n        \n        \n        \n        \n            <property name=\"forbiddenSummaryFragments\"\n                      value=\"^@return the *|^This method returns |^A [{]@code [a-zA-Z0-9]+[}]( is a )\"/>\n        \n        \n        \n            \n            <property name=\"target\"\n                      value=\"CLASS_DEF, INTERFACE_DEF, ENUM_DEF, METHOD_DEF, CTOR_DEF, VARIABLE_DEF\"/>\n        \n        \n            \n            \n            \n            \n            \n        \n        \n            \n        \n        \n            \n        \n        \n            \n        \n        \n        \n            \n            \n        \n    \n\r\n\r\n\r\n\nCould someone please suggest what should be adjusted to make it work?\nThank you!\n",
    "AcceptedAnswerId": 71501025,
    "AcceptedAnswer": "The plugin by default comes with Checkstyle version 8.29. Try explicitly defining the CheckStyle version (plus a small version bump to 3.1.2). For example, with version 9.2:\n\n    org.apache.maven.plugins\n    maven-checkstyle-plugin\n    3.1.2\n    \n       ...\n    \n    \n        \n            com.puppycrawl.tools\n            checkstyle\n            9.2\n        \n    \n    \n        ...\n    \n\n\n"
}
{
    "Id": 71063202,
    "PostTypeId": 1,
    "Title": "check valid date in java",
    "Body": "I tried to check a String input that is a valid date using the format dd/MM/yyyy like this:\nString input = Scanner.nextLine();\nDateTimeFormatter formater = DateTimeFormatter.ofPattern(\"dd/MM/yyyy\");\ntry{\n    LocaleDate.parse(input, formater);\n}\ncatch(Exception e)\n\nBut it can't check some rules below:\nLeap year, February 29 days.\n\nCommon year, February 28 days.\n\nMonth 1, 3, 5, 7, 8, 10, 12, max 31 days.\n\nMonth 4, 6, 9, 11, max 30 days.\n\nWhen I use input = \"30/02/2022\", it's legal.\nI use netbeans 8.2 and jdk 1.8. Do they support some methods for checking these rules?\n",
    "AcceptedAnswerId": 71063276,
    "AcceptedAnswer": "There are two things you need to change in your formatter:\n\nUse uuuu instead of yyyy. It's easy to try the latter, but y means \"year within ERA\". It doesn't know whether it's BC or AD. u means \"year\" including ERA information.\nThe default resolver style is SMART. Use .withResolverStyle(ResolverStyle.STRICT) to return a strict copy of the formatter.\n\n"
}
{
    "Id": 71250218,
    "PostTypeId": 1,
    "Title": "Java, project panama and how to deal with Hunspell 'suggest' result",
    "Body": "I'm experimenting with Hunspell and how to interact with it using Java Project Panama (Build 19-panama+1-13 (2022/1/18)). I was able to get some initial testing done, as in creating a handle to Hunspell and subsequently using that to perform a spell check. I'm now trying something more elaborate, letting Hunspell give me suggestions for a word not present in the dictionary. This is the code that I have for that now:\npublic class HelloHun {\n    public static void main(String[] args) {\n        MemoryAddress hunspellHandle = null;\n        try (ResourceScope scope = ResourceScope.newConfinedScope()) {\n            var allocator = SegmentAllocator.nativeAllocator(scope);\n\n            // Point it to US english dictionary and (so called) affix file\n            // Note #1: it is possible to add words to the dictionary if you like\n            // Note #2: it is possible to have separate/individual dictionaries and affix files (e.g. per user/doc type)\n            var en_US_aff = allocator.allocateUtf8String(\"/usr/share/hunspell/en_US.aff\");\n            var en_US_dic = allocator.allocateUtf8String(\"/usr/share/hunspell/en_US.dic\");\n\n            // Get a handle to the Hunspell shared library and load up the dictionary and affix\n            hunspellHandle = Hunspell_create(en_US_aff, en_US_dic);\n\n            // Feed it a wrong word\n            var javaWord = \"koing\";\n\n            // Do a simple spell check of the word\n            var word = allocator.allocateUtf8String(javaWord);\n            var spellingResult = Hunspell_spell(hunspellHandle, word);\n            System.out.println(String.format(\"%s is spelled %s\", javaWord, (spellingResult == 0 ? \"incorrect\" : \"correct\")));\n\n            // Hunspell also supports giving suggestions for a word - which is what we do next\n            // Note #3: by testing this `koing` word in isolation - we know that there are 4 alternatives for this word\n            // Note #4: I'm still investigating how to access individual suggestions\n\n            var suggestions = allocator.allocate(10);\n            var suggestionCount = Hunspell_suggest(hunspellHandle, suggestions, word);\n\n            System.out.println(String.format(\"There are %d suggestions for %s\", suggestionCount, javaWord));\n\n            // `suggestions` - according to the hunspell API - is a `pointer to an array of strings pointer`\n            // we know how many `strings` pointer there are, as that is the returned value from `suggest`\n            // Question: how to process `suggestions` to get individual suggestions\n\n\n        } finally {\n            if (hunspellHandle != null) {\n                Hunspell_destroy(hunspellHandle);\n            }\n        }\n    }\n}\n\nWhat I'm seeing is that a call to Hunspell_suggest (created from jextract) succeeds and gives me back (4) suggestions (which I verified using Hunspell from the commandline) - so no problem there.\nWhat is more challenging for me now is how do I unpack the suggestions element that comes back from this call? I've been looking at various examples, but none of them seem to go into this level of detail (and even if I find examples, they seem to be using outdated panama APIs).\nSo in essence, here is my question:\nHow do I unpack a structure that reportedly consists of a pointer to an array of strings pointer using panama JDK19 APIs to their respective collection of strings?\n",
    "AcceptedAnswerId": 71258371,
    "AcceptedAnswer": "Looking at the header here: https://github.com/hunspell/hunspell/blob/master/src/hunspell/hunspell.h#L80\n/* suggest(suggestions, word) - search suggestions\n * input: pointer to an array of strings pointer and the (bad) word\n *   array of strings pointer (here *slst) may not be initialized\n * output: number of suggestions in string array, and suggestions in\n *   a newly allocated array of strings (*slts will be NULL when number\n *   of suggestion equals 0.)\n */\nLIBHUNSPELL_DLL_EXPORTED int Hunspell_suggest(Hunhandle* pHunspell,\n                                              char*** slst,\n                                              const char* word);\n\nThe slst is a classic 'out' parameter. i.e. we pass a pointer to some value (in this case a char** i.e. an array of strings), and the function will set this pointer for us, as a way to return multiple results. (the first result being the number of suggestions)\nIn panama you use 'out' parameters by allocating a segment with the layout of the type the parameter is a pointer of. In this case char*** is a pointer to char**, so the layout is ADDRESS. We then pass the created segment to the function, and finally retrieve/use the value from that segment after the function call, which will have filled in the segment contents:\n// char***\nvar suggestionsRef = allocator.allocate(ValueLayout.ADDRESS); // allocate space for an address\nvar suggestionCount = Hunspell_suggest(hunspellHandle, suggestionsRef, word);\n// char** (the value set by the function)\nMemoryAddress suggestions = suggestionsRef.get(ValueLayout.ADDRESS, 0);\n\nAfter that, you can iterate over the array of strings:\nfor (int i = 0; i < suggestionCount; i++) {\n    // char* (an element in the array)\n    MemoryAddress suggestion = suggestions.getAtIndex(ValueLayout.ADDRESS, i);\n    // read the string\n    String javaSuggestion = suggestion.getUtf8String(suggestion, 0);\n}\n\n"
}
{
    "Id": 71338792,
    "PostTypeId": 1,
    "Title": "java.lang.NoClassDefFoundError: Failed resolution of: Ljava/lang/Math8 when upgrading Gradle and Android Gradle Plugin",
    "Body": "I'm working on an Android app with a Gradle version of 7.1.1 and an Android Gradle Plugin version of 7.0.0. When I upgrade to Gradle version 7.2 and Android Gradle Plugin version 7.1.1, I get the following error.\n2022-03-02 17:15:47.072 25300-25300/... E/AndroidRuntime: FATAL EXCEPTION: main\n    Process: ..., PID: 25300\n    java.lang.NoClassDefFoundError: Failed resolution of: Ljava/lang/Math8;\n        at j$.time.Instant.ofEpochSecond(Instant.java:328)\n        at j$.time.Instant.(Instant.java:232)\n        at j$.time.Instant.ofEpochMilli(Instant.java:344)\n        ...\n        at kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)\n        at kotlinx.coroutines.DispatchedTask.run(DispatchedTask.kt:106)\n        at android.os.Handler.handleCallback(Handler.java:883)\n        at android.os.Handler.dispatchMessage(Handler.java:100)\n        at android.os.Looper.loop(Looper.java:214)\n        at android.app.ActivityThread.main(ActivityThread.java:7356)\n        at java.lang.reflect.Method.invoke(Native Method)\n        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:492)\n        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:930)\n     Caused by: java.lang.ClassNotFoundException: Didn't find class \"java.lang.Math8\" on path: DexPathList[[zip file \"/data/app/...-NbMXeOj8LumN03n4IMK5Cw==/base.apk\"],nativeLibraryDirectories=[/data/app/...-NbMXeOj8LumN03n4IMK5Cw==/lib/x86, /data/app/...-NbMXeOj8LumN03n4IMK5Cw==/base.apk!/lib/x86, /system/lib, /system/product/lib]]\n        at dalvik.system.BaseDexClassLoader.findClass(BaseDexClassLoader.java:196)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:379)\n        at java.lang.ClassLoader.loadClass(ClassLoader.java:312)\n        at j$.time.Instant.ofEpochSecond(Instant.java:328) \n        at j$.time.Instant.(Instant.java:232) \n        at j$.time.Instant.ofEpochMilli(Instant.java:344) \n        ...\n        at kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33) \n        at kotlinx.coroutines.DispatchedTask.run(DispatchedTask.kt:106) \n        at android.os.Handler.handleCallback(Handler.java:883) \n        at android.os.Handler.dispatchMessage(Handler.java:100) \n        at android.os.Looper.loop(Looper.java:214) \n        at android.app.ActivityThread.main(ActivityThread.java:7356) \n        at java.lang.reflect.Method.invoke(Native Method) \n        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:492) \n        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:930)\n\nThe error is coming from this code:\nfun toLocalStartOfDay(date: Long): Instant = Instant.ofEpochMilli(date)\n    .atZone(ZoneId.systemDefault())\n    .withHour(0)\n    .withMinute(0)\n    .withSecond(0)\n    .withNano(0)\n    .toInstant()\n\nThe build.gradle file is set to target JVM 1.8 with desugaring.\ncompileOptions {\n    coreLibraryDesugaringEnabled = true\n    sourceCompatibility JavaVersion.VERSION_1_8\n    targetCompatibility JavaVersion.VERSION_1_8\n}\n\nkotlinOptions {\n    jvmTarget = '1.8'\n}\n\nThe desugar_jdk_libs version is set to 1.0.9.\nversions.androidDesugaringVersion = '1.0.9'\nsupport.android_desugaring = \"com.android.tools:desugar_jdk_libs:$versions.androidDesugaringVersion\"\n\nWhy would upgrading cause this error?\n",
    "AcceptedAnswerId": 71340133,
    "AcceptedAnswer": "Desugaring effects \"a subset of java.time\" so upgrading to the latest version of desugar_jdk_libs should fix the issue. At the time of posting, the latest version is 1.1.5.\nReferences\n\nJava 8+ API desugaring support (Android Gradle Plugin 4.0.0+)\ndesugar_jdk_libs (Maven)\n\n"
}
{
    "Id": 71771423,
    "PostTypeId": 1,
    "Title": "React Native: 'compileJava' task (current target is 1.8) and 'compileKotlin' task (current target is 11) jvm target compat",
    "Body": "Hello everyone I am trying to create and run a react native app. I run\nnpx react-native init rn4 but when I run npm run android I have this error:\n> Task :react-native-gradle-plugin:compileKotlin\n'compileJava' task (current target is 1.8) and 'compileKotlin' task (current target is 11) jvm target compatibility should be set to the same Java version.\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\ReactExtension.kt: (10, 37): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\ReactExtension.kt: (119, 30): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\ReactExtension.kt: (135, 26): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\ReactExtension.kt: (155, 32): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\ReactExtension.kt: (161, 31): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\ReactExtension.kt: (169, 36): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\ReactPlugin.kt: (99, 48): 'reactRoot: DirectoryProperty' is deprecated. reactRoot was confusing and has been replace with rootto point to your root project and reactNativeDir to point to the folder of the react-native NPM package\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\TaskConfiguration.kt: (10, 37): 'ApplicationVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\TaskConfiguration.kt: (11, 37): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\TaskConfiguration.kt: (12, 37): 'LibraryVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\TaskConfiguration.kt: (28, 51): 'BaseVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\TaskConfiguration.kt: (131, 12): 'ApplicationVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\TaskConfiguration.kt: (132, 12): 'LibraryVariant' is deprecated. Deprecated in Java\nw: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\kotlin\\com\\facebook\\react\\TaskConfiguration.kt: (250, 14): 'BaseVariant' is deprecated. Deprecated in Java\n\n> Task :react-native-gradle-plugin:compileJava\n6 actionable tasks: 6 executed\nNote: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\java\\com\\facebook\\react\\codegen\\generator\\SchemaJsonParser.java uses or overrides a deprecated API.\nNote: Recompile with -Xlint:deprecation for details.\n\nFAILURE: Build failed with an exception.\n\n* Where:\nBuild file 'C:\\Users\\emanu\\App\\rn4\\android\\app\\build.gradle' line: 1\n\n* What went wrong:\nA problem occurred evaluating project ':app'.\n> Failed to apply plugin 'com.android.internal.application'.\n   > Android Gradle plugin requires Java 11 to run. You are currently using Java 1.8.\n     You can try some of the following options:\n       - changing the IDE settings.\n       - changing the JAVA_HOME environment variable.\n       - changing `org.gradle.java.home` in `gradle.properties`.\n\n* Try:\n> Run with --stacktrace option to get the stack trace.\n> Run with --info or --debug option to get more log output.\n> Run with --scan to get full insights.\n\n* Get more help at https://help.gradle.org\n\nBUILD FAILED in 59s\n\nerror Failed to install the app. Make sure you have the Android development environment set up: https://reactnative.dev/docs/environment-setup.\nError: Command failed: gradlew.bat app:installDebug -PreactNativeDevServerPort=8081\nNote: C:\\Users\\emanu\\App\\rn4\\node_modules\\react-native-gradle-plugin\\src\\main\\java\\com\\facebook\\react\\codegen\\generator\\SchemaJsonParser.java uses or overrides a deprecated API.\nNote: Recompile with -Xlint:deprecation for details.\n\nFAILURE: Build failed with an exception.\n\n* Where:\nBuild file 'C:\\Users\\emanu\\App\\rn4\\android\\app\\build.gradle' line: 1\n\n* What went wrong:\nA problem occurred evaluating project ':app'.\n> Failed to apply plugin 'com.android.internal.application'.\n   > Android Gradle plugin requires Java 11 to run. You are currently using Java 1.8.\n     You can try some of the following options:\n       - changing the IDE settings.\n       - changing the JAVA_HOME environment variable.\n       - changing `org.gradle.java.home` in `gradle.properties`.\n\n* Try:\n> Run with --stacktrace option to get the stack trace.\n> Run with --info or --debug option to get more log output.\n> Run with --scan to get full insights.\n\n* Get more help at https://help.gradle.org\n\nBUILD FAILED in 59s\n\n    at makeError (C:\\Users\\emanu\\App\\rn4\\node_modules\\execa\\index.js:174:9)\n    at C:\\Users\\emanu\\App\\rn4\\node_modules\\execa\\index.js:278:16\n    at processTicksAndRejections (node:internal/process/task_queues:96:5)\n    at async runOnAllDevices (C:\\Users\\emanu\\App\\rn4\\node_modules\\@react-native-community\\cli-platform-android\\build\\commands\\runAndroid\\runOnAllDevices.js:109:5)\n    at async Command.handleAction (C:\\Users\\emanu\\App\\rn4\\node_modules\\@react-native-community\\cli\\build\\index.js:192:9)\ninfo Run CLI with --verbose flag for more details.\n\nI also run cd android && ./gradlew clean and the output is:\nFAILURE: Build failed with an exception.\n\n* Where:\nBuild file 'C:\\Users\\emanu\\App\\rn4\\android\\app\\build.gradle' line: 1\n\n* What went wrong:\nA problem occurred evaluating project ':app'.\n> Failed to apply plugin 'com.android.internal.application'.\n   > Android Gradle plugin requires Java 11 to run. You are currently using Java 1.8.\n     You can try some of the following options:\n       - changing the IDE settings.\n       - changing the JAVA_HOME environment variable.\n       - changing `org.gradle.java.home` in `gradle.properties`.\n\nThis is the file in android/gradle/wrapper/gradle-wrapper.properties\ndistributionBase=GRADLE_USER_HOME\ndistributionPath=wrapper/dists\ndistributionUrl=https\\://services.gradle.org/distributions/gradle-7.3.3-all.zip\nzipStoreBase=GRADLE_USER_HOME\nzipStorePath=wrapper/dists\n\nand this is the output when I run ./gradlew --version\n------------------------------------------------------------\nGradle 7.3.3\n------------------------------------------------------------\n\nBuild time:   2021-12-22 12:37:54 UTC\nRevision:     6f556c80f945dc54b50e0be633da6c62dbe8dc71\n\nKotlin:       1.5.31\nGroovy:       3.0.9\nAnt:          Apache Ant(TM) version 1.10.11 compiled on July 10 2021\nJVM:          1.8.0_302 (Oracle Corporation 25.302-b08)\nOS:           Windows 10 10.0 amd64\n\nI read similar posts but I haven't been able to fix it. With folders that I created some days ago I have no problem when I run the app.\nSomeone can help me please?\nVery thanks!\n",
    "AcceptedAnswerId": 71800545,
    "AcceptedAnswer": "If you are using React Native witch Chocolatey, you must update JDK version to 11.\nIn order to do the update, execute this in PowerShell (with admin privileges):\nchoco install -y openjdk11\n\nAfter that, the first time (only the first time) you run npm android, you will get a lot of warnings, but the built of the project will work.\nIf you continue receiving an error, maybe you need to adjust the gradle version of your project to be compatible with the new JDK version.\nYou can achieve this by editing the file YOUR_PROJECT\\android\\gradle\\wrapper\\gradle-wrapper.properties\nUpdate the version of distributionUrl to 7.4.2\nI hope I have been helpful\n"
}
{
    "Id": 71966064,
    "PostTypeId": 1,
    "Title": "Java: FileOutputStream(\"NUL:\") not working after Java upgrade",
    "Body": "On Windows, NUL is the null output device similar to /dev/null on Linux.\nWith Oracle Java 8 Update 331, trying to get a new FileOutputStream(\"NUL:\") throws an exception. Previously (Java 8u321) it worked fine.\nThe problem seems to be the colon:\n\nnew FileOutputStream(\"NUL\") - OK\nnew FileOutputStream(\"NUL:\") - exception\n\nCan anyone point me to docs or JDK sources regarding this change? I can't change the code itself because it is in a 3rd party lib (xnio-api).\ntry\n{\n  new FileOutputStream(\"NUL:\");\n  System.out.println(\"OK\");\n}\ncatch (FileNotFoundException e)\n{\n  System.out.println(e);\n}\n\n",
    "AcceptedAnswerId": 71966125,
    "AcceptedAnswer": "I suspect this is the offending change.\nApparently it tries to avoid accessing ADS (alternate data streams), but seems to \"accidentally\" also prevent access to device-files like this.\nIf that's correct, then you can try setting the system property jdk.io.File.enableADS to true to re-enable the old behaviour.\n"
}
{
    "Id": 71434304,
    "PostTypeId": 1,
    "Title": "Does Java Evaluate a Variable Declared as Final only Once?",
    "Body": "I'm writing a Java program that requires thousands of System.out.println() statements that will be printed hundreds of millions (or billions) of times throughout the lifecycle of the program for debugging purposes:\nif (GVar.runInDebugMode) System.out.println(\"Print debug message\");\n\nIn the real world, these statements can be deactivated in order to speed up a computational heavy calculation.\nIf I set:\npublic final static boolean runInDebugMode = false;\n\nDoes the compiler re-evaluate runInDebugMode each time it comes across a statement like: if (GVar.runInDebugMode) or since it was declared as final it will be evaluated once at the beginning of the program and won't put additional strain on the CPU? In other words, would I be better off commenting out all debug statements entirely once I deploy the app or is setting runInDebugMode  to false sufficient?\n",
    "AcceptedAnswerId": 71470775,
    "AcceptedAnswer": "When you declare a variable like\npublic final static boolean runInDebugMode = false;\n\nit\u2019s a compile-time constant.\n\nA constant variable is a final variable of primitive type or type String that is initialized with a constant expression (\u00a715.29).\n\nwhich means that\n\nA reference to a field that is a constant variable (\u00a74.12.4) must be resolved at compile time to the value V denoted by the constant variable's initializer.\nIf such a field is static, then no reference to the field should be present in the code in a binary file, including the class or interface which declared the field.\n\nIn other words, when you write if(runInDebugMode) anywhere and runInDebugMode is false at compile time, the behavior is as if you\u2019ve written if(false), as the value must be resolved at compile time and no reference to the field appears in the compiled class file.\nYour use case has been discussed specifically in \u00a714.22\n\nHowever, in order to allow the if statement to be used conveniently for \"conditional compilation\" purposes, the actual rules differ.\nAs an example, the following statement results in a compile-time error:\nwhile (false) { x=3; }\n\nbecause the statement x=3; is not reachable; but the superficially similar case:\nif (false) { x=3; }\n\ndoes not result in a compile-time error. An optimizing compiler may realize that the statement x=3; will never be executed and may choose to omit the code for that statement from the generated class file, but the statement x=3; is not regarded as \"unreachable\" in the technical sense specified here.\nThe rationale for this differing treatment is to allow programmers to define \"flag\" variables such as:\nstatic final boolean DEBUG = false;\n\nand then write code such as:\nif (DEBUG) { x=3; }\n\nThe idea is that it should be possible to change the value of DEBUG from false to true or from true to false and then compile the code correctly with no other changes to the program text.\nConditional compilation comes with a caveat. If a set of classes that use a \"flag\" variable - or more precisely, any static constant variable (\u00a74.12.4) - are compiled and conditional code is omitted, it does not suffice later to distribute just a new version of the class or interface that contains the definition of the flag.\n\nSo, this statement makes clear that this form of conditional compilation matches the intent of the language designers and that compilers are entitled to omit the code in question (all relevant compilers do). In principle, a compiler is not required to omit the code, but since it must not generate a reference to the field GVar.runInDebugMode in the compiled code, the code can\u2019t contain a real conditional. If the code is not omitted, it must be skipped in a de-facto unconditional way. Either, by a goto instruction or, when compiling in the most na\u00efve way imaginable, by literally testing false, iconst_0; ifeq \u2026. Both approaches would be on the nanosecond scale in interpreted execution mode and no challenge to the JIT compiler/ optimizer at all.\n\nIt\u2019s worth mentioning that static final fields are trusted fields which are normally not even changeable by Reflection. This is used, e.g. by the Assertion feature, as under the hood, a class containing an assert statement will have a static final boolean field initialized at class initialization time (so it\u2019s not a compile-time constant) and each assert statement will skip its check conditionally, depending on the state of the static final variable. It was as early as at Java\u00a01.4 time, when it was concluded that the necessary dead code elimination is commonplace in JVMs, to rely on it in this way.\nSo even if you turn your debug flag from compile-time constant to an initialization-time constant, the impact on the performance would be hardly noticeable. But the way you\u2019re using it now, the code is removed at compile-time already and doesn\u2019t rely on the JVM anyway.\n"
}
{
    "Id": 71363302,
    "PostTypeId": 1,
    "Title": "Java sorting list of array vs sorting list of list",
    "Body": "I have a list of points where each point is a tiny list of size 2. I want to sort the list of points in increasing order of x and if x values are equal, I break tie by sorting in decreasing order of y.\nI wrote a custom comparator to sort the points like this:\nCollections.sort(points, (a, b) -> {\n    if (a.get(0) != b.get(0)) {\n        return a.get(0) - b.get(0);\n    } return b.get(1) - a.get(1); \n});\n\nHere's the input before sorting:\n(2, 1000)\n(9, -1000)\n(3, 15)\n(9, -15)\n(5, 12)\n(12, -12)\n(5, 10)\n(10001, -10)\n(19, 8)\n(10001, -8)\n\nHere's the result produced after sorting with the above comparator:\n(2, 1000)\n(3, 15)\n(5, 12)\n(5, 10)\n(9, -15)\n(9, -1000)\n(12, -12)\n(19, 8)\n(10001, -10)\n(10001, -8)\n\nObservations:\n\nThe input is sorted in ascending order on x.\n(5, 12) was correctly put before (5, 10).\n(9, -15) was correctly put before (9, -1000).\nHowever, (10001, -10) was put before (10001, -8). Even though -8 is larger than -10.\n\nFeel like I am missing something trivial. I experimented with a few other ways of writing the comparator like using Integer.compare(a, b) or just a.compareTo(t), but got the same result.\nFinally, I changed the representation of point from List to int[] and wrote the same comparator again. See results below:\nCollections.sort(points, (a, b) -> {\n    if (a[0] != b[0])\n        return a[0] - b[0];\n    return b[1] - a[1];\n});\n\nInput before sorting:\n(2, 1000)\n(9, -1000)\n(3, 15)\n(9, -150\n(5, 12)\n(12, -12)\n(5, 10)\n(10001, -10)\n(19, 8)\n(10001, -8)\n\nAfter sorting:\n(2, 1000)\n(3, 15)\n(5, 12)\n(5, 10)\n(9, -15)\n(9, -1000)\n(12, -12)\n(19, 8)\n(10001, -8)\n(10001, -10)\n\nSo list of arrays is getting sorted correctly as (10001, -8) was correctly put before (10001, -10).\nI am not able to understand why changing the representation of point resolved the issue and hence this question. I can give more details on how I am creating the List of points if required.\n",
    "AcceptedAnswerId": 71363726,
    "AcceptedAnswer": "\nI am missing something trivial\n\nMethod equals() should be used for object comparison. Double equals == checks whether two references point to the same object in memory.\nIf you change the condition inside the comparator to !a.get(0).equals(b.get(0)) it will work correctly.\n\nHowever, (10001, -10) was put before (10001, -8). Even though -8 is larger than -10.\n\nThe reason for such behavior is that JVM caches all the instances of Integer (as well as Byte, Short and Long) in the range [-128; 127]. I.e. these instances are reused, the result of autoboxing of let's say int with a value of 12 will be always the same object.\nBecause small values in your example like 3, 5, 12 will be represented by a single object, they were compared with == without issues. But the result of comparison with == for two Integer instances with a value of 10001 will be false because in this case there will be two distinct objects in the heap.\nThe approach of caching frequently used objects is called the Flyweight design pattern. It's very rarely used in Java because this pattern can bring benefits when tons of identical objects are being created and destroyed. Only in such a case caching these objects will pay off with a significant performance improvement. As far as I know, it's used in game development.\nUse the power of objects\nPoint must be an object, not a list, as Code-Apprentice has pointed out in his answer. Use the power of objects and don't overuse collections. It brings several advantages:\n\nclass provides you a structure, it's easier to organize your code when you are thinking in terms of objects;\nbehavior declared inside a class is reusable and easier to test;\nwith classes, you can use the power of polymorphism.\n\nCaution: objects could be also misused, one of the possible indicators of that is when a class doesn't declare any behavior apart from getters and its data is being processed somehow in the code outside this class.\nAlthough the notion of point (as a geometrical object) isn't complicated, there are some useful options with regard to methods. For example, you could make instances of the Point class to be able to check to whether they are aligned horizontally or vertically, or whether two points are within a particular radius. And Point class can implement Comparable interface so that points will be able to compare themselves without a Comparator.\nSorting\nWith Java 8 method sort()\nwas added to the List interface. It expects an instance of Comparator, and if element of the list implement comparable, and you want them to be sorted according to the natural order null can be passed as an argument.\n\nIf the specified comparator is null then all elements in this list must implement the Comparable interface and the elements' natural ordering should be used.\n\nSo instead of using utility class Collections you can invoke method sort() directly on a list of points (assuming that Point implements Comparable):\npoints.sort(null); // the same as   points.sort(Comparator.naturalOrder()); \n\nAlso, you can create multiple custom comparators by utilizing default and static methods from the Comparator interface like comparingInt() and thenComparing().\n(for more information on how to build comparators with Java 8 methods take a look at this tutorial)\n"
}
{
    "Id": 71642208,
    "PostTypeId": 1,
    "Title": "Parameter value [%Gabrek%] did not match expected type [java.lang.Character (n/a)];",
    "Body": "i've been writing wirting a program in Spring Boot Web with JPA and i'm using a query to access some data with a 'contains' and 'ignorecase' filter, i've done this before in other programs and it has worked fine, but now i'm getting this error, i'm completely lost at this point since i can't find anything in google, i went really far down the rabbit hole looking as to why it happens and so far i don't see anything out of place in my code, the type of variable declared seems to be okay but as i've said, i'm lost. It's important to mention that for some reason when I do the query on my website for the first time, everything works fine, i get the proper results and all, but when I go back to home and try with another query (or even the same) i get the error. Code below:\nModel\nimport javax.persistence.Column;\nimport javax.persistence.Entity;\nimport javax.persistence.GeneratedValue;\nimport javax.persistence.GenerationType;\nimport javax.persistence.Id;\n\n@Entity\npublic class Serie {\n    \n    @Id\n    @Column(columnDefinition = \"NUMERIC(19,0)\")\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Integer id;\n    private String title;\n    private String red;\n    @Column(columnDefinition = \"NUMERIC(19,0)\")\n    private double rating;\n\nRepository\nimport java.util.List;\n\nimport org.springframework.data.jpa.repository.JpaRepository;\n\nimport cl.desafiolatam.imdb.modelo.Serie;\n\npublic interface SerieRepository extends JpaRepository {\n\n    public List findByTitleContainingIgnoreCase(String title);\n    \n}\n\nService\nimport cl.desafiolatam.imdb.vo.SerieVO;\n\npublic interface SerieService {\n    \n    public SerieVO findByTitleContainingIgnoreCase(String title);\n\n}\n\nService implementation\nimport java.util.ArrayList;\nimport java.util.List;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Service;\nimport org.springframework.transaction.annotation.Transactional;\n\nimport cl.desafiolatam.imdb.dao.SerieRepository;\nimport cl.desafiolatam.imdb.modelo.Serie;\nimport cl.desafiolatam.imdb.service.SerieService;\nimport cl.desafiolatam.imdb.vo.SerieVO;\n\n@Service\npublic class SerieServiceImpl implements SerieService {\n    \n    private static final Logger logger = LoggerFactory.getLogger(SerieServiceImpl.class);\n    \n    @Autowired\n    SerieRepository dao;\n    SerieVO respuesta;\n\n    @Override\n    @Transactional(readOnly = true)\n    public SerieVO findByTitleContainingIgnoreCase(String title) {\n        \n        respuesta = new SerieVO(\"Ha ocurrido un error!\", \"104\", new ArrayList());\n\n        try {\n            List serie = dao.findByTitleContainingIgnoreCase(title);\n            System.out.println(serie);\n            if(serie.size() > 0) {\n                respuesta.setSeries(serie);\n                respuesta.setMensaje(\"Se ha encontrado el registro\");\n                respuesta.setCodigo(\"0\");\n            } else {\n                respuesta.setMensaje(\"No se ha encontrado el registro\");\n                respuesta.setCodigo(\"104\");\n            }\n        } catch (Exception e) {\n            logger.error(\"Error al buscar la serie\", e);\n        }\n        \n        return respuesta;\n    }\n\n}\n\nVisual object\nimport java.util.List;\n\nimport cl.desafiolatam.imdb.modelo.Serie;\n\npublic class SerieVO extends GenericVO {\n    \n    List series;\n\n    public SerieVO(String mensaje, String codigo, List series) {\n        super(mensaje, codigo);\n        this.series = series;\n    }\n\n    public SerieVO() {\n        super();\n    }\n\nController\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Controller;\nimport org.springframework.ui.Model;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.ModelAttribute;\nimport org.springframework.web.bind.annotation.PostMapping;\nimport org.springframework.web.bind.annotation.RequestParam;\nimport org.springframework.web.servlet.ModelAndView;\nimport org.springframework.web.servlet.mvc.support.RedirectAttributes;\n\nimport cl.desafiolatam.imdb.modelo.Serie;\nimport cl.desafiolatam.imdb.service.SerieService;\nimport cl.desafiolatam.imdb.vo.SerieVO;\n\n@Controller\npublic class SerieController {\n\n    private final static Logger logger = LoggerFactory.getLogger(SerieController.class);\n\n    @Autowired\n    private SerieService svc;\n\n@GetMapping(\"/buscarSerie\")\n    public ModelAndView buscarSerie(Model model, @RequestParam String nombreSerie) {\n        \n        SerieVO respuestaServicio = new SerieVO();\n        respuestaServicio.setMensaje(\"No se ha encontrado la serie\");\n        \n        try {\n            respuestaServicio = svc.findByTitleContainingIgnoreCase(nombreSerie);\n            model.addAttribute(\"listaSeries\", respuestaServicio.getSeries());\n            return new ModelAndView(\"resultadoserie\");\n        } catch (Exception e) {\n            logger.error(\"Error al buscar la serie\", e);\n        }\n        \n        return new ModelAndView(\"redirect:/user\");\n        \n    }\n}\n\nSearch input\n\n        \n            \n                \n                    Buscar serie\n                \n            \n            \n                \n                    \n                        \n                            \n                                <input type=\"text\" class=\"form-control\" id=\"floatingInputGrid\"\n                                    value=\"\" name=\"nombreSerie\" required> <label\n                                    for=\"floatingInputGrid\">Serie\n                            \n                        \n                    \n                    \n                        \n                    \n                \n            \n        \n    \n\nAs i've said, im really lost, researched everywhere, and checked the code in my last projects, i just can't find out why this one does me this dirty. Won't even fail at the start, it gives me a glimpse of hope and when i want to retry it, it crushes that little hope. :)\nI tried deleting my code and copy&paste from projects where i know it works as intended, changed the variable and param. names to make it work with the new program but didn't work. Did a side by side comparison, tried a @Query writing the specific instruction. Looking for info. only with the 'contains' filter and yet, nothing worked.\n",
    "AcceptedAnswerId": 71649782,
    "AcceptedAnswer": "According to the Spring Data JPA issue #2472 this seems to be a problem in Hibernate 5.6.6 and 5.6.7.\nThe Hibernate bug is HHH-15142.\nThe solution is to either downgrade to Hibernate 5.6.5 or wait for a Hibernate patch to solve this issue.\nUpdate: According to the bug report above this is resolved in version 5.6.9.\n"
}
{
    "Id": 71525731,
    "PostTypeId": 1,
    "Title": "java.lang.IllegalAccessError: class org.jetbrains.kotlin.kapt3.base.KaptContext Android",
    "Body": "I've been getting an error like this for days, but I couldn't find a solution. Can you please help me?\nWhat could the problem be caused by?\nError :\njava.lang.IllegalAccessError: class org.jetbrains.kotlin.kapt3.base.KaptContext (in unnamed module @0x6acdb135) cannot access class com.sun.tools.javac.util.Context (in module jdk.compiler) because module jdk.compiler does not export com.sun.tools.javac.util to unnamed module @0x6acdb135\n    at org.jetbrains.kotlin.kapt3.base.KaptContext.(KaptContext.kt:28)\n    at org.jetbrains.kotlin.kapt3.KaptContextForStubGeneration.(KaptContextForStubGeneration.kt:40)\n    at org.jetbrains.kotlin.kapt3.AbstractKapt3Extension.contextForStubGeneration(Kapt3Extension.kt:287)\n    at org.jetbrains.kotlin.kapt3.AbstractKapt3Extension.analysisCompleted(Kapt3Extension.kt:171)\n    at org.jetbrains.kotlin.kapt3.ClasspathBasedKapt3Extension.analysisCompleted(Kapt3Extension.kt:102)\n    at org.jetbrains.kotlin.cli.jvm.compiler.TopDownAnalyzerFacadeForJVM.analyzeFilesWithJavaIntegration$invokeExtensionsOnAnalysisComplete(TopDownAnalyzerFacadeForJVM.kt:112)\n    at org.jetbrains.kotlin.cli.jvm.compiler.TopDownAnalyzerFacadeForJVM.analyzeFilesWithJavaIntegration(TopDownAnalyzerFacadeForJVM.kt:122)\n    at org.jetbrains.kotlin.cli.jvm.compiler.TopDownAnalyzerFacadeForJVM.analyzeFilesWithJavaIntegration$default(TopDownAnalyzerFacadeForJVM.kt:86)\n    at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler$analyze$1.invoke(KotlinToJVMBytecodeCompiler.kt:252)\n    at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler$analyze$1.invoke(KotlinToJVMBytecodeCompiler.kt:243)\n    at org.jetbrains.kotlin.cli.common.messages.AnalyzerWithCompilerReport.analyzeAndReport(AnalyzerWithCompilerReport.kt:113)\n    at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler.analyze(KotlinToJVMBytecodeCompiler.kt:243)\n    at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler.compileModules$cli(KotlinToJVMBytecodeCompiler.kt:90)\n    at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler.compileModules$cli$default(KotlinToJVMBytecodeCompiler.kt:56)\n    at org.jetbrains.kotlin.cli.jvm.K2JVMCompiler.doExecute(K2JVMCompiler.kt:169)\n    at org.jetbrains.kotlin.cli.jvm.K2JVMCompiler.doExecute(K2JVMCompiler.kt:52)\n    at org.jetbrains.kotlin.cli.common.CLICompiler.execImpl(CLICompiler.kt:92)\n    at org.jetbrains.kotlin.cli.common.CLICompiler.execImpl(CLICompiler.kt:44)\n    at org.jetbrains.kotlin.cli.common.CLITool.exec(CLITool.kt:98)\n    at org.jetbrains.kotlin.incremental.IncrementalJvmCompilerRunner.runCompiler(IncrementalJvmCompilerRunner.kt:412)\n    at org.jetbrains.kotlin.incremental.IncrementalJvmCompilerRunner.runCompiler(IncrementalJvmCompilerRunner.kt:112)\n    at org.jetbrains.kotlin.incremental.IncrementalCompilerRunner.compileIncrementally(IncrementalCompilerRunner.kt:358)\n    at org.jetbrains.kotlin.incremental.IncrementalCompilerRunner.compileIncrementally$default(IncrementalCompilerRunner.kt:300)\n    at org.jetbrains.kotlin.incremental.IncrementalCompilerRunner.compileImpl$rebuild(IncrementalCompilerRunner.kt:119)\n    at org.jetbrains.kotlin.incremental.IncrementalCompilerRunner.compileImpl(IncrementalCompilerRunner.kt:170)\n    at org.jetbrains.kotlin.incremental.IncrementalCompilerRunner.compile(IncrementalCompilerRunner.kt:81)\n    at org.jetbrains.kotlin.daemon.CompileServiceImplBase.execIncrementalCompiler(CompileServiceImpl.kt:607)\n    at org.jetbrains.kotlin.daemon.CompileServiceImplBase.access$execIncrementalCompiler(CompileServiceImpl.kt:96)\n    at org.jetbrains.kotlin.daemon.CompileServiceImpl.compile(CompileServiceImpl.kt:1658)\n    at jdk.internal.reflect.GeneratedMethodAccessor103.invoke(Unknown Source)\n    at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.base/java.lang.reflect.Method.invoke(Method.java:568)\n    at java.rmi/sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:360)\n    at java.rmi/sun.rmi.transport.Transport$1.run(Transport.java:200)\n    at java.rmi/sun.rmi.transport.Transport$1.run(Transport.java:197)\n    at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)\n    at java.rmi/sun.rmi.transport.Transport.serviceCall(Transport.java:196)\n    at java.rmi/sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:587)\n    at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:828)\n    at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:705)\n    at java.base/java.security.AccessController.doPrivileged(AccessController.java:399)\n    at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:704)\n    at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n    at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n    at java.base/java.lang.Thread.run(Thread.java:833)\n\n\nExecution failed for task ':app:kaptGenerateStubsMacellanDebugKotlin'.\n> Internal compiler error. See log for more details\n\n",
    "AcceptedAnswerId": 71527580,
    "AcceptedAnswer": "I found a solution and fixed this damn problem :D\nI recommend using, adding it to the root build.gradle. This will force using the given dependency in the whole project:\nbuild.gradle (Project)\nallprojects {\n    configurations.all {\n        resolutionStrategy {\n            force 'org.xerial:sqlite-jdbc:3.34.0'\n        }\n    }\n}\n\n"
}
{
    "Id": 71818173,
    "PostTypeId": 1,
    "Title": "How to handle NumberFormatException with Java StreamAPI",
    "Body": "Is there a way to filter out all values that are bigger than the max value that can be stored in a Long using Stream API?\nThe current situation is that you can search in the frontend with a simple search bar after some customers by using their ID.\nFor example: 123456789, 10987654321. If you put a \"separator\" between these two IDs, everything works. But if you forget the \"separator\" my code is trying to parse 12345678910987654321 into a Long and I guess there is the problem.\nThat causes a NumberFormatException after trying to search. Is there a way to filter these numbers out that can't be parsed into a Long because they are too big?\nString hyphen = \"-\";\n\nString[] customerIds = bulkCustomerIdProperty.getValue()\n              .replaceAll(\"[^0-9]\", hyphen)\n              .split(hyphen);\n...\ncustomerFilter.setCustomerIds(Arrays.asList(customerIds).stream()\n              .filter(n -> !n.isEmpty()) \n              .map(n -> Long.valueOf(n)) // convert to Long\n              .collect(Collectors.toSet()));\n\n",
    "AcceptedAnswerId": 71818306,
    "AcceptedAnswer": "You can either extract parsing into a separate method and wrap it with a try/catch, or use BigInteger to eliminate values that exceed the range of long.\nExample with BigInteger:\nSet result =  Stream.of(\"\", \"12345\", \"9999999999999999999999999999\")\n        .filter(n -> !n.isEmpty())\n        .map(BigInteger::new)\n        .filter(n -> n.compareTo(BigInteger.valueOf(Long.MAX_VALUE)) <= 0 &&\n                     n.compareTo(BigInteger.valueOf(Long.MIN_VALUE)) >= 0)\n        .map(BigInteger::longValueExact) // convert to Long\n        .peek(System.out::println) // printing the output\n        .collect(Collectors.toSet());\n\nExample with handling NumberFormatException in a separate method:\nSet result =  Stream.of(\"\", \"12345\", \"9999999999999999999999999999\")\n        .filter(n -> !n.isEmpty())\n        .map(n -> safeParse(n))\n        .filter(OptionalLong::isPresent)\n        .map(OptionalLong::getAsLong) // extracting long primitive and boxing it into Long\n        .peek(System.out::println) // printing the output\n        .collect(Collectors.toSet());\n\npublic static OptionalLong safeParse(String candidate) {\n    try {\n        return OptionalLong.of(Long.parseLong(candidate));\n    } catch (NumberFormatException e) {\n        return OptionalLong.empty();\n    }\n}\n\nOutput (from peek())\n12345\n\n"
}
{
    "Id": 71884469,
    "PostTypeId": 1,
    "Title": "Unable to find /oauth/device/code Auth0 Java API",
    "Body": "Is there an API to fetch the device code via Auth0 Java API, we use the following snippet in Go, the question is if there is a standard API or should we make a HTTP request call\nurl := \"https://dev-foo.us.auth0.com/oauth/device/code\"\n\npayload := strings.NewReader(\"client_id=RO6N7mr&scope=openid&audience=https://dev-foo.us.auth0.com/api/v2/\")\n\nreq, _ := http.NewRequest(\"POST\", url, payload)\n\n",
    "AcceptedAnswerId": 71909729,
    "AcceptedAnswer": "The documentation tells you that you need to send a POST request like the following:\n\nPOST https://YOUR_DOMAIN/oauth/device/code\n\n\nContent-Type:\n\n\napplication/x-www-form-urlencoded\nclient_id=YOUR_CLIENT_ID&scope=SCOPE&audience=API_IDENTIFIER\n\nand the response would look like\nHTTP/1.1 200 OK\nContent-Type: application/json\n{\n  \"device_code\":\"GmRh...k9eS\",\n  \"user_code\":\"WDJB-MJHT\",\n  \"verification_uri\":\"https://YOUR_DOMAIN/device\",\n  \"verification_uri_complete\":\"https://YOUR_DOMAIN/device?user_code=WDJB-MJHT\",\n  \"expires_in\":900, //in seconds\n  \"interval\":5\n}\n\n\n"
}
{
    "Id": 72598626,
    "PostTypeId": 1,
    "Title": "Official recommendation / coding style guide on using multiple @throws tags for the same exception in JavaDoc",
    "Body": "I just recently found out that one can use multiple @throws tags for the same exception in Javadoc.\nOne of my students used it to document one of his methods in Connect Four:\n/*\n * ...\n * @throws IllegalArgumentException if the number of rows or columns is invalid \n * @throws IllegalArgumentException if one of the players has {@link Stone#None} as stone\n * @throws IllegalStateException if both players use the same stone color\n */\npublic void doSomething(...) { ... }\n\nNow my (and his) question: Is there an official style guide or a general recommendation on whether to use a single @throws tag or \"is it fine\" to use multiple ones per exception type?\n",
    "AcceptedAnswerId": 72600530,
    "AcceptedAnswer": "There is an Oracle style guide for javadocs:\n\nHow to Write Doc Comments for the Javadoc Tool.\n\nWhether that counts as \"official\" depends on your point of view.  Either way, I cannot see any mention in that document of multiple tags for the same exception.\nHowever, according to the following Q&A, multiple @throws tags for the same exception is supported by the standard Javadoc tool chain; i.e. each of them will result in an entry in the generated HTML.\n\nCan I use multiple @throws tags for the same exception in Javadoc?\n\n(My personal opinion is the javadocs will be more readable if you don't do this, but that is just my opinion.)\n"
}
{
    "Id": 73126185,
    "PostTypeId": 1,
    "Title": "What is overhead of Java Native Memory Tracking in \"summary\" mode?",
    "Body": "I'm wondering what is the real/typical overhead when NMT is enabled via \u2011XX:NativeMemoryTracking=summary (the full command options I'm after are -XX:+UnlockDiagnosticVMOptions \u2011XX:NativeMemoryTracking=summary \u2011XX:+PrintNMTStatistics)\nI could not find much information anywhere - either on SO, blog posts or the official docs.\nThe docs say:\n\nNote: Enabling NMT causes a 5% -10% performance overhead.\n\nBut they do not say which mode is expected to have this performance overhead (both summary and detail?)\nand what this overhead really is (CPU, memory, ...).\nIn Native Memory Tracking guide they claim:\n\nEnabling NMT will result in a 5-10 percent JVM performance drop, and memory usage for NMT adds 2 machine words to all malloc memory as a malloc header. NMT memory usage is also tracked by NMT.\n\nBut again, is this true for both summary and detail mode?\nWhat I'm after is basically whether it's safe to add \u2011XX:NativeMemoryTracking=summary permanently for a production app (similar to continuous JFR recording) and what are potential costs.\nSo far, when testing this on our app, I didn't spot a difference but it's difficult to\nIs there an authoritative source of information containing more details about this performance overhead?\nDoes somebody have experience with enabling this permanently for production apps?\n",
    "AcceptedAnswerId": 73167790,
    "AcceptedAnswer": "The overhead of Native Memory Tracking obviously depends on how often the application allocates native memory. Usually, this is not something too frequent in a Java application, but cases may differ. Since you've already tried and didn't notice performance difference, your application is apparently not an exception.\nIn the summary mode, Native Memory Tracking roughly does the following things:\n\nincreases every malloc request in the JVM by 2 machine words (16 bytes);\nrecords the allocation size and flags in these 2 words;\natomically increments (or decrements on free) the counter corresponding to the given memory type;\nbesides malloc and free, it also handles changes in virtual memory reservation and allocations of new arenas, but these are even less frequent than malloc/free calls.\n\nSo, to me, the overhead is quite small; 5-10% is definitely a large overestimation (the numbers would make sense for detail mode which collects and stores stack traces, which is expensive, but summary doesn't do that).\nWhen many threads concurrently allocate/free native memory, the update of an atomic counter could become a bottleneck, but again, that's more like an extreme case. In short, if you measured a real application and didn't notice any degradation, you're likely safe to enable NMT summary in production.\n"
}
{
    "Id": 73281636,
    "PostTypeId": 1,
    "Title": "Java Generics: Stream.map() returns \"capture of ?\" instead of \"?\"",
    "Body": "I'm trying to build a List of Classes that implement a certain interface called Interface:\nList> myList= myMap.entrySet().stream()\n    .filter(entry -> entry.getValue().equals(myValue))\n    .map(Map.Entry::getKey)   // Stream\n    .map(Interface::getClass) // Stream>\n    .distinct()\n    .toList();\n\nI added as comment the type of the elements in the Stream after map() is called.\nThe code iterates over all the entries in the map, and if their value is equal to myValue, then:\n\nfirst, gets the instance of type Interface (which is the key of the entry)\nthen, gets the Class implementing the Interface.\n\nmyMap is defined as:\nMap myMap = new HashMap()\n\nThe error I'm getting :\nIncompatible types.\nFound: 'java.util.List>>',\nrequired: 'java.util.List>'\n\nI am clearly missing something about how Generics work in Java, but I am at a loss here. I suppose it's something related to the fact that the compiler cannot correctly reify my ? wildcard.\n",
    "AcceptedAnswerId": 73281848,
    "AcceptedAnswer": "As @Slaw has pointed out in the comments, in this case getClass() is capable to provide the information about the generic type to the compiler.\nAccording to the documentation:\n\nThe actual result type is Class where |X| is the erasure of the static type of the expression on which getClass is called.\n\nHence, at compile time, we would have a type ? extends Interface and the reason of the observed behavior is related solely to peculiarities of type inference in Java.\nIn this case, when we are chaining methods after map() operation, the compiler fails to infer the type of the method reference Interface::getClass correctly based on the resulting type returned by the stream.\nIf we substitute toList, which expects elements of type T and produces List, with collect(Collectors.toList()), in which collector is of type Collector, the compiler would be able to do its job (here's a proof):\nList> myList = myMap.entrySet().stream()\n    .filter(entry -> Objects.equals(entry.getValue(), myValue))\n    .map(Map.Entry::getKey)   // Stream\n    .map(Interface::getClass) // Stream>\n    .distinct()\n    .collect(Collectors.toList());\n\nBut to make type inference working with toList() we need to provide the generic type explicitly.\nFor instance, this code would compile, because the type of Interface::getClass could be inferred from the assignment context (here there are no operations after map(), hence myStream directly says what should be the return type of map()):\nStream> myStream = myMap.entrySet().stream()\n    .filter(entry -> Objects.equals(entry.getValue(), myValue))\n    .map(Map.Entry::getKey)\n    .map(Interface::getClass);\n\nList> myList = myStream.distinct().toList();\n\nA more handy way would be to use a so-called Type Witness:\nMap myMap = Map.of(new ClasA(), 1, new ClasB(), 1);\n        \nint myValue = 1;\n        \nList> myList = myMap.entrySet().stream()\n    .filter(entry -> Objects.equals(entry.getValue(), myValue))\n    .map(Map.Entry::getKey)                               // Stream\n    .>map(Interface::getClass) // Stream>\n    .distinct()\n    .toList();\n        \nmyList.forEach(c -> System.out.println(c.getSimpleName()));\n\nOutput:\nClasA\nClasB\n\nDummy classes:\ninterface Interface {}\nclass ClasA implements Interface {}\nclass ClasB implements Interface {}\n\n"
}
{
    "Id": 73336136,
    "PostTypeId": 1,
    "Title": "Does having a wrapper object return value (e.g. Integer) cause auto boxing in Java?",
    "Body": "I couldn't find a definitive answer for this seemingly simple question. If I write a method like this:\npublic Integer getAnInt() {\n  int[] i = {4};\n  return i[0];\n}\n\nis the return value autoboxed into an Integer, or does it depend on what happens to the value after it's returned (e.g. whether the variable it is assigned to is declared as an Integer or int)?\n",
    "AcceptedAnswerId": 73336170,
    "AcceptedAnswer": "Yes, boxed\nIt will be (auto)boxed in the bytecode (.class file) because it's part of the public API, so other code might depend on the return value being an Integer.\nThe boxing and unboxing might be removed at runtime by the JITter under the right circumstances, but I don't know if it does that sort of thing.\n"
}
{
    "Id": 72841549,
    "PostTypeId": 1,
    "Title": "Container Fails to Start: Insufficient memory for the Java Runtime Environment to continue",
    "Body": "We have an enterprise application running on Java 8. The deployment environment is built & updated through Bitbucket pipelines. I have a graphic showing the high-level architecture of the environment.  We have two app servers running identical configurations apart from some application specific environment variables.\nIt was all working well until a week ago when after a successful pipeline run, the 2 app instances on one of the servers stopped working with the following error:\nThere is insufficient memory for the Java Runtime Environment to continue.\nCannot create GC thread. Out of system resources.\n\nBoth the instances are working fine on the other server. In contrast, the containers fail to start on this server.\nSolutions Tried\nThe error accompanies the following information:\nPossible reasons:\nThe system is out of physical RAM or swap space\nThe process is running with CompressedOops enabled, and the Java Heap may be blocking the growth of the native heap.\nPossible solutions:\n\nReduce memory load on the system\nIncrease physical memory or swap space\nCheck if swap backing store is full\nDecrease Java heap size (-Xmx/-Xms)\nDecrease number of Java threads\nDecrease Java thread stack sizes (-Xss)\nSet larger code cache with -XX:ReservedCodeCacheSize=\n\nWe have tried:\n\nAdding more swap memory. The server has 8GB of RAM while we have tried the swap from 4GB to 9GB.\nPlayed with the heap sizes Xms & Xmx from 128m to 4096m.\nIncreased the RAM on this server to 16GB while the other server that works still does on 8GB.\n\nHere is how the memory & swap consumption looks like:\nfree -mh\n              total        used        free      shared  buff/cache   available\nMem:           15Gi       378Mi        12Gi       1.0Mi       2.9Gi        14Gi\nSwap:           9Gi          0B         9Gi\n\nI have links to several related artifacts.  These include the complete docker logs output and the output of docker info on the failing server and the operational server.\nThis is what docker ps -a gets us:\n:~$ docker ps -a\nCONTAINER ID   IMAGE                                                                                  COMMAND                  CREATED        STATUS                    PORTS                                       NAMES\nd29747bf2ad3   :a7608a838625ae945bd0a06fea9451f8bf11ebe4   \"catalina.sh run\"        10 hours ago   Exited (1) 10 hours ago                                               jbbatch\n0951b6eb5d42   :a7608a838625ae945bd0a06fea9451f8bf11ebe4   \"catalina.sh run\"        10 hours ago   Exited (1) 10 hours ago                                               jbapp\n\nWe are out of ideas right now as we have tried almost all the solutions on stack overflow. What are we missing?\n",
    "AcceptedAnswerId": 72841934,
    "AcceptedAnswer": "I see that your Docker image uses Ubuntu 22.04 LTS as its base. Recently base Java images were rebuilt on top of this LTS version, which caused a lot of issues on older Docker runtimes. Most likely this is what you're experiencing. It has nothing to do with memory, but rather with Docker incompatibility with a newer Linux version used as a base image.\nYour operational server has Docker server version 20.10.10, while the failing server has version 20.10.09. The incompatibility issue was fixed exactly in Docker 20.10.10. Some more technical details on the incompatibility issue are available here.\nThe solution would be to upgrade the failing server to at least Docker 20.10.10.\n"
}
{
    "Id": 71832118,
    "PostTypeId": 1,
    "Title": "sbt assembly cannot create jar getting java.lang.UnsupportedOperationException",
    "Body": "I am using\nscala 1.12.10\nakka 2.6.3\naddSbtPlugin(\"io.spray\" % \"sbt-revolver\" % \"0.9.1\")\naddSbtPlugin(\"com.eed3si9n\" % \"sbt-assembly\" % \"1.1.0\")\n\nHowever when executing sbt assembly I am getting:\njava.lang.UnsupportedOperationException: The Security Manager is deprecated and will be removed in a future release\n    at java.base/java.lang.System.setSecurityManager(System.java:416)\n    at sbt.TrapExit$.installManager(TrapExit.scala:53)\n    at sbt.StandardMain$.runManaged(Main.scala:109)\n    at sbt.xMain.run(Main.scala:76)\n    at xsbt.boot.Launch$$anonfun$run$1.apply(Launch.scala:111)\n    at xsbt.boot.Launch$.withContextLoader(Launch.scala:131)\n    at xsbt.boot.Launch$.run(Launch.scala:111)\n    at xsbt.boot.Launch$$anonfun$apply$1.apply(Launch.scala:37)\n    at xsbt.boot.Launch$.launch(Launch.scala:120)\n    at xsbt.boot.Launch$.apply(Launch.scala:20)\n    at xsbt.boot.Boot$.runImpl(Boot.scala:56)\n    at xsbt.boot.Boot$.main(Boot.scala:18)\n    at xsbt.boot.Boot.main(Boot.scala)\n[error] [launcher] error during sbt launcher: java.lang.UnsupportedOperationException: The Security Manager is deprecated and will be removed in a future release\n\nrunning java 18\njava -version\nopenjdk version \"18\" 2022-03-22\nOpenJDK Runtime Environment (build 18+36-2087)\nOpenJDK 64-Bit Server VM (build 18+36-2087, mixed mode, sharing)\n\n",
    "AcceptedAnswerId": 71847512,
    "AcceptedAnswer": "Using java 8 solved this issue as AminMal suggested\n"
}
{
    "Id": 71641264,
    "PostTypeId": 1,
    "Title": "How can I solve this issue on Mac M1 Caused by: java.lang.Exception: No native library is found for os.name=Mac and os.arch=aarch64",
    "Body": "I solved this issue with the code below in my build.gradle\n  allprojects {\nconfigurations.all {\n    resolutionStrategy {\n        force 'org.xerial:sqlite-jdbc:3.34.0'\n      }\n   }\n } \n\nBut it has an effect on the project I am working on. for some reason, it is not working with room sql implemented on the project.\nI get this error when i removed the code above.\nIs there a better approach to solve this.\nCaused by: java.lang.ExceptionInInitializerError\nat androidx.room.processor.DatabaseProcessor.doProcess(DatabaseProcessor.kt:82)\nat androidx.room.processor.DatabaseProcessor.process(DatabaseProcessor.kt:57)\nat androidx.room.RoomProcessor$DatabaseProcessingStep.process(RoomProcessor.kt:134)\nat com.google.auto.common.BasicAnnotationProcessor.process(BasicAnnotationProcessor.java:330)\nat com.google.auto.common.BasicAnnotationProcessor.process(BasicAnnotationProcessor.java:181)\nat org.jetbrains.kotlin.kapt3.base.incremental.IncrementalProcessor.process(incrementalProcessors.kt)\nat org.jetbrains.kotlin.kapt3.base.ProcessorWrapper.process(annotationProcessing.kt:161)\nat \n\n \n\njdk.compiler/com.sun.tools.javac.processing.JavacProcessingEnvironment.callProcessor(JavacProcessingEnvironment.java:980)\n... 39 more\nCaused by: java.lang.Exception: No native library is found for os.name=Mac and \nos.arch=aarch64. path=/org/sqlite/native/Mac/aarch64\nat org.sqlite.SQLiteJDBCLoader.loadSQLiteNativeLibrary(SQLiteJDBCLoader.java:333)\nat org.sqlite.SQLiteJDBCLoader.initialize(SQLiteJDBCLoader.java:64)\nat androidx.room.verifier.DatabaseVerifier.(DatabaseVerifier.kt:68)\n... 47 more\n\n",
    "AcceptedAnswerId": 71898182,
    "AcceptedAnswer": "update your room library\n   implementation \"androidx.room:room-runtime:2.4.2\"\n   implementation \"androidx.room:room-ktx:2.4.2\"\n   kapt \"androidx.room:room-compiler:2.4.2\"\n\nHere is Reference\n"
}
{
    "Id": 72046624,
    "PostTypeId": 1,
    "Title": "Firebase Tools and Java 11",
    "Body": "This question falls somewhere between Firebase Tools, MacOS and Java. Probably 75% Java, 20% Firebase Tools and 5% MacOS.\nStarting with v10.5, firebase-tools started stating that 'Support for Java version \nI run macOS v11.6.5 on a Macbook Pro from mid-2014. When I go to Java's Downloads page, it recommends Java 'Version 8 Update 331'. Not Java 11.\nInformation on downloading Java 11 seems to be scarce. Oracle's page of certified configurations includes MacOS 11, but I can't find anywhere obvious where Java 11 can be readily downloaded.\nA big part of the problem seems to be the terminology used. If I run java -version, I get:\njava version \"1.8.0_331\"\nJava(TM) SE Runtime Environment (build 1.8.0_331-b09)\nJava HotSpot(TM) 64-Bit Server VM (build 25.331-b09, mixed mode)\n\nOkay, I have build 1.8 of the Java Runtime Environment, aka the JRE if you are a Java enthusiast. That is apparently what is triggering the warning in Firebase Tools.\nThere is also a Java product out there called 'Java SE 11'. The product itself is ambiguous, but the checksums all say 'SDK'. (A Software Development Kit: a thing that enables developers to develop Java programs. The name doesn't imply a Runtime Environment: a thing that enables Java to run on an operating system.) There is an article out there which claims that, if you install Java SE 11 and run java -version, it will spit out java version \"11.0.7\". That will probably satisfy Firebase Tools.\nBut Oracle's release notes say: 'In Windows and macOS, installing the JDK in previous releases optionally installed a JRE. In JDK 11, this is no longer an option.' No longer an option... as in now you implicitly get JRE 11 with SDK 11? Or as in the SDK and JRE are now fully divorced, and the JRE must be ferreted out of its hiding like a wild beast?\nUPDATE 6/5/22: Java's checksums page now says 'JDK', and I guess that is better than 'SDK' because it implies 'Java Development Kit', which this Wikipedia article claims to include both a JRE ('java') and SDK (most of the other files).\n",
    "AcceptedAnswerId": 72046625,
    "AcceptedAnswer": "To install Java SE:\nGo here.\n\nScroll down to find your product. I chose Java SE 11. (Oracle will probably list later versions as they are made available.)\nChoose your operating system. I chose MacOS.\nChoose your file set. I chose the DMG installer.\nDownload your chosen file set.\n\n\n5. Do whatever is required by your platform to install Java SE using the downloaded file set from #5.\nAfter installing Java SE 11, java -version now says \"11.0.14\" and Firebase Tools is now satisfied. My best guess is that JRE 11 was implicitly downloaded, and that developers need to start ignoring the main Download page used by everyone else. (Why didn't the main Download page recommend Java 11 from the start?) Hopefully someone will see this question and clarify whether in the future, the 'Java SE' product implicitly includes both the JRE and SDK, and that the numbering system will always encompass both. In other words, hopefully when someone says we need 'Java 11', it means that we need to download SE 11, containing JRE 11 and SDK 11.\n"
}
{
    "Id": 72140664,
    "PostTypeId": 1,
    "Title": "Azure build error: \"Android Gradle plugin requires Java 11 to run. You are currently using Java 1.8\"",
    "Body": "When building Flutter app in azure devOps, I receive this error:\nBuild file 'D:\\a\\1\\s\\android\\app\\build.gradle' line: 24\n\n* What went wrong:\nA problem occurred evaluating project ':app'.\n> Failed to apply plugin 'com.android.internal.application'.\n   > Android Gradle plugin requires Java 11 to run. You are currently using Java 1.8.\n     You can try some of the following options:\n       - changing the IDE settings.\n       - changing the JAVA_HOME environment variable.\n       - changing `org.gradle.java.home` in `gradle.properties`.\n\nI've tried, these solutions:\n\nCreating jitpack.yml file, with - openjdk11 value.\nAdding below lines to app/build.gradle file inside android {} block:\n\n...\ncompileOptions {\n\nsourceCompatibility JavaVersion.VERSION_11\n\n    targetCompatibility JavaVersion.VERSION_11\n}\n\nkotlinOptions {\n    jvmTarget = JavaVersion.VERSION_11.toString()\n}\n\nAnd another solutions, but my error doesn't solve. By the way, I easily run app and build apk, locally on my mac without any errors, but when I push my code, Azure gives those build error.\n",
    "AcceptedAnswerId": 72140711,
    "AcceptedAnswer": "My error is solved by adding below lines into azure-pipelines.yml file:\nsteps:\n - task: JavaToolInstaller@0\n    inputs:\n      versionSpec: '11'\n      jdkArchitectureOption: 'x64'\n      jdkSourceOption: 'PreInstalled'\n\n"
}
{
    "Id": 73187929,
    "PostTypeId": 1,
    "Title": "Android Studio Chipmunk (2021.2.1) Java 8 library desugaring in D8 and R8 Build Error: \"Unsupported desugared library configuration version\"",
    "Body": "After updating my apps build gradle and dependencies (I did not update Android Studio itself), Android Studio is giving me this error: Error: Unsupported desugared library configuration version, please upgrade the D8/R8 compiler.\nBefore the update everything compiled fine.\nI am using:\n\ncom.android.tools:desugar_jdk_libs:1.2.0 (This was the newest version I could find)\nGradle plugin version 7.2.0\nGradle version 7.5\nAndroid Studio version Chipmunk (2021.2.1)\n\nDid I configuration something wrong? How can I fix this? Thanks in advance!\n",
    "AcceptedAnswerId": 73189430,
    "AcceptedAnswer": "According to this page, the minimum version of Android Gradle plugin required is 7.3.0-beta03 to be able to upgrade the desugar library to 1.2.0, and 7.3.x is not yet available for Android Studio Chipmunk.\n"
}
{
    "Id": 74011238,
    "PostTypeId": 1,
    "Title": "Understanding Java 17 Vector slowness and performance with pow operator",
    "Body": "I have a question relating to the pow() function in Java's 17 new Vector API feature. I'm trying to implement the black scholes formula in a vectorized manner, but I'm having difficulty in obtaining the same performance as the scalar implementation\nThe code is as follows:\n\nI create an array of doubles (currently, just 5.0)\nI loop over elements of that array (different looping syntax for scalar and vector)\nI create DoubleVectors from the double arrays within and do calculations (or just calculations for scalar) I am trying to do e^(value), and I believe that is the problem\n\nHere are some code snippets:\n    public static double[] createArray(int arrayLength)\n    {\n        double[] array0 = new double[arrayLength];\n        for(int i=0;i<arrayLength;i++)\n        {\n            array0[i] = 2.0;\n        }\n        return array0;\n    } \n\n    @Param({\"256000\"})\n    int arraySize;\n    public static final VectorSpecies SPECIES = DoubleVector.SPECIES_PREFERRED;\n    DoubleVector vectorTwo =  DoubleVector.broadcast(SPECIES,2);\n    DoubleVector vectorHundred =  DoubleVector.broadcast(SPECIES,100);\n\n    double[] scalarTwo = new double[]{2,2,2,2};\n    double[] scalarHundred  = new double[]{100,100,100,100};\n\n    @Setup\n    public void Setup()\n    {\n        javaSIMD = new JavaSIMD();\n        javaScalar = new JavaScalar();\n        spotPrices = createArray(arraySize);\n        timeToMaturity = createArray(arraySize);\n        strikePrice = createArray(arraySize);\n        interestRate = createArray(arraySize);\n        volatility = createArray(arraySize);\n        e = new double[arraySize];\n        for(int i=0;i<arraySize;i++)\n        {\n            e[i] = Math.exp(1);\n        }\n        upperBound = SPECIES.loopBound(spotPrices.length);\n    }\n    @Benchmark\n    @BenchmarkMode(Mode.Throughput)\n    @OutputTimeUnit(TimeUnit.MILLISECONDS)\n    public void testVectorPerformance(Blackhole bh) {\n        var upperBound = SPECIES.loopBound(spotPrices.length);\n        for (var i=0;i<upperBound; i+= SPECIES.length())\n        {\n            bh.consume(javaSIMD.calculateBlackScholesSingleCalc(spotPrices,timeToMaturity,strikePrice,\n                    interestRate,volatility,e, i));\n        }\n    }\n\n    @Benchmark\n    @BenchmarkMode(Mode.Throughput)\n    @OutputTimeUnit(TimeUnit.MILLISECONDS)\n    public void testScalarPerformance(Blackhole bh) {\n        for(int i=0;i<arraySize;i++)\n        {\n            bh.consume(javaScalar.calculateBlackScholesSingleCycle(spotPrices,timeToMaturity,strikePrice,\n                    interestRate,volatility, i,normDist));\n        }\n    }\n\n    public DoubleVector calculateBlackScholesSingleCalc(double[] spotPrices, double[] timeToMaturity, double[] strikePrice,\n                                                        double[] interestRate, double[] volatility, double[] e,int i){\n...(skip lines)\n        DoubleVector vSpot = DoubleVector.fromArray(SPECIES, spotPrices, i);\n...(skip lines)\n        DoubleVector powerOperand = vRateScaled\n                .mul(vTime)\n                .neg();\n        DoubleVector call  = (vSpot\n                .mul(CDFVectorizedExcelOptimized(d1,vE)))\n                .sub(vStrike\n                .mul(vE\n                        .pow(powerOperand))\n                .mul(CDFVectorizedExcelOptimized(d2,vE)));\n        return call;\n\nHere are some JMH benchmarks (2 forks,2 warmups,2 iterations) on a Ryzen 5800X using WSL: Overall, it seems ~2x slower vs the scalar version.  I ran a simple time before vs time after separately, of the method without JMH and it seems inline.\nResult \"blackScholes.TestJavaPerf.testScalarPerformance\":\n  0.116 \u00b1(99.9%) 0.002 ops/ms [Average]\n       89873915287      cycles:u                  #    4.238 GHz                      (40.43%)\n      242060738532      instructions:u            #    2.69  insn per cycle   \n\n      \nResult \"blackScholes.TestJavaPerf.testVectorPerformance\":\n  0.071 \u00b1(99.9%) 0.001 ops/ms [Average]\n       90878787665      cycles:u                  #    4.072 GHz                      (39.25%)\n      254117779312      instructions:u            #    2.80  insn per cycle  \n\nI also enabled diagnostic options for the JVM. I see the following:\n\"-XX:+UnlockDiagnosticVMOptions\", \"-XX:+PrintIntrinsics\",\"-XX:+PrintAssembly\"\n\n  0x00007fe451959413:   call   0x00007fe451239f00           ; ImmutableOopMap {rsi=Oop }\n                                                            ;*synchronization entry\n                                                            ; - jdk.incubator.vector.DoubleVector::arrayAddress@-1 (line 3283)\n                                                            ;   {runtime_call counter_overflow Runtime1 stub}\n  0x00007fe451959418:   jmp    0x00007fe4519593ce\n  0x00007fe45195941a:   movabs $0x7fe4519593ee,%r10         ;   {internal_word}\n  0x00007fe451959424:   mov    %r10,0x358(%r15)\n  0x00007fe45195942b:   jmp    0x00007fe451193100           ;   {runtime_call SafepointBlob}\n  0x00007fe451959430:   nop\n  0x00007fe451959431:   nop\n  0x00007fe451959432:   mov    0x3d0(%r15),%rax\n  0x00007fe451959439:   movq   $0x0,0x3d0(%r15)\n  0x00007fe451959444:   movq   $0x0,0x3d8(%r15)\n  0x00007fe45195944f:   add    $0x40,%rsp\n  0x00007fe451959453:   pop    %rbp\n  0x00007fe451959454:   jmp    0x00007fe451231e80           ;   {runtime_call unwind_exception Runtime1 stub}\n  0x00007fe451959459:   hlt    \n   \n[Exception Handler]\n  0x00007fe451959460:   call   0x00007fe451234580           ;   {no_reloc}\n  0x00007fe451959465:   movabs $0x7fe46e76df9a,%rdi         ;   {external_word}\n  0x00007fe45195946f:   and    $0xfffffffffffffff0,%rsp\n  0x00007fe451959473:   call   0x00007fe46e283d40           ;   {runtime_call}\n  0x00007fe451959478:   hlt    \n[Deopt Handler Code]\n  0x00007fe451959479:   movabs $0x7fe451959479,%r10         ;   {section_word}\n  0x00007fe451959483:   push   %r10\n  0x00007fe451959485:   jmp    0x00007fe4511923a0           ;   {runtime_call DeoptimizationBlob}\n  0x00007fe45195948a:   hlt    \n\n--------------------------------------------------------------------------------\n\n============================= C2-compiled nmethod ==============================\n  ** svml call failed for double_pow_32\n                                            @ 3   jdk.internal.misc.Unsafe::loadFence (0 bytes)   (intrinsic)\n                                            @ 3   jdk.internal.misc.Unsafe::loadFence (0 bytes)   (intrinsic)\n                                          @ 2   java.lang.Math::pow (6 bytes)   (intrinsic)\n\nInvestigations/Questions:\n\nIm writing different implementations of the formula, it is not 1:1 - could this be the cause? Looking at the number of instructions according to JMH, there is roughly a 12billion difference in num of instructions. With vectorization the processor runs at a lower clock rate as well.\nIs the choice of input numbers a problem? I've tried i+10/(array.Length) as well.\nIs there a reason I see that the SVML call fail for double_pow_32 ? I don't see this problem for smaller input array sizes BTW\nI changed the pow to mul (for both,obviously the eq is now very different) but it seems to be much faster as a result, results are as expected scalar vs vector\n\nNote: I believe it is using 256bit width vectors (checked during debugging)\n",
    "AcceptedAnswerId": 74017185,
    "AcceptedAnswer": "This might be related to JDK-8262275, Math vector stubs are not called for double64 vectors\n\nFor Double64Vector, the svml math vector stubs intrinsification is failing and they are not being called from jitted code.\nBut we do have svml double64 vectors.\n\nYou might try alternative operations, e.g. instead of vE.pow(powerOperand) with vE being a vector of e, you can use powerOperand.lanewise(VectorOperators.EXP) to perform ex for all lanes.\nKeep in mind that this API is work in progress in incubator state\u2026\n"
}
{
    "Id": 74356407,
    "PostTypeId": 1,
    "Title": "How to get the date and time in format 2022-10-03T19:45:47.844Z in Java",
    "Body": "I need the current system date and time in 2022-10-03T19:45:47.844Z format in a java class.\nI tried using the zoneddatetime and simple date format but couldn't get the write syntax or code from online. I'm beginner in Java, any help is appreciated.\nThanks.\n",
    "AcceptedAnswerId": 74356572,
    "AcceptedAnswer": "I hope this solves your problem:\nimport java.time.ZoneId;\nimport java.time.ZonedDateTime;\nimport java.time.format.DateTimeFormatter;\n\npublic class Main {\n    public static void main(String[] args) {\n        ZonedDateTime zdt = ZonedDateTime.now(ZoneId.of(\"UTC\"));\n        DateTimeFormatter formatter =\n                DateTimeFormatter.ofPattern(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\");\n        System.out.println(zdt.format(formatter));\n    }\n}\n\n"
}
{
    "Id": 73299265,
    "PostTypeId": 1,
    "Title": "Java Stream Collect() classifier can't detect type",
    "Body": "I have the following code reading lines from a text file:\ntry (BufferedReader br = new BufferedReader(new InputStreamReader(Uio.decodeFrom(url)))) {\n        return br.lines()\n                .parallel()\n                .map(s -> s.split(\"\\\\s+\")) // split by whitespace\n                .collect(\n                        Collectors.groupingByConcurrent(\n                                arr -> arr[0], // String 1\n                                Collectors.groupingByConcurrent(\n                                        arr -> arr[arr.length-1], // String 2\n                                        Collectors.counting()\n                                )\n                        )\n                );\n    } catch (IOException e) {\n        throw new UncheckedIOException(e);\n    }\n\nThe text file has data like\nString1     ... cols      ... String2\nstring1data ... otherdata ... string2data\n...\n\nAnd I'm trying to group by String1 and String2 and get their counts. Then end result should be a Map>. However, with the code above, the compiler is saying that the collect() returns a  ConcurrentMap >.\nWhy are the keys not Strings?\n",
    "AcceptedAnswerId": 73299327,
    "AcceptedAnswer": "I can duplicate this error message, but the replacement of String with Object in the error message appears to be a red herring.  The real problem is that Java's generics are invariant.\nIf the call to collect is returning a ConcurrentMap>, that doesn't match Map>, even though a ConcurrentMap is a Map.  The inner Map type must match exactly without a wildcard and bounds.\nIf you introduce an upper-bounded wildcard to the return type, it will compile without error.  Have it return the type Map>, so that the inner ConcurrentMap will match.\nA return type of Map> will also work.\nIt's unclear why String wasn't captured until the generics invariant issue was worked out.  Just a guess: the compiler didn't capture String yet, because it found the invariant generics issue first.  Once the invariant generics issue is resolved, it compiles without error, implying String does get inferred.\n"
}
{
    "Id": 73480342,
    "PostTypeId": 1,
    "Title": "Manifest for java:8-jre-alpine not found: manifest unknown: manifest unknown",
    "Body": "I'm facing this error while building on Ubuntu server:\n\nStep 1/10 : FROM java:8-jre-alpine\nERROR: Service 'XXXX' failed to build: manifest for java:8-jre-alpine not found: manifest unknown: manifest unknown\n\nIt was working fine since months, suddenly now its not working. What could be the reason?\n",
    "AcceptedAnswerId": 73490179,
    "AcceptedAnswer": "I change java:8 to openjdk:8 and it works.\n"
}
{
    "Id": 74377433,
    "PostTypeId": 1,
    "Title": "What is the difference between \".\" and \"/\" in java classname?",
    "Body": "I'm new to java. When I try to learn Maven in 5 minutes, I found that this command\njava -cp target/my-app-1.0-SNAPSHOT.jar com.mycompany.app.App\n\nworked the same way as\njava -cp target/my-app-1.0-SNAPSHOT.jar com/mycompany/app/App\n\nIt drives me crazy because the last argument in the second command is actually a path. What is the difference between \".\" and \"/\" in java classname?\nI have looked up some articles but still don't get it.\n",
    "AcceptedAnswerId": 74377496,
    "AcceptedAnswer": "This is an implementation detail leaking out.  Class names in the language are dot-separated; class names in the classfile format are slash-separated.  (https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-4.html#jvms-4.2.)  For the most part, internal names are not visible to users, but they do leak in some circumstances.  Many tools that deal with classfiles will convert from the external (dotted) to internal (slashed) name using something like replace('.', '/'), which has the effect that internal names are also accepted by the tool.  That's what's going on here.\n"
}
{
    "Id": 72040055,
    "PostTypeId": 1,
    "Title": "Wildfly org.jboss.nio -> FileNotFoundException: Invalid file path with Windows Java JDK 11.0.15+10",
    "Body": "Since the update to Eclipse Tamurin JDK 11.0.15+10 we notice a problem as soon a HTTP request reaches Wildfly 20.0.1.Final. The same behaviour exsists in Wildfly 26.1.0.Final This only happens with the JDK Windows version, the Linux JDK works fine.\nAs it is an \"Invalid file path\" error, an OS dependent BUG seems possible.\nUntil now SAP Machine is the only JDK that does not encounter this failure.\nI'm still not sure if this is a JDK or a Wildfly problem...\nYou can check that when opening the Wildfly Management Interface.\nERROR [io.undertow.request] (External Management Request Threads -- 1) UT005071: Undertow request failed HttpServerExchange{ GET /management}: java.io.IOError: java.io.FileNotFoundException: Invalid file path\n    at org.jboss.xnio@3.8.1.Final//org.xnio.channels.Channels$4.run(Channels.java:1103)\n    at org.jboss.xnio@3.8.1.Final//org.xnio.channels.Channels$4.run(Channels.java:1093)\n    at java.base/java.security.AccessController.doPrivileged(Native Method)\n    at org.jboss.xnio@3.8.1.Final//org.xnio.channels.Channels.(Channels.java:1093)\n    at io.undertow.core@2.1.3.Final//io.undertow.io.UndertowOutputStream.write(UndertowOutputStream.java:231)\n    at io.undertow.core@2.1.3.Final//io.undertow.io.BlockingSenderImpl.writeBuffer(BlockingSenderImpl.java:245)\n    at io.undertow.core@2.1.3.Final//io.undertow.io.BlockingSenderImpl.writeBuffer(BlockingSenderImpl.java:238)\n    at io.undertow.core@2.1.3.Final//io.undertow.io.BlockingSenderImpl.send(BlockingSenderImpl.java:75)\n    at io.undertow.core@2.1.3.Final//io.undertow.io.BlockingSenderImpl.send(BlockingSenderImpl.java:107)\n    at org.jboss.as.domain-http-interface@12.0.3.Final//org.jboss.as.domain.http.server.DomainUtil.writeResponse(DomainUtil.java:89)\n    at org.jboss.as.domain-http-interface@12.0.3.Final//org.jboss.as.domain.http.server.DomainApiHandler$1.doSendResponse(DomainApiHandler.java:177)\n    at org.jboss.as.domain-http-interface@12.0.3.Final//org.jboss.as.domain.http.server.ResponseCallback.sendResponse(ResponseCallback.java:32)\n    at org.jboss.as.domain-http-interface@12.0.3.Final//org.jboss.as.domain.http.server.DomainApiHandler.handleRequest(DomainApiHandler.java:232)\n    at io.undertow.core@2.1.3.Final//io.undertow.server.handlers.encoding.EncodingHandler.handleRequest(EncodingHandler.java:72)\n    at org.jboss.as.domain-http-interface@12.0.3.Final//org.jboss.as.domain.http.server.DomainApiCheckHandler.handleRequest(DomainApiCheckHandler.java:91)\n    at org.jboss.as.domain-http-interface@12.0.3.Final//org.jboss.as.domain.http.server.security.ElytronIdentityHandler.lambda$handleRequest$0(ElytronIdentityHandler.java:62)\n    at org.wildfly.security.elytron-private@1.12.1.Final//org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:328)\n    at org.wildfly.security.elytron-private@1.12.1.Final//org.wildfly.security.auth.server.SecurityIdentity.runAs(SecurityIdentity.java:285)\n    at org.jboss.as.controller@12.0.3.Final//org.jboss.as.controller.AccessAuditContext.doAs(AccessAuditContext.java:254)\n    at org.jboss.as.controller@12.0.3.Final//org.jboss.as.controller.AccessAuditContext.doAs(AccessAuditContext.java:225)\n    at org.jboss.as.domain-http-interface@12.0.3.Final//org.jboss.as.domain.http.server.security.ElytronIdentityHandler.handleRequest(ElytronIdentityHandler.java:61)\n    at io.undertow.core@2.1.3.Final//io.undertow.server.handlers.BlockingHandler.handleRequest(BlockingHandler.java:56)\n    at io.undertow.core@2.1.3.Final//io.undertow.server.Connectors.executeRootHandler(Connectors.java:370)\n    at io.undertow.core@2.1.3.Final//io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:830)\n    at org.jboss.threads@2.3.3.Final//org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35)\n    at org.jboss.threads@2.3.3.Final//org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:1982)\n    at org.jboss.threads@2.3.3.Final//org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1486)\n    at org.jboss.threads@2.3.3.Final//org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1348)\n    at java.base/java.lang.Thread.run(Thread.java:829)\n    at org.jboss.threads@2.3.3.Final//org.jboss.threads.JBossThread.run(JBossThread.java:485)\nCaused by: java.io.FileNotFoundException: Invalid file path\n    at java.base/java.io.FileOutputStream.(FileOutputStream.java:231)\n    at java.base/java.io.FileOutputStream.(FileOutputStream.java:126)\n    at org.jboss.xnio@3.8.1.Final//org.xnio.channels.Channels$4.run(Channels.java:1098)\n    ... 29 more\n\n\n\n\n\nJDK\nWorks with Wildfly\n\n\n\n\nEclipse Tamurin\nno\n\n\nAmazon Coretto\nno\n\n\nAzul Zulu\nno\n\n\nBellsoft\nno\n\n\nOracle OpenJDK\nno\n\n\nOracle JDK\nno\n\n\nSAP Machine\nyes\n\n\n\n",
    "AcceptedAnswerId": 72465068,
    "AcceptedAnswer": "This is an issue in the JDK. You can wait for JDK 11.0.16 or downgrade to a lower version like JDK 11.0.14.\n"
}
{
    "Id": 73878386,
    "PostTypeId": 1,
    "Title": "Lock-free array expansion in Java",
    "Body": "I have an array to which many threads are writing. However each thread has a pre-assigned range of indices which it may write to. Further, nothing will be reading from the array until all threads are done.\nSo far, so thread-safe. The problem arises when I need to expand the array, by which of course I mean swap it out for a larger array which copies the first. This is only done occasionally (similar to an ArrayList).\nCurrently I'm acquiring a lock for every single write to the array. Even though there is no need to lock in order to keep the array consistent, I'm having to lock in case the array is currently being copied/swapped.\nAs there are very many writes I don't want to require a lock for them. I'm okay with a solution which requires locking for writer threads only while the array is being copied and swapped, as this is infrequent.\nBut I can't just impose write locks only when the copy/swap is in progress, as threads may already be committing writes to the old array.\nI think I need some variety of barrier which waits for all writes to complete, then pauses the threads while I copy/swap the array. But CyclicBarrier would require me to know exactly how many threads are currently active, which is non-trivial and possibly susceptible to edge-cases in which   the barrier ends up waiting forever, or lowers itself too early. In particular I'm not sure how I'd deal with a new thread coming in while the barrier is already up, or how to deal with threads which are currently polling a job queue, so will never decrement the barrier count while there are no new jobs.\nI may have to implement something which (atomically) counts active threads and tries to pre-empt all the edge cases.\nBut this may well be a \"solved\" problem that I don't know about, so I'm hoping there may be a simpler (therefore better) solution than the Cyclic barrier/thread counting. Ideally one which uses an existing utility class.\nBy the way, I've considered CopyOnWriteArray. This is no use to me, as it copies for every write (a lot of them), not just array expansions.\nAlso note the structure written to pretty much has to be an array, or array-based.\nThanks\n",
    "AcceptedAnswerId": 73878933,
    "AcceptedAnswer": "Although it's technically not correct, you can probably use a ReadWriteLock. The threads that are writing to a single portion all use a read lock (this is the technically incorrect part, they're not reading...), and the resize uses a write lock. That way, all writing threads can work together. A resize has to wait until all portioned writes are done, which then blocks the entire array. Once that is done, all portioned writes can continue.\n"
}
{
    "Id": 72703351,
    "PostTypeId": 1,
    "Title": "Java 19 Pattern Matching Compilation Error: \"the switch statement does not cover all possible input values\"",
    "Body": "Using the Brian Goetz article: https://www.infoq.com/articles/data-oriented-programming-java/\nsealed interface Opt { \n    record Some(T value) implements Opt { }\n    record None() implements Opt { }\n}\n\nThis compiles and runs as expected. The exhaustive pattern matching works:\nOpt optValue = doCalc(value);\nswitch (optValue) {\n  case Opt.Some some -> System.out.printf(\"got string: %s%n\", some.value());\n  case Opt.None none -> System.out.printf(\"got none%n\");\n};\n\nThis variation where I use the new Record patterns preview feature, breaks the exhaustive pattern matching, where this won't compile without adding a default case statement:\nOpt optValue = doCalc(value);\nswitch (optValue) {\n    case Opt.Some(String v) -> System.out.printf(\"got string: %s%n\", v);\n    case Opt.None none -> System.out.printf(\"got none%n\");\n};\n\nWith OpenJDK Runtime Environment (build 19-ea+32-2220), I get the compilation error: the switch statement does not cover all possible input values.\nWhen I add a default case statement, and the program works, but I don't get exhaustive pattern matching.\nIf I remove the record pattern matching, the program works.\nIf I create a variation of this without generics, that uses sealed classes, exhaustive pattern matching, and record patterns, it works.\nHowever, it seems the combination of record patterns, generics and exhaustive pattern matching does not work.\n",
    "AcceptedAnswerId": 73977879,
    "AcceptedAnswer": "This is a known bug in Java 19. This was confirmed by Brian Goetz himself on the amber-dev mailing list.\nUPDATE: This issue is completely fixed in Java 20.\n"
}
{
    "Id": 74240190,
    "PostTypeId": 1,
    "Title": "Numeric comparing option for Java Collator",
    "Body": "Problem:\nLet's say we have the following list of strings {\"Test1.txt\", \"Test2.txt\", \"Test11.txt\", \"Test22.txt\"}, sorting them using String::compareTo or Collator::compare would result in following order:\nTest1.txt\nTest2.txt\nTest22.txt\nTest3.txt\n\nWhich is inconvenient(arguably), while a more human-friendly outcome is:\nTest1.txt\nTest2.txt\nTest3.txt\nTest22.txt\n\nTo resolve this issues we can write our own compare method which is numeric sensitive.\nBut what if we want numeric sensitive sort as well as the benefit of using existing implementation of Collator (or to avoid implementing one) for internationalization?\nIs there a right way to handle this? or maybe a reliable library that addresses this problem?\nOther Languages:\nIn Javascript world the Intl.Collator's constructors accepts a CollatorOption which allows you to set configs to achieve such functionality and more:\nconst usCollator = Intl.Collator(\"us\", { numeric: true });\nconst list = [\"Test1.txt\", \"Test2.txt\", \"Test3.txt\", \"Test22.txt\"];\nlist.sort(usCollator.compare);\nconsole.log(list);\n\n",
    "AcceptedAnswerId": 74302933,
    "AcceptedAnswer": "You can use alphanumeric-comparator, which is available in Maven.\n"
}
{
    "Id": 74337681,
    "PostTypeId": 1,
    "Title": "Is the permits relationship of Java Sealed classes/interfaces transitive",
    "Body": "If I read the JLS \u00a78.1.6 and \u00a79.1.4 correctly, the classes that a sealed class/interface permits, are just the direct subclasses/interfaces.\nTo illustrate this, consider the following example:\npublic sealed interface I1 permits I2, C, D { /*...*/ }\npublic final class C implements I1 { /*...*/ }\npublic final class D implements I1 { /*...*/ }\n\npublic sealed interface I2 extends I1 permits E, F { /*...*/ }\npublic final class E implements I2 { /*...*/ }\npublic final class F implements I2 { /*...*/ }\n\nIf I understand the specification correctly, I1 obviously permits C and D but not E and F (via the extends hierarchy of I2 from I1). Is this correct?\nThe reason I'm asking is what patterns are allowed for switch expressions of the following kind:\nI1 i1 = // ...\nreturn switch (i1) {\n    case C c -> \"1\";\n    case D d -> \"2\";\n    case E e -> \"3\"; // Can we match over E?\n    case F f -> \"4\"; // Can we match over F?\n    default  -> \"5\";\n};\n\n",
    "AcceptedAnswerId": 74339207,
    "AcceptedAnswer": "\nI1 obviously permits C and D but not E and F. Is this correct?\n\nMore accurately, you can say that C and D are in the set of permitted direct subclasses of I1, which is a term defined in section 9.1.4. The JLS doesn't really define what \"I1 permits C and D\" means though.\nAs for your switch expression, the reason why it works is two-fold. First, you are able to write a type pattern in a switch label if the type of the switch selector expression is downcast-convertible to that type.\n14.11.1\n\nA pattern case element p is switch compatible with T if p is applicable at type T (14.30.3).\n\n14.30.3:\n\nA pattern p is said to be applicable at a type T if one of the following rules apply:\n\nA type pattern that declares a pattern variable of a reference type U is applicable at another reference type T if T is downcast convertible to U (5.5).\n\n\nObviously, E is downcast-convertible to I1 through a widening reference conversion, because E implements I1. Note that this fact has nothing to do with permits. It is simply a result of E implements I2 and I2 extends I1. Surely you would agree that implements and extends are transitive!\nSecond, switch expressions need to be exhaustive. Your switch expression is always exhaustive because it has a default case. However, it is still exhaustive even without the default case.\nFrom now on, we will consider your switch expression but without the default case, because that is where permits plays a role. The rules to determine whether the set of case labels you wrote are exhaustive are specified in 14.11.1.1. The important bit of your case is (this is kind of an inductive definition):\n\n\nA set of case elements is exhaustive for a type T if it contains a pattern that is unconditional at type T (14.30.3).\nA set of case elements is exhaustive for a type T that includes an abstract and sealed class or interface named C, if it is exhaustive\nfor every applicable permitted direct subtype of T.\n\n\n\"applicable permitted direct subtype of T\" in your case is really just the same as \"permitted direct subtype of T\". You can also treat \"a type T that includes an abstract and sealed class or interface named C\" as the same as T - the \"includes\" relationship isn't relevant to your case. With T=I1 in mind, we can start \"running\" this algorithm.\nWe use the second rule first - the permitted direct subtypes of I1 are I2, C and D. Since we have a C c and D d in the case elements, we know that our set of case elements is exhaustive for C and D (first rule). Is it also exhaustive for I2? To determine that, we use the second rule again. The permitted direct subtypes of I2 are E and F. Using the first rule, we know that the case elements E e and F f are exhaustive for E and F respectively. We have now proven that that the set of case elements are exhaustive for I2, C and D, so it is exhaustive for I1, according to the second rule.\nSo if you are talking about how switch patterns work, I think \"inductive\" is a better word to describe how the exhaustiveness of switch case labels are verified.\n"
}
{
    "Id": 72724816,
    "PostTypeId": 1,
    "Title": "Running unit tests with Spark 3.3.0 on Java 17 fails with IllegalAccessError: class StorageUtils cannot access class sun.nio.ch.DirectBuffer",
    "Body": "According to the release notes, and specifically the ticket Build and Run Spark on Java 17 (SPARK-33772), Spark now supports running on Java 17.\nHowever, using Java 17 (Temurin-17.0.3+7) with Maven (3.8.6) and maven-surefire-plugin (3.0.0-M7), when running a unit test that uses Spark (3.3.0) it fails with:\n\njava.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x1e7ba8d9) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x1e7ba8d9\n\nThe stack is:\njava.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x1e7ba8d9) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x1e7ba8d9\n  at org.apache.spark.storage.StorageUtils$.(StorageUtils.scala:213)\n  at org.apache.spark.storage.StorageUtils$.(StorageUtils.scala)\n  at org.apache.spark.storage.BlockManagerMasterEndpoint.(BlockManagerMasterEndpoint.scala:114)\n  at org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:353)\n  at org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:290)\n  at org.apache.spark.SparkEnv$.create(SparkEnv.scala:339)\n  at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:194)\n  at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:279)\n  at org.apache.spark.SparkContext.(SparkContext.scala:464)\n  at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2704)\n  at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:953)\n  at scala.Option.getOrElse(Option.scala:189)\n  at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:947)\n  [...]\n\nThe question Java 17 solution for Spark - java.lang.NoClassDefFoundError: Could not initialize class org.apache.spark.storage.StorageUtils was asked only 2 months ago, but this pre-dated the Spark 3.3.0 release, and thus predated official support for Java 17.\nWhy can't I run my Spark 3.3.0 test with Java 17, and how can we fix it?\n",
    "AcceptedAnswerId": 72724817,
    "AcceptedAnswer": "Even though Spark now supports Java 17, it still references the JDK internal class sun.nio.ch.DirectBuffer:\n  // In Java 8, the type of DirectBuffer.cleaner() was sun.misc.Cleaner, and it was possible\n  // to access the method sun.misc.Cleaner.clean() to invoke it. The type changed to\n  // jdk.internal.ref.Cleaner in later JDKs, and the .clean() method is not accessible even with\n  // reflection. However sun.misc.Unsafe added a invokeCleaner() method in JDK 9+ and this is\n  // still accessible with reflection.\n  private val bufferCleaner: DirectBuffer => Unit = [...]\n\nUnder the Java module system, access to this class is restricted.  The Java 9 migration guide says:\n\nIf you must use an internal API that has been made inaccessible by default, then you can break encapsulation using the --add-exports command-line option.\n\nWe need to open access to our module.  To do this for Surefire, we add this configuration to the plugin:\n\n  org.apache.maven.plugins\n  maven-surefire-plugin\n  3.0.0-M7\n  \n    --add-exports java.base/sun.nio.ch=ALL-UNNAMED\n  \n\n\nBased on a discussion with one of the Spark developers, Spark adds the following in order to execute all of its internal unit tests.\n\nThese options are used to pass all Spark UTs, but maybe you don't need all.\n\n--add-opens=java.base/java.lang=ALL-UNNAMED\n--add-opens=java.base/java.lang.invoke=ALL-UNNAMED\n--add-opens=java.base/java.lang.reflect=ALL-UNNAMED\n--add-opens=java.base/java.io=ALL-UNNAMED\n--add-opens=java.base/java.net=ALL-UNNAMED\n--add-opens=java.base/java.nio=ALL-UNNAMED\n--add-opens=java.base/java.util=ALL-UNNAMED\n--add-opens=java.base/java.util.concurrent=ALL-UNNAMED\n--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED\n--add-opens=java.base/sun.nio.ch=ALL-UNNAMED\n--add-opens=java.base/sun.nio.cs=ALL-UNNAMED\n--add-opens=java.base/sun.security.action=ALL-UNNAMED\n--add-opens=java.base/sun.util.calendar=ALL-UNNAMED\n\nIt was also commented:\n\nHowever, these Options needn't explicit add when using spark-shell, spark-sql and spark-submit\n\n"
}
{
    "Id": 74683791,
    "PostTypeId": 1,
    "Title": "Java CompletableFuture for sequential code",
    "Body": "My new team is writing a Java gRPC service and to ensure that we never block the request thread we ended-up wrapping more or less ALL methods inside a CompletableFuture even if those endpoints are conceptually a sequential list of operation (no parallelism).\nSo the code look something like (a Java example is available at the end if needed) :\n  methodA()\n    methodB()\n      methodD() (let say this one is a 15ms RPC call)\n      methodE()\n    methodC()\n      methodF() (let say this one is a 5ms CPU intensive work)\n      methodG()\n \n\nContext:\n\nIn practice the application is much bigger and there're many more layers of functions\nEach application host need to handle 1000 QPS, so you can imagine that methodA is called at that rate\nSome function (few) make a RPC call that can take 5-30ms (IO)\nSome function (very few) run CPU intensive work (\n\nEdit 1: After more reading online yesterday, I understand that if, and only if, we are using true non-blocking HTTP and DB Client (and it doesn't seem like JDBC is non-blocking), this pattern can reduce the total number of threads required. My understanding is that if we have enough memory to keep one thread per request, using a synchronous code would still probably be the most efficient implementation (reduce the overhead of switching threads and loading data), but if we didn't have enough memory to keep that many threads alive, then this notion of making the whole code non-blocking can reduce the number of thread and thus allow the application to scale to more request.\nQuestion 1:\nI understand this unblocks the \"request thread\", but in practice what's the advantage? Are we truly saving CPU time? In the example below, it feels like \"some\" thread will be alive the whole time anyways (in the example below, mostly the thread from CompletableFuture.supplyAsync in methodD), it just happens that it\u2019s not the same thread as the one who received the initial request.\nQuestion 2:\nIs that pattern truly a \"best practice\" and all services should follow a similar pattern? Outside of making the code a bit harder to read I feel, per request 50+ methods gets invoked and 50+ times we call a mix of CompletableFuture .thenCompose() or .supplyAsync. It seems like it's would be adding some overhead. Was CompletableFuture designed to be used that way across the whole code base in every method?\nAnnex (java example):\n  public void myEndpoint(MyRequest request, StreamObserver responseObserver) {\n    methodA(10)\n        .thenApply((response) -> responseObserver.next(response));\n    \n  }\n\n  public CompletableFuture methodA(Integer input) {\n    return CompletableFuture.completedFuture(input)\n        .thenCompose(this::methodB)\n        .thenCompose(this::methodC)\n        .thenApply((i) -> {\n          System.out.println(\"MethodA executed by \".concat(Thread.currentThread().getName() + \": \" + i));\n          return i;\n        });\n  }\n\n  public CompletableFuture methodB(Integer input) {\n    return CompletableFuture.completedFuture(input)\n        .thenCompose(this::methodD)\n        .thenCompose(this::methodE)\n        .thenApply((i) -> {\n          System.out.println(\"MethodB executed by \".concat(Thread.currentThread().getName() + \": \" + i));\n          return i;\n        });\n  }\n\n  public CompletableFuture methodC(Integer input) {\n    return CompletableFuture.completedFuture(input)\n        .thenCompose(this::methodF)\n        .thenCompose(this::methodG)\n        .thenApply((i) -> {\n          System.out.println(\"MethodC executed by \".concat(Thread.currentThread().getName() + \": \" + i));\n          return i;\n        });\n  }\n\n  public CompletableFuture methodD(Integer input) {\n    return CompletableFuture.supplyAsync(() -> {\n      try {\n        // Assume it's a RPC call that takes 5-30ms\n        Thread.sleep(20);\n        System.out.println(\"MethodD executed by \".concat(Thread.currentThread().getName() + \": \" + input));\n      } catch (InterruptedException e) {\n        throw new RuntimeException(e);\n      }\n      return input + 1;\n    });\n  }\n\n  public CompletableFuture methodE(Integer input) {\n    return CompletableFuture.supplyAsync(() -> {\n      System.out.println(\"MethodE executed by \".concat(Thread.currentThread().getName() + \": \" + input));\n      return input + 1;\n    });\n  }\n\n  public CompletableFuture methodF(Integer input) {\n    return CompletableFuture.supplyAsync(() -> {\n      try {\n        // Let's assume it's a CPU intensive work that takes 2-5ms\n        Thread.sleep(5);\n        System.out.println(\"MethodF executed by \".concat(Thread.currentThread().getName() + \": \" + input));\n      } catch (InterruptedException e) {\n        throw new RuntimeException(e);\n      }\n      return input + 1;\n    });\n  }\n\n  public CompletableFuture methodG(Integer input) {\n    return CompletableFuture.supplyAsync(() -> {\n      System.out.println(\"MethodG executed by \".concat(Thread.currentThread().getName() + \": \" + input));\n      return input + 1;\n    });\n  }\n\n",
    "AcceptedAnswerId": 74796834,
    "AcceptedAnswer": "The premise is that threads are a scarce resource, which is not intrinsic to threads but a consequence of using a pool of threads with a configured maximum. The reason today\u2019s frameworks use a pool is that threads, as implemented today, are expensive and creating too many of them can cause significant performance problems.\nYou wrote\n\nMy understanding is that if we have enough memory to keep one thread per request, using a synchronous code would still probably be the most efficient implementation\u2026\n\nwhich is going into the right direction, but it\u2019s important to keep in mind that there might be more constraints than memory. Some operating system\u2019s schedulers become significantly less efficient with a large number of threads, some may even have a fixed limit on how many threads a process is allowed to create.\nSo, when you block a thread by waiting for another, you are limiting the parallel processing capabilities of the thread pool. This applies if you are using, as you put it, a \u201ctrue non-blocking\u201d API, or just any already existing API that returns futures. Submitting your own operations via supplyAsync has no point as the supplier\u2019s code still is executed by a thread, as you correctly pointed out.\nBut when you have an existing future returned by an operation, you should rather chain dependent processing steps instead of waiting for its result via join and friends. Note that calling join() on existing futures can make things even worse than just blocking threads:\nWhen you call join() on a CompletableFuture, it tries to compensate the problem. When the caller is a worker thread of a Fork/Join pool, one of two things can happen:\n\nInstead of doing nothing, it may try to fetch pending jobs and execute them in-place, similar to awaitQuiescence.\n\nIn the best case, it will directly pick up the job you just scheduled with supplyAsync (if using the same pool) and execute it, almost as if you executed it without CompletableFuture (just consuming far more stack space).\nIn the worst case, the thread will be busy executing a long running, entirely unrelated job while the job it\u2019s actually waiting for has been completed long ago. Imagine what happens if that unrelated job also calls join.\n\n\nIt may end up actually blocking the thread but using ForkJoinPool.managedBlock(\u2026), which may start a new worker thread to ensure that the pool\u2019s configured parallelism is kept. Great to solve the problem of reduced parallelism, but on the other hand, reintroducing the very problem of resource consumption you actually wanted to solve with thread pools.\n\nThe worst of all is that you can\u2019t even predict which of the two things will happen.\n\nThere are, however, cases where not blocking a request thread by utilizing other threads has a point. Most notably when the response time for the request itself matters and the results of the background computation are delivered independent of the initial response. The most prominent example of this pattern is the event dispatch thread of GUI frameworks which must be kept free of long running operations, to be able to process subsequent user input.\n\nNote that there is a general solution on the way, to make 99% of all future chains obsolete. Virtual Threads, which are in preview state in JDK\u00a019, are cheap to create and allow to create one thread per request, just like you envisioned in the cite above. When a virtual thread gets blocked, it will release the underlying platform thread for the next virtual thread, so there is no reason to hesitate to call join() on any future, even those belonging to \u201ctrue non-blocking\u201d APIs.\nThe best way to interoperate with this concept and the status quo is to design methods to not return futures, but perform the operation in-place. It\u2019s still possible to design a future chain when necessary, i.e. by using .thenApplyAsync(this::inPlaceEvalMethod) instead of .thenCompose(this::futureReturningMethod). But at the same time, you can write a plain sequential version just calling these methods, which can be executed by a virtual thread. In fact, you could even add the plain sequential version today and benchmark both approaches. The results might convince your team members that \u201cnot blocking the request thread\u201d is not necessarily an improvement.\n"
}
{
    "Id": 72738837,
    "PostTypeId": 1,
    "Title": "In Java, what does the / (i.e., forward slash) mean in object references like $Lambda$15/0x00000008000a9440@32e6e9c3)?",
    "Body": "In JShell, if I do this:\ninterface Foo { String foo(); }\n(Foo) () -> \"hi\"\n\nI get\n|  created interface Foo\n$2 ==> $Lambda$15/0x00000008000a9440@32e6e9c3\n\nFrom the research below, I know the following:\n$Lambda = an in-memory reference, as opposed to one persisted to disk by an anonymous inner class (AIC), to the generated bytecode\n$15 = an object reference to the AIC\n@32e6e9c3 = the sequential number of the object created--at least, in IntelliJ\nBut what does the / (slash) indicate, as in /0x00000008000a9440?\n",
    "AcceptedAnswerId": 72887915,
    "AcceptedAnswer": "Summary\n$Lambda$15/0x00000008000a9440 is the name of the created hidden class.\nAs it will be shown below, 0x00000008000a9440 is called a suffix.\nThe name of the class can be retrieved by calling the java.lang.Class.getName() method.\nTherefore:\n\nFor example, the same class names can be retrieved by a Java program (not through JShell).\nThe question does not seem to be about JShell, but about the Java language and the Java Virtual Machine.\n\nExample program to show name of hidden class\nProgram class\npackage info.brunov.stackoverflow.question72804142;\n\nimport java.util.function.Supplier;\n\npublic final class Program {\n    public static void main(final String args[]) {\n        printRuntimeInformation();\n\n        final Supplier supplier1 = () -> \"\";\n        final Supplier supplier2 = () -> \"\";\n        final Supplier supplier3 = () -> \"\";\n        System.out.println(\n            String.format(\"Supplier 1: %s\", supplier1.getClass().getName())\n        );\n        System.out.println(\n            String.format(\"Supplier 2: %s\", supplier2.getClass().getName())\n        );\n        System.out.println(\n            String.format(\"Supplier 3: %s\", supplier3.getClass().getName())\n        );\n    }\n\n    private static void printRuntimeInformation() {\n        System.out.println(\n            String.format(\n                \"Java Virtual Machine specification name: %s\",\n                System.getProperty(\"java.vm.specification.name\")\n            )\n        );\n        System.out.println(\n            String.format(\n                \"Java Virtual Machine specification version: %s\",\n                System.getProperty(\"java.vm.specification.version\")\n            )\n        );\n        System.out.println(\n            String.format(\n                \"Java Virtual Machine specification vendor: %s\",\n                System.getProperty(\"java.vm.specification.vendor\")\n            )\n        );\n        System.out.println(\n            String.format(\n                \"Java Virtual Machine implementation name: %s\",\n                System.getProperty(\"java.vm.name\")\n            )\n        );\n        System.out.println(\n            String.format(\n                \"Java Virtual Machine implementation version: %s\",\n                System.getProperty(\"java.vm.version\")\n            )\n        );\n        System.out.println(\n            String.format(\n                \"Java Virtual Machine implementation vendor: %s\",\n                System.getProperty(\"java.vm.vendor\")\n            )\n        );\n    }\n}\n\nProgram output\nJava Virtual Machine specification name: Java Virtual Machine Specification\nJava Virtual Machine specification version: 18\nJava Virtual Machine specification vendor: Oracle Corporation\nJava Virtual Machine implementation name: OpenJDK 64-Bit Server VM\nJava Virtual Machine implementation version: 18.0.1-ea+10-Debian-1\nJava Virtual Machine implementation vendor: Debian\nSupplier 1: info.brunov.stackoverflow.question72804142.Program$$Lambda$18/0x0000000800c031f0\nSupplier 2: info.brunov.stackoverflow.question72804142.Program$$Lambda$19/0x0000000800c033f8\nSupplier 3: info.brunov.stackoverflow.question72804142.Program$$Lambda$20/0x0000000800c03600\n\nDocumentation references\nJEP 371: Hidden Classes\nThe hidden classes have been introduced since JDK 15.\nFor additional details, please, refer to the JEP: JEP 371: Hidden Classes.\nHere is an excerpt from the JEP on the hidden class names:\n\nThe major difference in how a hidden class is created lies in the name it is given. A hidden class is not anonymous. It has a name that is available via Class::getName and may be shown in diagnostics (such as the output of java -verbose:class), in JVM TI class loading events, in JFR events, and in stack traces. However, the name has a sufficiently unusual form that it effectively makes the class invisible to all other classes. The name is the concatenation of:\n\nThe binary name in internal form (JVMS 4.2.1) specified by this_class in the ClassFile structure, say A/B/C;\nThe '.' character; and\nAn unqualified name (JVMS 4.2.2) that is chosen by the JVM implementation.\n\nFor example, if this_class specifies com/example/Foo (the internal form of the binary name com.example.Foo), then a hidden class derived from the ClassFile structure may be named com/example/Foo.1234. This string is neither a binary name nor the internal form of a binary name.\nGiven a hidden class whose name is A/B/C.x, the result of Class::getName is the concatenation of:\n\nThe binary name A.B.C (obtained by taking A/B/C and replacing each '/' with '.');\nThe '/' character; and\nThe unqualified name x.\n\nFor example, if a hidden class is named com/example/Foo.1234, then the result of Class::getName is com.example.Foo/1234. Again, this string is neither a binary name nor the internal form of a binary name.\nThe namespace of hidden classes is disjoint from the namespace of normal classes. Given a ClassFile structure where this_class specifies com/example/Foo/1234, invoking cl.defineClass(\"com.example.Foo.1234\", bytes, ...) merely results in a normal class named com.example.Foo.1234, distinct from the hidden class named com.example.Foo/1234. It is impossible to create a normal class named com.example.Foo/1234 because cl.defineClass(\"com.example.Foo/1234\", bytes, ...) will reject the string argument as being not a binary name.\n\nJavadoc: java.lang.Class#getName() method\nLet's refer to the method documentation: Class (Java SE 15 & JDK 15).\nAn excerpt from the documentation:\n\npublic\u00a0String\u00a0getName()\nReturns the name of the entity (class, interface, array class, primitive type, or void) represented by this Class object.\nIf this Class object represents a class or interface, not an array class, then:\n\nIf the class or interface is not hidden, then the binary name of the class or interface is returned.\nIf the class or interface is hidden, then the result is a string of the form: N + '/' +  where N is the binary name indicated by the class file passed to Lookup::defineHiddenClass, and  is an unqualified name.\n\n\nImplementation details: OpenJDK Java Virtual Machine: Hidden class name\nIntroduction\nLet's consider the source code of OpenJDK 18.\nLet's refer to the tag: openjdk/jdk18 at jdk-18+37.\nPlease, note that:\n\nThe below execution paths are theoretical: I am using the mentioned source code tag.\nThe below call stacks are real: I am using OpenJDK 18.0.1-ea+10-Debian-1.\n\nHidden class name mangling\nHidden class creation (the java.lang.invoke.MethodHandles.Lookup.defineHiddenClass() method) includes the mangling of its name.\nLet's consider the following call stack:\n\"main@1\" prio=5 tid=0x1 nid=NA runnable\n  java.lang.Thread.State: RUNNABLE\n      at java.lang.System$2.defineClass(System.java:2346)\n      at java.lang.invoke.MethodHandles$Lookup$ClassDefiner.defineClass(MethodHandles.java:2432)\n      at java.lang.invoke.MethodHandles$Lookup$ClassDefiner.defineClassAsLookup(MethodHandles.java:2413)\n      at java.lang.invoke.MethodHandles$Lookup.defineHiddenClass(MethodHandles.java:2119)\n      at java.lang.invoke.InnerClassLambdaMetafactory.generateInnerClass(InnerClassLambdaMetafactory.java:385)\n      at java.lang.invoke.InnerClassLambdaMetafactory.spinInnerClass(InnerClassLambdaMetafactory.java:293)\n      at java.lang.invoke.InnerClassLambdaMetafactory.buildCallSite(InnerClassLambdaMetafactory.java:228)\n      at java.lang.invoke.LambdaMetafactory.metafactory(LambdaMetafactory.java:341)\n      at java.lang.invoke.DirectMethodHandle$Holder.invokeStatic(DirectMethodHandle$Holder:-1)\n      at java.lang.invoke.Invokers$Holder.invokeExact_MT(Invokers$Holder:-1)\n      at java.lang.invoke.BootstrapMethodInvoker.invoke(BootstrapMethodInvoker.java:134)\n      at java.lang.invoke.CallSite.makeSite(CallSite.java:315)\n      at java.lang.invoke.MethodHandleNatives.linkCallSiteImpl(MethodHandleNatives.java:279)\n      at java.lang.invoke.MethodHandleNatives.linkCallSite(MethodHandleNatives.java:269)\n      at info.brunov.stackoverflow.question72804142.Program.main(Program.java:9)\n\nThen let's consider the following execution path as the continuation of the call stack:\nClass java.lang.ClassLoader#defineClass0(ClassLoader loader, Class lookup, String name, byte[] b, int off, int len, ProtectionDomain pd, boolean initialize, int flags, Object classData)\n\n// Native calls below.\njclass Unsafe_DefineClass0(JNIEnv *env, jobject unsafe, jstring name, jbyteArray data, int offset, int length, jobject loader, jobject pd)\njclass Unsafe_DefineClass_impl(JNIEnv *env, jstring name, jbyteArray data, int offset, int length, jobject loader, jobject pd)\nJNIEXPORT jclass JNICALL\njclass JVM_DefineClass(JNIEnv *env, const char *name, jobject loader, const jbyte *buf, jsize len, jobject pd)\njclass jvm_define_class_common(const char *name, jobject loader, const jbyte *buf, jsize len, jobject pd, const char *source, TRAPS)\nInstanceKlass* SystemDictionary::resolve_from_stream(ClassFileStream* st, Symbol* class_name, Handle class_loader, const ClassLoadInfo& cl_info, TRAPS)\nInstanceKlass* SystemDictionary::resolve_hidden_class_from_stream(ClassFileStream* st, Symbol* class_name, Handle class_loader, const ClassLoadInfo& cl_info, TRAPS)\nInstanceKlass* KlassFactory::create_from_stream(ClassFileStream* stream, Symbol* name, ClassLoaderData* loader_data, const ClassLoadInfo& cl_info, TRAPS)\nInstanceKlass* ClassFileParser::create_instance_klass(bool changed_by_loadhook, const ClassInstanceInfo& cl_inst_info, TRAPS)\nvoid ClassFileParser::mangle_hidden_class_name(InstanceKlass* const ik)\n\nLet's refer to the piece of source code: jdk18/classFileParser.cpp at jdk-18+37 \u00b7 openjdk/jdk18:\nvoid ClassFileParser::mangle_hidden_class_name(InstanceKlass* const ik) {\n  ResourceMark rm;\n  // Construct hidden name from _class_name, \"+\", and &ik. Note that we can't\n  // use a '/' because that confuses finding the class's package.  Also, can't\n  // use an illegal char such as ';' because that causes serialization issues\n  // and issues with hidden classes that create their own hidden classes.\n  char addr_buf[20];\n  if (DumpSharedSpaces) {\n    // We want stable names for the archived hidden classes (only for static\n    // archive for now). Spaces under default_SharedBaseAddress() will be\n    // occupied by the archive at run time, so we know that no dynamically\n    // loaded InstanceKlass will be placed under there.\n    static volatile size_t counter = 0;\n    Atomic::cmpxchg(&counter, (size_t)0, Arguments::default_SharedBaseAddress()); // initialize it\n    size_t new_id = Atomic::add(&counter, (size_t)1);\n    jio_snprintf(addr_buf, 20, SIZE_FORMAT_HEX, new_id);\n  } else {\n    jio_snprintf(addr_buf, 20, INTPTR_FORMAT, p2i(ik));\n  }\n\nPlease, note that the + character is used as the separator.\nGet hidden class name\nThe java.lang.Class#getName() method includes the character replacement: + is replaced with /.\nLet's consider the following execution path:\nString java.lang.Class.getName()\nString java.lang.Class.initClassName()\n\n// Native calls below.\nJNIEXPORT jstring JNICALL JVM_InitClassName(JNIEnv *env, jclass cls)\noop java_lang_Class::name(Handle java_class, TRAPS)\nconst char* java_lang_Class::as_external_name(oop java_class)\nconst char* Klass::external_name() const\nstatic char* convert_hidden_name_to_java(Symbol* name)\n\nLet's refer to the piece of source code: jdk18/klass.cpp at jdk-18+37 \u00b7 openjdk/jdk18:\n// Replace the last '+' char with '/'.\nstatic char* convert_hidden_name_to_java(Symbol* name) {\n\n"
}
{
    "Id": 72635074,
    "PostTypeId": 1,
    "Title": "Java Record with @Builder.Default",
    "Body": "I'm wondering is there any way to combine java record with lombok's @Builder.Default?\nLet's consider an example with properties object for new file creation.\nBefore java 14\n@Value\n@Builder\npublic class FileProperties {\n    @Builder.Default\n    String directory = System.getProperty(\"user.home\");\n    @Builder.Default\n    String name = \"New file\";\n    @Builder.Default\n    String extension = \".txt\";\n}\n\nJava 14\n@Builder\npublic record FileProperties (\n        String directory,\n        String name,\n        String extension\n) {}\n\nBut in case if I try to use something like\n@Builder\npublic record FileProperties (\n        @Builder.Default\n        String directory = System.getProperty(\"user.home\")\n) {}\n\nCompiler will fail with an error, revealing that such syntax is not allowed. Do we have any solution to this problem?\n",
    "AcceptedAnswerId": 75812314,
    "AcceptedAnswer": "This functionality is not available at the moment. Please check the first comment under the question\n\nNot right now, I hadn't considered that when extending support of @Builder to records.\n\n"
}
{
    "Id": 73162834,
    "PostTypeId": 1,
    "Title": "Why writing map entries to a HashSet is slower than to a CopyOnWriteArraySet in Java",
    "Body": "I think writing to a HashSet will be faster than to a CopyOnWriteArraySet; I'm not doing multi threading here. However I surpisingly got benchmark results indicate writing map entries to a CopyOnWriteArraySet is faster.\nI did benchmarking on writing 1000 of Map.Entry into a HashSet vs CopyOnWriteArraySet.\nBenchmark          (n)   Mode  Cnt     Score    Error  Units\nA.writeToCOWAS    1000  thrpt    4  1269.214 \u00b1 40.635  ops/s\nA.writeToHashSet  1000  thrpt    4   223.118 \u00b1 34.955  ops/s\n\nIn addition to that, I got benchmark results of equals() and hashCode() of Map.Entry reveal that the former is more expensive.\nBenchmark           Mode  Cnt          Score          Error  Units\nMapEntry.equals    thrpt    4  177773394.054 \u00b1 75436098.388  ops/s\nMapEntry.hashCode  thrpt    4  272240403.923 \u00b1 38794396.671  ops/s\n\nI believe writing to a HashSet calls to hashCode() while CopyOnWriteArraySet calls to equals().\nIn the case of writing Integer or String,HashSet is way faster. Then I'm wondering what happens with Map.Entry type and why CopyOnWriteArraySet is faster according to my analysis?\nMy perf test:\n@State(Scope.Benchmark)\n@Fork(value = 2)\n@Warmup(iterations = 2, time = 3)\n@Measurement(iterations = 2, time = 3)\npublic class A {\n    public Set> set;\n\n    @Param({\"1000\"})\n    public int n;\n\n    @Setup\n    public void setup() {\n        set = new HashSet((int) (n / 0.75f + 1f), 0.75f);\n        for (int i = 0; i < n; i++)\n            set.add(Map.entry(i, i));\n    }\n\n    private void eliminateDeadCode(Set> out, Blackhole hole) {\n        int hash = 0;\n        for (Map.Entry o : out)\n            hash += o.hashCode();\n        hole.consume(hash);\n        if (out.size() != set.size())\n            throw new RuntimeException(out.size() + \" != \" + set.size());\n    }\n\n    @Benchmark\n    public void writeToCOWAS(Blackhole hole) {\n        Set> out = new CopyOnWriteArraySet(set);\n        eliminateDeadCode(out, hole);\n    }\n\n    @Benchmark\n    public void writeToHashSet(Blackhole hole) {\n        Set> out = new HashSet(set);\n        eliminateDeadCode(out, hole);\n    }\n\n    public static void main(String[] args) throws RunnerException {\n        Options opt = new OptionsBuilder()\n                .include(A.class.getSimpleName())\n                .build();\n        new Runner(opt).run();\n    }\n}\n\n",
    "AcceptedAnswerId": 73188382,
    "AcceptedAnswer": "Hulk's answer is very instructive. However the problem is not necessarily the Map.entry() hashCode implementation, which is this, at least in Java 11:\npublic int hashCode() {\n    return key.hashCode() ^ value.hashCode();\n}\n\nThe problem is that the hash codes of key and value are always the same, both in the OP's test, and in Hulk's test, hence the hash codes combined via XOR will always end up as 0. Change it so that key and value are different, and performance will change.\n"
}
{
    "Id": 73603358,
    "PostTypeId": 1,
    "Title": "Understanding javadoc for ZonedDateTime::plusDays",
    "Body": "I am not able to understand one specific part of doc provided for the plusDays() method in ZonedDateTimeClass. Doc states:\n\nReturns a copy of this ZonedDateTime with the specified number of days\nadded.\nThis operates on the local time-line, adding days to the local\ndate-time. This is then converted back to a ZonedDateTime, using the\nzone ID to obtain the offset.\nWhen converting back to ZonedDateTime, if the local date-time is in an\noverlap, then the offset will be retained if possible, otherwise the\nearlier offset will be used. If in a gap, the local date-time will be\nadjusted forward by the length of the gap.\nThis instance is immutable and unaffected by this method call.\nParams: days \u2013 the days to add, may be negative\nReturns: a ZonedDateTime based on this date-time with the days added,\nnot null\nThrows: DateTimeException \u2013 if the result exceeds the supported date\nrange\n\nHow I understand this: Assume we have ZonedDateTime object representing September 4, 2022 6 PM in America/New_York TimeZone. So this method will first convert it to LocalDateTime, that is, it will lose timezone information and just retain September 4, 2022 6 PM. It will add some number of days to it, let's say 7, so that the result is September 11, 2022 6 PM, and now it will convert it back to ZonedDateTime object by providing back the information related to timezone.\nHowever, I am not able to understand the latter part of documentation, that is,\n\nWhen converting back to ZonedDateTime, if the local date-time is in an\noverlap, then the offset will be retained if possible, otherwise the\nearlier offset will be used. If in a gap, the local date-time will be\nadjusted forward by the length of the gap.\n\nWhat do they mean by local date-time is in an overlap? ...then the offset will be retained if possible, otherwise the earlier offset will be used. - what are these two different offsets? If in a gap... - what is this gap?\n",
    "AcceptedAnswerId": 73604362,
    "AcceptedAnswer": "The \"gap\" and \"overlap\" terms are defined in the class-level Javadoc of the ZonedDateTime class:\n\nThis class handles conversion from the local time-line of LocalDateTime to the instant time-line of Instant. The difference between the two time-lines is the offset from UTC/Greenwich, represented by a ZoneOffset.\nConverting between the two time-lines involves calculating the offset using the rules accessed from the ZoneId. Obtaining the offset for an instant is simple, as there is exactly one valid offset for each instant. By contrast, obtaining the offset for a local date-time is not straightforward. There are three cases:\n\nNormal, with one valid offset. For the vast majority of the year, the normal case applies, where there is a single valid offset for the local date-time.\nGap, with zero valid offsets. This is when clocks jump forward typically due to the spring daylight savings change from \"winter\" to \"summer\". In a gap there are local date-time values with no valid offset.\nOverlap, with two valid offsets. This is when clocks are set back typically due to the autumn daylight savings change from \"summer\" to \"winter\". In an overlap there are local date-time values with two valid offsets.\n\n\nExample\nLet's use your specific example of the America/New_York time zone.  Per timeanddate.com, the daylight saving time changes in New York for 2022 are:\n\nMar 13, 2022 - Daylight Saving Time Started\nWhen local standard time was about to reach\nSunday, March 13, 2022, 2:00:00 am clocks were turned forward 1 hour to\nSunday, March 13, 2022, 3:00:00 am local daylight time instead.\nNov 6, 2022 - Daylight Saving Time Ends\nWhen local daylight time is about to reach\nSunday, November 6, 2022, 2:00:00 am clocks are turned backward 1 hour to\nSunday, November 6, 2022, 1:00:00 am local standard time instead.\n\nTherefore, there are no times between 2:00 and 2:59 on March 13 in the New York time zone.  1:59 occurs in standard time.  When that minute ends, no 2:00 hour occurs, and instead the local time jumps to 3:00 daylight time.\nAdditionally, the times between 1:00 and 1:59 occur twice on November 6: one in daylight time and then one in standard time.\nJava ZonedDateTime example\nZoneId zone = ZoneId.of(\"America/New_York\");\n\n// 2022-03-13T03:15:30-04:00[America/New_York] (no 2:15)\nSystem.out.println(\n        ZonedDateTime.of(LocalDateTime.parse(\"2022-03-12T02:15:30\"), zone)\n        .plusDays(1));\n\nSince 2:15 AM on March 12 doesn't exist and is within a 1-hour gap, the following logic you quoted applies, adding 1 hour to the local time:\n\nIf in a gap, the local date-time will be adjusted forward by the length of the gap.\n\nTherefore, 3:15 AM is used when adding 1 day to March 11 at 1:15 AM.\nZoneId zone = ZoneId.of(\"America/New_York\");\n\n// 2022-11-06T01:15:30-04:00[America/New_York] (First 1:15)\nSystem.out.println(\n        ZonedDateTime.of(LocalDateTime.parse(\"2022-11-05T01:15:30\"), zone)\n        .plusDays(1));\n\n// 2022-11-06T01:15:30-05:00[America/New_York] (Second 1:15)\nSystem.out.println(\n        ZonedDateTime.of(LocalDateTime.parse(\"2022-11-05T01:15:30\"), zone)\n        .plusDays(1).plusHours(1));\n\nSince 1:15 AM is during an overlap \u2014 1:15 AM occurs twice on November 6 \u2014 the following logic you quoted applies, using the same -04:00 zone offset as 1:15 AM on November 5:\n\nif the local date-time is in an overlap, then the offset will be retained if possible\n\nTherefore, adding 1 day to November 5 at 1:15 uses the first 1:15 on November 6.  This is made more evident by the second call, which shows that adding an hour to this timestamp returns the second 1:15 of November 6.  The fact that these are different points on the timeline despite both being 1:15 local time is evident by their differing zone offsets: -04:00 & -05:00.\n"
}
{
    "Id": 73630599,
    "PostTypeId": 1,
    "Title": "Java regex inside text blocks",
    "Body": "I surely hoped that this would be supported:\nprivate static void regex() {\n    String plain = \"\\\\w+\";\n    String withTextBlocks = \"\"\"\n        \\w+\n    \"\"\";\n}\n\nbut withTextBlocks does not compile under Java-17. Isn\u2019t it the point of text blocks that we should not escape? I have been through the JEP and maybe the explanation is there, but I can't grok through it. And a second question in case someone knows, is there a future JEP for this? Thank you.\n",
    "AcceptedAnswerId": 73639221,
    "AcceptedAnswer": "You are conflating text blocks with raw strings.  These are different features, though they were explored together and this may explain why you mentally folded them together.  There is no support yet for raw strings (which turn out to be somewhat more slippery than they might first appear.)\n\nIsn\u2019t it the point of text blocks that we should not escape?\n\nNo, that is not the point of text blocks.  The point of text blocks is to allow us to represent two dimensional blocks of text in code, preserving the block's relative indentation but not absolute indentation.  This allows us to freely indent the source representation of the text block itself to match surrounding code, without affecting the indentation of the string the text block describes.\nAn additional design goal is that text blocks should differ from ordinary string literals only in ways that pertain to their two-dimensional nature.  There should not be a different set of escape characters, or different escaping rules.  (If we ever do raw strings, it should apply equally to text blocks and traditional string literals.)  If text blocks worked the way you wanted, you'd probably be complaining that you can't do the same with single-line strings.  These aspects are orthogonal and the language should treat them orthogonally.\n"
}
{
    "Id": 73841877,
    "PostTypeId": 1,
    "Title": "Regex (?U)\\p{Punct} is missing some Unicode punctuation signs in Java",
    "Body": "First of all, I want to remove all punctuation signs in a String. I wrote the following code.\nPattern pattern = Pattern.compile(\"\\\\p{Punct}\");\nMatcher matcher = pattern.matcher(\"!\\\"#$%&'()*+,-./:;?@[\\\\]^_`{|}~\uff08hello\uff09\");\nif (matcher.find())\n    System.out.println(matcher.replaceAll(\"\"));\n\nAfter replacement I got this output: \uff08hello\uff09.\nSo the pattern matches the one of !\"#$%&'()*+,-./:;?@[\\]^_{|}~`, which matches the official docs.\nBut I want to remove \"\uff08\" Fullwidth Left Parenthesis U+FF08* and \"\uff09\" Fullwidth Right Parenthesis U+FF09 as well, so I changed my code to this:\nPattern pattern = Pattern.compile(\"(?U)\\\\p{Punct}\");\n        Matcher matcher = pattern.matcher(\"!\\\"#$%&'()*+,-./:;?@[\\\\]^_`{|}~\uff08\uff09\");\n        if (matcher.find())\n            System.out.println(matcher.replaceAll(\"\"));\n\nAfter replacement, I got this output: $+^|~`\nIt indeed matched \"\uff08\" Fullwidth Left Parenthesis U+FF08* and \"\uff09\" Fullwidth Right Parenthesis U+FF09, bit it missed $+^|~`.\nI am so confused. Why did that happen? Can anyone give some help?\n",
    "AcceptedAnswerId": 73841931,
    "AcceptedAnswer": "Unicode (that is when you use (?U)) and POSIX (when not using (?U)) disagrees on what counts as a punctuation.\nWhen you don't use (?U), \\p{Punct} matches the POSIX punctuation character class, which is just\n!\"#$%&'()*+,-./:;?@[\\]^_`{|}~\n\nWhen you use (?U), \\p{Punct} matches the Unicode Punctuation category, which does not include some of the characters in the above list, namely:\n$+^`|~\n\nFor example, the Unicode category for $ is \"Symbol, Currency\", or Sc. See here.\nIf you want to match $+^`|~, plus all the Unicode punctuations, you can put them both in a character class. You can also just directly use the Unicode category \"P\", rather than turning on Unicode mode with (?U).\nPattern pattern = Pattern.compile(\"[\\\\p{P}$+^`|~]\");\nMatcher matcher = pattern.matcher(\"!\\\"#$%&'()*+,-./:;?@[\\\\]^_`{|}~\uff08\uff09\");\n// you don't need \"find\" first\nSystem.out.println(matcher.replaceAll(\"\"));\n\n"
}
{
    "Id": 74081398,
    "PostTypeId": 1,
    "Title": "Android Studio : Cause: dagger/hilt/android/plugin/HiltGradlePlugin has been compiled by a more recent version of the Java Runtime",
    "Body": "I am getting this error while opening a project\nCause: dagger/hilt/android/plugin/HiltGradlePlugin has been compiled by a more recent version of the Java Runtime (class file version 55.0), this version of the Java Runtime only recognizes class file versions up to 52.0\nWhat i tried are :\nPlugin [id: 'dagger.hilt.android.plugin'] was not found in any of the following sources\nhttps://github.com/google/dagger/issues/3495\nDagger-hilt error while compiling project\nClass has been compiled by a more recent version of the Java Environment\nHow to resovle Java Runtime (class file version 55.0), this version of the Java Runtime only recognizes class file versions up to 52.0 error?\njava.lang.UnsupportedClassVersionError while integrating firebase performance library in react native app\njava.lang.unsupportedclassversionerror in gradle build\nThe Hilt Android Gradle plugin is applied but no com.google.dagger:hilt-android-compiler dependency was found\n",
    "AcceptedAnswerId": 74247022,
    "AcceptedAnswer": "The youtube link solution reported fixed the issue in my case, however here the instructions for the very latest Android Studio version (Android Studio Dolphin | 2021.3.1 Patch 1) on MacOS\n\nSelect your project App main folder in the Android Studio Project panel\nRight click -> Open Module Settings\nSelect the Project entry below the Project Settings section\nIn the dropdown menu next to SDK, select the Java 11 version\nClick on Apply and OK\nRebuild the project\n\nIf this doesn't work could be something deeper messed up in your machine JDK configuration or IDE configuration, would be easier I think to uninstall completely the IDE, clean the configuration file and install from scratch.\nIt could be overkill but sometime this is the most reliable way especially when nothing works.\n"
}
{
    "Id": 74837939,
    "PostTypeId": 1,
    "Title": "How to delete an \"Island\" of numbers in a 2D array in Java",
    "Body": "I'm creating a method that takes a 2D array and scans throughout the array to find \"Chunks\" of numbers that are completely surrounded by zeros and convert those Chunks (I call them the islands) into zeros.\nI'm trying to delete all of the \"islands\" except for the largest one.\nFor example, for this 2D array\n1 2 3 2 2 1 \n3 2 2 1 2 3\n3 2 2 1 3 2\n2 3 2 3 2 2\n2 2 3 1 1 2\n3 2 1 2 3 2\n2 3 1 2 3 2\n2 2 0 0 0 0\n0 0 0 1 2 0\n0 0 0 0 0 0 \n\nAfter the method the 2D array should now be:\n1 2 3 2 2 1 \n3 2 2 1 2 3\n3 2 2 1 3 2\n2 3 2 3 2 2\n2 2 3 1 1 2\n3 2 1 2 3 2\n2 3 1 2 3 2\n2 2 0 0 0 0\n0 0 0 0 0 0\n0 0 0 0 0 0 \n\nthe small chunk of 1 2  is \"deleted\"\nHere is a second example, as the method should also take chunks of numbers that are not part of the \"main\" chunk as Islands and that are on the edges as well.\nThe original array would be:\n1 2 3 2 2 1 \n3 2 2 1 2 3\n3 2 2 1 3 2\n2 3 2 3 2 2\n2 2 3 1 1 2\n3 2 1 2 3 2\n2 3 1 2 3 2\n2 2 0 0 0 0\n0 0 0 1 2 3\n0 0 0 0 3 2 \n\nAfter the method execution, it should be:\n1 2 3 2 2 1 \n3 2 2 1 2 3\n3 2 2 1 3 2\n2 3 2 3 2 2\n2 2 3 1 1 2\n3 2 1 2 3 2\n2 3 1 2 3 2\n2 2 0 0 0 0\n0 0 0 0 0 0\n0 0 0 0 0 0 \n\nIn this case, the island\n1 2 3 \n  3 2\n\nis deleted because it is separate from the big chunk and is surrounded by zeros.\nThe following code is the one I have so far, and it does not work as intended. It's wrong because I believe that it's taking the main chunk as an Island, and what happens is that it converts the entire array into zeros instead of deleting only the small Islands. It includes an example, and you should see what It does when you run it.\npublic class destroyIslands {\n    public static void main(String[] args) {\n        int[][] example = { {1, 2, 3, 1, 2},\n                            {2, 3, 2, 1, 2},\n                            {3, 2, 1, 2, 2},\n                            {0, 2, 0, 0, 0},\n                            {0, 0, 0, 2, 1} };\n        \n        example = deleteIslandBoard(example);\n        printGrid(example);\n    }\n    \n    public static int[][] deleteIslandBoard(int[][] array) {\n      // Create a boolean array to track which cells have been visited\n      boolean[][] visited = new boolean[array.length][array[0].length];\n    \n      // Iterate \n      for (int i = 0; i < array.length; i++) {\n        for (int j = 0; j < array[0].length; j++) {\n            // If the cell is not visited and is part of an island\n            if (!visited[i][j] && array[i][j] != 0) {\n                // Delete the island by setting all cells to 0\n                deleteIsland(array, i, j, visited);\n            }\n        }\n      }\n      // Return the modified array\n      return array;\n    }\n\n    public static void deleteIsland(int[][] array, int i, int j, boolean[][] visited) {\n      // Check if the current cell is out of board or if it has already been visited\n      if (i = array.length || j = array[0].length || visited[i][j]) {\n        return;\n      }\n      // Mark the current cell as visited\n      visited[i][j] = true; // If the current cell is part of the island, set it to 0\n      if (array[i][j] != 0) {\n        array[i][j] = 0;\n        // Recursively delete the neighboring cells that are part of the island\n        deleteIsland(array, i - 1, j, visited);\n        deleteIsland(array, i + 1, j, visited);\n        deleteIsland(array, i, j - 1, visited);\n        deleteIsland(array, i, j + 1, visited);\n      }\n    }\n    \n    public static void printGrid(int[][] grid) {\n        for(int i = 0; i < grid.length; i++) {\n            for(int j = 0; j < grid[i].length; j++) {\n                System.out.print(grid[i][j] + \" \");\n            }\n            System.out.println();\n        }\n    }\n}\n\nAny idea of what should I change?\n",
    "AcceptedAnswerId": 74839246,
    "AcceptedAnswer": "This problem can be solved in linear time O(n) by treating the cells of the given Matrix as the Vertexes of an undirected disjointed Graph.\nThe task boils down to exploring all Connected components (islands) in a Graph, and comparing them with each other.\nAnd for that we would need to implement of the Graph-traversal algorithms. I've chosen the Depth first search algorithm for that purpose.\nTo keep things simple, a Vertex of a graph would be represented as an array int[] of two elements containing coordinates of a cell (feel free to reimplement it by defining a separate class for a Vertex to make each vertex aware of it neighbors by holding a reference to a collection of Vertices)\nFor convenience, I've made several changes to your DestroyIslands class:\n\nIntroduced an inner class Island, which wraps a list of cells that constitute an Island (Connected component of the Graph). This class implements Comparable in based on size of the cells to make it easier to find the largest Island. And defines the method destroy() to nullify the rest Islands.\nIntroduced a static array NEIGHBOURS of type int[][] representing all possible adjacent cells, which should be considered while iterating through the matrix from left to right and from top to bottom.\nReference to the Matrix is stored in the instance field grid, and all methods of DestroyIslands are defined as instance methods (if you want to keep them static, fill free to change them as you see fit, it would be easy if you grasp the algorithm itself).\n\nThat's how implementation might look like:\npublic class DestroyIslands {\n    public static final int[][] NEIGHBOURS = // adjacent cells\n        {{0, 1},   // horizontal -\n         {1, 0},   // vertical   |\n         {1, 1},   // diagonal   \\\n         {1, -1}}; // diagonal   /\n\n    private List islands = new ArrayList(); // collection of Islands\n    private int[][] grid; // matrix\n    \n    public DestroyIslands(int[][] grid) {\n        this.grid = grid;\n    }\n    \n    public class Island implements Comparable {\n        private List cells = new ArrayList();\n        \n        public void addCell(int[] cell) {\n            cells.add(cell);\n        }\n        \n        public void destroy() {\n            cells.forEach(cell -> grid[cell[0]][cell[1]] = 0);\n        }\n        \n        @Override\n        public int compareTo(Island other) {\n            return Integer.compare(cells.size(), other.cells.size());\n        }\n    }\n    \n    public void deleteIslandBoard() {\n        exploreIslands();\n        deleteSmallerIslands();\n    }\n    \n    public void exploreIslands() {\n        boolean[][] visited = new boolean[grid.length][grid[0].length];\n        \n        for (int i = 0; i < grid.length; i++) {\n            for (int j = 0; j < grid[0].length; j++) {\n                \n                if (!visited[i][j] && grid[i][j] != 0) { // if a New Island was found\n                    exploreIsland(new int[]{i, j}, visited); // explore the Island, i.e. index all its cell and mark them as visited\n                }\n            }\n        }\n    }\n    \n    /**\n     * Depth first search implementation\n     */\n    public void exploreIsland(int[] cell, boolean[][] visited) {\n        Island island = new Island();\n        islands.add(island); // updating the list of Islands\n        \n        Deque stack = new ArrayDeque();\n        stack.push(cell);\n        \n        while (!stack.isEmpty()) {\n            int[] next = stack.poll();\n            island.addCell(next);\n            \n            for (int[] shift : NEIGHBOURS) {\n                int row = next[0] + shift[0];\n                int col = next[1] + shift[1];\n                \n                if (isValid(row, col) && !visited[row][col]) { // if cell exist, non-zero and not visited yet\n                    stack.push(new int[]{row, col});\n                    visited[row][col] = true;\n                }\n            }\n        }\n    }\n    \n    public boolean isValid(int row, int col) {\n        return row >= 0 && row < grid.length\n            && col >= 0 && col < grid[0].length\n            && grid[row][col] != 0;\n    }\n    \n    public void deleteSmallerIslands() {\n        if (islands.isEmpty()) return; // otherwise Collections.max() would throw NoSuchElementException\n\n        Island largest = Collections.max(islands);\n        for (Island next : islands) {\n            if (next != largest) next.destroy();\n        }\n    }\n    \n    public void printGrid() {\n        for (int i = 0; i < grid.length; i++) {\n            for (int j = 0; j < grid[i].length; j++) {\n                System.out.print(grid[i][j] + \" \");\n            }\n            System.out.println();\n        }\n    }\n}\n\nmain()\npublic static void main(String[] args) {\n        int[][] example = {\n            {1, 2, 3, 1, 2},\n            {2, 3, 2, 1, 2},\n            {3, 2, 1, 2, 2},\n            {0, 2, 0, 0, 0},\n            {0, 0, 0, 2, 1}};\n        \n        DestroyIslands destroyIslands = new DestroyIslands(example);\n        destroyIslands.deleteIslandBoard();\n        destroyIslands.printGrid();\n    }\n\nOutput:\n1 2 3 1 2 \n2 3 2 1 2 \n3 2 1 2 2 \n0 2 0 0 0 \n0 0 0 0 0\n\nA link to Online Demo\n"
}
{
    "Id": 74752707,
    "PostTypeId": 1,
    "Title": "GitHub Actions : How to resolve : \"The process '/usr/bin/gpg' failed with exit code 2\" problem on actions/setup-java@v3",
    "Body": "Introduction\nCurrently, I'm trying to contribute on a GitHub Action that automatically publishes a java library.\nThe branch where I'm developing: https://github.com/MathieuSoysal/Java-maven-library-publisher/tree/2-add-automated-tests\nThe yaml code of the Action :\nname: Java maven library publisher\nauthor: \"Mathieu Soysal (@MathieuSoysal)\"\ndescription: \"Build automatically Java Maven library and publish it to GitHub Packages and Maven Central.\"\nbranding:\n  icon: \"package\"\n  color: \"gray-dark\"\n\ninputs:\n  nexus-username:\n    description: \"Nexus username\"\n    required: true\n  nexus-password:\n    description: \"Nexus password\"\n    required: true\n  gpg-private-key:\n    description: \"GPG private key\"\n    required: true\n  gpg-passphrase:\n    description: \"GPG passphrase\"\n    required: true\n  github-token:\n    description: \"GitHub token\"\n    required: true\n  # Java version to use\n  java-version:\n    description: \"Java version to use\"\n    required: true\n    default: \"17\"\n  # Library version\n  library-version:\n    description: \"Library version\"\n    required: false\n    default: \"\"\n\nruns:\n  using: \"composite\"\n\n  steps:\n    - name: Checkout\n      uses: actions/checkout@v3\n\n    - name: Set up JDK 17 for deploy to OSSRH\n      uses: actions/setup-java@v3\n      with:\n        distribution: \"adopt\"\n        java-version: ${{ inputs.java-version }}\n        server-id: ossrh\n        server-username: ${{ inputs.nexus-username }}\n        server-password: ${{ inputs.nexus-password }}\n        gpg-private-key: ${{ inputs.gpg-private-key }}\n        gpg-passphrase: ${{ inputs.gpg-passphrase }}\n\n    - name: Build with Maven\n      run: mvn -B package --file pom.xml\n      shell: bash\n\n    - name: Update package version\n      if: ${{ inputs.library-version != '' }}\n      run: mvn versions:set -DnewVersion=${{ inputs.library-version }}\n      shell: bash\n\n    - name: Prepare Maven environnement with Java 17 for deployment to OSSRH\n      run: export MAVEN_OPTS=\"--add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.desktop/java.awt.font=ALL-UNNAMED\"\n      shell: bash\n\n    - name: Publish to Apache Maven Central\n      run: mvn deploy -PossrhDeploy\n      shell: bash\n      env:\n        MAVEN_USERNAME: ${{ inputs.nexus-username }}\n        MAVEN_CENTRAL_TOKEN: ${{ inputs.nexus-password }}\n        MAVEN_GPG_PASSPHRASE: ${{ inputs.gpg-passphrase }}\n\n    - name: Set up JDK 17 for deploy to github packages\n      uses: actions/setup-java@v3\n      with:\n        distribution: \"adopt\"\n        java-version: ${{ inputs.java-version }}\n        server-id: github\n\n    - name: Publish to GitHub Packages Apache Maven\n      run: mvn deploy -PgithubDeploy\n      shell: bash\n      env:\n        GITHUB_TOKEN: ${{ inputs.github-token }}\n\nlink to the code: https://github.com/MathieuSoysal/Java-maven-library-publisher/blob/2-add-automated-tests/action.yaml\nThe workflow that execute the Action:\nname: Test Actions\n\non: [push]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Maven Library build and publish\n        uses: ./\n        with:\n          nexus-username: ${{ secrets.NEXUS_USERNAME }}\n          nexus-password: ${{ secrets.NEXUS_PASSWORD }}\n          gpg-private-key: ${{ secrets.GPG_PRIVATE_KEY }}\n          gpg-passphrase: ${{ secrets.GPG_PASSPHRASE }}\n          library-version: $GITHUB_RUN_NUMBER\n          github-token: ${{ secrets.GITHUB_TOKEN }}\n          java-version: 17\n\nLink to the code: https://github.com/MathieuSoysal/Java-maven-library-publisher/blob/2-add-automated-tests/.github/workflows/test-action.yml\nProblem\nWhen i'm trying to execute the action I obtain this error:\nGetting action download info\nDownload action repository 'actions/setup-java@v3' (SHA:c3ac5dd0ed8db40fedb61c32fbe677e6b355e94c)\nRun ./\nRun actions/checkout@v3\nSyncing repository: ***/Java-maven-library-publisher\nGetting Git version info\nTemporarily overriding HOME='/home/runner/work/_temp/45376e45-02aa-4aa5-b536-5f744f7e10d3' before making global git config changes\nAdding repository directory to the temporary git global config as a safe directory\n/usr/bin/git config --global --add safe.directory /home/runner/work/Java-maven-library-publisher/Java-maven-library-publisher\n/usr/bin/git config --local --get remote.origin.url\nhttps://github.com/***/Java-maven-library-publisher\nRemoving previously created refs, to avoid conflicts\nCleaning the repository\nDisabling automatic garbage collection\nSetting up auth\nFetching the repository\nDetermining the checkout info\nChecking out the ref\n/usr/bin/git log -1 --format='%H'\n'0e8da131bf626b218ddccbd08a661c7921dfb8da'\nRun actions/setup-java@v3\nInstalled distributions\nCreating settings.xml with server-id: ossrh\nWriting to /home/runner/.m2/settings.xml\nImporting private gpg key\nError: The process '/usr/bin/gpg' failed with exit code 2\n\nQuestion\nSomeone know how we can fix this The process '/usr/bin/gpg' failed with exit code 2 for actions/setup-java@v3 ?\n",
    "AcceptedAnswerId": 74848449,
    "AcceptedAnswer": "Can you make sure GPG private key is in the correct format. The key should be in the ASCII Armored format, which can be done by running the following command:\ngpg --armor --export-secret-keys  > gpg_key.asc\n\nOnce the key is in the correct format, add it as an input variable in the Action and pass it to the action in the workflow.\n"
}
